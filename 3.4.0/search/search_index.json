{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Self-hosted videoconferencing and custom WebRTC solutions","text":"","tags":["setupwowjs","setupcardglow"]},{"location":"#home","title":"Home","text":"<p>Ready-to-use videoconferencing solution</p> <p>           For teams, businesses and organizations that need a reliable and secure video conferencing solution running on their servers.         </p> <ul> <li>Multi-party HQ video conferencing</li> <li>Customize with your branding and corporate colors</li> <li>Feature rich: screen sharing, chat, virtual background, recording...</li> <li>Ready to use AI integrations</li> <li>Embed right into your app with pre-built components</li> </ul> Get Started <p>Developer-oriented SDKs for custom apps</p> <p>           For developers that need complete freedom to build their real-time application using SDKs and self-host a production-ready solution.         </p> <ul> <li>Programmable client and server SDKs for all languages compatible with LiveKit</li> <li>Build your custom UI from scratch with total freedom</li> <li>Low level control of real time media: codecs, protocols, bitrates...</li> <li>Precise control of recording and streaming with custom layouts</li> <li>Advanced telephony and AI integrations</li> </ul> Get Started Self-hosted AWS &amp; Azure templates HQ real-time video Performant, Scalable, Fault-Tolerant &amp; Observable Tutorials available Customer support Ready-to-use application No-code &amp; Low-code options available Low-level SDKs High control over real-time features AI agents Models Rooms &amp; Meetings  Audio tracks &amp; Video tracks  Links OpenVidu Meet OpenVidu Platform <p>Learn more about OpenVidu Meet vs OpenVidu Platform</p> <ul> <li> <p> Self-hosted</p> <p>OpenVidu is designed from the ground up to be self-hosted in your own servers. With OpenVidu you can easily deploy and manage a production-ready live-video solution in your own infrastructure, whether it is on premises or in your favorite cloud provider. Leverage your hardware and regain control of your users' data!</p> </li> <li> <p> Professional support</p> <p>We are experts in WebRTC. We have been developing real time tools and supporting customers building their solutions for over a decade. Let's work together to make your project a success! Contact us now.</p> </li> <li> <p> Easy to deploy</p> <p>What could take a whole DevOps team days of work, with OpenVidu you can have it ready in minutes: an easy installation, configuration and administration experience to your self-hosted, production grade, real-time solution. Install now.</p> </li> <li> <p> Cost effective</p> <p>OpenVidu COMMUNITY is open source, free and can handle a significant user load. With OpenVidu PRO you can handle more simultaneous Rooms in the same hardware thanks to mediasoup integration. This allows reducing the cost of each Room, making OpenVidu PRO truly cost-effective as a self-hosted solution. See Pricing.</p> </li> <li> <p> Performant</p> <p>OpenVidu is built to be incredibly powerful. It is based on the best open source WebRTC stacks: LiveKit  and mediasoup . By combining the best of both worlds, OpenVidu provides outstanding performance.</p> </li> <li> <p> Scalable</p> <p>OpenVidu has been designed from the outset with scalability in mind. Host videoconference rooms and large live streams with hundreds of participants. Autoscale your cluster to adapt to the demand and optimize your resources.</p> </li> <li> <p> Fault tolerant</p> <p>OpenVidu offers fault tolerance in all its components. Deploy a reliable cluster knowing that if one of your node goes down, others will be able to continue working with no downtime.</p> </li> <li> <p> Observable</p> <p>OpenVidu brings everything necessary to monitor the status, health, load and history of your deployment. It automatically collects events, metrics and logs and provides OpenVidu Dashboard and a Grafana stack to navigate them.</p> </li> </ul> <ul> <li> <p> WebRTC</p> <p>Achieve ultra-low latency in your videoconference or live-streaming app thanks to WebRTC .</p> </li> </ul> <ul> <li> <p> Security at all levels</p> <p>Fine-grained access control and highly secure deployments for the most demanding security requirements. E2E encryption coming soon!</p> </li> <li> <p> Multiplatform</p> <p>Chrome, Firefox, Safari, Android, iOS, Unity, Windows, macOS, Linux... OpenVidu is compatible with all of them.</p> </li> <li> <p> Up to 4K video and HQ audio</p> <p>HD up to 4K video resolution, and crisp audio quality with noise cancellation and echo suppression.</p> </li> <li> <p> Recording</p> <p>Record your video calls with complete freedom. You can use predefined layouts or easily build your own.</p> </li> <li> <p> Broadcast to YouTube/Twitch</p> <p>OpenVidu allows you to easily broadcast your sessions to live-streaming platforms such as YouTube or Twitch.</p> </li> <li> <p> Screen sharing</p> <p>Screen share from browsers or native applications with ease, always with the best quality.</p> </li> <li> <p> Virtual Backgrounds</p> <p>Apply effects to your videos, blurring the background or replacing it with an image.</p> </li> <li> <p> Server side processing</p> <p>For the most advanced use cases: you can add pipelines to process video and audio streams in real time in your servers.</p> </li> </ul> Build, deploy on-premises and scale your videoconferencing or live streaming app with ease. Contact us if you need it : we are here to help! Talk to an expert","tags":["setupwowjs","setupcardglow"]},{"location":"#get-started","title":"Choose the ideal OpenVidu solution for your real-time needs","text":"","tags":["setupwowjs","setupcardglow"]},{"location":"#get-started","title":"Self-host a production-ready live-video platform with advanced capabilities typically reserved for pricy SaaS solutions","text":"","tags":["setupwowjs","setupcardglow"]},{"location":"#get-started","title":"All the features you need to quickly build your perfect real-time application","text":"","tags":["setupwowjs","setupcardglow"]},{"location":"account/","title":"Account","text":""},{"location":"openvidu-meet-vs-openvidu-platform/","title":"OpenVidu Meet vs OpenVidu Platform","text":"","tags":[]},{"location":"openvidu-meet-vs-openvidu-platform/#openvidu-meet-vs-openvidu-platform","title":"OpenVidu Meet vs OpenVidu Platform","text":"<p>OpenVidu offers two different products:</p> <ul> <li>OpenVidu Meet: a complete, high-quality video calling service designed to be self-hosted. Ideal for teams, businesses and organizations that need a reliable, secure and customizable video conferencing solution running on their servers.</li> <li>OpenVidu Platform: a solution comprised of a self-hosted deployment and a set of SDKs and APIs that greatly simplifies the development of any type of real-time application.</li> </ul> <p> </p> <p>Both OpenVidu Meet and OpenVidu Platform provide production-grade performance, scalability, fault-tolerance and observability. What product should you choose?</p> <ul> <li>Give OpenVidu Meet a try if your use case falls under the category of \"video conferencing application\": e-learning, telehealth, team collaboration, customer support, etc. Don't mistake the simplicity for a lack of possibilities: OpenVidu Meet offers branding customizations and many features out-of-the-box, such as screen-sharing, recording, advanced chat, virtual backgrounds, and more coming soon: broadcasting, E2E encryption, AI agents...</li> <li>Choose OpenVidu Platform if you really need total control and flexibility to build your own custom real-time app, either from scratch or integrating OpenVidu Platform into your existing app. OpenVidu Platform provides low-level WebRTC SDKs for any language, and full control over features like audio/video/data streaming, media ingestion, telephony and AI integrations.</li> </ul> <p></p> Self-hosted AWS &amp; Azure templates HQ real-time video Performant, Scalable, Fault-Tolerant &amp; Observable Tutorials available Customer support Ready-to-use application No-code &amp; Low-code options available Low-level SDKs High control over real-time features AI agents Models Rooms &amp; Meetings  Audio tracks &amp; Video tracks  Links OpenVidu Meet OpenVidu Platform","tags":[]},{"location":"pricing/","title":"Pricing","text":"","tags":["setupwowjs"]},{"location":"pricing/#pricing","title":"Pricing","text":"OpenVidu COMMUNITY OpenVidu PRO Price Free 0.0006$ core/minute Type of deployment OpenViduSingle NodeCOMMUNITY OpenViduSingle Node PRO OpenViduElastic OpenViduHigh Availability Suitability For applications with medium user load Enjoy the benefits of OpenVidu PRO in a single-node installation For applications with dynamic user load that require scalability For applications where both scalability and fault tolerance are critical Features Custom LiveKit distribution with Redis, Egress, Ingress, S3 storage and observability Same features as OpenVidu Single Node COMMUNITY plus 2x performance and advanced observability Same benefits as OpenVidu Single Node PRO plus scalability Same benefits as OpenVidu Elastic plus fault tolerance Number of servers 1 Node 1 Node 1 Master Node +N Media Nodes  4 Master Nodes +N Media Nodes Installation instructions Install Install Install Install <p>OpenVidu offers two editions:</p> <ul> <li>OpenVidu COMMUNITY, completely open-source and free to use. Offers a single node deployment suitable for medium user load.</li> <li>OpenVidu PRO, which is proprietary and with a simple pay-per-use pricing model. Offers advanced multi-node deployments suitable for applications that require improved performance, scalability, fault tolerance, and observability.</li> </ul> <p>OpenVidu offers two solutions: OpenVidu Meet and OpenVidu Platform. They target different use cases (see OpenVidu Meet vs OpenVidu Platform), but they do not affect pricing: you can have either solution in an OpenVidu COMMUNITY or OpenVidu PRO deployment.</p>","tags":["setupwowjs"]},{"location":"pricing/#how-is-openvidu-pro-priced","title":"How is OpenVidu Pro priced?There is a 15-day free trial period waiting for you!","text":"<p>OpenVidu Pro follows a simple pricing model based on the number of cores used by the OpenVidu Pro cluster:</p> $0.0006 per core per minute available for your OpenVidu PRO cluster  <p>Taking into account the following points:</p> <ul> <li>You only pay for your OpenVidu Pro cluster(s) for the time they are running. Usage will be registered the moment you start your cluster and will stop as soon as you shut your cluster down. When turned on, your cluster will be charged even in idle state (without active Rooms).</li> <li>You pay for every available core at any given time: if you cluster grows for one hour, that hour you will pay more. If your cluster decreases the next hour, next hour will be cheaper. Master Nodes and Media Nodes have the same core per minute price.</li> <li>Your OpenVidu Pro cluster(s) need to allow outbound traffic to domain <code>accounts.openvidu.io</code> port <code>443</code>. If you are behind a very restrictive corporate firewall that doesn't allow this, please contact us through commercial@openvidu.io.</li> </ul> Get an OpenVidu License","tags":["setupwowjs"]},{"location":"pricing/#why-is-openvidu-pro-priced-like-this","title":"Why is OpenVidu Pro priced like this?","text":"<p>There are deliberate reasons for this pricing model in OpenVidu Pro:</p> <ul> <li>We believe that a platform specifically designed to be self-hosted should have a pricing model that is as close to hardware as possible: that is the total number of cores available to the cluster over time.</li> <li>This pricing model is simple, transparent and easy to predict: you pay only for the time the cluster is running and always according to its size.</li> <li>The cost is directly proportional to the size of your cluster: larger clusters pay more, smaller clusters pay less.</li> <li>Elasticity is encouraged: adjust the size of your cluster according to the load at any given time to minimize costs.</li> </ul>","tags":["setupwowjs"]},{"location":"pricing/#when-and-how-are-you-charged","title":"When and how are you charged?","text":"<p>Users must create an OpenVidu account and get an OpenVidu License. This license will be required to deploy an OpenVidu Pro cluster (OpenVidu Elastic or OpenVidu High Availability).</p> <p>When purchasing an OpenVidu License, you will have to indicate your billing address and a credit card. You will receive a 15-day free trial period during which you will not be charged at all.</p> <p>After the free trial period, a monthly billing cycle will charge all your expenses to your credit card. Therefore, you will receive an invoice each month. You can review your upcoming expenses and your past invoices in your OpenVidu account page. And don't worry: we don't store any credit card data. The entire billing process is securely done via Stripe .</p> <p>OpenVidu Pro clusters will automatically report their usage on a recurring basis. That's why they need outbound access to domain <code>accounts.openvidu.io</code> port <code>443</code>. If you are behind a very restrictive corporate firewall that doesn't allow this, please contact us through commercial@openvidu.io.</p>","tags":["setupwowjs"]},{"location":"pricing/#pricing-examples","title":"Pricing examplesThere is a 15-day free trial period waiting for you!","text":"<p>As explained above, every minute of an OpenVidu Pro cluster is charged according to the number of cores available for the cluster. So let's see some actual examples, first noting the following points:</p> <ul> <li>The examples represent a continuous usage of the cluster, but remember that you can shut it down whenever you are not using it and that you can drop nodes to save resources.</li> <li>Each example shows in a table the price for 8 hours, 1 day and 1 month of continuous usage, as well as the approximated amount of video Tracks and Rooms of 8 participants the cluster would support. This is done to provide a basic insight into the capacity of each cluster. These 8-to-8 Rooms assume 64 video Tracks (640x480) and 64 audio Tracks in them (2 tracks published and 14 tracks subscribed per Participant), with no Egress, Ingress or other additional features.</li> </ul> Get an OpenVidu License","tags":["setupwowjs"]},{"location":"pricing/#openvidu-elastic-with-12-cores-in-total","title":"OpenVidu Elastic with 12 cores in total","text":"<p>This OpenVidu Pro Elastic cluster has 1 Master Node of 4 cores and 2 Media Nodes of 4 cores each.</p> Number of video Tracks 2000  Number of Rooms with 8 Participants 30 8 hours $3.46  24 hours (1 day of uninterrupted use) $10.37  720 hours (1 month of uninterrupted use) $311.04","tags":["setupwowjs"]},{"location":"pricing/#openvidu-elastic-with-20-cores-in-total","title":"OpenVidu Elastic with 20 cores in total","text":"<p>This OpenVidu Pro Elastic cluster has 1 Master Node of 4 cores and 4 Media Nodes of 4 cores each.</p> Number of video Tracks 4000  Number of Rooms with 8 Participants 60 8 hours $5.76  24 hours (1 day of uninterrupted use) $17.28  720 hours (1 month of uninterrupted use) $518.40","tags":["setupwowjs"]},{"location":"pricing/#openvidu-high-availability-with-32-cores-in-total","title":"OpenVidu High Availability with 32 cores in total","text":"<p>This OpenVidu Pro HA cluster has 4 Master Nodes of 4 cores each and 4 Media Nodes of 4 cores each. The number of simultaneous Rooms and Tracks will be the same as in the previous example, but this cluster will provide fault tolerance thanks to the replication of the Master Nodes.</p> Number of video Tracks 4000  Number of Rooms with 8 Participants 60 8 hours $9.21  24 hours (1 day of uninterrupted use) $27.65  720 hours (1 month of uninterrupted use) $829.44","tags":["setupwowjs"]},{"location":"pricing/#openvidu-elastic-with-a-variable-number-of-cores","title":"OpenVidu Elastic with a variable number of cores","text":"<p>This OpenVidu Pro Elastic cluster takes advantage of the elasticity of the platform. It has a fixed Master Node of 4 cores, but a variable number of Media Nodes. Let's imagine a scenario where our days are divided in three phases according to the user load:</p> <ul> <li>First 8 hours of the day the demand is low. 1 Media Node of 4 cores is enough to handle it.</li> <li>The next 8 hours of the day the user load increases significantly (this is very typical if our application is used more during working hours). We add another Media Node of 8 cores to handle this new demand.</li> <li>The last 8 hours of the day the demand decreases, and we are able to remove the Media Node of 8 cores and keep only the Media Node of 4 cores.</li> </ul> First 8 hours of the day with low demand(8 cores in total) Video Tracks1000 8x8 Rooms15Price$2.30  Next 8 hours of the day with high demand(16 cores in total) Price$4.61 Video Tracks3000 8x8 Rooms45 Last 8 hours of the day with low demand(8 cores in total) Price$2.30 Video Tracks1000 8x8 Rooms15 Total for 1 day $9.21 Total for 1 month $276.30","tags":["setupwowjs"]},{"location":"support/","title":"Support","text":""},{"location":"support/#support","title":"Support","text":"<p>Self-hosting your own solutions can be challenging. We have built OpenVidu to make this task as easy as possible. But of course you may encounter difficulties in the process, or your particular use case may require customized assistance. The OpenVidu team specializes in customer support. Together we will make your project a success!</p>"},{"location":"support/#commercial-support","title":"Commercial support","text":"<p>Do not hesitate to contact us at commercial@openvidu.io. We provide consultancy, prioritizing bug fixes or new features, custom app development, etc.</p> <p>Let's work together and build something great!</p> <p>Info</p> <p>Do you need help updating from OpenVidu 2 to OpenVidu 3 ? Write us to pro.support.v2apps@openvidu.io and we will be happy to guide you through the process.</p>"},{"location":"support/#community-support","title":"Community support","text":"<p>The public forum  is the right place to ask any questions that do not involve private information, so that the whole community can benefit from the exchange of ideas.</p>"},{"location":"blog/","title":"Blog","text":""},{"location":"blog/#blog","title":"Blog","text":""},{"location":"conditions/cookie-policy/","title":"Cookie Policy","text":""},{"location":"conditions/cookie-policy/#what-are-cookies","title":"What are cookies?","text":"<p>TIKAL TECHNOLOGIES SL web page uses cookies, which are small files that it exchanges with the visitor's web browser for different purposes. That is done in a totally \"invisible\" and harmless way for the visitor, so your visit to the page is more fluid and you are not interrupted by some functions. The following explains which is the usage of cookies in TIKAL TECHNOLOGIES SL website and how you can disable them if you don't agree.</p>"},{"location":"conditions/cookie-policy/#what-kind-of-information-do-we-collect","title":"What kind of information do we collect?","text":"<p>TIKAL TECHNOLOGIES SL web page uses cookies for the following purposes</p> <ul> <li>Functional cookies: they are used to improve the visitor's navigation through the website, making it more user-friendly. It is important to understand that cookies do not contain any kind of specific personal information, and most of them are deleted from the hard disk at the end of the browser session.</li> <li>Analytical Cookies: TIKAL TECHNOLOGIES SL website uses cookies from Google Analytics, to analyze how visitors use the page. This way, TIKAL TECHNOLOGIES SL can offer improvements in the usability of the webpage. Google Analytics only collects and processes anonymous data through the TIKAL TECHNOLOGIES SL website. There is further information about the management of Google Analytics' web analysis services at www.google.com/analytics.</li> </ul>"},{"location":"conditions/cookie-policy/#how-are-users-able-to-change-the-cookies-configuration-in-their-browsers","title":"How are users able to change the cookies configuration in their browsers?","text":"<p>Any browser allows you to make adjustments on the actions to perform whenever a website asks you to store a cookie. You can:</p> <ul> <li>Allow web pages to deposit cookies in the browser.</li> <li>Allow the cookies of the visited web pages only to remain in the browser as long as the page remains open.</li> <li>Do not allow web pages to deposit cookies in the browser. Please note that in this case, some website functions will not be operational or the full page could even not work at all.</li> <li>Allow one by one which web pages will be able to deposit cookies in the browser. Please note that in unauthorized pages some website functions will not be operational or the full page could even not work at all.</li> </ul> <p>The modification of the cookies configuration can be done in the option \"Configuration\" of the browser, in the \"Privacy\" section.</p>"},{"location":"conditions/privacy-policy/","title":"Privacy Policy","text":"<p>In accordance with the provisions of Regulation (EU) 2016/679 and the Organic Law 3/2018 of 5 December, on the protection of personal data and guarantee of digital rights, we inform you that the data you provide will be incorporated to the treatment system owned by TIKAL TECHNOLOGIES SL with CIF B85986669 and address at Calle Chile, N\u00ba 10, 28290 - Las Rozas de Madrid (Madrid), for the purpose of ELECTRONIC COMMERCE, CUSTOMER MANAGEMENT, AND OTHER PURPOSES. Your data may be processed by third parties (they will be data processors recipients of your data for contractual purposes for example, our computer maintenance company) requiring the same level of established rights, obligations and responsibilities. Your details will be kept for the time only strictly necessary. They will be deleted when a period of time has elapsed without any use being made of it. You agree to notify us of any changes in the data. You will be able to exercise your access rights, rectification, limitation of treatment, deletion, portability and opposition to processing of your personal data by addressing your request to the management or to the e-mail info@naevatec.com. You can contact the appropriate supervisory authority to make any complaint you may consider necessary.</p>"},{"location":"conditions/terms-of-service/","title":"Terms of Service","text":"<p>The purpose of the following terms and conditions is to explain our obligations as providers of the service, as well as your obligations as a client. Please read them carefully. </p> <p>The aforementioned terms and conditions shall be applied from the moment TIKAL TECHNOLOGIES provides you with access to the service, thus it is understood that you have voluntarily accepted them as part of the contractual obligations between the parties involved, that is, between TIKAL TECHNOLOGIES (TIKAL form now on) and you as client. OpenVidu PRO is a service which will vary with time, so as to adapt to its clients and users\u00b4 new requirements, which in turn, will likely affect the terms and conditions so that they suit the changes and variations made to TIKAL. </p> <p>TIKAL reserves the right to change the terms and conditions at any given moment, notwithstanding, it shall always endeavour to communicate these via e-mail or through the application itself; consequently, we strongly advise you to ensure that you have read and understood the terms and conditions whose most recent, updated version, is available on our website.</p>"},{"location":"conditions/terms-of-service/#first-definitions","title":"First. Definitions.","text":"<p>For the legal purposes of this contract, the following definitions will apply:</p> <ol> <li>Software application: a set of instructions which will be interpreted, utilized and executed by a computer system. Even when there may be many of them, the present contract may refer to them in singular, and likewise when pertaining to its backup files.</li> <li>Telematics application: a software application within a server which is connected to the Internet such that it can be accessed remotely through electronic networks. The assignment of the license to use the telematics application OpenVidu PRO is the subject of the present contract.</li> <li>Client of the telematics application: the natural or legal person who benefits from the licence to use the telematics application, thus assuming all obligations arising from the present contract.</li> <li>User of the telematics application: the natural person authorized by the client to use the telematics application, who in turn assumes all obligations arising from the present contract and said utilization.</li> <li>Parties: TIKAL and the client.</li> <li>Exploitation rights over the telematics application: TIKAL TECHNOLOGIES SL</li> <li>Third parties: any natural or legal person alien to the present contractual relation, who, for any reason, enters into a formal, legally binding agreement with either TIKAL or the client.</li> <li>The service, all supporting infrastructure provided by TIKAL that allows the client to register, download, provision bill, and operate its instance of the telematics application</li> <li>Hardware: electronic, mechanic or magnetic devices necessary for the telematics application, and its complementary parts, to work properly.</li> <li>Personal data: any information regarding an identified or identifiable natural person.</li> <li>Updates: new versions of the telematics application and/or its modules, which include new functionalities and improvements when compared to earlier versions.</li> <li>Telematics application modules: parts of the telematics application which manage specific functionalities, and whose licence to use them, the client must acquire separately.</li> </ol>"},{"location":"conditions/terms-of-service/#second-purpose","title":"Second. Purpose","text":"<ol> <li>The purpose of the present contract is the licensing of the right to use the telematics application OpenVidu PRO by TIKAL TECHNOLOGIES SL. to the client, so that it may be use in the management of their business. Subject to the terms and conditions provided in this agreement, TIKAL hereby grants to the client a non-exclusive, non-sublicensable, non-transferable license to use the telematics application OpenVidu PRO (from now on \u201ctelematics application\u201d). Under no circumstances however, does said licence grant the client sales rights over the telematics application whose ownership remains entirely with TIKAL TECHNOLOGIES SL.</li> <li>The client\u00b4s rights to use the telematics application are subjected and limited by both the duration, and the terms and conditions established in the present contract.</li> <li>Hereby the client agrees to use the telematics application in compliance with the law, the present contract, and the good and rational will inherently present in any civilized society.</li> <li>The client acknowledges having examined that OpenVidu PRO features fulfil their needs, and that it has been appropriately informed by TIKAL about them.</li> </ol>"},{"location":"conditions/terms-of-service/#third-use-limitations-and-duty-of-care","title":"Third. Use limitations and duty of care.","text":"<ol> <li>The client must protect and guard the telematics application; thus, it may not share any information whatsoever with third parties. It is specifically forbidden the use of the telematics application outside the business sphere for which it has been acquired, or outside any of the dispositions stipulated in this contract. The client may not sell, lease, transfer, or otherwise sublicense the telematics application or take part in any act which may result in the violation of their duty of care and protection. The client may not assign, transfer, pledge or make any other disposition of the rights acquired through this contract, of any part of the contract, or of any of the rights, claims or obligations under the contract.</li> <li>The client is obligated to refrain from using the telematics application for illegal purposes or any other purposes contrary to what is established in the present contract, or any action that may be injurious to TIKAL\u00b4s rights and interests, to the owner of the telematics application, as well as to any third parties involved. Said actions include, but are not limited to, any deed that may harm, overload, disrupt, or otherwise render useless the telematics application, thus preventing other clients and users from making use of it.</li> <li>Changes to the telematics application are strictly forbidden. These include, but are not limited to, such things as reverse engineering, decompiling, disassembling, reproducing, translating, modifying, commercializing, cloning, transforming or transmitting to any natural or legal person, partially or entirely, by any means, whether mechanic, magnetic, photocopies, etc\u2026 or to eliminate or block any proprietary notice or logos pertaining to the telematics application. The components and elements subject to the aforementioned restrictions include, but are not limited to, such things as the logical diagrams, source codes, object and/or data model; except prior, written authorization from TIKAL. These restrictions stand, even when said actions where needed for the interoperability with other computer programs or telematics applications.</li> <li>The client or the user must protect and safeguard, both physically and intellectually, the telematics application, namely, its contents, logical procedures, and access protocols, by establishing the necessary means in order to guarantee the non-disclosure, cloning, reproduction, altering, translation, transformation, access by third parties, or any other action that shall imply a violation of the duty of care or of any intellectual and industrial property right.</li> <li>The telematics application may only be used by the client or authorized user, for processing the client\u00b4s own data and their products, but under no circumstances shall it be used to process third parties \u2018data.</li> <li>TIKAL cannot guarantee uninterrupted access to the service throughout the entire validity period of this contract due to unforeseeable factors such as network issues, telecommunications service providers, breakdown in computers, as well as other contingencies such as repair and maintenance work, and software updates. Notwithstanding this, TIKAL reserves the right to adopt any necessary measures to limit the service, should it be considered that improper and/or irresponsible use of the telematics application is occurring, specially when said uses run counter to the terms and conditions provided in the present contract.</li> <li>Should the client or user breach the terms of contract, in a continuous and sustained fashion, or acting in bad faith, TIKAL shall terminate the provision of the service, without reimbursing any amount, on the grounds of abusive and improper use.</li> <li>Interpretation and scope. Any other right which has not been stated or directly mentioned in the present contract, remains reserved to TIKAL. Under no circumstances shall the terms and conditions of this contract be interpreted or applied in such a fashion that could be injurious to TIKAL or in any manner that runs counter to the regular exploitation framework of a telematics application.</li> </ol>"},{"location":"conditions/terms-of-service/#fourth-liability","title":"Fourth. Liability.","text":"<ol> <li>TIKAL\u00b4s telematics application is access-ready in its current state and configuration. Should the application contain any deficiency attributable to TIKAL TECHNOLOGIES SL, the latter pledges to make use of all the resources available to them in order to solve the issue as promptly as possible. Nonetheless, it declines any liability and does not give any guarantee regarding violations perpetrated by third parties, marketability, satisfactory quality or suitability for a specific purpose.</li> <li>TIKAL shall act with due diligence and professionalism by making use of all its resources available so as to ensure the quality, reliability, and security of the telematics application. In any case, TIKAL\u00b4s assumes no liability for any damages, direct or indirect, incidental or special, including, but not limited to, such things as damages or financial loss, work disruptions, failure, breakdown, or any losses, even when the possibility of such inconveniences occurring, which include third-party complaints, were previously notified to a member of TIKAL\u00b4s staff.</li> <li>The client accepts, within reason, to tolerate specific, isolated disruptions in connectivity and hereby forfeits the right to claim any liability, contractual or otherwise, as well as damages owing to possible failures, slowness or access errors. TIKAL declines any liability concerning data loss, accidental or otherwise, resulting from the client\u00b4s actions or activities.</li> <li>The client or user is solely responsible for the provision and payment of the costs necessary to ensure compatibility between the telematics application and their equipment, including all hardware, software, electronic components, and any other component required to access the telematics application, these include, but are not limited to, such things as telecommunication services, Internet access and connectivity, operating systems, or any other program, equipment or services, required to access and use the telematics application.</li> <li>TIKAL declines any liability regarding any content that the client or user may host within the telematics application OpenVidu PRO, since at no moment, does TIKAL intervene in the internal processing of said content. Therefore, and in accordance with art.16 of LSSI-CE, TIKAL is not legally bound to remove any content from the server, provided there is no \u201cactual knowledge\u201d that the activity or information stored is illegal, libellous, or injurious to third-party rights or assets. In this regard, it shall be understood that \u201cactual knowledge\u201d exits, when there is a court or administrative decision, ordering to block or remove content and that the contractor (TIKAL) has been made aware of it. Notwithstanding, TIKAL reserves the right to remove this type of content out of its own volition, once it has been detected, whilst the client waives any right to claim or demand compensation. Should the application be in any way damaged due to the introduction of malign software or content (virus, trojan,\u2026) TIKAL reserves the right to automatically terminate the contract without having to pay any compensation whatsoever. On the other hand, TIKAL hereby reserves the right to demand compensation from the client or user for any damages caused to the system.</li> <li>The client or user shall burden all legal costs incurred when the cause is attributable to them, these include TIKAL lawyers\u2019 fees, even when a final court decision has yet to be reached.</li> <li>TIKAL uses information security protocols which are broadly accepted and observed by the industry such as firewalls, access-control procedures, and crypto mechanisms in order to avoid any unauthorized access to the data. For this purpose, the client hereby grants TIKAL access to data so that it can perform access-control authentication. The licensing process or any process which entails the introduction of personal data shall always conducted under a rigorous communication protocol so as to ensure no third parties have access to data transmitted electronically.</li> </ol>"},{"location":"conditions/terms-of-service/#fifth-intellectual-and-industrial-property-rights","title":"Fifth. Intellectual and industrial property rights.","text":"<ol> <li>The exploitation rights of the telematics application are owned by TIKAL and protected by Spanish Intellectual Property Laws applicable in any country where it is used. The structure, organization and coding of the telematics application constitute confidential and valuable industrial and commercial secrets which belong to TIKAL. Therefore, the client must treat the telematics application in the same fashion they would when utilizing any material protected by intellectual property rights, thus copying, duplicating, or cloning the application is strictly forbidden.</li> <li>The present licence to use the telematics application does not imply, either explicitly or implicitly, the assignment of the intellectual and industrial rights over said application, the hardware, or the data model.</li> <li>Brands must be utilized in accordance with the commercial uses of brands, including acknowledging the proprietor\u2019s name of the brand. Brands may only be used in order identify those printouts produced by the telematics application. Said utilization does not imply or grant any property rights over the application.</li> <li>The knowledge and expertise intrinsic to the telematics application, as well as the knowledge utilized to configure it, is confidential information which belongs to the owner of the telematics application TIKAL. The client acknowledges this and assumes all liability regarding fraudulent use, or illegal copy or duplication of said application, or complementary programs, or utilization of this information by third parties, being liable for any breach of the present contract, by them or by any person or persons depending or associated with the client, or when these individuals have been granted access, directly or indirectly, to the telematics application by the client.</li> <li>Updates: For the entire validity period of the present contract, and in accordance with the terms and conditions stipulated in the next paragraph, the client is entitled to have access to the updates of the telematics application as they arise. The client assumes all legal liability for the updates, regarding limitations and duty of care, in the same fashion as with the original computer application. Updates to additional modules of the telematics application shall be given to those clients who have acquired from TIKAL the licence to use said modules.</li> <li>Hereby the client gives TIKAL consent to incorporate them as such into their business portfolio, thus allowing TIKAL to use their brand and logo on its website as well as in documents which may be given to other potential clients, for the sole purpose of said portfolio, and provided that the client does not express opposition to them being used in such a fashion.</li> </ol>"},{"location":"conditions/terms-of-service/#sixth-right-to-amend","title":"Sixth. Right to amend.","text":"<p>TIKAL reserves the right to update the telematics application to the latest version available on the market. Said updates may include, but are not limited to, such things as new functionalities, improvements, and modifications and legal updates to the telematics application, which may vary, at any moment such things as its features, performance, and configuration of the telematics application content. </p> <p>TIKAL pledges to evaluate and take into consideration suggestions and requests made by clients and users of the telematics application so that they may be incorporated in the new versions of said application; however, it is TIKAL\u00b4s right, not the client\u00b4s to decide which modifications or improvements may be included in the aforementioned versions. </p> <p>TIKAL reserves the right to modify, at any moment, the characteristics, features, and conditions of TIKAL for the benefit and development of the service. With this in mind, TIKAL may only have to observe the formality of having to notify the client via an on-line notice, or by modifying any clause in this contract. Notwithstanding the foregoing, TIKAL shall endeavour to promptly notify the client so that the latter may adapt them.</p>"},{"location":"conditions/terms-of-service/#seventh-exclusion-and-termination-of-licensing","title":"Seventh. Exclusion and termination of licensing.","text":"<ol> <li>TIKAL reserves the right to exclude and/or terminate, temporarily or in a definite manner, the client\u00b4s right to use the telematics application, in case the following occurring:<ul> <li>Breach of any of the terms and conditions of the present contract.</li> <li>Breach of law and order and/or improper, illegal, or negligent professional behavior.</li> <li>When a court, administrative, or official decision is made to do so.</li> </ul> </li> <li>The exclusion clause, or termination of this contract, does not imply that TIKAL forfeits the right to take legal actions or file for financial compensation when the client has acted in bad faith to damage, directly or indirectly, the telematics application.</li> </ol>"},{"location":"conditions/terms-of-service/#eighth-communications","title":"Eighth. Communications.","text":"<ol> <li>For the purposes of establishing a line of communication regarding the present contract both parties agree to use the place of residence which appears in it. The client pledges to keep the e-mail account provided in this licensing agreement, operational, activated and updated for the purposes of communications with TIKAL, which constitutes TIKAL\u00b4s preferred line of communication (albeit not the only one). In general terms, the client pledges to keep their personal details updated, and must communicate TIKAL, in a clear, unambiguous manner, of any changes.</li> <li>Should the client fail to notify said changes, notifications or notices delivered to the address(es) given by the client in the licensing agreement, shall be considered valid.</li> <li>The client consents that telephone conversations with TIKAL may be recorded with the intent to improve the quality and security of the service.</li> </ol>"},{"location":"conditions/terms-of-service/#ninth-duration","title":"Ninth. Duration.","text":"<ol> <li>The contract shall be valid indefinitely from the moment the client requests it. The client can also put the end to the contract at any time he wishes, being obliged to pay the pending consumed service.</li> <li>As long as the period contract holds it is understood that the validity of the contract published on TIKAL\u00b4s website and containing all updates, prevails.</li> </ol>"},{"location":"conditions/terms-of-service/#tenth-terms-of-payment","title":"Tenth. Terms of payment.","text":"<ol> <li>The price, payment method, billing and payment of the telematics application licensing, object of the present contract, is stipulated in the Current Official Rates Section published on TIKAL\u00b4s website (https://openvidu.io at the time of writing), which are considered part of a whole to all intents and purposes.</li> <li>The price stipulated in the aforementioned Current Official Rates Section, do not include valued added tax (VAT), nor does it include any other taxes or fees established by law whose current rates shall be applied for the provision of the service when signing the present contract. Therefore, said amounts may be increased according to current tax rates.</li> <li>Payment will be done monthly and will cover the whole amount of the service consumed during last month period according to the currently published rates from TIKAL.</li> <li>Monthly payments include both the basic rate for the provision of the service, and the corresponding rate(s) for any optional or additional service hired.</li> <li>Payments must be made effective by the credit or debit card that the client has agreed with TIKAL when first hiring the service. Visa and MasterCard shall be the accepted cards.</li> <li>Total or partial delay in payment by the client for the amount(s) TIKAL has billed them shall grant TIKAL the right to cancel or terminate all contracted obligations in accordance with the present contract. Suspension of the service provision shall be realized within the next fifteen natural days after the contract has reached its expiry date, prior notice to the client. After said fifteen natural days from the day the service was suspended, and prior notification to the client, TIKAL may terminate the contract. If the client pays the full amount owed to TIKAL during said period, the latter shall re-establish the service as promptly as possible from the moment it is notified that the debt has been settled. Notwithstanding the foregoing, TIKAL reserves the right to ask for a two-month deposit as a guarantee before re-establishing the service. The client accepts all liability for any legal costs incurred due to claims made by TIKAL regarding breach of payment after the contract has reached its expiry date, including, but not limited to, such things as the return of invoices and late-payment interest.      When the client returns, for any cause alien to TIKAL, two or more direct-debit invoices, TIKAL shall be entitled to unilaterally opt for the annual hiring and billing of the service.</li> <li>When the client has defaulted on a payment, either totally or partially, during three months, for the amount owed to TIKAL, the latter has the right to rescind the contract between the two parties, as well as the direct and definite termination and cancellation of the service hired by the client, including the database linked to the client\u00b4s services, without prior notice from TIKAL.</li> <li>TIKAL shall apply upon its rates any current deals and offers existing at the time the client hires the service, provided they comply with the terms and conditions of said deals and offers so that they may benefit from them. The client acknowledges and accepts the fact they may obtain detailed information, at any given time, regarding said deals and offers on TIKAL\u00b4s website or through the habitual communication channels with which TIKAL provides its clients.</li> </ol>"},{"location":"conditions/terms-of-service/#eleventh-data-protection","title":"Eleventh. Data Protection.","text":"<p>The parties involved agree that they know, comply with, and are subject to, the Spanish and European laws and legislation regarding Personal Data Protection, thus they must give proper use and treatment to all data arising from any activity subjected to the terms and conditions of this contract.</p>"},{"location":"conditions/terms-of-service/#data-controller-agreement-between-the-client-and-tikal","title":"Data Controller agreement between the client and TIKAL.","text":"<p>In accordance with the Spanish Data Protection Laws, TIKAL\u00b4s access to the client\u00b4s personal files shall not be considered a violation of said laws, insofar as TIKAL is effectively the Data Controller and said access is necessary for the provision of the service which is the subject of this contract. </p> <p>In this regard, and for the purposes of Data Protection regulation, TIKAL shall be regarded as the \u201cData Controller\u201d of the client\u00b4s data. Notwithstanding the foregoing, TIKAL pledges that it shall treat said data in conformity with the client\u00b4s instructions provided in this contract, and that under no circumstances shall it utilise them for any other purposes outside of what the parties have agreed in this contract, nor shall it transfer or communicate them to a third party, not even for back-up or storage purposes. At the same time, the duration and validity of this agreement shall correspond to the type of service hired by the client. </p> <p>Once the provision of said service terminates and the data shall no longer be necessary to perform the aforementioned Data Controller role, all personal data shall be either destroyed or returned to the person, persons or entity responsible for it, as well as any storage medium, documents or files containing personal data. </p> <p>In order to provide the service and what said provision entails, TIKAL shall be granted access to the following information:</p> <ol> <li>Contact details</li> <li>Company profile data</li> <li>Assets and billed services data</li> <li>Tax identification data</li> </ol> <p>TIKAL\u00b4s obligations as Data Controller are described as follows:</p> <ol> <li>Treat all data in accordance with the instructions received by the person, persons or entity in charge of its treatment and only for the purposes provided in this contract.</li> <li>To not communicate or transfer any data to third parties, except prior consent by the body in charge of its treatment, or in cases provided for by the law.</li> <li>TIKAL may not outsource, either totally or partially, the provision of the service(s) described in the present contract, except prior authorization from the client whom shall be informed with due notice about the outsourcing entity as well as the services being outsourced. In this case, TIKAL shall draft and execute a new contract with said outsourcing entity, always in accordance with the current Data Protection laws.</li> <li>To not disclose any personal data to which TIKAL may have had access, even after the termination of this contract.</li> <li>To guarantee that the staff managing personal data pledge to keep the confidentiality which said data entails and that they comply with the proper security protocols.</li> <li>To assist the person or body responsible for data treatment regarding data protection.</li> <li>To provide the person or body responsible for data protection with support and assistance when performing an impact assessment, or when consulting the regulatory authorities, if applicable. Additionally, to provide said person or body with the necessary information so that it may prove their compliance with the rules and regulations.</li> <li>Notwithstanding the foregoing, said person or body has mechanisms in place so as to guarantee the confidentiality, integrity, and availability of the systems and services concerning data protection, as well as to restore the access and availability to data in case of system failure. Additionally, it is endowed with capabilities so as to regularly verify and assess the efficacy of the security protocol.</li> </ol> <p>Duties of the responsible for data treatment:</p> <ol> <li>To guarantee, at all times, compliance with the Data Protection Laws.</li> <li>Make all necessary enquiries beforehand.</li> <li>To supervise that proper data treatment is occurring.</li> <li>To provide the data controller with all necessary data for the provision of the service.</li> </ol> <p>TIKAL\u00b4s duties as Data Controller:</p> <ol> <li>To guarantee, at all times, compliance with the Data Protection Laws.</li> <li>Make all necessary enquiries beforehand.</li> <li>To supervise that proper data treatment is occurring.</li> <li>To provide the data controller with all necessary data for the provision of the service.</li> </ol>"},{"location":"conditions/terms-of-service/#twelfth-confidentiality","title":"Twelfth. Confidentiality.","text":"<ol> <li>All data and information transmitted between the parties is strictly confidential and property of TIKAL and the client, and its protection is of the utmost importance. To this intent, both parties hereby contract the obligation to safeguard said data and information by adopting all appropriate measures to ensure that only authorized individuals shall have access to it; authorized individuals being understood as those employees which are needed by the parties involved so as to keep the provision of the service, which is the object of this contract, in good working order.</li> <li>In this regard, the signatory parties are hereby subject to the following confidential agreement:<ul> <li>Hereby TIKAL pledges to keep confidential all data and information supplied by, and concerning the client, as well as the output arisen from the service provided. In this regard, TIKAL possesses strict internal controls whose objective and end are to guarantee the integrity of the present confidential agreement.</li> <li>The client therefore agrees to keep confidential all data and information arising from TIKAL\u00b4s internal processes, specially the existence, utilization, and functionalities of any process used in the provision of the service.</li> <li>The present confidential agreement shall remain valid even after the termination of the present contractual relation and extends indefinitely to all members of staff that have been granted access to said confidential information.</li> </ul> </li> </ol>"},{"location":"conditions/terms-of-service/#thirteenth-termination-rescission-nullity","title":"Thirteenth. Termination. Rescission. Nullity.","text":"<ol> <li>The present contract shall be considered void for infringement, committed by any of the parties involved, of the Spanish Civil Code, and in particular, of the Spanish Commercial Code, and the obligations arising from the following:<ul> <li>Mutual consent of the parties involved.</li> <li>When the present contract has reached its expiry date which is specified in clause tenth, or within the subsequent extensions thereof.</li> <li>By unilateral rescission provided that the party wishing to rescind communicates this at least one month in advance.</li> <li>When any of the parties has been officially put into administration, has filed for bankruptcy protection, is under bankruptcy or insolvency proceedings, or is under liquidation or dissolution.</li> <li>Due to any other reason(s) provided for in law.</li> <li>Should any of the parties involved breach the contracted obligations provided in the present contract, the other party may consider it as void. Said consideration warrants no prior notice or compensation of any kind, but for the need to communicate the decision to the other party; unless the unaccrued obligations owed by the party are performed within the next fifteen days, counting from the moment said party was notified that they are in breach of the contract . Notwithstanding the foregoing, the other party reserves the right to claim or file for damages caused by this infringement.</li> </ul> </li> <li>TIKAL pledges to destroy all data provided by the client once the contractual relation is extinguished. Likewise, TIKAL shall destroy or return any document or storage medium containing any IT-related data arising from said contractual relation. Once said contractual relation terminates, the client may request TIKAL to supply them with a hard, back-up copy of all data pertaining to and arising from said relation, to any address the client wishes, prior to a written request to do so, which must be sent within the week after the end of the contract. The client shall burden the costs incurred arising from the handling and mailing of said request.</li> <li>The client may cease or cancel the use of the telematics application whenever they wish to do so. Should the client or any authorized user by them request the cancellation of the service at TIKAL\u00b4s offices, it shall become effective on the same day said request was made. Therefore, it is advised to carefully observe said process to avoid any resources or data loss that the client or user may have in their TIKAL\u00b4s account. Should it not be possible for them to initiate said cancellation process at TIKAL\u00b4s offices, the client may request it by contacting TIKAL\u00b4s customer service via any of the channels provided in this contract. Said cancellation shall become effective on the day stipulated by the client, provided that the request has been made with enough time to be processed correctly.</li> </ol>"},{"location":"conditions/terms-of-service/#fourteenth-applicable-legislation-and-jurisdiction","title":"Fourteenth. Applicable legislation and jurisdiction.","text":"<p>The present is a business contract regulated by Spanish laws. The parties involved agree that any discrepancy, legal or civil action, claim or complain arising from the interpretation and execution of the present contract, shall be, directly or indirectly, taken to the Court of Madrid, thus all parties involved hereby renounce to take any matters pertaining to this agreement to any other jurisdiction. </p> <p>The present document constitutes the total agreement of the parties in relation to the matters covered in this agreement, thus substitutes all previous obligations, liabilities, and agreements, both written and verbal, existing prior to the signature and execution of this contract. </p> <p>The following website (www.naevatec.com) belongs to: TIKAL TECHNOLOGIES SL TAX ID: B85986669 10 Chile Rd/St 28290 \u2013 Las Rozas de Madrid (Madrid City) Spain. Registered in the Madrid\u00b4s Trade Register, volume/tome 28043. Book 0 Section 8th of the Registry Book, Page 37, Sheet M-505315.</p>"},{"location":"docs/","title":"OpenVidu Platform","text":"Build your real-time application with complete freedom using SDKs","tags":["Platform"]},{"location":"docs/#what-is-openvidu-platform","title":"What is OpenVidu Platform?","text":"<p>OpenVidu Platform enables you to build real-time applications. You can build your new OpenVidu application from scratch, but it is also very easy to integrate OpenVidu in your already existing application.</p> <p>OpenVidu is based on WebRTC technology and allows developing any kind of use case you can imagine: one-to-one calls, video conference rooms, massive live-streaming events, management and processing of drones and camera feeds...</p> <p>OpenVidu is built on the best open source technologies: LiveKit , from which it inherits all its amazing SDKs to integrate it into your front-end and back-end applications, and mediasoup , from which it inherits the best performance and optimization for media routing.</p> <p> </p> OpenVidu is a custom fork of LiveKit, 100% compatible in terms of its API and SDKs, with the power of mediasoup at its core. This and other integrations provide improved performance, new features and facilitate the deployment and management of your self-hosted, production-grade cluster.","tags":["Platform"]},{"location":"docs/#use-cases","title":"Use cases","text":"<p>OpenVidu is a super versatile platform that can be used to build just about any kind of real-time application you can think of. Most common use cases can be classified into one of the following categories:</p>","tags":["Platform"]},{"location":"docs/#video-conferencing","title":"Video conferencing","text":"<p>Video conferencing rooms are virtual spaces where two or more users can send video and audio and interact with each other in real-time. They can scale in size, from a simple 1-to-1 call to a massive video conference with thousands of participants. For example:</p> <ul> <li>A 1-to-1 video-call center to attend your customers face to face.</li> <li>An e-health application where doctors can treat their patients directly from it, in a private and secure manner using end-to-end encryption.</li> <li>A banking application where customers may sign a contract, live and recording the call as proof of it.</li> <li>A webinar platform where speakers can give their talks to large audiences, with the possibility of viewers temporarily turning their cameras to ask questions.</li> </ul> <p>Info</p> <p>If your use case actually fits into the video conferencing category, OpenVidu Meet  may be the perfect solution for you. Give it a try!</p>","tags":["Platform"]},{"location":"docs/#live-streaming","title":"Live-streaming","text":"<p>Live streaming applications allow one publisher to broadcast video to many viewers. It can be a single video feed, multiple video feeds (webcam and screen share) or there could be even multiple publishers. The general rule is that the ratio of viewers to publishers is very high, in the order of thousands.</p> <p>Ultra-low latency live-streaming (below 300ms) allows for actual real-time interaction between the viewers and the publishers. This differs from traditional live-streaming platforms where the latency is usually in the order of seconds. In this way you can build applications like:</p> <ul> <li>A TEDx-like application, where a speaker can give a talk to a massive audience of thousands of viewers, who may communicate through a chat. Real time subtitles and translations can be added to the stream.</li> <li>An application to stream sport events, where viewers can switch between different cameras to watch the game from different angles to increase fan engagement.</li> <li>A global live auction platform where the auctioneer can be seen by the bidders in real-time with sub-second latency all around the world.</li> </ul>","tags":["Platform"]},{"location":"docs/#ai-agents","title":"AI Agents","text":"<p>AI has changed the world, forever. OpenVidu can be used to integrate any kind of AI agent in your in application, using real-time audio/video/data tracks as inputs for LLMs or any other kind of AI model. With these capabilities, you can expand your application to new horizons:</p> <ul> <li>Implement real-time subtitles, translations, word-detection, sentiment analysis, profanity filter, etc. in your video conferences.</li> <li>Add a summary generator to your video conference app, that can extract the most important parts of the conversation to be shared with the participants.</li> <li>Build a 1-to-1 virtual assistant that can speak naturally with your users, using the latest Text-To-Speech AI models.</li> <li>Implement object detection in your live-streaming app, to detect and track objects in real-time in the video feed.</li> </ul>","tags":["Platform"]},{"location":"docs/#robotics-and-embedded-systems","title":"Robotics and embedded systems","text":"<p>The future lies in the integration of cameras and sensors in all kinds of devices, everywhere: industry, homes, public spaces, emergency services... OpenVidu can be used to receive and process video and audio streams from these devices, and doing so in real-time. For example:</p> <ul> <li>A security system to receive the feed of IP cameras and sending an alert when detecting a person.</li> <li>A drone control system to receive the video feed from each drone camera and securely record it. Any other sensor reading could also be sent to be synchronized later with the recorded video feed.</li> <li>A real-time translation app that uses the latest AI models to provide high-quality translations of spoken language in real time.</li> </ul>","tags":["Platform"]},{"location":"docs/#openvidu-application-architecture","title":"OpenVidu application architecture","text":"<p>Every OpenVidu application consists of 3 main components:</p> <ul> <li>Your OpenVidu deployment: provides all the necessary infrastructure for streaming real-time audio and video. It is built upon LiveKit server and mediasoup server, but it can usually be treated as a black box where its internal aspects are not important: you just deploy it and connect your application to it. It can be a single server or a cluster, deployed on premises or in your cloud provider.</li> <li>Your Application client: runs in your user devices and interacts with the OpenVidu server through any LiveKit client SDK. As OpenVidu server is 100% compatible with LiveKit protocol, you can integrate any LiveKit client SDK in your Application client. Your users will join rooms as participants to send and receive real-time audio and video tracks. It needs a token generated by the Application server to join a room.</li> <li>Your Application server: interacts with the OpenVidu deployment through any LiveKit server SDK. As OpenVidu server is 100% compatible with LiveKit protocol, you can integrate any LiveKit server SDK in your application server. At a minimum, it is responsible for the generation of tokens for the Application client to join a room. But you can implement your own business logic managing rooms, participants and tracks from the safety of your Application server.</li> </ul>","tags":["Platform"]},{"location":"docs/#basic-concepts","title":"Basic concepts","text":"","tags":["Platform"]},{"location":"docs/#room","title":"Room","text":"<p>A Room is a virtual space where Participants can connect to send and receive media Tracks. Two Participants can only communicate if they are connected to the same Room.</p>","tags":["Platform"]},{"location":"docs/#participant","title":"Participant","text":"<p>A Participant is a user connected to a specific Room. Each Participant can publish as many video and audio Tracks as needed, and subscribe to any other Participant's Tracks, as long as they are connected to the same Room.</p>","tags":["Platform"]},{"location":"docs/#track","title":"Track","text":"<p>A Track is a data flow of audio or video. Participants create them from a local media source (a webcam, a microphone, a screen share) and publish them into a Room. Other Participants of the same Room can subscribe to them.</p> <p>With these three concepts you can build any kind of real-time application you can think of. The figure below shows two simple examples.</p> <p> </p> Room \"Daily meeting\" has 2 Participants: \"Alice\" is publishing Track \"Webcam\" and \"Mic\" and is receiving Track \"Screen\" from \"Bob\". \"Bob\" is publishing Track \"Screen\" and receiving Tracks \"Webcam\" and \"Mic\" from \"Alice\". <p> </p> Room \"Remote support\" has 3 Participants: Participant \"Dan\" is not publishing any Track, but receiving all Tracks in the Room. Participant \"Erin\" is only receiving Track \"Mic\" from Participant \"Carol\", but not Track \"Screen\".","tags":["Platform"]},{"location":"docs/#other-concepts","title":"Other concepts","text":"<p>Apart from these basic building blocks, there are other concepts that will be tipically used in your OpenVidu application. All of them are just special types of Participants that connect to Rooms to perform specific tasks:</p> <ul> <li>Egress: a process that exports media out of a Room. It is a special type of Participant that only subscribes to Tracks. It allows recording tracks to a file or streaming them to an external destination (via HLS or RTMP).</li> <li>Ingress: a process that imports media into a Room. It is a special type of Participant that only publishes Tracks. It allows bringing external media sources into a Room, such as an MP4 file, an IP camera or a RTMP stream.</li> <li>Agents: a process that performs AI-driven operations to the media of a Room. It is a special type of Participant that can both subscribe and publish Tracks, analyzing and/or modifying them in between. It allows implementing any AI task you can imagine: real-time subtitles, translations, object detection, AI voice bots, etc.</li> </ul>","tags":["Platform"]},{"location":"docs/#openvidu-editions","title":"OpenVidu Editions","text":"<p>OpenVidu is available in two editions:</p> <ul> <li>OpenVidu COMMUNITY: free to use. It is a single-server deployment and provides a custom LiveKit distribution with Egress, Ingress, S3 storage and monitoring. Ideal for development and testing, but also for medium-scale production deployments. You can host hundreds of simultaneous participants in your rooms by running OpenVidu Community in a sufficiently powerful server!</li> <li>OpenVidu PRO: OpenVidu commercial edition. It is a multi-server deployment with all the features of OpenVidu Community plus 2x performance, scalability, fault tolerance and improved monitoring and observability. Ideal for large-scale production deployments with heavy traffic that require the highest standards. You can start with OpenVidu Community and upgrade to OpenVidu Pro when needed.</li> </ul> <p></p> Type of deployment OpenViduLocal (development) OpenViduSingle Node OpenViduElastic OpenViduHigh Availability OpenVidu Edition COMMUNITY PRO COMMUNITY PRO PRO PRO Suitability For local development in your laptop For applications with medium user load For applications with dynamic user load that require scalability For applications where both scalability and fault tolerance are critical Features Friendly Docker Compose setup with Redis, Egress, Ingress, S3 storage and observability. With automatic certificate management to test across devices in your network COMMUNITY Custom LiveKit distribution with Redis, Egress, Ingress, S3 storage and observability.PRO Same features but adding 2x performance and advanced observability. Same benefits as OpenVidu Single Node plus 2x performance, advanced observability and scalability Same benefits as OpenVidu Elastic plus fault tolerance Number of servers Your laptop 1 Node 1 Master Node +N Media Nodes 4 Master Nodes +N Media Nodes Installation instructions Install Install Install Install","tags":["Platform"]},{"location":"docs/comparing-openvidu/","title":"Comparing OpenVidu","text":"<p>This section compares OpenVidu to other videoconference/streaming solutions, to better understand what it is, what it is not, and what advantages and disadvantages it may have over them.</p>","tags":["Platform","setupcustomgallery"]},{"location":"docs/comparing-openvidu/#openvidu-meet-vs-openvidu-platform","title":"OpenVidu Meet vs OpenVidu Platform","text":"<p>OpenVidu offers two different solutions suitable for different use cases. Find out which is the best for you here: OpenVidu Meet vs OpenVidu Platform.</p>","tags":["Platform","setupcustomgallery"]},{"location":"docs/comparing-openvidu/#openvidu-vs-livekit","title":"OpenVidu vs LiveKit","text":"<p>First of all, and perhaps the most obvious question, how does OpenVidu differ from LiveKit, and what kind of relationship is there between them? This can be answered with four simple points:</p> <ul> <li>OpenVidu is a fork of LiveKit. It is 100% compatible with LiveKit: any application built for LiveKit is compatible with OpenVidu.</li> <li>OpenVidu is a superset of LiveKit. It provides all the open source features of LiveKit and supports all of its SDKs, but it also extends LiveKit with extra features, APIs and internal enhancements, most notably integration with mediasoup .</li> <li>OpenVidu is a production-ready self-hosted solution. It offers an easy deployment process to self-host a high performance, fault-tolerant, scalable and observable cluster. OpenVidu provides an interactive installer that manages all the complexities, so you can quickly host a production deployment that would otherwise require advanced DevOps/SRE expertise.</li> <li>OpenVidu is a support team for self-hosted deployments. The OpenVidu team is made up of real-time experts with over a decade of experience in the field. We specialize in customer support and are always ready to help you bring your ideas to life.</li> </ul> <p></p> <p>OpenVidu is a custom fork of LiveKit, 100% compatible in terms of its API and SDKs, with the power of mediasoup at its core. This and other integrations provide improved performance, new features and facilitate the deployment and management of your cluster.</p> <p>LiveKit comes in two flavors: LiveKit Open Source  and LiveKit Cloud .</p>","tags":["Platform","setupcustomgallery"]},{"location":"docs/comparing-openvidu/#openvidu-community-vs-livekit-open-source","title":"OpenVidu COMMUNITY vs LiveKit Open Source","text":"<p>LiveKit Open Source is probably the most advanced and feature-rich open source WebRTC stack available today. It has a simple but very versatile API design, and has a large collection of SDKs to integrate into your application on both the frontend and backend. Regardless of your technology stack, there is sure to be a LiveKit Open Source SDK available for you! This is why OpenVidu is fully compatible with LiveKit protocols. You can use any LiveKit SDK to build your application, and it will work seamlessly with an OpenVidu deployment.</p> <p>What does OpenVidu Community bring over LiveKit Open Source?</p> <p>With OpenVidu Community you get a handful of features on top of LiveKit Open Source that will help with the development of your application:</p> <ul> <li>Egress and Ingress services already integrated with a Redis instance: LiveKit allows you to export media from a Room (for example recording it) or import media into a Room (for example ingesting a video file), using Egress  and Ingress  services respectively. These modules are independent of LiveKit Server and must be correctly configured and connected via a shared Redis. When running OpenVidu Community you will have all these services properly integrated, so you can focus on developing your app without worrying about anything else.</li> <li>S3 compatible storage for Egress recordings: OpenVidu Community comes with an S3 compatible storage already configured to store Egress  recordings (Minio ).</li> <li>Administration dashboard to monitor your Rooms: OpenVidu comes with an administration dashboard that allows you to monitor the status of your Rooms. Not only in real time, but also historically: the number of participants, the number of published tracks, Egress and Ingress processes... This is a great tool to have when developing your app, as it can help to spot issues and debugging your application's logic. See more.</li> <li>OpenVidu Meet: a fully-fledged, ready to use videoconference application. See more.</li> <li>Powerful and easy to use local development environment: OpenVidu provides a Docker Compose based deployment designed for development and testing devices on your local network. It comes with automatic certificate management that makes it easy to test mobile devices in your LAN. See more.</li> </ul>","tags":["Platform","setupcustomgallery"]},{"location":"docs/comparing-openvidu/#openvidu-pro-vs-livekit-open-source","title":"OpenVidu PRO vs LiveKit Open Source","text":"<p>Deploying LiveKit Open Source in production requires DevOps/SRE experience to operate your own network of media servers, load balance between them, maintain high uptime and monitor the health of your deployment. OpenVidu Pro makes this an easy process, hiding most of the complexities of such an advanced deployment. With OpenVidu Pro you can self-host a fault-tolerant, scalable and observable cluster, while doubling the original LiveKit Open Source performance to handle twice as many media streams with the same hardware.</p>","tags":["Platform","setupcustomgallery"]},{"location":"docs/comparing-openvidu/#openvidu-pro-vs-livekit-cloud","title":"OpenVidu PRO vs LiveKit Cloud","text":"<p>LiveKit Cloud is the official SaaS solution for LiveKit. They manage the infrastructure, with a pricing model based on the total bandwidth consumed by your application. It offers certain advantages over LiveKit Open Source:</p> <ul> <li>Analytics and telemetry dashboard. LiveKit Open Source does not export any metrics or logs out-of-the-box.</li> <li>Massive Rooms for livestreams, where a theoretically unlimited number of viewers can be established for published tracks. In LiveKit Open Source one Room must fit in a single server. LiveKit Cloud overcomes this limitation with a mesh architecture where one media server can connect to other media servers to distribute the load.</li> </ul> <p>Where does OpenVidu Pro stand in relation to LiveKit Cloud? OpenVidu Pro aims to deliver the same advanced benefits as LiveKit Cloud, but as a self-hosted solution. We intend to provide a performant, fault-tolerant, scalable and observable cluster that is easy to deploy, configure and administrate in your own infrastructure. For now, OpenVidu Pro brings:</p> <ul> <li>OpenVidu Pro provides a complete observability stack with Grafana, Loki, Promtail and Mimir, as well as OpenVidu Dashboard to visualize the data. See more.</li> <li>We are currently working on supporting the same scalability as LiveKit Cloud to support big videoconferences and massive live streams. See more.</li> </ul>","tags":["Platform","setupcustomgallery"]},{"location":"docs/comparing-openvidu/#openvidu-vs-saas-solutions","title":"OpenVidu vs SaaS solutions","text":"<p>This includes many services like Agora , GetStream , Daily , Vonage , Jitsi as a Service , Whereby , Zoom SDK , Dolby Millicast , Amazon Chime SDK .</p> <p>The main difference between OpenVidu and these services is who owns the infrastructure, and where your users' data flows. All these SaaS solutions provide:</p> <ul> <li>A public endpoint that your application connects to, so all media is routed through their servers.</li> <li>Different sets of SDKs to integrate with your application. Some more complete than others, and maybe some low-code options.</li> <li>A pricing model usually based on one of these two options: minutes-per-participant or total GBs of bandwidth consumed.</li> </ul> <p>Using a SaaS provider is a great option for some use cases, but not all. OpenVidu is designed to be self-hosted. This allows you to have full control over your infrastructure and data, taking the most out of your own resources and complying with the most strict regulations. While having the best features provided by SaaS: scalability, fault tolerance, observability. See Production ready for more information.</p>","tags":["Platform","setupcustomgallery"]},{"location":"docs/comparing-openvidu/#openvidu-vs-sfus","title":"OpenVidu vs SFUs","text":"<p>This includes projects such as Kurento , mediasoup , Pion , Janus , Jitsi Videobridge  or Medooze .</p> <p>These are all media servers. More specifically, they fall under the umbrella of the so-called SFUs (Selective Forwarding Units): they are able to receive media streams from different clients and selectively forward them to other clients, usually without transcoding or mixing the media.</p> <p>SFUs are generally low-level tools. Using them directly to implement real-time applications requires a deep understanding of signaling protocols, codecs, networking and other low-level concepts. OpenVidu is a higher-level abstraction compared to SFUs. It internally uses SFUs to rely the media streams (more specifically Pion  and mediasoup ), but hides all complexities to offer a simpler way to develop videoconferencing and live-streaming applications.</p>","tags":["Platform","setupcustomgallery"]},{"location":"docs/comparing-openvidu/#openvidu-vs-mediasoup","title":"OpenVidu vs mediasoup","text":"<p>mediasoup  is a WebRTC SFU. It is a minimalist media server with a super low level API that allows building custom real-time applications. Compared to other SFUs, mediasoup is well known for its outstanding performance.</p> <p>OpenVidu uses mediasoup internally to transmit media streams. We have embedded mediasoup as the WebRTC engine right at the core of LiveKit Open Source, which allows OpenVidu to offer the fantastic APIs and SDKs of LiveKit while providing the cutting-edge performance of mediasoup. Learn more about mediasoup integration in section Performance.</p>","tags":["Platform","setupcustomgallery"]},{"location":"docs/comparing-openvidu/#openvidu-vs-microsoft-teams-google-meet-zoom","title":"OpenVidu vs Microsoft Teams, Google Meet, Zoom","text":"<p>All these well-known video conferencing tools are final applications that provide little to no customization at all. They are proprietary, closed-source apps designed to be used as-is, and they are not intended to be integrated into other systems.</p> <p>OpenVidu is inherently different, as it provides a set of APIs and SDKs to integrate real-time video capabilities into your own application. In other words: with OpenVidu you can easily build your own custom Microsoft Teams, Google Meet or Zoom-like application. See Use cases for some examples of what you can build with OpenVidu.</p>","tags":["Platform","setupcustomgallery"]},{"location":"docs/getting-started/","title":"Getting started","text":"","tags":["Platform"]},{"location":"docs/releases/","title":"Releases","text":"","tags":["Platform"]},{"location":"docs/releases/#340","title":"3.4.0","text":"<p>For the Release Notes of OpenVidu Meet 3.4.0, please visit here: OpenVidu Meet 3.4.0 </p>","tags":["Platform"]},{"location":"docs/releases/#changelog","title":"Changelog","text":"<ul> <li>LiveKit stack updated to v1.9.0: OpenVidu is now based on LiveKit v1.9.0, which includes several improvements and bug fixes. You can find the release notes here .</li> <li>Egress updated to v1.10.0: the Egress service has been updated to v1.10.0, which includes several improvements and bug fixes when exporting media from rooms. You can find the release notes here .</li> <li>OpenVidu Single Node native deployment in Google Cloud Platform (GCP): you can now deploy OpenVidu Single Node in GCP using its native resources thanks to our new Terraform template. Follow the GCP deployment guide. Templates for OpenVidu Elastic and OpenVidu High Availability in GCP are coming soon.</li> <li>No need for a domain name to deploy OpenVidu in production: thanks to sslip.io  integration, you can now deploy OpenVidu in production with a valid SSL certificate without owning a custom domain name. Just deploy OpenVidu 3.4.0 and skip the domain name configuration during the installation process: OpenVidu will automatically detect your public IP and provide a secure domain name using sslip.io.</li> <li>OpenVidu agents new configurations: configure a custom CPU threshold to accept new jobs, and modify the agent's log level. See Change CPU load threshold and Log level.</li> <li>Custom AI agents now natively support graceful shutdown, ensuring no interruptions in the services provided by your custom agents when your OpenVidu cluster scales down.</li> <li>OpenVidu Dashboard optimizations: the addition of several new search indexes to the database has significantly improved the response time of the OpenVidu Dashboard when loading historical data.</li> <li>Fixed bug that caused empty <code>participantInfo</code> object when receiving transcription events using the Speech Processing agent. This fix was also contributed to LiveKit open source (PR 3735 ).</li> <li>New load balancing strategy for Egress: egresses were previously distributed across Media Nodes using a \"binpack\" strategy (trying to fill up one node before using the next one). This could lead to unbalanced CPU usage across nodes in certain scenarios. There is now a new load balancing strategy called \"cpuload\" that prioritizes nodes with lower CPU usage, leading to a more balanced cluster in terms of CPU utilization. This is now the default strategy. Learn how to configure it here.</li> <li>Egress ability to auto kill processes under high CPU load can be disabled: by default, if an egress detects a high CPU load (&gt;95%) during a sustained period of time (10 seconds), the parent process automatically kills the most consuming egress. This helps preventing it from affecting the performance of other processes in the same Media Node. This default behavior can be now disabled if necessary. Learn how to do so here.</li> <li>Extended scalability documentation: we have improved our scalability documentation explaining in detail how OpenVidu handles Room, Egress, Ingress and Agent allocation in multi-node deployments. All load balancing strategies and how to configure them are now explained in depth.</li> </ul>","tags":["Platform"]},{"location":"docs/releases/#version-table","title":"Version table","text":"Artifact Version Info Link livekit/livekit-server v1.9.0 mediasoup 3.12.16 livekit/egress v1.10.0 livekit/ingress v1.4.3 livekit/agents v1.2.6 MinIO 2025.5.24 Caddy 2.10.0 MongoDB 8.0.9 Redis 7.4.4 Grafana 11.6.2 Prometheus 3.4.0 Promtail / Loki 3.5.1 Mimir 2.16.0","tags":["Platform"]},{"location":"docs/releases/#330","title":"3.3.0","text":"","tags":["Platform"]},{"location":"docs/releases/#changelog_1","title":"Changelog","text":"<ul> <li> <p>AI Services: OpenVidu now supports a catalog of AI services that can be easily integrated into your application to enhance the user experience and add advanced features. These services are delivered through OpenVidu agents: a set of pre-configured and ready-to-use AI modules that seamlessly integrate into your Rooms.</p> <p>We are starting with the Speech Processing agent: it focuses on transcribing audio speech to text and processing the results in various ways. Currently offering the Live Captions service, which generates live captions for your users' speech with great accuracy to display them in your frontend application. The Live Captions service supports many leading AI providers, such as OpenAI, Google, Azure, Amazon and more (see Supported AI providers).</p> <p>Of course, you can also implement your own custom agents using the powerful LiveKit Agents framework and deploy it along your OpenVidu deployment. Any LiveKit agent is compatible with OpenVidu. Learn how to do so here.</p> </li> <li> <p>Use a single domain for your deployment (EXPERIMENTAL): OpenVidu deployments now support TURN with TLS without an additional Domain Name using the flag <code>--experimental-turn-tls-with-main-domain</code>. This is great for production deployments, as it allows you to use a single domain and still support users behind restrictive firewalls.</p> <p>You can deploy any OpenVidu deployment with this feature enabled:</p> <ul> <li>On Premises: perform a non-interactive installation passing the flag. How to perform a non-interactive installation for each OpenVidu deployment: OpenVidu Single Node COMMUNITY, OpenVidu Single Node PRO, OpenVidu Elastic, OpenVidu High Availability with DNS, OpenVidu High Availability with NLB.</li> <li>AWS: when deploying the CloudFormation template, add the flag <code>--experimental-turn-tls-with-main-domain</code> to the parameter named <code>(Optional) Additional Installer Flags\"</code>, and leave empty parameters under <code>(Optional) TURN server configuration with TLS</code>.</li> <li>Azure: when deploying the ARM template, add the flag <code>--experimental-turn-tls-with-main-domain</code> to the parameter named <code>(Optional) Additional Install Flags</code>, and leave empty parameters under <code>(Optional) TURN server configuration with TLS</code>.</li> </ul> </li> <li> <p>Azure deployment bug fixes:</p> <ul> <li>Media Nodes are now automatically deleted if the installation process fails, preventing unwanted resources being left in your Azure account.</li> <li>A misconfiguration was preventing the TURN server from working correctly in Azure. This is now fixed.</li> <li>Fixed a race condition during the deployment process in Azure that sometimes caused problems when creating multiple subnets concurrently (9728d96).</li> </ul> </li> </ul>","tags":["Platform"]},{"location":"docs/releases/#version-table_1","title":"Version table","text":"Artifact Version Info Link livekit/livekit-server v1.8.4 mediasoup 3.12.16 livekit/egress v1.9.1 livekit/ingress v1.4.3 livekit/agents v1.1.4 MinIO 2025.5.24 Caddy 2.10.0 MongoDB 8.0.9 Redis 7.4.4 Grafana 11.6.2 Prometheus 3.4.0 Promtail / Loki 3.5.1 Mimir 2.16.0","tags":["Platform"]},{"location":"docs/releases/#320","title":"3.2.0","text":"","tags":["Platform"]},{"location":"docs/releases/#changelog_2","title":"Changelog","text":"<ul> <li>OpenVidu Single Node PRO: OpenVidu Single Node PRO is a new type of OpenVidu deployment targeting users that want to deploy OpenVidu as a single-node setup, but that still want the 2x performance boost and the advanced observability provided by multi-node OpenVidu PRO deployments.</li> <li>Azure deployments (Beta): OpenVidu now supports native deployments in Microsoft Azure. You can now deploy OpenVidu Single Node COMMUNITY, OpenVidu Single Node PRO, OpenVidu Elastic and OpenVidu High Availability in Azure using ARM templates. During version 3.2.0, Azure deployments will be considered in Beta.</li> <li> <p>New Azure recording tutorials: OpenVidu deployments in Azure use Azure Blob Storage to store recordings (instead of S3). For this reason, we have extended our recording tutorials with Azure Blob Storage compatible examples. You can find them in the following links:</p> <ul> <li>Recording Basic Azure.</li> <li>Recording Advanced Azure.</li> </ul> </li> <li> <p>External proxy configuration: By default, OpenVidu is deployed with an internal Caddy server to configure and manage SSL certificates. However, there are certain scenarios where using an external proxy might be preferable:</p> <ul> <li>You wish to manage SSL certificates manually.</li> <li>A specific proxy server is required for enhanced security.</li> <li>You need to integrate a proxy server already in your infrastructure.</li> </ul> <p>For any of these cases, now all OpenVidu deployments allow configuring external proxies. You can find the instructions to do so in this how-to guide.</p> </li> <li> <p>LiveKit stack updated to v1.8.4: OpenVidu 3.2.0 is now based on LiveKit v1.8.4, which includes several improvements and bug fixes. You can find the release notes here.</p> </li> <li>OpenVidu installer improvements: Some users have reported issues when installing OpenVidu, which were finally caused by old versions of Docker and/or Docker Compose. The OpenVidu installer now checks both versions and displays a descriptive error message if they are incompatible.</li> <li> <p>OpenVidu Angular Components: see Angular Components documentation.</p> <ul> <li>Virtual Backgrounds improvements: More efficient use of resources by reusing the existing context. Avoid video flickering when changing the background. Improved resource reallocation management for smoother rendering. Contribution to LiveKit\u2019s track-processors-js package (PR 86) resolving an issue affecting its dependencies.</li> <li>Fixed panel reopening issue with <code>ovAdditionalPanels</code> directive. Custom panels created with <code>ovAdditionalPanels</code> would not reopen correctly after switching between default panels (activities, participants or chat). Now, returning to a custom panel restores it as expected without closing all panels.</li> <li>Minor style fixes.</li> </ul> </li> <li> <p>Deployment bug fixes:</p> <ul> <li>OpenVidu On Premises deployments that made use of v2compatibility module had a wrong configuration affecting the S3 MinIO bucket. This could cause issues when recording sessions from your OpenVidu v2 application. This is now fixed.</li> <li>Wrong Caddy configuration in OpenVidu High Availability deployments made some services not reachable in specific scenarios of fault tolerance. This is now fixed.</li> </ul> </li> </ul>","tags":["Platform"]},{"location":"docs/releases/#breaking-changes","title":"Breaking changes","text":"<ul> <li>For OpenVidu On Premises deployments, the default S3 bucket in MinIO has been renamed from <code>app-data</code> to <code>openvidu-appdata</code> (in Single Node and Elastic deployments) and from <code>cluster-data</code> to <code>openvidu-clusterdata</code> (in High Availability deployments).</li> <li>Port rules in OpenVidu High Availability with Network Load Balancer have changed. Check the port rules from the installation instructions.</li> </ul>","tags":["Platform"]},{"location":"docs/releases/#version-table_2","title":"Version table","text":"Artifact Version Info Link livekit/livekit-server v1.8.4 mediasoup 3.12.16 livekit/egress v1.9.1 livekit/ingress v1.4.3 MinIO 2025.5.24 Caddy 2.10.0 MongoDB 8.0.9 Redis 7.4.4 Grafana 11.6.2 Prometheus 3.4.0 Promtail / Loki 3.5.1 Mimir 2.16.0","tags":["Platform"]},{"location":"docs/releases/#310","title":"3.1.0","text":"","tags":["Platform"]},{"location":"docs/releases/#changelog_3","title":"Changelog","text":"<ul> <li>IP cameras support: OpenVidu now allows you to connect RTSP IP cameras to your Rooms. This feature has been included in our custom fork of the Ingress module, which is used to ingest media into a Room. Check out how to do it here. IP cameras support has also been included into the v2 compatibility module. This means that if your OpenVidu 2 application is using the IP cameras feature, you can now upgrade your deployment to OpenVidu 3 and keep using this feature.</li> <li>OpenVidu Updater: you can now update the version of your OpenVidu deployment very easily using our new OpenVidu Updater module. OpenVidu Updater will take care of the whole process, from stopping the services to updating the configuration files. It will also manage backups to allow rollbacks in case of any issue. You can update your OpenVidu deployment from 3.0.0 to 3.1.0:<ul> <li>Update your OpenVidu On Premises deployment: Update OpenVidu Single Node, Update OpenVidu Elastic, Update OpenVidu High Availability.</li> <li>Update your OpenVidu AWS deployment: for AWS deployment we recommend updating from 3.0.0 to 3.1.0 by redeploying the CloudFormation. From 3.1.0 onwards OpenVidu Updater will also be able to seamlessly update your AWS deployment.</li> </ul> </li> <li>mediasoup stability: we believe we have reached the right point of maturity to take mediasoup as the internal RTC engine from experimental to production ready. There are still some limitations to take into account, but the general stability of the system is now considered production ready.</li> <li>v2 Compatibility bug fixes: there have been several improvements to the compatibility between OpenVidu v2 applications and OpenVidu v3 deployments:<ul> <li>REST API: Field <code>clientData</code> of the Connection object wasn't being properly set. Now it is.</li> <li>Webhook: webhook event <code>webrtcConnectionCreated</code> wasn't being sent when an audio-only Publisher published to the Session. Now it is.</li> <li>openvidu-browser-v2compatibility:<ul> <li>Event <code>videoElementCreated</code> wasn't being triggered for Subscriber participants. Now it is.</li> <li>Event <code>streamCreated</code> wasn't being triggered by the Session object for Streams coming from audio-only Publishers. Now it is.</li> <li>Event <code>streamPropertyChanged</code> wasn't being triggered when an audio-only Publisher muted/unmuted its audio. Now it is.</li> </ul> </li> </ul> </li> </ul>","tags":["Platform"]},{"location":"docs/releases/#version-table_3","title":"Version table","text":"Artifact Version Info Link livekit/livekit-server v1.8.3 mediasoup 3.12.16 livekit/egress v1.9.0 livekit/ingress v1.4.3 MinIO 2025.2.7 Caddy 2.8.4 MongoDB 8.0.4 Redis 7.4.2 Grafana 11.5.1 Prometheus 3.1.0 Promtail / Loki 3.3.2 Mimir 2.15.0","tags":["Platform"]},{"location":"docs/releases/#300","title":"3.0.0","text":"","tags":["Platform"]},{"location":"docs/releases/#changelog_4","title":"Changelog","text":"<ul> <li>General Availability of OpenVidu 3, which is considered now stable and production-ready. Beta versions of OpenVidu 3 are preparing to be discontinued (including 3.0.0-beta1, 3.0.0-beta2 and 3.0.0-beta3).</li> </ul>","tags":["Platform"]},{"location":"docs/releases/#known-limitations","title":"Known limitations","text":"<ul> <li>When using mediasoup:<ul> <li>No <code>ConnectionQualityChanged</code> event (LiveKit reference).</li> <li>No <code>TrackStreamStateChanged</code> event (LiveKit reference).</li> <li>Limited ingress support: non-simulcast video tracks are not supported. Firefox may experience issues when subscribing to ingress video.</li> </ul> </li> </ul>","tags":["Platform"]},{"location":"docs/releases/#version-table_4","title":"Version table","text":"Artifact Version Info Link livekit/livekit-server v1.8.0 mediasoup 3.12.16 livekit/egress v1.8.4 livekit/ingress v1.4.2 MinIO 2024.10.13 Caddy 2.8.4 MongoDB 7.0.15 Redis 7.4.1 Grafana 11.3.0 Prometheus 2.55.0 Promtail / Loki 3.2.1 Mimir 2.14.1","tags":["Platform"]},{"location":"docs/releases/#300-beta3","title":"3.0.0-beta3","text":"","tags":["Platform"]},{"location":"docs/releases/#changelog_5","title":"Changelog","text":"<ul> <li>Centralized configuration: OpenVidu now automatically manages and synchronizes the configuration of all its components. This means that updating any configuration parameter in multi-node deployments (OpenVidu Elastic and OpenVidu High Availability) is as simple as updating the required file in a single node. OpenVidu handles the distribution and restart of the affected services across all nodes. See how easily you can change the configuration here.</li> <li>mediasoup support:<ul> <li>Dynacast is now supported (LiveKit reference).</li> <li>Adaptive Streaming is now supported (LiveKit reference).</li> <li>Speaker Detection events (LiveKit reference).</li> <li>Server API method <code>MutePublishTrack</code> (LiveKit reference).</li> <li>Client API method <code>RemoteTrackPublication.setEnabled</code> (LiveKit JS reference).</li> </ul> </li> <li>OpenVidu Call:<ul> <li>When using it against an OpenVidu Local Deployment, recordings couldn't be accessed from the application's frontend. This is now fixed and OpenVidu Call is able to access recordings.</li> <li>There was an error when applying Virtual Backgrounds (\"No camera tracks found. Cannot apply background\"). This is now fixed.</li> <li>Docker image openvidu/openvidu-call is now 50% smaller.</li> </ul> </li> <li>OpenVidu v2 compatibility:<ul> <li>There was a race condition when multiple participants connected to the Session at the same time that could cause remote <code>streamCreated</code> events to not be triggered. This is now fixed.</li> <li>Configuration parameter <code>V2COMPAT_OPENVIDU_PRO_AWS_S3_BUCKET</code> did not allow configuring sub-buckets (\"openvidu\" worked fine, but \"openvidu/subbucket\" did not). Now it is possible to do so.</li> <li>The operation to list recordings (available for REST API, openvidu-java-client, openvidu-node-client) was limited to 1000 recordings. This is now fixed and all recordings are always returned.</li> </ul> </li> <li>AWS deployments: all secrets are now synchronized with AWS Secrets Manager. You can update any secret from the AWS console and restart your cluster for them to have immediate effect in all your nodes. This is also true in reverse: you can update any secret inside your node, and after restarting the cluster, the values in AWS Secrets Manager will be properly synchronized.</li> <li>New application tutorials available: iOS, Android, Recording.</li> </ul>","tags":["Platform"]},{"location":"docs/releases/#known-limitations_1","title":"Known limitations","text":"<ul> <li>When using mediasoup:<ul> <li>No <code>ConnectionQualityChanged</code> event (LiveKit reference).</li> <li>No <code>TrackStreamStateChanged</code> event (LiveKit reference).</li> </ul> </li> </ul>","tags":["Platform"]},{"location":"docs/releases/#version-table_5","title":"Version table","text":"Artifact Version Info Link livekit/livekit-server v1.7.2 mediasoup 3.12.16 livekit/egress v1.8.2 livekit/ingress v1.4.2 MinIO 2024.6.13 Caddy 2.8.4 MongoDB 7.0.11 Redis 7.2.5 Grafana 10.3.3 Prometheus 2.50.1 Promtail / Loki 2.8.9 Mimir 2.11.0","tags":["Platform"]},{"location":"docs/releases/#300-beta2","title":"3.0.0-beta2","text":"","tags":["Platform"]},{"location":"docs/releases/#changelog_6","title":"Changelog","text":"<ul> <li>Improved mediasoup support:<ul> <li>Data messages work (LiveKit reference).</li> <li>Ingress supported (LiveKit reference).</li> </ul> </li> <li>Improved OpenVidu Local Deployment:<ul> <li>Fixed Room Composite Egress (LiveKit reference) support when using mediasoup.</li> <li>WebHooks (LiveKit reference) supported against a local OpenVidu Call.</li> </ul> </li> <li>Production deployments have a better private IP discovery process when there are multiple valid private IPs in the same host. This will make more deployments work out-of-the-box without the need of manual intervention.</li> <li>OpenVidu PRO Evaluation Mode improved. Before, a maximum of 2 Rooms of 8 Participants each could be created. Now the upper limit of Participants still apply, but the number of Rooms is unlimited. For example, you can have 4 Rooms of 2 Participants each, or 1 Room of 8 Participants.</li> <li>Minor bug fixes related to OpenVidu Call.</li> </ul>","tags":["Platform"]},{"location":"docs/releases/#known-limitations_2","title":"Known limitations","text":"<ul> <li>When using mediasoup:<ul> <li>No support for Speaker Detection events (LiveKit reference).</li> <li>No <code>ConnectionQualityChanged</code> event (LiveKit reference).</li> <li>No support for Dynacast (LiveKit reference).</li> <li>No support for Adaptive Streaming (LiveKit reference).</li> </ul> </li> <li>When using OpenVidu Call against an OpenVidu Local Deployment, recordings cannot be accessed.</li> </ul>","tags":["Platform"]},{"location":"docs/releases/#version-table_6","title":"Version table","text":"Artifact Version Info Link livekit/livekit-server v1.6.0 mediasoup 3.12.16 livekit/egress v1.8.2 livekit/ingress v1.2.0 MinIO 2024.06.13 Caddy 2.7.6 MongoDB 7.0.11 Redis 7.2.5 Grafana 10.3.3 Prometheus 2.50.1 Promtail / Loki 2.8.9 Mimir 2.11.0","tags":["Platform"]},{"location":"docs/releases/#300-beta1","title":"3.0.0-beta1","text":"","tags":["Platform"]},{"location":"docs/releases/#version-table_7","title":"Version table","text":"Artifact Version Info Link livekit/livekit-server v1.6.0 mediasoup 3.12.16 livekit/egress v1.8.2 livekit/ingress v1.2.0 MinIO 2024.06.13 Caddy 2.7.6 MongoDB 7.0.11 Redis 7.2.5 Grafana 10.3.3 Prometheus 2.50.1 Promtail / Loki 2.8.9 Mimir 2.11.0","tags":["Platform"]},{"location":"docs/ai/custom-agents/","title":"Custom agents","text":"","tags":["Platform"]},{"location":"docs/ai/custom-agents/#custom-agents","title":"Custom agents","text":"<p>OpenVidu provides a set of built-in agents, each one offering a set of AI services to help enhance the user experience in your Rooms. But you can also create your own custom agents to fine-tune the AI capabilities of your OpenVidu application. You can do so using the powerful LiveKit Agents framework .</p>","tags":["Platform"]},{"location":"docs/ai/custom-agents/#1-implement-your-custom-agent-using-the-livekit-agents-framework","title":"1. Implement your custom agent using the LiveKit Agents framework","text":"<p>LiveKit Agents consists of a Python or Node program that connects to LiveKit Rooms to perform some kind of AI pipeline over the media tracks published to the Room by regular Participants.</p> <p>The agent actually behaves as any other regular Participant of the Room, but thanks to its connection to Speech-to-Text services, LLMs and Text-to-Speech service, it can transcribe audio tracks, analyze video tracks, generate speech, etc... and publish the results back to the Room. This allows building any kind of flow interaction between your users and the AI service, all in real-time.</p> <p>An incredible set of plugins  make it very easy to integrate your agent code with the most popular AI providers. You have further information in the LiveKit Agents integrations  documentation.</p> <p>Tip</p> <p>To start building your own custom agent, the best way is to follow the LiveKit's Voice AI quickstart  guide. You can customize it to your needs once you grasp the basics of the Agents framework. You also have a great collection of recipes  to inspire you.</p>","tags":["Platform"]},{"location":"docs/ai/custom-agents/#2-dockerize-your-custom-agent","title":"2. Dockerize your custom agent","text":"<p>Once you are satisfied with your custom agent implementation, you need to build a Docker image of it. When using the Python SDK and having a project structure similar to this...</p> <pre><code>.\n\u251c\u2500\u2500 agent.py\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 Dockerfile\n</code></pre> <p>...here you have a typical example of an agent's Dockerfile:</p> <pre><code># This is an example Dockerfile that builds a minimal container for running LK Agents\n# syntax=docker/dockerfile:1\nARG PYTHON_VERSION=3.11.11\nFROM python:${PYTHON_VERSION}-slim\n\n# Prevents Python from writing pyc files.\nENV PYTHONDONTWRITEBYTECODE=1\n\n# Keeps Python from buffering stdout and stderr to avoid situations where\n# the application crashes without emitting any logs due to buffering.\nENV PYTHONUNBUFFERED=1\n\n# Create a non-privileged user that the app will run under.\n# See https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#user\nARG UID=10001\nRUN adduser \\\n    --disabled-password \\\n    --gecos \"\" \\\n    --home \"/home/appuser\" \\\n    --shell \"/sbin/nologin\" \\\n    --uid \"${UID}\" \\\n    appuser\n\n# Install gcc, g++ and other build dependencies.\nRUN apt-get update &amp;&amp; \\\n    apt-get install -y \\\n    gcc \\\n    g++ \\\n    python3-dev \\\n    git \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\nUSER appuser\n\nRUN mkdir -p /home/appuser/.cache\nRUN chown -R appuser /home/appuser/.cache\n\nWORKDIR /home/appuser\n\nCOPY requirements.txt .\nRUN python -m pip install --user --no-cache-dir -r requirements.txt\n\nCOPY ./*.py .\n\n# ensure that any dependent models are downloaded at build-time\nRUN python agent.py download-files\n\n# Run the application.\nCMD [\"python\", \"agent.py\", \"start\"]\n</code></pre>","tags":["Platform"]},{"location":"docs/ai/custom-agents/#3-add-your-custom-agent-to-your-openvidu-deployment","title":"3. Add your custom agent to your OpenVidu deployment","text":"","tags":["Platform"]},{"location":"docs/ai/custom-agents/#1-ssh-into-an-openvidu-node-and-go-to-configuration-folder","title":"1. SSH into an OpenVidu Node and go to configuration folder","text":"<p>Depending on your OpenVidu deployment type:</p> OpenVidu Local (Development)OpenVidu Single NodeOpenVidu ElasticOpenVidu High Availability <p>If you are using OpenVidu Local (Development), simply navigate to the configuration folder of the project:</p> <pre><code># For OpenVidu Local COMMUNITY\ncd openvidu-local-deployment/community\n\n# For OpenVidu Local PRO\ncd openvidu-local-deployment/pro\n</code></pre> <p>If you are using OpenVidu Single Node, SSH into the only OpenVidu node and navigate to:</p> <pre><code>cd /opt/openvidu/config\n</code></pre> <p>If you are using OpenVidu Elastic, SSH into the only Master Node and navigate to:</p> <pre><code>cd /opt/openvidu/config/cluster/media_node\n</code></pre> <p>If you are using OpenVidu High Availability, SSH into any of your Master Nodes (doesn't matter which one) and navigate to:</p> <pre><code>cd /opt/openvidu/config/cluster/media_node\n</code></pre>","tags":["Platform"]},{"location":"docs/ai/custom-agents/#2-add-a-agent-agent_nameyaml-file","title":"2. Add a <code>agent-AGENT_NAME.yaml</code> file","text":"<p>Located in the configuration folder of your OpenVidu node, create a file named <code>agent-AGENT_NAME.yaml</code>, where <code>AGENT_NAME</code> must be a unique name for your agent. The minimal content of this file is:</p> <pre><code># Docker image of the agent.\ndocker_image: YOUR_IMAGE\n\n# Whether to run the agent or not.\nenabled: true\n\nCUSTOM_CONFIGURATION: ...\n</code></pre> <ul> <li> <p>The <code>docker_image</code> field must be the full name of the Docker image you built in step 2. Of course, your OpenVidu nodes must have access to that Docker image's registry.</p> </li> <li> <p>The <code>enabled</code> field indicates whether the agent will be started by OpenVidu or not. Setting this to <code>false</code> will result in your agent NOT being launched and not being available, even if you later try to manually dispatch your agent.</p> </li> <li> <p>You can add as many other properties as you want to this YAML file. You can access them within your agent's code (see Accessing the agent's configuration file).</p> </li> </ul>","tags":["Platform"]},{"location":"docs/ai/custom-agents/#3-restart-openvidu","title":"3. Restart OpenVidu","text":"<p>Depending on your OpenVidu deployment type:</p> OpenVidu Local (Development)OpenVidu Single NodeOpenVidu ElasticOpenVidu High Availability <p>Run where <code>docker-compose.yaml</code> is located:</p> <pre><code>docker compose restart\n</code></pre> <p>Run this command in your node:</p> <pre><code>sudo systemctl restart openvidu\n</code></pre> <p>Run this command in your Master Node:</p> <pre><code>sudo systemctl restart openvidu\n</code></pre> <p>Run this command in one of your Master Nodes:</p> <pre><code>sudo systemctl restart openvidu\n</code></pre> <p>After restarting OpenVidu your agent will be up and running, ready to process new Rooms.</p> <p>Warning</p> <p>If your agent container keeps restarting, there might be an error in your configuration. Check its logs to find out what is wrong.</p>","tags":["Platform"]},{"location":"docs/ai/custom-agents/#tips-when-coding-your-custom-agent","title":"Tips when coding your custom agent","text":"<p>When developing your custom agent using the Python or Node SDKs, there are some tips that can help:</p>","tags":["Platform"]},{"location":"docs/ai/custom-agents/#dispatching-your-custom-agent","title":"Dispatching your custom agent","text":"<p>You can control when to dispatch your agent in your agent's code. By default, agents will dispatch (connect) automatically to new Rooms. If you want to manually control when to dispatch your agent, simply add property <code>agent_name</code> to your <code>WorkerOptions</code> when creating the agent:</p>  Python Node.js <pre><code>opts = WorkerOptions(\n    ...\n    agent_name=\"my-custom-agent\",\n)\n</code></pre> <pre><code>const opts = new WorkerOptions({\n  ...\n  agentName: \"my-custom-agent\",\n});\n</code></pre> <p>Property <code>agent_name</code> must match the value <code>AGENT_NAME</code> in the file <code>agent-AGENT_NAME.yaml</code> created here.</p> <p>Then you can manually dispatch your agent using the Dispatch API or via a Participant connection.</p>","tags":["Platform"]},{"location":"docs/ai/custom-agents/#accessing-the-agents-configuration-file","title":"Accessing the agent's configuration file","text":"<p>It can be very useful to access your agent's YAML configuration file from within your agent's code. OpenVidu automatically mounts file <code>agent-AGENT_NAME.yaml</code> for your agent's Docker container. You have the path to the file in env var <code>AGENT_CONFIG_FILE</code>. You can read the file's content directly in your agent's code (a YAML parser can be very useful). For example:</p>  Python Node.js <pre><code>import os\nimport yaml\n\nwith open(os.environ[\"AGENT_CONFIG_FILE\"], \"r\") as f:\n    config = yaml.safe_load(f)\n\nprint(config)\n</code></pre> <pre><code>import fs from 'fs';\nimport yaml from 'js-yaml';\n\nconst configFile = process.env.AGENT_CONFIG_FILE;\nconst config = yaml.load(fs.readFileSync(configFile, 'utf8'));\n\nconsole.log(config);\n</code></pre>","tags":["Platform"]},{"location":"docs/ai/custom-agents/#elasticity-and-graceful-shutdowns","title":"Elasticity and graceful shutdowns","text":"<p>Custom agents in multi-node OpenVidu deployments (OpenVidu Elastic and OpenVidu High Availability) support automatic graceful shutdowns when Media Nodes are scaled down.</p> <p>When a Media Node hosting custom agents is being removed from the OpenVidu cluster:</p> <ol> <li>Existing jobs complete: Custom agents are allowed to finish processing their current jobs before stopping.</li> <li>New jobs rejected: Custom agents reject new job requests, which will be redirected to other Media Nodes in the cluster.</li> </ol> <p>This ensures no interruptions in the services provided by your custom agents when your OpenVidu cluster scales down.</p>","tags":["Platform"]},{"location":"docs/ai/live-captions/","title":"Live captions","text":"","tags":["Platform"]},{"location":"docs/ai/live-captions/#live-captions","title":"Live Captions","text":"<p>Transcribe the audio tracks of your Rooms in real time with great accuracy and display the results as live captions in your frontend.</p>","tags":["Platform"]},{"location":"docs/ai/live-captions/#how-to-enable-live-captions-service-in-your-openvidu-deployment","title":"How to enable Live Captions service in your OpenVidu deployment","text":"<p>Live Captions service is provided by the Speech Processing agent:</p> <p> Enable the Speech Processing agent</p> <p>You configure the Live Captions service by setting up the following properties when modifying file <code>agent-speech-processing.yaml</code>:</p> agent-speech-processing.yaml<pre><code>live_captions:\n  # How this agent will connect to Rooms [automatic, manual]\n  # - automatic: the agent will automatically connect to new Rooms.\n  # - manual: the agent will connect to new Rooms only when your application dictates it by using the Agent Dispatch API.\n  processing: automatic\n\n  # Which speech-to-text AI provider to use [aws, azure, google, opeanai, groq, deepgram, assemblyai, fal, clova, speechmatics, gladia, sarvam]\n  # The custom configuration for the selected provider must be set below\n  provider: YOUR_PROVIDER\n\n  # Custom configuration for the selected provider\n  YOUR_PROVIDER: ...\n</code></pre> <p>Choosing a provider</p> <p>You must set up a specific <code>provider</code> from the list of supported providers. Each provider has its own custom configuration. Some of them provide advanced features such as integrated profanity filters or translation. Check out the configuration reference below for more details.</p>","tags":["Platform"]},{"location":"docs/ai/live-captions/#how-to-receive-live-captions-in-your-frontend-application","title":"How to receive Live Captions in your frontend application","text":"<p>Live Captions are received in your frontend application using the Text Stream API  of LiveKit client SDKs. You must specifically subscribe to the Room topic <code>lk.transcription</code> to automatically receive transcription events. For example, in JavaScript:</p> <pre><code>room.registerTextStreamHandler(\"lk.transcription\", async (reader, participantInfo) =&gt; {\n    const message = await reader.readAll();\n    const isFinal = reader.info.attributes[\"lk.transcription_final\"] === \"true\";\n    const trackId = reader.info.attributes[\"lk.transcribed_track_id\"];\n    if (isFinal) {\n      console.log(`Participant ${participantInfo.identity} and track ${trackId} said: ${message}`);\n    } else {\n      console.log(`Participant ${participantInfo.identity} and track ${trackId} is saying: ${message}`);\n    }\n  }\n);\n</code></pre> <p>Info</p> <p>Refer to LiveKit documentation  to see how to handle transcription events in other frontend platforms.</p> <ul> <li>From the <code>participantInfo</code> object of the text stream handler you can get the participant's <code>identity</code> that originated the transcription event.</li> <li> <p>From the <code>reader.info.attributes</code> you can get the following properties:</p> <ul> <li><code>lk.transcription_final</code>: string that is <code>\"true\"</code> if the transcription is final or <code>\"false\"</code> if it is an interim. See Final vs Interim transcriptions section for more details.</li> <li><code>lk.transcribed_track_id</code>: string with the ID of the audio track that was transcribed. This can be used to identify the exact source of the transcription in case the participant is publishing multiple audio tracks.</li> </ul> </li> </ul>","tags":["Platform"]},{"location":"docs/ai/live-captions/#final-vs-interim-transcriptions","title":"Final vs Interim transcriptions","text":"<p>When receiving transcription events from the <code>lk.transcription</code> text stream topic, you may receive two types of transcriptions:</p> <ul> <li>Interim transcription: partial transcription that may be updated in future events with more accurate results. They are marked with <code>lk.transcription_final</code> set to string <code>\"false\"</code> in the event attributes.</li> <li>Final transcriptions: transcription for which the AI provider is confident enough to consider it completed for that portion of the speech. They are final and will not be updated with more interim transcriptions. They are marked with <code>lk.transcription_final</code> set to string <code>\"true\"</code> in the event attributes.</li> </ul> <p>The difference between interim and final transcriptions is important: interim results allow you to display live captions in your frontend application while the user is actively speaking, instead of having to wait for the user to finish its sentence to receive a final transcription result.</p> <p>Warning</p> <p>Not all AI providers support interim transcriptions (see the Supported AI providers table). All providers will actually generate at least one interim transcription before a final transcription, but the ones marked with  in the table will simply generate a single interim result just before each final result, that will completely match its content.</p>","tags":["Platform"]},{"location":"docs/ai/live-captions/#supported-ai-providers","title":"Supported AI providers","text":"<p>Below is the list of cloud providers that can handle the Live Captions service.</p> AI provider YAML property Service description Interim results <code>aws</code> Uses Amazon Transcribe  <code>azure</code> Uses Azure Speech service  <code>azure_openai</code> Uses Azure OpenAI  <code>google</code> Uses Google Cloud Speech-to-Text  <code>openai</code> Uses OpenAI Speech to text  <code>groq</code> Uses Groq Speech  <code>deepgram</code> Uses Deepgram Speech-to-Text API  <code>assemblyai</code> Uses AssemblyAI Speech-to-Text API  <code>fal</code> Uses Fal Speech-to-Text API  <code>clova</code> Uses Naver Clova Speech Recognition . Specialized in Japanese, Korean and Chinese languages <code>speechmatics</code> Uses Speechmatics Real-Time API  <code>gladia</code> Uses Gladia Speech-to-Text API  <code>sarvam</code> Uses Sarvam Speech-to-Text API . Optimized for Indian languages <p>This is the description of the columns in the table above:</p> <ul> <li>YAML property: set this value as the <code>provider</code> property in the <code>agent-speech-processing.yaml</code> file to use that provider.</li> <li>Interim results: whether the provider supports interim (non-final) transcription results. See Final vs Interim transcriptions for more details.</li> </ul> <p>Info</p> <ul> <li>You will need an account in the provider's platform to get the necessary credentials.</li> <li>Each provider has its own custom configuration. Some of them provide advanced features such as integrated profanity filters or translation. Check out the configuration reference below for more details.</li> </ul>","tags":["Platform"]},{"location":"docs/ai/live-captions/#tutorial","title":"Tutorial","text":"<p>Check out the Live Captions tutorial for a complete example.</p>","tags":["Platform"]},{"location":"docs/ai/live-captions/#configuration-reference","title":"Configuration reference","text":"<p>Below are the properties related to the Live Captions service available in the <code>agent-speech-processing.yaml</code> file.</p> <pre><code>live_captions:\n  # How this agent will connect to Rooms [automatic, manual]\n  # - automatic: the agent will automatically connect to new Rooms.\n  # - manual: the agent will connect to new Rooms only when your application dictates it by using the Agent Dispatch API.\n  processing: automatic\n\n  # Which speech-to-text AI provider to use [aws, azure, google, openai, groq, deepgram, assemblyai, fal, clova, speechmatics, gladia, sarvam]\n  # The custom configuration for the selected provider must be set below\n  provider:\n\n  aws:\n    # Credentials for AWS Transcribe. See https://docs.aws.amazon.com/transcribe/latest/dg/what-is.html\n    aws_access_key_id:\n    aws_secret_access_key:\n    aws_default_region:\n    # See https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html\n    language:\n    # The name of the custom vocabulary you want to use.\n    # See https://docs.aws.amazon.com/transcribe/latest/dg/custom-vocabulary.html\n    vocabulary_name:\n    # The name of the custom language model you want to use.\n    # See https://docs.aws.amazon.com/transcribe/latest/dg/custom-language-models-using.html\n    language_model_name:\n    # Whether or not to enable partial result stabilization. Partial result stabilization can reduce latency in your output, but may impact accuracy.\n    # See https://docs.aws.amazon.com/transcribe/latest/dg/streaming-partial-results.html#streaming-partial-result-stabilization\n    enable_partial_results_stabilization:\n    # Specify the level of stability to use when you enable partial results stabilization (enable_partial_results_stabilization: true). Valid values: high | medium | low\n    # See https://docs.aws.amazon.com/transcribe/latest/dg/streaming-partial-results.html#streaming-partial-result-stabilization\n    partial_results_stability:\n    # The name of the custom vocabulary filter you want to use to mask or remove words.\n    # See https://docs.aws.amazon.com/transcribe/latest/dg/vocabulary-filtering.html\n    vocab_filter_name:\n    # The method used to filter the vocabulary. Valid values: mask | remove | tag\n    # See https://docs.aws.amazon.com/transcribe/latest/dg/vocabulary-filtering.html\n    vocab_filter_method:\n\n  azure:\n    # Credentials for Azure Speech Service.\n    # One of these combinations must be set:\n    #  - speech_host\n    #  - speech_key + speech_region\n    #  - speech_auth_token + speech_region\n    # See https://learn.microsoft.com/en-us/azure/ai-services/speech-service/get-started-speech-to-text?tabs=macos%2Cterminal&amp;pivots=programming-language-python#prerequisites\n    speech_host:\n    speech_key:\n    speech_auth_token:\n    speech_region:\n    # Azure handles multiple languages and can auto-detect the language used. It requires the candidate set to be set. E.g. [\"en-US\", \"es-ES\"]\n    # See https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=stt#supported-languages\n    language:\n    # Removes profanity (swearing), or replaces letters of profane words with stars. Valid values: Masked | Removed | Raw\n    # See https://learn.microsoft.com/en-us/azure/ai-services/translator/profanity-filtering\n    profanity:\n\n  azure_openai:\n    # Credentials for Azure OpenAI APIs. See https://learn.microsoft.com/en-us/azure/api-management/api-management-authenticate-authorize-azure-openai\n    # Azure OpenAI API key\n    azure_api_key:\n    # Azure Active Directory token\n    azure_ad_token:\n    # Azure OpenAI endpoint in the following format: https://{your-resource-name}.openai.azure.com. Mandatory value.\n    azure_endpoint:\n    # Name of your model deployment. If given with `azure_endpoint`, sets the base client URL to include `/deployments/{azure_deployment}`.\n    azure_deployment:\n    # OpenAI REST API version used for the request. Mandatory value.\n    api_version:\n    # OpenAI organization ID.\n    organization:\n    # OpenAI project ID.\n    project:\n    # The language code to use for transcription (e.g., \"en\" for English).\n    language:\n    # ID of the model to use for speech-to-text.\n    model:\n    # Initial prompt to guide the transcription.\n    prompt:\n\n  google:\n    # Credentials for Google Cloud. This is the content of a Google Cloud credential JSON file.\n    # Below is a dummy example for a credential type of \"Service Account\" (https://cloud.google.com/iam/docs/service-account-creds#key-types)\n    credentials_info: |\n      {\n        \"type\": \"service_account\",\n        \"project_id\": \"my-project\",\n        \"private_key_id\": \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n        \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\\n-----END PRIVATE KEY-----\\n\",\n        \"client_email\": \"my-email@my-project.iam.gserviceaccount.com\",\n        \"client_id\": \"xxxxxxxxxxxxxxxxxxxxx\",\n        \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n        \"token_uri\": \"https://oauth2.googleapis.com/token\",\n        \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n        \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/my-email%40my-project.iam.gserviceaccount.com\",\n        \"universe_domain\": \"googleapis.com\"\n      }\n    # Which model to use for recognition. If not set, uses the default model for the selected language.\n    # See https://cloud.google.com/speech-to-text/docs/transcription-model\n    model:\n    # The location to use for recognition. Default is \"us-central1\". Latency will be best if the location is close to your users.\n    # Check supported languages and locations at https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages\n    location:\n    # List of language codes to recognize. Default is [\"en-US\"].\n    # See https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages\n    languages:\n    # Whether to detect the language of the audio. Default is true.\n    detect_language:\n    # If 'true', adds punctuation to recognition result hypotheses. This feature is only available in select languages. Setting this\n    # for requests in other languages has no effect at all. The default 'false' value does not add punctuation to result hypotheses.\n    # See https://cloud.google.com/speech-to-text/docs/automatic-punctuation\n    punctuate:\n    # The spoken punctuation behavior for the call. If not set, uses default behavior based on model of choice.\n    # e.g. command_and_search will enable spoken punctuation by default. If 'true', replaces spoken punctuation\n    # with the corresponding symbols in the request. For example, \"how are you question mark\" becomes \"how are you?\".\n    # See https://cloud.google.com/speech-to-text/docs/spoken-punctuation for support. If 'false', spoken punctuation is not replaced.\n    spoken_punctuation:\n    # Whether to return interim (non-final) transcription results. Defaults to true.\n    interim_results:\n\n  openai:\n    # API key for OpenAI. See https://platform.openai.com/api-keys\n    api_key:\n    # The OpenAI model to use for transcription. See https://platform.openai.com/docs/guides/speech-to-text\n    model:\n    # The language of the input audio. Supplying the input language in ISO-639-1 format\n    # (https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) will improve accuracy and latency.\n    language:\n    # Optional text prompt to guide the transcription. Only supported for whisper-1.\n    prompt:\n\n  groq:\n    # API key for Groq. See https://console.groq.com/keys\n    api_key:\n    # See https://console.groq.com/docs/speech-to-text\n    model:\n    # The language of the input audio. Supplying the input language in ISO-639-1 format\n    # (https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) will improve accuracy and latency.\n    language:\n    # Prompt to guide the model's style or specify how to spell unfamiliar words. 224 tokens max.\n    prompt:\n\n  deepgram:\n    # See https://console.deepgram.com/\n    api_key:\n    # See https://developers.deepgram.com/reference/speech-to-text-api/listen-streaming#request.query.model\n    model:\n    # See https://developers.deepgram.com/reference/speech-to-text-api/listen-streaming#request.query.language\n    language:\n    # Whether to enable automatic language detection. Defaults to false. See https://developers.deepgram.com/docs/language-detection\n    detect_language: false\n    # Whether to return interim (non-final) transcription results. Defaults to true. See https://developers.deepgram.com/docs/interim-results\n    interim_results: true\n    # Whether to apply smart formatting to numbers, dates, etc. Defaults to false. See https://developers.deepgram.com/docs/smart-format\n    smart_format: false\n    # When smart_format is used, ensures it does not wait for sequence to be complete before returning results. Defaults to true. See https://developers.deepgram.com/docs/smart-format#using-no-delay\n    no_delay: true\n    # Whether to add punctuations to the transcription. Defaults to true. Turn detector will work better with punctuations. See https://developers.deepgram.com/docs/punctuation\n    punctuate: true\n    # Whether to include filler words (um, uh, etc.) in transcription. Defaults to true. See https://developers.deepgram.com/docs/filler-words\n    filler_words: true\n    # Whether to filter profanity from the transcription. Defaults to false. See https://developers.deepgram.com/docs/profanity-filter\n    profanity_filter: false\n    # List of tuples containing keywords and their boost values for improved recognition. Each tuple should be (keyword: str, boost: float). Defaults to None. keywords does not work with Nova-3 models. Use keyterms instead.\n    # keywords:\n    #   - [OpenVidu, 1.5]\n    #   - [WebRTC, 1]\n    # List of key terms to improve recognition accuracy. Defaults to None. keyterms is supported by Nova-3 models.\n    # Commented below is an example\n    keyterms:\n      # - \"OpenVidu\"\n      # - \"WebRTC\"\n\n  assemblyai:\n    # API key for AssemblyAI. See https://www.assemblyai.com/dashboard/api-keys\n    api_key:\n    # Whether to return formatted final transcripts (proper punctuation, letter casing...). If enabled, formatted final transcripts are emitted shortly following an end-of-turn detection.\n    format_turns: true\n\n  fal:\n    # API key for fal. See https://fal.ai/dashboard/keys\n    api_key:\n    # See https://fal.ai/models/fal-ai/wizper/api#schema\n    language:\n\n  clova:\n    # Secret key issued when registering the app\n    api_key:\n    # API Gateway's unique invoke URL created in CLOVA Speech Domain.\n    # See https://guide.ncloud-docs.com/docs/en/clovaspeech-domain#create-domain\n    invoke_url:\n    # See https://api.ncloud-docs.com/docs/en/ai-application-service-clovaspeech-longsentence\n    language:\n    # Value between 0 and 1 indicating the threshold for the confidence score of the transcribed text. Default is 0.5.\n    # If the confidence score is lower than the threshold, the transcription event is not sent to the client.\n    # For a definition of the confidence score see https://api.ncloud-docs.com/docs/en/ai-application-service-clovaspeech-grpc\n    threshold:\n\n  speechmatics:\n    # API key for Speechmatics. See https://portal.speechmatics.com/manage-access/\n    api_key:\n    # ISO 639-1 language code. All languages are global and can understand different dialects/accents. To see the list of all supported languages, see https://docs.speechmatics.com/introduction/supported-languages\n    language:\n    # Operating point to use for the transcription per required accuracy &amp; complexity. To learn more, see https://docs.speechmatics.com/features/accuracy-language-packs#accuracy\n    operating_point:\n    # Partial transcripts allow you to receive preliminary transcriptions and update as more context is available until the higher-accuracy final transcript is returned. Partials are returned faster but without any post-processing such as formatting. See https://docs.speechmatics.com/features/realtime-latency#partial-transcripts\n    enable_partials:\n    # RFC-5646 language code to make spelling rules more consistent in the transcription output. See https://docs.speechmatics.com/features/word-tagging#output-locale\n    output_locale:\n    # The delay in seconds between the end of a spoken word and returning the final transcript results. See https://docs.speechmatics.com/features/realtime-latency#configuration-example\n    max_delay:\n    # See https://docs.speechmatics.com/features/realtime-latency#configuration-example\n    max_delay_mode:\n    # Configuration for speaker diarization. See https://docs.speechmatics.com/features/diarization\n    speaker_diarization_config:\n      # See https://docs.speechmatics.com/features/diarization#max-speakers\n      max_speakers:\n      # See https://docs.speechmatics.com/features/diarization#speaker-sensitivity\n      speaker_sensitivity:\n      # See https://docs.speechmatics.com/features/diarization#prefer-current-speaker\n      prefer_current_speaker:\n    # Permitted punctuation marks for advanced punctuation. See https://docs.speechmatics.com/features/punctuation-settings\n    # Commented is an example of punctuation settings\n    punctuation_overrides:\n      # permitted_marks: [ \".\", \",\" ]\n      # sensitivity: 0.4\n    # See https://docs.speechmatics.com/features/custom-dictionary\n    # Commented below is an example of a custom dictionary\n    additional_vocab:\n      # - content: financial crisis\n      # - content: gnocchi\n      #   sounds_like:\n      #     - nyohki\n      #     - nokey\n      #     - nochi\n      # - content: CEO\n      #   sounds_like:\n      #     - C.E.O.\n\n  gladia:\n    # API key for Gladia. See https://app.gladia.io/account\n    api_key:\n    # Whether to return interim (non-final) transcription results. Defaults to True\n    interim_results:\n    # List of language codes to use for recognition. Defaults to None (auto-detect). See https://docs.gladia.io/chapters/limits-and-specifications/languages\n    languages:\n    # Whether to allow switching between languages during recognition. Defaults to True\n    code_switching:\n\n  sarvam:\n    # API key for Sarvam. See https://dashboard.sarvam.ai/key-management\n    api_key:\n    # BCP-47 language code for supported Indian languages. See https://docs.sarvam.ai/api-reference-docs/speech-to-text/transcribe#request.body.language_code.language_code\n    language:\n    # The Sarvam STT model to use. See https://docs.sarvam.ai/api-reference-docs/speech-to-text/transcribe#request.body.model.model\n    model:\n</code></pre>","tags":["Platform"]},{"location":"docs/ai/overview/","title":"Overview","text":"","tags":["Platform"]},{"location":"docs/ai/overview/#ai-services","title":"AI Services","text":"<p>OpenVidu offers a catalog of AI services that can be easily integrated into your application to enhance the user experience and add advanced features. These services are provided by OpenVidu agents: a set of pre-configured and ready-to-use AI modules.</p> <p>These are the currently available OpenVidu agents:</p> <ul> <li>Speech Processing agent: provides all the AI services related to transcribing audio speech to text and processing the results in various ways.</li> </ul> <p> List of provided AI services  Enable the agent</p>","tags":["Platform"]},{"location":"docs/ai/overview/#speech-processing-agent","title":"Speech Processing agent","text":"<ul> <li> <p> Live Captions</p> <p>Generate live captions for your users' speech with great accuracy and display the results in your frontend.</p> <p> Go to Live Captions</p> </li> <li> <p> Transcription</p> <p>Store the transcriptions of your Rooms in your backend.</p> <p> Coming soon</p> </li> <li> <p> Translation</p> <p>Translate the transcriptions of your Rooms into multiple languages.</p> <p> Coming soon</p> </li> <li> <p> Summary</p> <p>Summarize the transcriptions of your Rooms into concise text.</p> <p> Coming soon</p> </li> <li> <p> Keyword detection</p> <p>Detect keywords in your users' speech and trigger actions based on them.</p> <p> Coming soon</p> </li> <li> <p> Profanity filter</p> <p>Filter profanity words in your users' speech, replacing them with alternative characters.</p> <p> Coming soon</p> </li> </ul>","tags":["Platform"]},{"location":"docs/ai/openvidu-agents/agent-dispatch/","title":"Agent dispatch","text":"","tags":["Platform"]},{"location":"docs/ai/openvidu-agents/agent-dispatch/#openvidu-agents-dispatch","title":"OpenVidu agents dispatch","text":"<p>OpenVidu agents remain idle until they are dispatched to a Room. This idle state may consume some resources, but ensures agents are ready to process Rooms immediately. This is done to optimize resource usage and ensure that agents are only active when needed.</p>","tags":["Platform"]},{"location":"docs/ai/openvidu-agents/agent-dispatch/#automatic-agent-dispatch","title":"Automatic agent dispatch","text":"<p>To configure automatic dispatch for an agent's AI service, set this property in your <code>agent-AGENT_NAME.yaml</code> file:</p> <pre><code>AI_SERVICE:\n    processing: automatic\n</code></pre> <p>Tip</p> <p>For example, for the Live Captions service:</p> <pre><code>live_captions:\n    processing: automatic\n</code></pre> <p>Agents configured with <code>processing: automatic</code> in one of their AI services will immediately join new Rooms and will start processing media tracks as soon as possible. This \"as soon as possible\" moment can vary depending on the type of agent, the AI service that is providing, and its configuration.</p> <p>Automatic dispatch is useful when the same AI service needs to be present in all Rooms, at all times.</p>","tags":["Platform"]},{"location":"docs/ai/openvidu-agents/agent-dispatch/#explicit-agent-dispatch","title":"Explicit agent dispatch","text":"<p>To configure explicit dispatch for an agent's AI service, set this property in your <code>agent-AGENT_NAME.yaml</code> file:</p> <pre><code>AI_SERVICE:\n    processing: manual\n</code></pre> <p>Tip</p> <p>For example, for the Live Captions service:</p> <pre><code>live_captions:\n    processing: manual\n</code></pre> <p>Agents configured with <code>processing: manual</code> in their AI services will not join any Room automatically. Instead, the agent must be explicitly dispatched to the required Room at the required time.</p> <p>Explicit dispatch is useful when you need fine control over which Rooms the agent should process, and when.</p> <p>There are 2 different ways to explicitly dispatch an agent to a specific Room:</p>","tags":["Platform"]},{"location":"docs/ai/openvidu-agents/agent-dispatch/#dispatch-via-api","title":"Dispatch via API","text":"Node.js Go Ruby Java Python .NET Server API <p>Using LiveKit Node SDK </p> <pre><code>import { AgentDispatchClient } from 'livekit-server-sdk';\n\nconst OPENVIDU_URL = 'https://my-openvidu-host';\nconst API_KEY = 'api-key';\nconst API_SECRET = 'api-secret';\n\nconst agentDispatchClient = new AgentDispatchClient(OPENVIDU_URL, API_KEY, API_SECRET);\n\n// create a dispatch request for an agent named \"AGENT_NAME\" to join \"my-room\"\nconst dispatch = await agentDispatchClient.createDispatch('my-room', 'AGENT_NAME');\n\nconsole.log('Dispatch created:', dispatch);\n</code></pre> <p>Using LiveKit Go SDK </p> <pre><code>import (\n    livekit \"github.com/livekit/protocol/livekit\"\n    lksdk \"github.com/livekit/server-sdk-go/v2\"\n)\n\nconst OPENVIDU_URL = \"https://my-openvidu-host\"\nconst API_KEY = \"api-key\"\nconst API_SECRET = \"api-secret\"\n\ndispatchClient := lksdk.NewAgentDispatchServiceClient(OPENVIDU_URL, API_KEY, API_SECRET)\n\n// create a dispatch request for an agent named \"AGENT_NAME\" to join \"my-room\"\ndispatchAgentRequest := &amp;livekit.CreateAgentDispatchRequest{\n    AgentName: \"AGENT_NAME\",\n    Room:      \"my-room\",\n}\ndispatch, err := dispatchClient.CreateDispatch(context.Background(), dispatchAgentRequest)\nif err != nil {\n    panic(err)\n}\n\nfmt.Printf(\"Dispatch created: %v\\n\", dispatch)\n</code></pre> <p>Using LiveKit Ruby SDK </p> <pre><code>require 'livekit'\n\nOPENVIDU_URL = \"https://my-openvidu-host\"\nAPI_KEY = \"api-key\"\nAPI_SECRET = \"api-secret\"\n\nagentDispatchClient = LiveKit::AgentDispatchServiceClient.new(\n    OPENVIDU_URL,\n    api_key: API_KEY,\n    api_secret: API_SECRET\n)\n\n# create a dispatch request for an agent named \"AGENT_NAME\" to join \"my-room\"\nresponse = agentDispatchClient.create_dispatch(roomName, agent)\nif response.error\n    puts \"Error creating dispatch: #{response.error}\"\nelse\n    dispatch = response.data\n    puts \"Dispatch created: #{dispatch}\"\nend\n</code></pre> <p>Using LiveKit Kotlin SDK </p> <pre><code>import io.livekit.server.AgentDispatchServiceClient;\nimport livekit.LivekitAgentDispatch.AgentDispatch;\n\nfinal String  OPENVIDU_URL = \"https://my-openvidu-host\";\nfinal String  API_KEY = \"api-key\";\nfinal String  API_SECRET = \"api-secret\";\n\nAgentDispatchServiceClient agentDispatchClient = AgentDispatchServiceClient.createClient(\n    OPENVIDU_URL,\n    API_KEY,\n    API_SECRET\n);\n\n// create a dispatch request for an agent named \"AGENT_NAME\" to join \"my-room\"\nAgentDispatch dispatch = agentDispatchClient.createDispatch(\"my-room\", \"AGENT_NAME\")\n    .execute().body();\n\nSystem.out.println(\"Dispatch created: \" + dispatch.getId());\n</code></pre> <p>Using LiveKit Python SDK </p> <pre><code>from livekit.api import LiveKitAPI, CreateAgentDispatchRequest\n\nOPENVIDU_URL = \"https://my-openvidu-host\"\nAPI_KEY = \"api-key\"\nAPI_SECRET = \"api-secret\"\n\nlkapi = LiveKitAPI(\n    url=OPENVIDU_URL, api_key=API_KEY, api_secret=API_SECRET\n)\n\n# create a dispatch request for an agent named \"AGENT_NAME\" to join \"my-room\"\nrequest = CreateAgentDispatchRequest(\n    agent_name=\"AGENT_NAME\",\n    room=\"my-room\",\n)\ndispatch = await lkapi.agent_dispatch.create_dispatch(request)\n\nprint(\"Dispatch created:\\n\", dispatch)\n</code></pre> <p>Using LiveKit .NET SDK </p> <pre><code>using Livekit.Server.Sdk.Dotnet;\n\nconst string OPENVIDU_URL = \"https://my-openvidu-host\";\nconst string API_KEY = \"api-key\";\nconst string API_SECRET = \"api-secret\";\n\nAgentDispatchServiceClient agentDispatchServiceClient = new AgentDispatchServiceClient(\n    OPENVIDU_URL,\n    API_KEY,\n    API_SECRET\n);\n\n// create a dispatch request for an agent named \"AGENT_NAME\" to join \"my-room\"\nvar agentDispatch = await agentDispatchServiceClient.CreateDispatch(new CreateAgentDispatchRequest\n{\n    AgentName = \"AGENT_NAME\",\n    Room = \"my-room\"\n});\nConsole.Out.WriteLine(\"Dispatch created: \" + agentDispatch.Id);\n</code></pre> <p>If your backend technology does not have its own SDK, you have two different options:</p> <ol> <li> <p>Consume the Agent Dispatch API directly:</p> <pre><code>curl -X POST https://my-openvidu-host/twirp/livekit.AgentDispatchService/CreateDispatch \\\n     -H \"Authorization: Bearer VALID_AUTHORIZATION_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"agent_name\": \"AGENT_NAME\", \"room\": \"my-room\"}'\n</code></pre> <p>You need as <code>VALID_AUTHORIZATION_TOKEN</code> a token with <code>room</code> and <code>roomAdmin</code> permissions. Visit LiveKit docs: Creating a token </p> <p></p> </li> <li> <p>Use the livekit-cli :</p> <pre><code>export LIVEKIT_URL=https://my-openvidu-host\nexport LIVEKIT_API_KEY=api-key\nexport LIVEKIT_API_SECRET=secret-key\n\nlk dispatch create \\\n    --agent-name AGENT_NAME \\\n    --room my-room\n</code></pre> </li> </ol> <p>Notes about the Agent Dispatch API</p> <ul> <li>The <code>agent_name</code> field must match the <code>AGENT_NAME</code> you used in the <code>agent-AGENT_NAME.yaml</code> file.</li> <li>The <code>room</code> field must match the <code>room</code> where you want to dispatch the agent.</li> </ul>","tags":["Platform"]},{"location":"docs/ai/openvidu-agents/agent-dispatch/#dispatch-via-a-participant-connection","title":"Dispatch via a Participant connection","text":"<p>You can configure a Participant's token to trigger the dispatch of an agent right at the moment that Participant connects to a Room. This is very useful to dispatch an agent to a specific Room only when a specific Participant joins.</p> <p>To create a Participant's token with Agent dispatch, you just need to include in the token the proper <code>RoomConfiguration</code> options, specifically the <code>agents</code> property. Visit LiveKit docs  to learn how.</p>","tags":["Platform"]},{"location":"docs/ai/openvidu-agents/overview/","title":"Overview","text":"","tags":["Platform"]},{"location":"docs/ai/openvidu-agents/overview/#openvidu-agents-overview","title":"OpenVidu agents: overview","text":"","tags":["Platform"]},{"location":"docs/ai/openvidu-agents/overview/#basic-concepts","title":"Basic concepts","text":"<p>The modules that provide AI services in OpenVidu are called OpenVidu agents. They are pre-configured and ready-to-use AI modules. OpenVidu agents interact with your Rooms in real time using the powerful LiveKit Agents framework .</p> <p>All OpenVidu agents follow the following general principles:</p> <ul> <li>Agents run in your OpenVidu nodes: in OpenVidu Single Node, agents run in the same node. In OpenVidu Elastic and OpenVidu High Availability, agents run in Media Nodes. They run as Docker containers, just like any other OpenVidu service.</li> <li>Agents are configured through YAML files: you just have to add a file <code>agent-AGENT_NAME.yaml</code> to the configuration folder of your OpenVidu deployment, and the agent will be automatically launched. This declarative approach makes agents easy to deploy, manage and scale.</li> </ul> <p>In more detail, each OpenVidu agent adheres to the following principles:</p> <ul> <li>Each agent is automatically deployed as a Docker container once per node: once in the only node of an OpenVidu Single Node deployment, and once in each Media Node of OpenVidu Elastic and OpenVidu High Availability deployments.</li> <li>Each agent is downloaded in background during OpenVidu startup: take into account that it might not be available immediately after OpenVidu starts, as it may take some time to download the agent image from the Docker registry.</li> <li>Each agent is identified, configured and deployed declaratively via its own <code>agent-AGENT_NAME.yaml</code> file: your OpenVidu deployment will detect agent YAML files and will automatically launch and configure them. <code>AGENT_NAME</code> must be a unique identifier per agent.</li> <li>Each agent container of each node can process multiple Rooms simultaneously: the limit is set by the node's hardware.</li> <li>Each enabled agent remains always running: this happens even when not processing any Rooms. This idle state may consume some resources, but ensures that agents are ready to process Rooms immediately.</li> </ul>","tags":["Platform"]},{"location":"docs/ai/openvidu-agents/overview/#list-of-available-openvidu-agents","title":"List of available OpenVidu agents","text":"<ul> <li>Speech Processing agent: provides all the AI services related to transcribing audio speech to text and processing the results in various ways.</li> </ul> <p> List of provided AI services  Enable the agent</p>","tags":["Platform"]},{"location":"docs/ai/openvidu-agents/overview/#troubleshooting-openvidu-agents","title":"Troubleshooting OpenVidu agents","text":"<p>Sometimes agents fail to process a Room. Sometimes they don't even start properly. This is usually due to some misconfiguration, such as incorrect credentials in the agent configuration.</p> <p>The best way to troubleshoot a failing agent is to check its logs. To do so:</p> OpenVidu Local (Development)OpenVidu Single NodeOpenVidu ElasticOpenVidu High Availability <pre><code>docker logs agent-AGENT_NAME\n</code></pre> <ul> <li> <p>You can search for the logs in your Grafana dashboard.</p> </li> <li> <p>Or SSH into the single OpeVidu node and check docker logs:</p> <pre><code>docker logs agent-AGENT_NAME\n</code></pre> </li> </ul> <ul> <li> <p>You can search for the logs in your Grafana dashboard.</p> </li> <li> <p>You can also SSH into the Media Node where the problematic agent is running and check docker logs:</p> <pre><code>docker logs agent-AGENT_NAME\n</code></pre> </li> </ul> <ul> <li> <p>You can search for the logs in your Grafana dashboard.</p> </li> <li> <p>You can also SSH into the Media Node where the problematic agent is running and check docker logs:</p> <pre><code>docker logs agent-AGENT_NAME\n</code></pre> </li> </ul>","tags":["Platform"]},{"location":"docs/ai/openvidu-agents/speech-processing-agent/","title":"Speech Processing agent","text":"","tags":["Platform"]},{"location":"docs/ai/openvidu-agents/speech-processing-agent/#speech-processing-agent","title":"Speech Processing agent","text":"<p>The Speech Processing agent provides all the AI services related to transcribing audio speech to text and processing the results in various ways.</p>","tags":["Platform"]},{"location":"docs/ai/openvidu-agents/speech-processing-agent/#list-of-provided-ai-services","title":"List of provided AI services","text":"<ul> <li>Live Captions: transcribe the audio tracks of your Rooms in real time with great accuracy and display the results as live captions in your frontend.</li> </ul>","tags":["Platform"]},{"location":"docs/ai/openvidu-agents/speech-processing-agent/#enable-the-agent-and-configure-ai-services","title":"Enable the agent and configure AI services","text":"","tags":["Platform"]},{"location":"docs/ai/openvidu-agents/speech-processing-agent/#1-ssh-into-an-openvidu-node-and-go-to-configuration-folder","title":"1. SSH into an OpenVidu Node and go to configuration folder","text":"<p>Depending on your OpenVidu deployment type:</p> OpenVidu Local (Development)OpenVidu Single NodeOpenVidu ElasticOpenVidu High Availability <p>If you are using OpenVidu Local (Development), simply navigate to the configuration folder of the project:</p> <pre><code># For OpenVidu Local COMMUNITY\ncd openvidu-local-deployment/community\n\n# For OpenVidu Local PRO\ncd openvidu-local-deployment/pro\n</code></pre> <p>If you are using OpenVidu Single Node, SSH into the only OpenVidu node and navigate to:</p> <pre><code>cd /opt/openvidu/config\n</code></pre> <p>If you are using OpenVidu Elastic, SSH into the only Master Node and navigate to:</p> <pre><code>cd /opt/openvidu/config/cluster/media_node\n</code></pre> <p>If you are using OpenVidu High Availability, SSH into any of your Master Nodes (doesn't matter which one) and navigate to:</p> <pre><code>cd /opt/openvidu/config/cluster/media_node\n</code></pre>","tags":["Platform"]},{"location":"docs/ai/openvidu-agents/speech-processing-agent/#2-modify-file-agent-speech-processingyaml","title":"2. Modify file <code>agent-speech-processing.yaml</code>","text":"<p>Locate file <code>agent-speech-processing.yaml</code> in the configuration folder of your OpenVidu node. Modify this file to enable the agent and configure the desired AI services.</p>","tags":["Platform"]},{"location":"docs/ai/openvidu-agents/speech-processing-agent/#enable-the-agent","title":"Enable the agent","text":"<pre><code>enabled: true\n</code></pre>","tags":["Platform"]},{"location":"docs/ai/openvidu-agents/speech-processing-agent/#configure-the-desired-ai-services","title":"Configure the desired AI services","text":"<p>You can set up the following AI services in this agent:</p> <ul> <li>Live Captions: see Live Captions service.</li> </ul>","tags":["Platform"]},{"location":"docs/ai/openvidu-agents/speech-processing-agent/#3-restart-openvidu","title":"3. Restart OpenVidu","text":"<p>Depending on your OpenVidu deployment type:</p> OpenVidu Local (Development)OpenVidu Single NodeOpenVidu ElasticOpenVidu High Availability <p>Run where <code>docker-compose.yaml</code> is located:</p> <pre><code>docker compose restart\n</code></pre> <p>Run this command in your node:</p> <pre><code>sudo systemctl restart openvidu\n</code></pre> <p>Run this command in your Master Node:</p> <pre><code>sudo systemctl restart openvidu\n</code></pre> <p>Run this command in one of your Master Nodes:</p> <pre><code>sudo systemctl restart openvidu\n</code></pre> <p>After restarting OpenVidu your agent will be up and running, ready to process new Rooms.</p> <p>Warning</p> <p>If your agent container keeps restarting, there might be an error in your configuration. Check its logs to find out what is wrong.</p>","tags":["Platform"]},{"location":"docs/ai/openvidu-agents/speech-processing-agent/#change-cpu-load-threshold","title":"Change CPU load threshold","text":"<p>By default, the agent will only accept new jobs if the average CPU load of its Media Node is below 70%. You can change this threshold in <code>agent-speech-processing.yaml</code>:</p> agent-speech-processing.yaml<pre><code># Maximum CPU load threshold for the agent to accept new jobs. Value between 0 and 1.\nload_threshold: 0.7\n</code></pre>","tags":["Platform"]},{"location":"docs/ai/openvidu-agents/speech-processing-agent/#log-level","title":"Log level","text":"<p>You can change the log level of the agent in <code>agent-speech-processing.yaml</code>:</p> agent-speech-processing.yaml<pre><code># Log level for the agent [DEBUG, INFO, WARNING, ERROR, CRITICAL]\nlog_level: INFO\n</code></pre>","tags":["Platform"]},{"location":"docs/ai/openvidu-agents/speech-processing-agent/#configuration-reference","title":"Configuration reference","text":"<p>Below is the full list of configuration properties available for the Speech Processing agent.</p> agent-speech-processing.yaml<pre><code># Docker image of the agent.\ndocker_image: docker.io/openvidu/agent-speech-processing:3.4.0\n\n# Whether to run the agent or not.\nenabled: false\n\n# Maximum CPU load threshold for the agent to accept new jobs. Value between 0 and 1.\nload_threshold: 0.7\n\n# Log level for the agent [DEBUG, INFO, WARNING, ERROR, CRITICAL]\nlog_level: INFO\n\nlive_captions:\n  # How this agent will connect to Rooms [automatic, manual]\n  # - automatic: the agent will automatically connect to new Rooms.\n  # - manual: the agent will connect to new Rooms only when your application dictates it by using the Agent Dispatch API.\n  processing: automatic\n\n  # Which speech-to-text AI provider to use [aws, azure, google, openai, groq, deepgram, assemblyai, fal, clova, speechmatics, gladia, sarvam]\n  # The custom configuration for the selected provider must be set below\n  provider:\n\n  aws:\n    # Credentials for AWS Transcribe. See https://docs.aws.amazon.com/transcribe/latest/dg/what-is.html\n    aws_access_key_id:\n    aws_secret_access_key:\n    aws_default_region:\n    # See https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html\n    language:\n    # The name of the custom vocabulary you want to use.\n    # See https://docs.aws.amazon.com/transcribe/latest/dg/custom-vocabulary.html\n    vocabulary_name:\n    # The name of the custom language model you want to use.\n    # See https://docs.aws.amazon.com/transcribe/latest/dg/custom-language-models-using.html\n    language_model_name:\n    # Whether or not to enable partial result stabilization. Partial result stabilization can reduce latency in your output, but may impact accuracy.\n    # See https://docs.aws.amazon.com/transcribe/latest/dg/streaming-partial-results.html#streaming-partial-result-stabilization\n    enable_partial_results_stabilization:\n    # Specify the level of stability to use when you enable partial results stabilization (enable_partial_results_stabilization: true). Valid values: high | medium | low\n    # See https://docs.aws.amazon.com/transcribe/latest/dg/streaming-partial-results.html#streaming-partial-result-stabilization\n    partial_results_stability:\n    # The name of the custom vocabulary filter you want to use to mask or remove words.\n    # See https://docs.aws.amazon.com/transcribe/latest/dg/vocabulary-filtering.html\n    vocab_filter_name:\n    # The method used to filter the vocabulary. Valid values: mask | remove | tag\n    # See https://docs.aws.amazon.com/transcribe/latest/dg/vocabulary-filtering.html\n    vocab_filter_method:\n\n  azure:\n    # Credentials for Azure Speech Service.\n    # One of these combinations must be set:\n    #  - speech_host\n    #  - speech_key + speech_region\n    #  - speech_auth_token + speech_region\n    # See https://learn.microsoft.com/en-us/azure/ai-services/speech-service/get-started-speech-to-text?tabs=macos%2Cterminal&amp;pivots=programming-language-python#prerequisites\n    speech_host:\n    speech_key:\n    speech_auth_token:\n    speech_region:\n    # Azure handles multiple languages and can auto-detect the language used. It requires the candidate set to be set. E.g. [\"en-US\", \"es-ES\"]\n    # See https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=stt#supported-languages\n    language:\n    # Removes profanity (swearing), or replaces letters of profane words with stars. Valid values: Masked | Removed | Raw\n    # See https://learn.microsoft.com/en-us/azure/ai-services/translator/profanity-filtering\n    profanity:\n\n  azure_openai:\n    # Credentials for Azure OpenAI APIs. See https://learn.microsoft.com/en-us/azure/api-management/api-management-authenticate-authorize-azure-openai\n    # Azure OpenAI API key\n    azure_api_key:\n    # Azure Active Directory token\n    azure_ad_token:\n    # Azure OpenAI endpoint in the following format: https://{your-resource-name}.openai.azure.com. Mandatory value.\n    azure_endpoint:\n    # Name of your model deployment. If given with `azure_endpoint`, sets the base client URL to include `/deployments/{azure_deployment}`.\n    azure_deployment:\n    # OpenAI REST API version used for the request. Mandatory value.\n    api_version:\n    # OpenAI organization ID.\n    organization:\n    # OpenAI project ID.\n    project:\n    # The language code to use for transcription (e.g., \"en\" for English).\n    language:\n    # ID of the model to use for speech-to-text.\n    model:\n    # Initial prompt to guide the transcription.\n    prompt:\n\n  google:\n    # Credentials for Google Cloud. This is the content of a Google Cloud credential JSON file.\n    # Below is a dummy example for a credential type of \"Service Account\" (https://cloud.google.com/iam/docs/service-account-creds#key-types)\n    credentials_info: |\n      {\n        \"type\": \"service_account\",\n        \"project_id\": \"my-project\",\n        \"private_key_id\": \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n        \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\\n-----END PRIVATE KEY-----\\n\",\n        \"client_email\": \"my-email@my-project.iam.gserviceaccount.com\",\n        \"client_id\": \"xxxxxxxxxxxxxxxxxxxxx\",\n        \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n        \"token_uri\": \"https://oauth2.googleapis.com/token\",\n        \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n        \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/my-email%40my-project.iam.gserviceaccount.com\",\n        \"universe_domain\": \"googleapis.com\"\n      }\n    # Which model to use for recognition. If not set, uses the default model for the selected language.\n    # See https://cloud.google.com/speech-to-text/docs/transcription-model\n    model:\n    # The location to use for recognition. Default is \"us-central1\". Latency will be best if the location is close to your users.\n    # Check supported languages and locations at https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages\n    location:\n    # List of language codes to recognize. Default is [\"en-US\"].\n    # See https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages\n    languages:\n    # Whether to detect the language of the audio. Default is true.\n    detect_language:\n    # If 'true', adds punctuation to recognition result hypotheses. This feature is only available in select languages. Setting this\n    # for requests in other languages has no effect at all. The default 'false' value does not add punctuation to result hypotheses.\n    # See https://cloud.google.com/speech-to-text/docs/automatic-punctuation\n    punctuate:\n    # The spoken punctuation behavior for the call. If not set, uses default behavior based on model of choice.\n    # e.g. command_and_search will enable spoken punctuation by default. If 'true', replaces spoken punctuation\n    # with the corresponding symbols in the request. For example, \"how are you question mark\" becomes \"how are you?\".\n    # See https://cloud.google.com/speech-to-text/docs/spoken-punctuation for support. If 'false', spoken punctuation is not replaced.\n    spoken_punctuation:\n    # Whether to return interim (non-final) transcription results. Defaults to true.\n    interim_results:\n\n  openai:\n    # API key for OpenAI. See https://platform.openai.com/api-keys\n    api_key:\n    # The OpenAI model to use for transcription. See https://platform.openai.com/docs/guides/speech-to-text\n    model:\n    # The language of the input audio. Supplying the input language in ISO-639-1 format\n    # (https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) will improve accuracy and latency.\n    language:\n    # Optional text prompt to guide the transcription. Only supported for whisper-1.\n    prompt:\n\n  groq:\n    # API key for Groq. See https://console.groq.com/keys\n    api_key:\n    # See https://console.groq.com/docs/speech-to-text\n    model:\n    # The language of the input audio. Supplying the input language in ISO-639-1 format\n    # (https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) will improve accuracy and latency.\n    language:\n    # Prompt to guide the model's style or specify how to spell unfamiliar words. 224 tokens max.\n    prompt:\n\n  deepgram:\n    # See https://console.deepgram.com/\n    api_key:\n    # See https://developers.deepgram.com/reference/speech-to-text-api/listen-streaming#request.query.model\n    model:\n    # See https://developers.deepgram.com/reference/speech-to-text-api/listen-streaming#request.query.language\n    language:\n    # Whether to enable automatic language detection. Defaults to false. See https://developers.deepgram.com/docs/language-detection\n    detect_language: false\n    # Whether to return interim (non-final) transcription results. Defaults to true. See https://developers.deepgram.com/docs/interim-results\n    interim_results: true\n    # Whether to apply smart formatting to numbers, dates, etc. Defaults to true. See https://developers.deepgram.com/docs/smart-format\n    smart_format: true\n    # When smart_format is used, ensures it does not wait for sequence to be complete before returning results. Defaults to true. See https://developers.deepgram.com/docs/smart-format#using-no-delay\n    no_delay: true\n    # Whether to add punctuations to the transcription. Defaults to true. Turn detector will work better with punctuations. See https://developers.deepgram.com/docs/punctuation\n    punctuate: true\n    # Whether to include filler words (um, uh, etc.) in transcription. Defaults to true. See https://developers.deepgram.com/docs/filler-words\n    filler_words: true\n    # Whether to filter profanity from the transcription. Defaults to false. See https://developers.deepgram.com/docs/profanity-filter\n    profanity_filter: false\n    # List of tuples containing keywords and their boost values for improved recognition. Each tuple should be (keyword: str, boost: float). Defaults to None. keywords does not work with Nova-3 models. Use keyterms instead.\n    # keywords:\n    #   - [OpenVidu, 1.5]\n    #   - [WebRTC, 1]\n    # List of key terms to improve recognition accuracy. Defaults to None. keyterms is supported by Nova-3 models.\n    # Commented below is an example\n    keyterms:\n      # - \"OpenVidu\"\n      # - \"WebRTC\"\n\n  assemblyai:\n    # API key for AssemblyAI. See https://www.assemblyai.com/dashboard/api-keys\n    api_key:\n    # Whether to return formatted final transcripts (proper punctuation, letter casing...). If enabled, formatted final transcripts are emitted shortly following an end-of-turn detection.\n    format_turns: true\n\n  fal:\n    # API key for fal. See https://fal.ai/dashboard/keys\n    api_key:\n    # See https://fal.ai/models/fal-ai/wizper/api#schema\n    language:\n\n  clova:\n    # Secret key issued when registering the app\n    api_key:\n    # API Gateway's unique invoke URL created in CLOVA Speech Domain.\n    # See https://guide.ncloud-docs.com/docs/en/clovaspeech-domain#create-domain\n    invoke_url:\n    # See https://api.ncloud-docs.com/docs/en/ai-application-service-clovaspeech-longsentence\n    language:\n    # Value between 0 and 1 indicating the threshold for the confidence score of the transcribed text. Default is 0.5.\n    # If the confidence score is lower than the threshold, the transcription event is not sent to the client.\n    # For a definition of the confidence score see https://api.ncloud-docs.com/docs/en/ai-application-service-clovaspeech-grpc\n    threshold:\n\n  speechmatics:\n    # API key for Speechmatics. See https://portal.speechmatics.com/manage-access/\n    api_key:\n    # ISO 639-1 language code. All languages are global and can understand different dialects/accents. To see the list of all supported languages, see https://docs.speechmatics.com/introduction/supported-languages\n    language:\n    # Operating point to use for the transcription per required accuracy &amp; complexity. To learn more, see https://docs.speechmatics.com/features/accuracy-language-packs#accuracy\n    operating_point:\n    # Partial transcripts allow you to receive preliminary transcriptions and update as more context is available until the higher-accuracy final transcript is returned. Partials are returned faster but without any post-processing such as formatting. See https://docs.speechmatics.com/features/realtime-latency#partial-transcripts\n    enable_partials:\n    # RFC-5646 language code to make spelling rules more consistent in the transcription output. See https://docs.speechmatics.com/features/word-tagging#output-locale\n    output_locale:\n    # The delay in seconds between the end of a spoken word and returning the final transcript results. See https://docs.speechmatics.com/features/realtime-latency#configuration-example\n    max_delay:\n    # See https://docs.speechmatics.com/features/realtime-latency#configuration-example\n    max_delay_mode:\n    # Configuration for speaker diarization. See https://docs.speechmatics.com/features/diarization\n    speaker_diarization_config:\n      # See https://docs.speechmatics.com/features/diarization#max-speakers\n      max_speakers:\n      # See https://docs.speechmatics.com/features/diarization#speaker-sensitivity\n      speaker_sensitivity:\n      # See https://docs.speechmatics.com/features/diarization#prefer-current-speaker\n      prefer_current_speaker:\n    # Permitted punctuation marks for advanced punctuation. See https://docs.speechmatics.com/features/punctuation-settings\n    # Commented is an example of punctuation settings\n    punctuation_overrides:\n      # permitted_marks: [ \".\", \",\" ]\n      # sensitivity: 0.4\n    # See https://docs.speechmatics.com/features/custom-dictionary\n    # Commented below is an example of a custom dictionary\n    additional_vocab:\n      # - content: financial crisis\n      # - content: gnocchi\n      #   sounds_like:\n      #     - nyohki\n      #     - nokey\n      #     - nochi\n      # - content: CEO\n      #   sounds_like:\n      #     - C.E.O.\n\n  gladia:\n    # API key for Gladia. See https://app.gladia.io/account\n    api_key:\n    # Whether to return interim (non-final) transcription results. Defaults to True\n    interim_results:\n    # List of language codes to use for recognition. Defaults to None (auto-detect). See https://docs.gladia.io/chapters/limits-and-specifications/languages\n    languages:\n    # Whether to allow switching between languages during recognition. Defaults to True\n    code_switching:\n\n  sarvam:\n    # API key for Sarvam. See https://dashboard.sarvam.ai/key-management\n    api_key:\n    # BCP-47 language code for supported Indian languages. See https://docs.sarvam.ai/api-reference-docs/speech-to-text/transcribe#request.body.language_code.language_code\n    language:\n    # The Sarvam STT model to use. See https://docs.sarvam.ai/api-reference-docs/speech-to-text/transcribe#request.body.model.model\n    model:\n</code></pre>","tags":["Platform"]},{"location":"docs/developing-your-openvidu-app/","title":"Developing your OpenVidu app","text":"","tags":["Platform"]},{"location":"docs/developing-your-openvidu-app/#developing-your-openvidu-application","title":"Developing your OpenVidu application","text":"<p>Here's a high-level overview of the steps involved in building an OpenVidu application:</p> <ol> <li>Launch an OpenVidu deployment</li> <li>Use LiveKit Server SDK in your application server</li> <li>Build the UI of your client application</li> <li>Deploy OpenVidu and your application</li> </ol>","tags":["Platform"]},{"location":"docs/developing-your-openvidu-app/#1-launch-an-openvidu-deployment","title":"1. Launch an OpenVidu deployment","text":"<p>The quickest way is to use OpenVidu local deployment.</p> <p>If you feel like it, you can directly launch a production-ready deployment on AWS, Azure or your own servers. Check out the different options at Deployment types.</p>","tags":["Platform"]},{"location":"docs/developing-your-openvidu-app/#2-use-livekit-server-sdk-in-your-application-server","title":"2. Use LiveKit Server SDK in your application server","text":"<p>OpenVidu is fully compatibly with LiveKit APIs. This means that any LiveKit Server SDK can be used in your application server.</p> <p>The only mandatory task to perform in your application server is:</p> <ul> <li>Creating access tokens. Your Participants will only be able to connect to your Rooms by using a valid access token. Visit the official documentation about Authentication  to learn how to generate access tokens and which permissions you can assign to them.</li> </ul> <p>There are other optional tasks that you can perform from your application server, depending on your requirements:</p> <ul> <li>Manage your Rooms and Participants: although most of your application logic will be in the frontend, you can also manage the logic of your Rooms and Participants from the security of your application backend. You can list, create, update and destroy Rooms and Participants. This is the official LiveKit documentation with all the available methods of the <code>RoomServiceClient</code>  exposed by the Server API. These methods are also available in all LiveKit Server SDKs.</li> <li>Manage Egress and Ingress: if your application needs some kind of recording, broadcasting or media ingestion, this operations must all be performed by your application server.</li> <li>Receive Webhook events: you can also listen to Webhook events in your application backend. In this way you can react to events happening in your Rooms: a Room has started, a Room has finished, a Participant has joined a Room, a Track has been published... Visit the official documentation about Webhooks .</li> <li>Publish Tracks from your backend: this is only for advanced applications that require server-side media publishing. Publishing media from your backend is possible by using LiveKit CLI , Python SDK , Go SDK , Node.js SDK  or Rust SDK .</li> </ul> <p>To get you started, here is a list of all available LiveKit Server SDKs and an application server tutorial using them. These tutorials are all set up to generate access tokens and receive webhook events, so they are perfect starting points for your application server.</p>  Node.js Go Ruby Java Python Rust PHP .NET Server API <p> Node.js Tutorial</p> <p> Reference Docs</p> <p> Go Tutorial</p> <p> Reference Docs</p> <p> Ruby Tutorial</p> <p> GitHub Repository</p> <p> Java Tutorial</p> <p> GitHub Repository</p> <p> Python Tutorial</p> <p> GitHub Repository</p> <p> Rust Tutorial</p> <p> Reference Docs</p> <p> PHP Tutorial</p> <p> GitHub Repository</p> <p> .NET Tutorial</p> <p> GitHub Repository</p> <p>If your backend technology does not have its own SDK, you have two different options:</p> <ol> <li> <p>Consume the Server API directly:  Reference Docs</p> </li> <li> <p>Use the livekit-cli:  GitHub Repository</p> </li> </ol>","tags":["Platform"]},{"location":"docs/developing-your-openvidu-app/#3-build-the-ui-of-your-client-application","title":"3. Build the UI of your client application","text":"<p>There are two main strategies to build the UI of your client application:</p> <ul> <li>Use a high-level UI Components library: you can use Angular Components and React Components to quickly set up your UI with building blocks that manage the events and state of the Room for you.</li> <li>Use a low-level client SDK: if you want extensive control and maximum flexibility when designing your UI, use any of the LiveKit Client SDKs .</li> </ul> <p>The table below summarizes the key differences between these two strategies to help you make an informed decision:</p> UI Components Low-level client SDKs What is it? Frontend libraries offering videoconferencing components to build your own application. There are Angular Components or React Components Integrate OpenVidu from scratch in your web, mobile or desktop application using LiveKit Client SDKs  Pros <ul><li>Very flexible components: adapt, extend or replace any component</li><li>Have your first version running in minutes, work on your customizations from there</li><li>Easily keep your client code up to date with the latest features</li></ul> <ul><li>Unlimited level of customization: build your own UI from scratch as you please</li><li>Available for all client platforms: browsers, iOS, Android, Flutter, React Native, Unity...</li></ul> Cons <ul><li>Only available for Angular and React web apps</li></ul> <ul><li>Higher complexity, although there are plenty of tutorials to smooth the learning curve</li></ul> Tutorials Angular Components tutorials Application client tutorials <p>Whatever strategy you choose to build the UI of your application, most common steps to perform are:</p> <ul> <li>Connect to a Room with an access token: the application client will connect to a Room with an access token generated by your application server. Once connected, the client becomes a Participant of the Room.</li> <li>Publish Tracks to the Room: the application client may create Tracks of any kind (audio from the microphone, video from the camera device, screen sharing from an application...) and publish them to the Room.</li> <li>Subscribe to Tracks from other Participants: the application client may receive the Tracks published by other Participants in the Room. It is possible to perform selective subscription, so the client can choose which Tracks to specifically subscribe to.</li> <li>Mute and unmute Tracks: the application client may mute and unmute its own Tracks, and also may disable the reception of any Track published by other Participants.</li> </ul> <p>Of course, depending on the use case, this may not be necessary for all users, or other additional steps may need to be taken. For example, in a live-streaming application, only presenters will publish Tracks, while all other viewers will only subscribe to them. Or it is possible that users may need exchange messages through a chat. Each specific application will need to refine its use of the UI Components or client SDKs to meet its requirements.</p> <p>Here is the list of all LiveKit Client SDKs: LiveKit Client SDKs . Below is a list of application client tutorials, which are perfect starting points for your client application.</p> <p> JavaScript</p> <p> React</p> <p> Angular</p> <p> Vue</p> <p> Electron</p> <p> Ionic</p> <p> Android</p> <p> iOS</p>","tags":["Platform"]},{"location":"docs/developing-your-openvidu-app/#4-deploy-openvidu-and-your-application","title":"4. Deploy OpenVidu and your application","text":"<p>You have different options to deploy OpenVidu in a production-ready environment, depending on the level of scalability, fault tolerance and observability you need. See Deployment types for more information.</p>","tags":["Platform"]},{"location":"docs/developing-your-openvidu-app/how-to/","title":"How to develop your OpenVidu app","text":"","tags":["Platform"]},{"location":"docs/developing-your-openvidu-app/how-to/#how-to-develop-your-openvidu-application","title":"How to develop your OpenVidu application","text":"<p>This page is a collection of the most common operations you may want to perform in your application while integrating OpenVidu. Depending on the scope of the operation, these operations will be performed on the client side using a LiveKit Client SDK, or on the server side using a LiveKit Server SDK (or directly using the HTTP server API). Consider the architecture of an OpenVidu application:</p> <p></p> <p>You can use this page as a cheat sheet to know at a glance how to do something, and you have links to the LiveKit reference documentation of each operation for a more detailed explanation.</p> <p>All client side operations are exemplified using the LiveKit JS Client SDK . For other client SDKs, refer to the corresponding LiveKit reference documentation.</p>","tags":["Platform"]},{"location":"docs/developing-your-openvidu-app/how-to/#generate-access-tokens","title":"Generate access tokens","text":"<p>The application client needs an access token to connect to a Room. This token must be generated by the application server. Visit LiveKit reference documentation to learn how to generate access tokens:</p> <p> Reference docs</p>","tags":["Platform"]},{"location":"docs/developing-your-openvidu-app/how-to/#manage-rooms","title":"Manage Rooms","text":"","tags":["Platform"]},{"location":"docs/developing-your-openvidu-app/how-to/#connect-to-a-room","title":"Connect to a Room","text":"<p>To connect to a Room you need the URL of your OpenVidu deployment (which is a WebSocket URL) and the access token generated by your application server.</p> <pre><code>import { Room } from \"livekit-client\";\n\nconst room = new Room();\nawait room.connect(wsUrl, token);\n</code></pre> <p> Reference docs</p>","tags":["Platform"]},{"location":"docs/developing-your-openvidu-app/how-to/#disconnect-from-a-room","title":"Disconnect from a Room","text":"<pre><code>await room.disconnect();\n</code></pre> <p> Reference docs</p>","tags":["Platform"]},{"location":"docs/developing-your-openvidu-app/how-to/#publish-a-track","title":"Publish a Track","text":"<p>You can directly publish the default camera and microphone of the device using methods <code>setCameraEnabled</code> and <code>setMicrophoneEnabled</code> of the <code>LocalParticipant</code> object:</p> <pre><code>// Publish a video track from the default camera\nawait room.localParticipant.setCameraEnabled(true);\n// Publish an audio track from the default microphone\nawait room.localParticipant.setMicrophoneEnabled(true);\n</code></pre> <p>It is also possible to publish both of them at the same time using method <code>LocalParticipant.enableCameraAndMicrophone</code>, which has the advantage of showing a single permission dialog to the user:</p> <pre><code>// Publish both default video and audio tracks triggering a single permission dialog\nawait room.localParticipant.enableCameraAndMicrophone();\n</code></pre> <p>To craft a custom Track, you can use the <code>LocalParticipant.createTracks</code> method and publish them with <code>LocalParticipant.publishTrack</code>:</p> <pre><code>var tracks = await room.localParticipant.createTracks({\n  audio: {\n    deviceId: \"default\",\n    autoGainControl: true,\n    echoCancellation: true,\n    noiseSuppression: true\n  },\n  video: {\n    deviceId: 'frontcamera';\n    facingMode: 'user'\n  },\n});\nawait Promise.all([\n    room.localParticipant.publishTrack(tracks[0]),\n    room.localParticipant.publishTrack(tracks[1]),\n]);\n</code></pre> <p> Reference docs</p>","tags":["Platform"]},{"location":"docs/developing-your-openvidu-app/how-to/#muteunmute-a-track","title":"Mute/Unmute a Track","text":"<p>To mute the default camera and microphone Tracks:</p> <pre><code>await room.localParticipant.setCameraEnabled(false);\nawait room.localParticipant.setMicrophoneEnabled(false);\n</code></pre> <p>To mute/unmute a custom Track:</p> <pre><code>// Mute the track\nawait track.mute();\n\n// Unmute the track\nawait track.unmute();\n</code></pre> <p> Reference docs</p>","tags":["Platform"]},{"location":"docs/developing-your-openvidu-app/how-to/#unpublish-a-track","title":"Unpublish a Track","text":"<p>To completely stop sending a Track to the Room, you must unpublish it:</p> <pre><code>await room.localParticipant.unpublishTrack(track, true);\n</code></pre> <p>The second boolean parameter indicates if the local Track should be stopped. This usually means freeing the device capturing it (switching off the camera LED, for example).</p> <p> Reference docs</p>","tags":["Platform"]},{"location":"docs/developing-your-openvidu-app/how-to/#send-messages","title":"Send messages","text":"<p>You can share information between Participants of a Room in different ways.</p> <p>First of all, you can set Room metadata that will be available for all clients in the <code>Room</code> object. You do so in your application server when calling the <code>CreateRoom</code> API  (available for all LiveKit Server SDKs and the HTTP Server API). The Room metadata will be available in the client side like this:</p> <pre><code>console.log(room.metadata);\n</code></pre> <p>You can update the Room metadata at any time from your application server with the <code>UpdateRoomMetadata</code> API  (available for all LiveKit Server SDKs and the HTTP Server API). The client side will be notified of the change with the <code>roomMetadataChanged</code> event of the <code>Room</code> object:</p> <pre><code>room.on(\"roomMetadataChanged\", (metadata) =&gt; {\n  console.log(\"New room metadata\", metadata);\n});\n</code></pre> <p>Secondly, you can also set Participant metadata. You do so when creating an access token  in your application server, setting <code>metadata</code> field of the JWT.</p> <p>Participants can also update their own metadata from the client side, if their access token was created with grant <code>canUpdateOwnMetadata</code> .</p> <pre><code>room.localParticipant.setMetadata(\"new metadata\");\n</code></pre> <p>The client side will be notified of the change with the <code>participantMetadataChanged</code> event of the <code>Room</code> and/or <code>Participant</code> object:</p> <pre><code>// To handle all metadata changes of all participants\nroom.on(\n  RoomEvent.ParticipantMetadataChanged,\n  (previousMetadata: string, participant) =&gt; {\n    console.log(\n      \"New metadata for participant\",\n      participant.identity,\n      participant.metadata\n    );\n  }\n);\n\n// To handle only metadata changes of a specific participant\nparticipant.on(\n  ParticipantEvent.ParticipantMetadataChanged,\n  (previousMetadata) =&gt; {\n    console.log(\n      \"New metadata for participant\",\n      participant.identity,\n      participant.metadata\n    );\n  }\n);\n</code></pre> <p>Finally, you can send messages to Participants in the Room using the <code>LocalParticipant.publishData</code>  method:</p> <pre><code>const data: Uint8Array = new TextEncoder().encode(JSON.stringify(\"\"));\nroom.localParticipant.publishData(data, {\n  reliable: true,\n  topic: \"chat\",\n  destinationIdentities: [\"participant-identity\"],\n});\n</code></pre> <p>The <code>DataPublishOptions</code>  allow setting the reliability of the message (depending on the nature of the message it can be sent as a reliable or lossy message), a topic to easily filter messages, and the participants that will receive the message.</p> <p>The client side will be notified of the message with the <code>dataReceived</code> event of the <code>Room</code> and/or <code>Participant</code> object:</p> <pre><code>// To receive all messages from the Room\nroom.on(\n  RoomEvent.DataReceived,\n  (payload: Uint8Array, participant: Participant, kind: DataPacket_Kind) =&gt; {\n    const strData = new TextDecoder().decode(payload);\n    console.log(\"Received data from\", participant.identity, strData);\n  }\n);\n\n// To receive messages only from a specific participant\nparticipant.on(\n  ParticipantEvent.DataReceived,\n  (payload: Uint8Array, kind: DataPacket_Kind) =&gt; {\n    const strData = new TextDecoder().decode(payload);\n    console.log(\"Received data from\", participant.identity, strData);\n  }\n);\n</code></pre> <p> Reference docs</p>","tags":["Platform"]},{"location":"docs/developing-your-openvidu-app/how-to/#from-your-application-server","title":"From your application server","text":"<p>Except for the generation of access tokens, it is possible for all the logic of your application to be contained entirely on the client side. Nonetheless, some use cases may require the management of the Rooms from the server side.</p> <p>These operations are only available in the server SDKs, and not in the client SDKs:</p> <ul> <li>Closing a Room. From the client side, a user can only leave his own Room.</li> <li>Removing any Participant from a Room. From the client side, a user can only leave his own Room.</li> <li>Muting any Track of any Participant. From the client side, a user can only mute/unmute his own Tracks.</li> <li>Updating the metadata of any Participant. From the client side, a user can only update his own metadata.</li> <li>Updating the metadata of the Room. From the client side this is not possible.</li> <li>Egress operations. Egress cannot be started and stopped on demand by users from the client side.</li> <li>Ingress operations. Ingress cannot be started and stopped on demand by users from the client side.</li> </ul> <p>You have here the complete list of the server-side operations, documented for the HTTP Server API. All the LiveKit Server SDKs have the same operations.</p> <ul> <li>RoomService : to manage Rooms and Participants.</li> <li>Egress : to manage egress operations.</li> <li>Ingress : to manage ingress operations.</li> </ul>","tags":["Platform"]},{"location":"docs/developing-your-openvidu-app/how-to/#screen-sharing","title":"Screen Sharing","text":"<p>To quickly publish a screen sharing Track:</p> <pre><code>await room.localParticipant.setScreenShareEnabled(true);\n</code></pre> <p>You can also create custom screen tracks, for example capturing the audio of the screen and fine-tuning the video capture options (checkout the ScreenTrackOptions  interface for detailed information):</p> <pre><code>const screenTracks = await room.localParticipant.createScreenTracks({\n  audio: true,\n  contentHint: \"detail\",\n  preferCurrentTab: true,\n  video: {\n    displaySurface: \"window\",\n  },\n});\nawait Promise.all([\n  room.localParticipant.publishTrack(screenTracks[0]),\n  room.localParticipant.publishTrack(screenTracks[1]),\n]);\n</code></pre> <p> Reference docs</p>","tags":["Platform"]},{"location":"docs/developing-your-openvidu-app/how-to/#virtual-background","title":"Virtual Background","text":"<p>It is possible to apply a virtual background to video tracks. In this way you can blur the background or replace it with an image.</p> <p>It is necessary to install an additional dependency to use this feature:</p> <pre><code>npm add @livekit/track-processors\n</code></pre> <p>To blur the background:</p> <pre><code>import { BackgroundBlur } from \"@livekit/track-processors\";\n\nconst videoTrack = await createLocalVideoTrack();\nconst blur = BackgroundBlur(10);\nawait videoTrack.setProcessor(blur);\n</code></pre> <p>To replace the background with an image:</p> <pre><code>import { VirtualBackground } from \"@livekit/track-processors\";\n\nconst videoTrack = await createLocalVideoTrack();\nconst image = VirtualBackground(\"https://picsum.photos/400\");\nawait videoTrack.setProcessor(image);\n</code></pre> <p> GitHub Repository</p>","tags":["Platform"]},{"location":"docs/developing-your-openvidu-app/how-to/#recording","title":"Recording","text":"<p>You can record your Rooms using the Egress module. Egress allows exporting media from a Room in different formats, including</p> <ul> <li>Room Composite Egress: a single video output with all the Tracks of a Room composited in a layout. You can even create your custom layouts.</li> <li>Track Composite Egress: a single video output combining an audio Track and a video Track.</li> <li>Track Egress: individual outputs for each Track of a Room.</li> </ul> <p>Visit the LiveKit reference documentation for a detailed explanation of Egress:</p> <p> Reference docs</p>","tags":["Platform"]},{"location":"docs/developing-your-openvidu-app/how-to/#stream-ingestion","title":"Stream ingestion","text":"<p>You can ingest media streams into your Rooms using the Ingress module. It supports different sources, including:</p> <ul> <li>RTMP: the Ingress module exposes an RTMP endpoint to which your user can stream their content. The ingress module will transcode and publish the stream to the Room, making it available to all participants.</li> <li>WHIP: the Ingress module exposes a WHIP endpoint to which your user can stream their content directly via WebRTC. You can choose whether the Ingress module should transcode the stream or directly relay it to the Room. Avoiding transcoding is the best option to minimize latency when ingesting media to a Room.</li> <li>Media files serve by an HTTP server: the Ingress module will fetch a media file, transcode it and publish it to the Room.</li> <li>Media served by an SRT server: the Ingress module will pull the media from an SRT server, transcode it and publish it to the Room.</li> </ul> <p>Visit the LiveKit reference documentation for a detailed explanation of Ingress:</p> <p> Reference docs</p>","tags":["Platform"]},{"location":"docs/developing-your-openvidu-app/how-to/#ip-cameras","title":"IP Cameras","text":"<p>With OpenVidu you can ingest RTSP streams into your Rooms. To do so, simply use the Ingress API  to create and ingress of input type <code>URL</code>, providing the IP camera RTSP URL as value:</p>  Node.js Go Ruby Java Python Rust PHP .NET Server API <p>Using LiveKit Node SDK </p> <pre><code>import { IngressClient, IngressInfo, IngressInput } from 'livekit-server-sdk';\n\nconst ingressClient = new IngressClient('https://my-openvidu-host', 'api-key', 'api-secret');\n\nconst ingress = {\n  name: 'my-ingress',\n  roomName: 'my-room',\n  participantIdentity: 'my-participant',\n  participantName: 'My Participant',\n  url: 'rtsp://admin:pass@192.168.1.79/mystream'\n};\n\nawait ingressClient.createIngress(IngressInput.URL_INPUT, ingress);\n</code></pre> <p>Using LiveKit Go SDK </p> <pre><code>import (\n  lksdk \"github.com/livekit/server-sdk-go/v2\"\n  livekit \"github.com/livekit/protocol/livekit\"\n)\n\ningressClient := lksdk.NewIngressClient(\n    \"https://my-openvidu-host\",\n    \"api-key\",\n    \"api-secret\",\n)\n\ningressRequest := &amp;livekit.CreateIngressRequest{\n    InputType:           livekit.IngressInput_URL_INPUT,\n    Name:                \"my-ingress\",\n    RoomName:            \"my-room\",\n    ParticipantIdentity: \"my-participant\",\n    ParticipantName:     \"My Participant\",\n    Url:                 \"rtsp://admin:pass@192.168.1.79/mystream\",\n}\n\ningressInfo, err := ingressClient.CreateIngress(context.Background(), ingressRequest)\n</code></pre> <p>Using LiveKit Ruby SDK </p> <pre><code>require 'livekit'\n\ningressClient = LiveKit::IngressServiceClient.new(\"https://my-openvidu-host\", api_key: \"api-key\", api_secret: \"api-secret\")\nresponse = ingressClient.create_ingress(\n  :URL_INPUT,\n  name: \"my-ingress\",\n  room_name: \"my-room\",\n  participant_identity: \"my-participant\",\n  participant_name: \"My Participant\",\n  url: \"rtsp://admin:pass@192.168.1.79/mystream\",\n)\nif response.error\n    puts \"Error creating ingress: #{response.error}\"\nelse\n    ingressInfo = response.data\n    puts \"Ingress created: #{ingressInfo}\"\nend\n</code></pre> <p>Using LiveKit Kotlin SDK </p> <pre><code>import io.livekit.server.IngressServiceClient;\nimport livekit.LivekitIngress.IngressInfo;\nimport livekit.LivekitIngress.IngressInput;\n\nIngressServiceClient ingressService = IngressServiceClient.createClient(\"https://my-openvidu-host\", \"api-key\", \"api-secret\");\n\nIngressInfo ingressInfo = ingressService.createIngress(\n    \"my-ingress\", // Ingress name\n    \"my-room\", // Room name\n    \"my-participant\", // Ingress participant identity\n    \"My Participant\", // Ingress participant name\n    IngressInput.URL_INPUT, // Ingress input type\n    null, null, null, null, // Other default options\n    \"rtsp://admin:pass@192.168.1.79/mystream\" // Input URL\n).execute().body();\n</code></pre> <p>Using LiveKit Python SDK </p> <pre><code>from livekit.api import LiveKitAPI\n\nlkapi = LiveKitAPI(\n    url=\"https://my-openvidu-host\", api_key=\"api-key\", api_secret=\"api-secret\"\n)\nrequest = CreateIngressRequest(\n    url=\"rtsp://admin:pass@192.168.1.79/mystream\",\n    name=\"my-ingress\",\n    room_name=\"my-room\",\n    participant_identity=\"my-participant\",\n    participant_name=\"My Participant\",\n    input_type=IngressInput.URL_INPUT,\n)\ningressInfo = await lkapi.ingress.create_ingress(request)\n</code></pre> <p>Using LiveKit Rust SDK </p> <pre><code>use livekit_api::services::ingress::*;\nuse livekit_protocol::*;\n\nlet ingress_client = IngressClient::with_api_key(\n    \"https://my-openvidu-host\",\n    \"api-key\",\n    \"api-secret\",\n);\nlet ingress_info = ingress_client.create_ingress(\n    IngressInput::UrlInput,\n    CreateIngressOptions {\n        name: \"my-ingress\".to_string(),\n        room_name: \"my-room\".to_string(),\n        participant_identity: \"my-participant\".to_string(),\n        participant_name: \"My Participant\".to_string(),\n        url: \"rtsp://admin:pass@192.168.1.79/mystream\".to_string(),\n        ..Default::default()\n    }).await;\n</code></pre> <p>Using LiveKit PHP SDK </p> <pre><code>&lt;?php\nuse Agence104\\LiveKit\\IngressServiceClient;\nuse Livekit\\IngressInput;\n\n$ingress_client = new IngressServiceClient(\"https://my-openvidu-host\", \"api-key\", \"api-secret\");\n$ingress_info = $ingress_client-&gt;createIngress(\n  IngressInput::URL_INPUT,\n  \"my-ingress\", // Ingress name\n  \"my-room\", // Room name\n  \"my-participant\", // Ingress participant identity\n  \"My Participant\", // Ingress participant name\n  NULL, NULL, NULL, // Other default options\n  \"rtsp://admin:pass@192.168.1.79/mystream\" // Input URL\n);\n</code></pre> <p>Using LiveKit .NET SDK </p> <pre><code>using Livekit.Server.Sdk.Dotnet;\n\nIngressServiceClient ingressServiceClient = new IngressServiceClient(\n    \"https://my-openvidu-host\",\n    \"api-key\",\n    \"api-secret\"\n);\nvar ingressInfo = await ingressServiceClient.CreateIngress(new CreateIngressRequest\n{\n    Name = \"my-ingress\",\n    RoomName = \"my-room\",\n    ParticipantIdentity = \"my-participant\",\n    ParticipantName = \"My Participant\",\n    InputType = IngressInput.UrlInput,\n    Url = \"rtsp://admin:pass@192.168.1.79/mystream\",\n});\n</code></pre> <p>If your backend technology does not have its own SDK, you have two different options:</p> <ol> <li> <p>Consume the Ingress API directly:  Reference Docs</p> </li> <li> <p>Use the livekit-cli :</p> <p>Create a file at <code>ingress.json</code> with the following content:</p> <pre><code>{\n  \"input_type\": \"URL_INPUT\",\n  \"name\": \"Name of the Ingress goes here\",\n  \"room_name\": \"Name of the room to connect to\",\n  \"participant_identity\": \"Unique identity for the room participant the Ingress service will connect as\",\n  \"participant_name\": \"Name displayed in the room for the participant\",\n  \"url\": \"rtsp://admin:pass@192.168.1.79/mystream\"\n}\n</code></pre> <p>Then run the following commands:</p> <pre><code>export LIVEKIT_URL=https://my-openvidu-host\nexport LIVEKIT_API_KEY=api-key\nexport LIVEKIT_API_SECRET=api-secret\n\nlk ingress create ingress.json\n</code></pre> </li> </ol> <p>Many audio and video codecs are supported for ingesting IP cameras:</p> <p>For video:</p> <ul> <li>H264</li> <li>VP8</li> <li>VP9</li> <li>MPEG4</li> <li>MJPEG</li> </ul> <p>For audio:</p> <ul> <li>AAC</li> <li>MP3</li> <li>OPUS</li> <li>G711</li> </ul>","tags":["Platform"]},{"location":"docs/developing-your-openvidu-app/how-to/#webhooks","title":"Webhooks","text":"<p>Your application server may receive webhooks coming from the OpenVidu deployment. These webhooks inform about events happening in the Rooms, including when a Room is created and finished, when a Participant joins and leaves a Room, when a Track is published and unpublished, and when Egress/Ingress operations take place in a Room.</p> <p>Every application server tutorial here is ready to receive webhooks: Application Server Tutorials.</p> <p>Visit the LiveKit reference documentation for a detailed explanation of each webhook event:</p> <p> Reference docs</p>","tags":["Platform"]},{"location":"docs/self-hosting/deployment-types/","title":"Deployment types","text":"","tags":["Platform"]},{"location":"docs/self-hosting/deployment-types/#deployment-types","title":"Deployment types","text":"<p>OpenVidu offers user-friendly installers that facilitate quick on-premises deployments, so you can self-host your real-time solution in your own infrastructure or any cloud provider.</p> <p>There are different deployment options available, depending on your needs:</p> Type of deployment OpenViduLocal (development) OpenViduSingle Node OpenViduElastic OpenViduHigh Availability OpenVidu Edition COMMUNITY PRO COMMUNITY PRO PRO PRO Suitability For local development in your laptop For applications with medium user load For applications with dynamic user load that require scalability For applications where both scalability and fault tolerance are critical Features Friendly Docker Compose setup with Redis, Egress, Ingress, S3 storage and observability. With automatic certificate management to test across devices in your network COMMUNITY Custom LiveKit distribution with Redis, Egress, Ingress, S3 storage and observability.PRO Same features but adding 2x performance and advanced observability. Same benefits as OpenVidu Single Node plus 2x performance, advanced observability and scalability Same benefits as OpenVidu Elastic plus fault tolerance Number of servers Your laptop 1 Node 1 Master Node +N Media Nodes 4 Master Nodes +N Media Nodes Installation instructions Install Install Install Install <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/deployment-types/#openvidu-local-development","title":"OpenVidu Local (development)","text":"<p>To run OpenVidu in your local machine, this is the quickest option. It is a Docker Compose setup that includes all the necessary services to run OpenVidu in your LAN, including automated SSL certificates that will be valid across all devices in your network.</p> <p>It comes in two flavors:</p> <ul> <li>OpenVidu Local COMMUNITY: mirrors the experience of OpenVidu Single Node COMMUNITY, fine-tuned for local development.</li> <li>OpenVidu Local PRO: mirrors the experience of OpenVidu Single Node PRO, fine-tuned for local development. In this case, OpenVidu runs in evaluation mode for free for development and testing purposes (some limits apply: maximum 8 Participants across all Rooms, maximum 5 minutes duration per Room).</li> </ul> <p> </p> OpenVidu Local (development)","tags":["Platform"]},{"location":"docs/self-hosting/deployment-types/#openvidu-single-node","title":"OpenVidu Single Node","text":"<p>This is the simplest production-ready OpenVidu deployment available. It provides all the features you need, but lacks scalability and fault tolerance. But make no mistake about it: it is perfectly suitable for medium-scale production deployments. For most projects OpenVidu Single Node will be enough, at least until your user load gets serious. You can host hundreds of simultaneous participants in your rooms by running OpenVidu Community on a sufficiently powerful server!</p> <p>It is composed of a single OpenVidu Node hosting all the necessary services in a monolithic setup. It comes in two flavors:</p> <ul> <li>OpenVidu Single Node COMMUNITY: all the features you need to build your real-time application.</li> <li>OpenVidu Single Node PRO: for those users that want the benefits of OpenVidu PRO in a single-node setup. It includes 2x performance and advanced observability features.</li> </ul> <p> </p> OpenVidu Single Node","tags":["Platform"]},{"location":"docs/self-hosting/deployment-types/#openvidu-elastic","title":"OpenVidu Elastic","text":"<p>This is the intermediate OpenVidu deployment. It provides scalability for your video rooms. Suitable for applications with dynamic load in the media plane that require scalability.</p> <p>It is composed of two different types of nodes, one of them running on a cluster of multiple servers and the other running as a single monolithic server:</p> <ul> <li>A cluster of Media Nodes hosting all the media-related services. Your video rooms scale up and down thanks to this cluster.</li> <li>A single Master Node hosting all the support services in a monolithic setup.</li> </ul> <p> </p> OpenVidu Elastic","tags":["Platform"]},{"location":"docs/self-hosting/deployment-types/#openvidu-high-availability","title":"OpenVidu High Availability","text":"<p>This is the most complete OpenVidu deployment. It provides scalability for your video rooms and fault tolerance in all its services. Suitable for applications where both scalability and availability are critical.</p> <p>It is composed of two different types of nodes running on two separate clusters:</p> <ul> <li>A cluster of Media Nodes hosting all the media-related services. Your video rooms scale up and down thanks to this cluster. The minimum number of nodes in this cluster is 1, and it is designed to scale up and down dynamically according to workload.</li> <li>A cluster of Master Nodes hosting all the support services in their high availability format. Your deployment is fault-tolerant thanks to this cluster. The minimum number of nodes in this cluster is 4, and it is designed to have a fixed number of nodes at all times.</li> </ul> <p> </p> OpenVidu High Availability cluster","tags":["Platform"]},{"location":"docs/self-hosting/deployment-types/#node-services","title":"Node services","text":"<p>OpenVidu is composed of several services that work together to provide a complete videoconferencing solution. Every service runs as a Docker container, coordinated with Docker Compose.</p>","tags":["Platform"]},{"location":"docs/self-hosting/deployment-types/#master-node-services","title":"Master Node services","text":"SERVICE DESCRIPTION OpenVidu Meet A high-quality video calling service based on OpenVidu. OpenVidu Dashboard Web application interface for managing your cluster and visualizing your Rooms. OpenVidu Operator Module that supervises the high availability services and updates the loadbalancing configuration dynamically. Redis Database used to share transient information between Media Nodes and coordinate them. In OpenVidu High Availability this is an instance of a Redis Cluster . MongoDB Database used to store analytics and monitoring persistent data. In OpenVidu High Availability this is an instance of a MongoDB Replica Set . Minio S3 bucket used to store recordings and common node configurations. In OpenVidu High Availability this is an instance of a Minio Multi-Node . Caddy Reverse proxy used as a loadbalancer to distribute client connections across your nodes and automatically manage your TLS certificate. Mimir (observability) Module used to store metrics from Prometheus. Promtail (observability) Module used to collect logs from all services and send them to Loki. Loki (observability) Module used to store logs. Grafana (observability) Module used to visualize logs and metrics in dashboards.","tags":["Platform"]},{"location":"docs/self-hosting/deployment-types/#media-node-services","title":"Media Node services","text":"SERVICE DESCRIPTION OpenVidu Server Media server used to stream real-time video, audio and data. Based on SFUs LiveKit and mediasoup. Egress Server Module used to export media from a Room (for example, recordings or RTMP broadcasting). See Egress . Ingress Server Module used to import media into a Room (for example, an MP4 video or an RTSP stream). See Ingress . Agents Modules used to add AI capabilities to Rooms. See AI Services. Caddy Reverse proxy used as a loadbalancer to distribute the load generated by the Media Nodes over the Minio, Mimir and Loki cluster. Prometheus (observability) Module used to collect metrics from OpenVidu Server and send them to Loki. Promtail (observability) Module used to collect logs from all services and send them to Loki.","tags":["Platform"]},{"location":"docs/self-hosting/faq/","title":"Installation FAQs","text":"","tags":["Platform"]},{"location":"docs/self-hosting/faq/#installation-faqs","title":"Installation FAQs","text":"","tags":["Platform"]},{"location":"docs/self-hosting/faq/#common-issues","title":"Common issues","text":"","tags":["Platform"]},{"location":"docs/self-hosting/faq/#everything-looks-alright-but-i-cannot-see-any-remote-video","title":"Everything looks alright, but I cannot see any remote video.","text":"","tags":["Platform"]},{"location":"docs/self-hosting/faq/#my-local-video-is-not-showing-up-on-the-browser","title":"My local video is not showing up on the browser","text":"","tags":["Platform"]},{"location":"docs/self-hosting/faq/#any-tips-to-make-easier-the-development-of-my-webrtc-application","title":"Any tips to make easier the development of my WebRTC application?","text":"","tags":["Platform"]},{"location":"docs/self-hosting/faq/#test-applications-in-my-network-with-multiple-devices","title":"Test applications in my network with multiple devices.","text":"","tags":["Platform"]},{"location":"docs/self-hosting/faq/#does-my-app-need-a-server-side","title":"Does my app need a server-side?","text":"","tags":["Platform"]},{"location":"docs/self-hosting/faq/#caddy-certificates-are-not-working-what-can-i-do","title":"Caddy certificates are not working. What can I do?","text":"","tags":["Platform"]},{"location":"docs/self-hosting/faq/#my-commercial-certificate-is-not-working-what-can-i-do","title":"My commercial certificate is not working. What can I do?","text":"","tags":["Platform"]},{"location":"docs/self-hosting/faq/#how-can-i-customize-the-caddy-configuration","title":"How can I customize the Caddy configuration?","text":"","tags":["Platform"]},{"location":"docs/self-hosting/faq/#openvidu-does-not-work-for-clients-behind-restrictive-firewalls","title":"OpenVidu does not work for clients behind restrictive firewalls.","text":"","tags":["Platform"]},{"location":"docs/self-hosting/faq/#fundamentals-knowledge","title":"Fundamentals Knowledge","text":"","tags":["Platform"]},{"location":"docs/self-hosting/faq/#what-is-a-domain-name-and-how-can-i-get-one","title":"What is a domain name and how can I get one?","text":"","tags":["Platform"]},{"location":"docs/self-hosting/faq/#what-is-an-aws-elastic-ip-and-how-can-i-create-one","title":"What is an AWS Elastic IP and how can I create one?","text":"","tags":["Platform"]},{"location":"docs/self-hosting/faq/#what-is-a-vpc-and-a-subnet-in-aws","title":"What is a VPC and a subnet in AWS?","text":"","tags":["Platform"]},{"location":"docs/self-hosting/faq/#what-is-a-dns-record-and-how-can-i-create-one","title":"What is a DNS record and how can I create one?","text":"","tags":["Platform"]},{"location":"docs/self-hosting/faq/#what-means-each-type-of-certificate-in-openvidu","title":"What means each type of certificate in OpenVidu?","text":"","tags":["Platform"]},{"location":"docs/self-hosting/faq/#what-is-stun-and-turn-and-why-do-i-need-them","title":"What is STUN and TURN and why do I need them?","text":"","tags":["Platform"]},{"location":"docs/self-hosting/faq/#what-is-a-caddy-server-and-why-is-it-used-in-openvidu","title":"What is a Caddy server and why is it used in OpenVidu?","text":"","tags":["Platform"]},{"location":"docs/self-hosting/faq/#what-is-the-operator-service-in-openvidu","title":"What is the \"operator\" service in OpenVidu?","text":"","tags":["Platform"]},{"location":"docs/self-hosting/local/","title":"OpenVidu Local installation","text":"","tags":["Platform"]},{"location":"docs/self-hosting/local/#openvidu-local-installation-development","title":"OpenVidu Local installation (Development)","text":"<p>For development purposes, we provide an easy to install local deployment  based on Docker Compose which will automatically configure all the necessary services for OpenVidu to develop and test your applications seamlessly.</p>","tags":["Platform"]},{"location":"docs/self-hosting/local/#installation-instructions","title":"Installation instructions","text":"<p>First, make sure you have the following prerequisites:</p>  Windows macOS Linux <ul> <li>Install Docker Desktop </li> </ul> <ul> <li>Install Docker Desktop </li> </ul> <ul> <li>Install Docker </li> <li>Install Docker Compose </li> </ul> <p>The installation consists of cloning a repository and running a script to configure your local IP address in the deployment. Then, you can start, stop, and manage your deployment with Docker Compose.</p> <p>To install OpenVidu locally, follow these steps:</p> OpenVidu COMMUNITYOpenVidu PRO <ol> <li> <p>Clone the following repository:</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> <p>Info</p> <p>To use a specific OpenVidu version, switch to the desired tag with <code>git checkout &lt;version&gt;</code>, e.g., <code>git checkout 3.0.0</code>. By default, the latest version is used.</p> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <ol> <li> <p>Clone the following repository:</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> <p>Info</p> <p>To use a specific OpenVidu version, switch to the desired tag with <code>git checkout &lt;version&gt;</code>, e.g., <code>git checkout 3.0.0</code>. By default, the latest version is used.</p> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/pro\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/pro\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/pro\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>Info</p> <p>OpenVidu PRO runs locally in evaluation mode for free for development and testing purposes. Some limits apply:</p> <ul> <li>Maximum 8 Participants across all Rooms</li> <li>Maximum 5 minutes duration per Room</li> </ul> <p>For a production environment, you need to create an OpenVidu account to get a license key. There's a 15 day free trial waiting for you!</p> <p>The deployment is ready when you see the following message:</p> <pre><code> =========================================\n \ud83c\udf89 OpenVidu is ready! \ud83c\udf89\n =========================================\n\n OpenVidu Server &amp;&amp; LiveKit Server URLs:\n\n     - From this machine:\n\n         - http://localhost:7880\n         - ws://localhost:7880\n\n     - From other devices in your LAN:\n\n         - https://xxx-yyy-zzz-www.openvidu-local.dev:7443\n         - wss://xxx-yyy-zzz-www.openvidu-local.dev:7443\n\n =========================================\n\n OpenVidu Developer UI (services and passwords):\n\n     - http://localhost:7880\n     - https://xxx-yyy-zzz-www.openvidu-local.dev:7443\n\n =========================================\n</code></pre> <p>By visiting http://localhost:7880 you have the OpenVidu Developer UI available with a summary of the services and passwords deployed. You can access the following services:</p> <ul> <li>OpenVidu API (LiveKit compatible) (http://localhost:7880): the main API endpoint for your OpenVidu and LiveKit applications. OpenVidu v2 compatibility API is only available in OpenVidu PRO.</li> <li>OpenVidu Dashboard (http://localhost:7880/dashboard): a web application interface to visualize your Rooms, Ingress and Egress services.</li> <li>MinIO (http://localhost:7880/minio-console): as an S3 storage service for recordings.</li> <li>OpenVidu Meet (http://localhost:9080): a high-quality video calling service based on OpenVidu.</li> </ul> <p>You just need to point your OpenVidu and LiveKit applications to <code>http://localhost:7880</code> or <code>ws://localhost:7880</code> and start developing. Check our tutorials if you want a step-by-step guide to develop your first application using OpenVidu.</p>","tags":["Platform"]},{"location":"docs/self-hosting/local/#configuration","title":"Configuration","text":"","tags":["Platform"]},{"location":"docs/self-hosting/local/#configure-your-application-to-use-the-local-deployment","title":"Configure your Application to use the Local Deployment","text":"<p>To point your applications to your local OpenVidu Local deployment, check the credentials at http://localhost:7880 or simply check the <code>.env</code> file. All access credentials of all services are defined in this file.</p> OpenVidu COMMUNITYOpenVidu PRO <p>Your authentication credentials and URLs to point your applications to are:</p> <ul> <li>URL: It must be <code>ws://localhost:7880</code> or <code>http://localhost:7880</code> depending on the SDK you are using.</li> <li>API Key: The value in <code>.env</code> of <code>LIVEKIT_API_KEY</code></li> <li>API Secret: The value in <code>.env</code> of <code>LIVEKIT_API_SECRET</code></li> </ul> <p>Your authentication credentials and URLs to point your applications to are:</p> <ul> <li> <p>Applications developed with LiveKit SDK:</p> <ul> <li>URL: It must be <code>ws://localhost:7880/</code> or <code>http://localhost:7880/</code> depending on the SDK you are using.</li> <li>API Key: The value in <code>.env</code> of <code>LIVEKIT_API_KEY</code></li> <li>API Secret: The value in <code>.env</code> of <code>LIVEKIT_API_SECRET</code></li> </ul> </li> <li> <p>Applications developed with OpenVidu v2:</p> <ul> <li>URL: The value in <code>.env</code> of <code>DOMAIN_NAME</code> as a URL. For example, <code>http://localhost:7880</code></li> <li>Username: <code>OPENVIDUAPP</code></li> <li>Password: The value in <code>.env</code> of <code>LIVEKIT_API_SECRET</code></li> </ul> </li> </ul> <p>If you want to use the OpenVidu Local deployment from other devices on your network, follow the instructions in the next section.</p>","tags":["Platform"]},{"location":"docs/self-hosting/local/#configuring-webhooks","title":"Configuring webhooks","text":"<p>To configure webhooks in your local deployment, simply go to the file <code>livekit.yaml</code> and add to the <code>webhooks</code> section the URL where you want to receive the events:</p> <pre><code>webhook:\n    &lt;LIVEKIT_API_KEY&gt;:&lt;LIVEKIT_API_SECRET&gt;:\n    urls:\n        - &lt;YOUR_WEBHOOK_URL&gt;\n</code></pre> <p>In case you are using the v2compatibility and you want to receive webhooks for OpenVidu v2 applications, you can configure the webhooks in the <code>.env</code> file. For example:</p> <pre><code>V2COMPAT_OPENVIDU_WEBHOOK_ENDPOINT=&lt;YOUR_WEBHOOK_URL&gt;\n</code></pre> <p>Where <code>&lt;YOUR_WEBHOOK_URL&gt;</code> is the URL where you want to receive the events.</p>","tags":["Platform"]},{"location":"docs/self-hosting/local/#accessing-your-local-deployment-from-other-devices-on-your-network","title":"Accessing your local deployment from other devices on your network","text":"<p>Testing WebRTC applications can be challenging because devices require a secure context (HTTPS) to access the camera and microphone. When using LiveKit Open Source, this isn't an issue if you access your app from the same computer where the LiveKit Server is running, as <code>localhost</code> is considered a secure context even over plain HTTP. Consider the following architecture:</p> <p>The simplest way to test your application is:</p> <ol> <li>Run LiveKit Server on your computer.</li> <li>Connect your app to LiveKit Server through <code>localhost</code>.</li> <li>Serve both your application client and server from the same computer.</li> <li>Access your app from <code>localhost</code> in a browser on the same computer.</li> </ol> <p>This setup is straightforward, but what if you need to test your app from multiple devices simultaneously, including real mobile devices? In this case, you must use a secure context (HTTPS), which introduces two challenges:</p> <ol> <li>LiveKit Server open source does not natively support HTTPS. You'll need a reverse proxy to serve LiveKit Server over HTTPS.</li> <li>Even with HTTPS, your SSL certificate might not be valid for local network addresses. You'll need to accept it in the browser for web apps, and install it on mobile devices.</li> </ol> <p>OpenVidu Local Deployment addresses these issues by providing a magic domain name <code>openvidu-local.dev</code> that resolves to any IP specified as a subdomain and provides a valid wildcard certificate for HTTPS. This is similar to services like nip.io , traefik.me, or localtls.</p> <p>When using OpenVidu Local Deployment, you can access OpenVidu Server (which is 100% LiveKit compatible) and your app from any device on your local network with a valid HTTPS certificate. The following table shows the URLs to access the deployment and your application locally and from other devices on your network:</p> Local access Access from devices in your local network Usage Access only from the development machine Access from any device connected to your local network. In the URLs below, replace <code>xxx-yyy-zzz-www</code> with the local IP address of the development machine, replacing the dots (<code>.</code>) with dashes (<code>-</code>). You can find the configured local IP in the <code>.env</code> file in the <code>LAN_PRIVATE_IP</code> variable Application Client (frontend) http://localhost:5080 https://xxx-yyy-zzz-www.openvidu-local.dev:5443 Application Server (backend) http://localhost:6080 https://xxx-yyy-zzz-www.openvidu-local.dev:6443 OpenVidu (LiveKit Compatible) URL http://localhost:7880 https://xxx-yyy-zzz-www.openvidu-local.dev:7443 <p>Info</p> <ul> <li>If you are developing locally, use <code>localhost</code> to access the services, but if you want to test your application from other devices on your network, use the <code>openvidu-local.dev</code> URLs.</li> <li>Replace <code>xxx-yyy-zzz-www</code> with your local IP address. You can find it in the <code>.env</code> file in the <code>LAN_PRIVATE_IP</code> variable.</li> </ul> <p>Warning</p> <p>If the URL isn't working because the IP address is incorrect or the installation script couldn't detect it automatically, you can update the <code>LAN_PRIVATE_IP</code> value in the <code>.env</code> file and restart the deployment with <code>docker compose up</code>.</p> <p>When developing web applications with this deployment, you can use the following code snippet to dynamically determine the appropriate URLs for the application server and the OpenVidu server based on the browser's current location. This approach allows you to seamlessly run your application on both your development machine and other devices within your local network without needing to manually adjust the URLs in your code.</p> <pre><code>if (window.location.hostname === \"localhost\") {\n  APPLICATION_SERVER_URL = \"http://localhost:6080\";\n  OPENVIDU_URL = \"ws://localhost:7880\";\n} else {\n  APPLICATION_SERVER_URL = \"https://\" + window.location.hostname + \":6443\";\n  OPENVIDU_URL = \"wss://\" + window.location.hostname + \":7443\";\n}\n</code></pre>","tags":["Platform"]},{"location":"docs/self-hosting/local/#about-openvidu-localdev-domain-and-ssl-certificates","title":"About <code>openvidu-local.dev</code> domain and SSL certificates","text":"<p>This setup simplifies the configuration of local OpenVidu deployments with SSL, making it easier to develop and test your applications securely on your local network by using the <code>openvidu-local.dev</code> domain and a wildcard SSL certificate valid for <code>*.openvidu-local.dev</code>. However, it\u2019s important to note that these certificates are publicly available and do not provide an SSL certificate for production use.</p> <p>The HTTPS offered by <code>openvidu-local.dev</code> is intended for development or testing purposes with the only goal of making your local devices trust your application (which is mandatory in WebRTC applications). For any other use case, it should be treated with the same security considerations as plain HTTP.</p> <p>For production, you should consider deploying a production-grade OpenVidu deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/configuration/changing-config/","title":"Changing configuration","text":"","tags":["Platform"]},{"location":"docs/self-hosting/configuration/changing-config/#how-to-change-openvidu-configuration","title":"How to change OpenVidu configuration","text":"<p>The following steps are valid to change any configuration file in any deployment type. Simply just go to one of your Master Nodes, or the only Node in your deployment, and follow these steps:</p> Steps to change OpenVidu configuration <ol> <li>Go to one of your Master Nodes (or the only node in your deployment).</li> <li>Go to <code>/opt/openvidu/config</code> directory.</li> <li>Find and change the configuration parameter you want to modify, it could be any file: <code>openvidu.env</code>, <code>master_node.env</code>, <code>livekit.yaml</code>, <code>egress.yaml</code>, etc.</li> <li> <p>Restart OpenVidu just by executing:</p> <pre><code>systemctl restart openvidu\n</code></pre> </li> </ol> <p>Notice that you only need to restart OpenVidu in one of the Master Nodes (or the only node in your deployment) to apply the changes to all the nodes.</p>","tags":["Platform"]},{"location":"docs/self-hosting/configuration/changing-config/#types-of-configuration-files","title":"Types of configuration files","text":"<p>Configuration files can be divided into three types:</p> <ol> <li><code>openvidu.env</code>: This file defines configuration parameters used by other services. Such as the domain name, credentials, etc.</li> <li><code>master_node.env</code> and <code>media_node.env</code> (Only in Elastic and High Availability): These files define specific configuration parameters of the node they are placed in. It is very useful when you want to have different parameter values in different nodes.</li> <li> <p><code>&lt;service&gt;.yaml</code> or <code>&lt;service&gt;.env</code>: These files define the configuration of each service. For example, <code>livekit.yaml</code> defines the configuration of the OpenVidu Server, <code>egress.yaml</code> defines the configuration of the Egress Service, etc. </p> <p>These files make use of the parameters defined in the <code>openvidu.env</code>, <code>master_node.env</code>, and <code>media_node.env</code> files. For example, any service configuration file can access the <code>DOMAIN_NAME</code> parameter defined in the <code>openvidu.env</code> file by using this syntax:</p> <pre><code>${openvidu.DOMAIN_NAME}\n</code></pre> <p>You can check the OpenVidu Configuration In depth section to learn more about how the configuration system works.</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/configuration/changing-config/#config-files","title":"Config files","text":"<p>These are the configuration files for each kind of deployment:</p> Single NodeElasticHigh Availability <p>The single node has all configuration files in the same directory <code>/opt/openvidu/config/</code>:</p> <pre><code>|-- /opt/openvidu/config/\n    |-- openvidu.env\n    |-- livekit.yaml\n    |-- egress.yaml\n    |-- ingress.yaml\n    |-- caddy.yaml\n    |-- redis.env\n    |-- minio.env\n    |-- mongo.env\n    |-- dashboard.env\n    |-- loki.yaml\n    |-- prometheus.yaml\n    |-- promtail.yaml\n    |-- meet.env\n    |-- agent-speech-processing.yaml\n    `-- grafana/\n</code></pre> <p>OpenVidu Elastic has all the cluster configuration at <code>/opt/openvidu/config/cluster/</code> with each configuration file separated depending on the node they are placed in: <code>master_node</code> or <code>media_node</code>. The file <code>openvidu.env</code> is placed at <code>/opt/openvidu/config/cluster/</code> because it is used by services of both types of nodes.</p> <p>Specific parameter values of each Master Node are placed at <code>/opt/openvidu/config/node/master_node.env</code>.</p> <p>Master Node</p> <pre><code>|-- /opt/openvidu/config/\n    |-- cluster/\n    |   |-- openvidu.env\n    |   |-- master_node/\n    |   |   |-- grafana/\n    |   |   |-- meet.env\n    |   |   |-- caddy.yaml\n    |   |   |-- dashboard.env\n    |   |   |-- loki.yaml\n    |   |   |-- mimir.yaml\n    |   |   |-- minio.env\n    |   |   |-- mongo.env\n    |   |   |-- operator.env\n    |   |   |-- promtail.yaml\n    |   |   |-- redis.env\n    |   |   `-- v2compatibility.env\n    |   `-- media_node/\n    |       |-- egress.yaml\n    |       |-- ingress.yaml\n    |       |-- livekit.yaml\n    |       |-- prometheus.yaml\n    |       |-- promtail.yaml\n    |       `-- agent-speech-processing.yaml\n    `-- node/\n    `-- master_node.env\n</code></pre> <p>Media Node</p> <p>The Media Node in contrast has only the <code>media_node.env</code> file, because the configuration is centralized in the Master Node.</p> <pre><code>|-- /opt/openvidu/config/\n    `-- node/\n        `-- media_node.env\n</code></pre> <p>OpenVidu High Availability has all the cluster configuration at <code>/opt/openvidu/config/cluster/</code> with each configuration file separated depending on the node they are placed in: <code>master_node</code> or <code>media_node</code>. The file <code>openvidu.env</code> is placed at <code>/opt/openvidu/config/cluster/</code> because it is used by services of both types of nodes.</p> <p>Specific parameter values of each Master Node are placed at <code>/opt/openvidu/config/node/master_node.env</code>.</p> <p>Master Node</p> <pre><code>|-- /opt/openvidu/config/\n    |-- cluster/\n    |   |-- openvidu.env\n    |   |-- master_node/\n    |   |   |-- grafana/\n    |   |   |-- meet.env\n    |   |   |-- caddy.yaml\n    |   |   |-- dashboard.env\n    |   |   |-- loki.yaml\n    |   |   |-- mimir.yaml\n    |   |   |-- minio.env\n    |   |   |-- mongo.env\n    |   |   |-- operator.env\n    |   |   |-- promtail.yaml\n    |   |   |-- redis.env\n    |   |   `-- v2compatibility.env\n    |   `-- media_node/\n    |       |-- caddy.yaml\n    |       |-- egress.yaml\n    |       |-- ingress.yaml\n    |       |-- livekit.yaml\n    |       |-- prometheus.yaml\n    |       |-- promtail.yaml\n    |       `-- agent-speech-processing.yaml\n    `-- node/\n    `-- master_node.env\n</code></pre> <p>Media Node</p> <p>The Media Node in contrast has only the <code>media_node.env</code> file, because the configuration is centralized in the Master Node.</p> <pre><code>|-- /opt/openvidu/config/\n    `-- node/\n        `-- media_node.env\n</code></pre>","tags":["Platform"]},{"location":"docs/self-hosting/configuration/changing-config/#troubleshooting-configuration","title":"Troubleshooting configuration","text":"<p>After changing the configuration and restarting, you need to make sure that the changes have been applied correctly. Here are some tips to check if something is wrong. All the following commands must be executed in one of the Master Nodes (or the only node in your deployment):</p> <ol> <li> <p>Execute a <code>docker ps</code>. If you see an <code>openvidu-init</code> container constantly restarting, it means that the configuration file you modified has a syntax error. Check the logs of this container to see the error with:</p> <pre><code>docker logs openvidu-init\n</code></pre> <p>The log is self-explanatory and will tell you what is wrong with the configuration file:</p> <pre><code>service 'openvidu': Failed to process config file '/opt/openvidu/config/livekit.yaml': Errors found:\n\n    *  Error at line 18: Unmatched opening brace at position 7\n</code></pre> <p>Once fixed, restart OpenVidu again:</p> <pre><code>systemctl restart openvidu\n</code></pre> </li> <li> <p>Execute a <code>docker ps</code>. If you don't see the <code>openvidu-init</code> container, but you see some containers restarting, check the logs of those restarting containers to see what is wrong:</p> <pre><code>docker logs &lt;container_id&gt;\n</code></pre> </li> <li> <p>If all the containers are running correctly, execute the following command:</p> <pre><code>tail -f /var/log/openvidu/nodes_errors.log\n</code></pre> <p>If you have an error like: 'No such file or directory' or simply the file is empty, the configuration is correct. If the file exists with content, some nodes may be malfunctioning. Check this file and failing container logs for errors.</p> <p>This is how the log file looks when there are Media Nodes with errors:</p> <pre><code>[2024-10-09T05:54:29Z] [ERROR] Error in Media Node - 10.5.0.5: Container 'openvidu' error:\ncould not parse config: yaml: unmarshal errors:\n  line 17: cannot unmarshal !!str `trueee` into bool\n\n[2024-10-09T05:54:29Z] [ERROR] Error in Media Node - 10.5.0.4: Container 'openvidu' error:\ncould not parse config: yaml: unmarshal errors:\n  line 17: cannot unmarshal !!str `trueee` into bool\n</code></pre> <p>As you can see, the log informs you about which Media Node is failing and the error that is causing the failure, so in this way you can fix the file which is causing the error. Once fixed, restart OpenVidu again:</p> <pre><code>systemctl restart openvidu\n</code></pre> <p>And again, check the logs until no errors appear.</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/configuration/in-depth/","title":"Configuration system in depth","text":"","tags":["Platform"]},{"location":"docs/self-hosting/configuration/in-depth/#openvidu-configuration-system-in-depth","title":"OpenVidu configuration system in depth","text":"<p>OpenVidu utilizes a powerful and flexible system for configuring services by expanding global parameters defined in the configuration files. This mechanism ensures consistency and simplifies management by allowing global settings to be referenced across multiple service configurations. The variable expansion follows the same interpolation rules as Docker Compose, providing a familiar syntax for those accustomed to Docker.</p>","tags":["Platform"]},{"location":"docs/self-hosting/configuration/in-depth/#how-variable-interpolation-works","title":"How Variable Interpolation Works","text":"<p>To understand how variable interpolation works in OpenVidu, it is important to consider two main types of configuration files: global configuration files and service configuration files.</p> <ol> <li> <p>Global Configuration Files:</p> <ul> <li>Global parameters are defined in the global configuration files such as <code>openvidu.env</code>, <code>master_node.env</code>, and <code>media_node.env</code>.</li> <li>These files contain key-value pairs that define parameters than can be used in service configuration files.</li> </ul> </li> <li> <p>Service Configuration Files:</p> <ul> <li>Each service configuration file can reference these global parameters using a specific syntax.</li> <li>The syntax <code>${openvidu.ENV_VAR}</code> is used to access and interpolate those values from the global configuration files.</li> <li>If you are configuring a service of the Master Node which needs a specific variable of the Master Node, you can use <code>${master_node.ENV_VAR}</code>.</li> <li>If you are configuring a service of the Media Node which needs a specific variable of the Media Node, you can use <code>${media_node.ENV_VAR}</code>.</li> </ul> </li> <li> <p>Interpolation Rules:</p> <ul> <li>The interpolation follows the Docker Compose specification, which provides robust handling of global variables.</li> <li>If a variable is mandatory and not set, the syntax <code>${VAR:?mandatory}</code> can be used to throw an error if the parameter is not defined, ensuring required configurations are not missed. For more detailed information about the interpolation rules, you can refer to the Docker Compose documentation on variable interpolation.</li> </ul> </li> <li> <p>Example:</p> <p>Look at this part of the <code>/opt/openvidu/config/media_node/livekit.yaml</code> configuration file in the Master Node of an Elastic deployment:</p> <pre><code>openvidu:\n    license: ${openvidu.OPENVIDU_PRO_LICENSE:?mandatory}\n    cluster_id: ${openvidu.DOMAIN_NAME:?mandatory}\n    node:\n        private_ip: ${media_node.MEDIA_NODE_PRIVATE_IP:?mandatory}\n</code></pre> <p>This file uses global variables from the <code>openvidu.env</code> and <code>media_node.env</code> files to set up the license, cluster ID, and private IP address for the LiveKit service. The <code>:?mandatory</code> part means these variables must be defined; otherwise, an error will occur. Since this file is for a Media Node, it uses the <code>media_node</code> variables, allowing each Media Node to have different values for the same variable.</p> <p>To use a variable from the <code>media_node.env</code> file, write it as <code>${media_node.ENV_VAR}</code>. Similarly, to use a variable from the <code>openvidu.env</code> or <code>master_node.env</code> file, write it as <code>${openvidu.ENV_VAR}</code> or <code>${master_node.ENV_VAR}</code> respectively.</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/configuration/in-depth/#config-files-replication","title":"Config Files Replication","text":"<p>In Elastic and High Availability deployments, the configuration files are replicated across all the Master Nodes in the cluster.</p> <p>This ensures that all nodes have the same configuration, making it easier to manage and maintain the cluster. The global configuration files are placed in the <code>/opt/openvidu/config/cluster/</code> directory, while the node-specific configuration files are placed in the <code>/opt/openvidu/config/node/</code> directory.</p>","tags":["Platform"]},{"location":"docs/self-hosting/configuration/reference/","title":"Configuration reference","text":"","tags":["Platform"]},{"location":"docs/self-hosting/configuration/reference/#configuration-reference","title":"Configuration reference","text":"","tags":["Platform"]},{"location":"docs/self-hosting/configuration/reference/#openviduenv","title":"<code>openvidu.env</code>:","text":"<p>This file defines global configuration parameters used by other services. Such as the domain name, credentials, etc.</p> Parameter Description <code>DOMAIN_NAME</code> The domain name for the deployment. Use this domain name to access. OpenVidu APIs and services. <code>LIVEKIT_API_KEY</code> Global LiveKit API Key and Secret used for apps to connect to OpenVidu. <code>LIVEKIT_API_SECRET</code> Global LiveKit API Key and Secret used for apps to connect to OpenVidu. <code>MINIO_ACCESS_KEY</code> Access key for MinIO. <code>MINIO_SECRET_KEY</code> Secret key for MinIO. <code>EXTERNAL_S3_ENDPOINT</code> If defined, Minio will not be used and the deployment will use an external S3 service. This is the endpoint of the external S3 service. <code>EXTERNAL_S3_ACCESS_KEY</code> Access key for the external S3 service if used. <code>EXTERNAL_S3_SECRET_KEY</code> Secret key for the external S3 service if used. <code>EXTERNAL_S3_REGION</code> Region of the external S3 service if used. <code>EXTERNAL_S3_PATH_STYLE_ACCESS</code> If <code>true</code>, use path-style access for the external S3 service if used. <code>EXTERNAL_S3_BUCKET_APP_DATA</code> External S3 bucket name for OpenVidu App Data. This is the bucket where application data like recordings, etc. will be stored. <code>EXTERNAL_S3_BUCKET_CLUSTER_DATA</code> External S3 bucket used in High Availability to store Observability data. <code>MONGO_ADMIN_USERNAME</code> MongoDB admin username. <code>MONGO_ADMIN_PASSWORD</code> MongoDB admin password. <code>DASHBOARD_ADMIN_USERNAME</code> Admin username for OpenVidu Dashboard <code>DASHBOARD_ADMIN_PASSWORD</code> Admin password for OpenVidu Dashboard <code>GRAFANA_ADMIN_USERNAME</code> Admin username for Grafana <code>GRAFANA_ADMIN_PASSWORD</code> Admin password for Grafana <code>OPENVIDU_PRO_LICENSE</code> PRO OpenVidu Pro license key. Get an OpenVidu Pro License here. <code>OPENVIDU_RTC_ENGINE</code> PRO The WebRTC engine to use. Can be <code>pion</code> or <code>mediasoup</code>.","tags":["Platform"]},{"location":"docs/self-hosting/configuration/reference/#meetenv","title":"<code>meet.env</code>:","text":"<p>This file defines the configuration parameters for the OpenVidu Meet service.</p> Parameter Description <code>SERVER_PORT</code> Port where the OpenVidu Meet service will be running. <code>SERVER_CORS_ORIGIN</code> CORS origin for the OpenVidu Meet service. It is <code>*</code> by default, allowing all origins. <code>LIVEKIT_URL</code> LiveKit URL for the OpenVidu Meet service to connect to the LiveKit server. <code>LIVEKIT_URL_PRIVATE</code> LiveKit URL for the OpenVidu Meet service to connect to the LiveKit server internally. This is used in High Availability deployments. <code>LIVEKIT_API_KEY</code> LiveKit API Key for the OpenVidu Meet service to connect to the LiveKit server. <code>LIVEKIT_API_SECRET</code> LiveKit API Secret for the OpenVidu Meet service to connect to the LiveKit server. <code>MEET_INITIAL_ADMIN_USER</code> Username for the Admin user of the OpenVidu Meet service. <code>MEET_INITIAL_ADMIN_PASSWORD</code> Password for the Admin user of the OpenVidu Meet service. <code>MEET_INITIAL_API_KEY</code> API Key for the OpenVidu Meet service. This is used by applications developed with OpenVidu Meet. <code>MEET_WEBHOOK_ENABLED</code> If <code>true</code>, the OpenVidu Meet service will send webhooks to the configured webhook endpoint. <code>MEET_WEBHOOK_URL</code> Webhook URL for the OpenVidu Meet service. This is the URL where the webhooks will be sent. <code>MEET_PREFERENCES_STORAGE_MODE</code> Storage mode for user preferences in OpenVidu Meet. Valid values are: <code>s3</code> (S3 bucket) and <code>abs</code> (Azure Blob Storage). <code>MEET_S3_BUCKET</code> S3 bucket name for OpenVidu Meet service. It is used to store recordings. <code>MEET_S3_SUBBUCKET</code> Path for the S3 bucket where OpenVidu Meet service will store recordings and user preferences. <code>MEET_S3_SERVICE_ENDPOINT</code> S3 service endpoint for OpenVidu Meet service. <code>MEET_S3_ACCESS_KEY</code> S3 access key for OpenVidu Meet service. <code>MEET_S3_SECRET_KEY</code> S3 secret key for OpenVidu Meet service. <code>MEET_AWS_REGION</code> AWS region of the S3 Bucket application. <code>MEET_S3_WITH_PATH_STYLE_ACCESS</code> If <code>true</code>, use path-style access for S3. <code>MEET_AZURE_CONTAINER_NAME</code> Azure Blob Storage container name for OpenVidu Meet service. It is used to store recordings. <code>MEET_AZURE_SUBCONATAINER_NAME</code> Path for the Azure Blob Storage container where OpenVidu Meet service will store recordings and user preferences. <code>MEET_AZURE_ACCOUNT_NAME</code> Azure Blob Storage account name for OpenVidu Meet service. <code>MEET_AZURE_ACCOUNT_KEY</code> Azure Blob Storage account key for OpenVidu Meet service. <code>MEET_REDIS_HOST</code> Redis host used by the OpenVidu Meet service to store session data. <code>MEET_REDIS_PORT</code> Redis port used by the OpenVidu Meet service to connect to the Redis server. <code>MEET_REDIS_USERNAME</code> Redis username used by the OpenVidu Meet service to connect to the Redis server. <code>MEET_REDIS_PASSWORD</code> Redis password used by the OpenVidu Meet service to connect to the Redis server. <code>MEET_REDIS_DB</code> Redis database used by the OpenVidu Meet service. Default value is <code>0</code>. <code>MEET_REDIS_SENTINEL_HOST_LIST</code> Redis Sentinel host list used by the OpenVidu Meet service to connect to Redis Sentinel servers. <code>MEET_REDIS_SENTINEL_PASSWORD</code> Redis Sentinel password used by the OpenVidu Meet service to connect to Redis Sentinel servers. <code>MEET_REDIS_SENTINEL_MASTER_NAME</code> Redis Sentinel master name used by the OpenVidu Meet service to connect to Redis Sentinel servers. <code>MEET_LOG_LEVEL</code> Log level for OpenVidu Meet service. Valid values are: <code>error</code>, <code>warn</code>, <code>info</code>, <code>verbose</code>, <code>debug</code>, <code>silly</code>.","tags":["Platform"]},{"location":"docs/self-hosting/configuration/reference/#pro-v2compatibilityenv","title":"PRO <code>v2compatibility.env</code>","text":"<p>Info</p> <p>OpenVidu V2 Compatibility is part of OpenVidu PRO. Before deploying, you need to create an OpenVidu account to get your license key. There's a 15-day free trial waiting for you!</p> <p>This file defines the configuration parameters for the OpenVidu V2 Compatibility Server. They resemble the configuration parameters of OpenVidu 2 , adding prefix <code>V2COMPAT_</code> to the parameter name.</p> Parameter Description <code>OPENVIDU_PRO_LICENSE</code> OpenVidu Pro license key. Get an OpenVidu Pro License here. <code>V2COMPAT_OPENVIDU_SHIM_PORT</code> Port where the OpenVidu V2 Compatibility will be running. By default is <code>4443</code> <code>V2COMPAT_OPENVIDU_SHIM_URL</code> Public URL used for openvidu v2 applications used by external clients to connect to the OpenVidu V2 Compatibility Server. <code>V2COMPAT_OPENVIDU_SECRET</code> OpenVidu Secret used by openvidu v2 applications to connect to the OpenVidu deployment. <code>V2COMPAT_LIVEKIT_URL</code> LiveKit URL used by external clients to connect to the OpenVidu V2 Compatibility Server using the LiveKit protocol. <code>V2COMPAT_LIVEKIT_URL_PRIVATE</code> LiveKit URL used by the OpenVidu V2 Compatibility Server to connect to the LiveKit Server internally. <code>V2COMPAT_LIVEKIT_API_KEY</code> LiveKit API Key used by the OpenVidu V2 Compatibility Server to interact with the LiveKit Server. <code>V2COMPAT_LIVEKIT_API_SECRET</code> LiveKit API Secret used by the OpenVidu V2 Compatibility Server to interact with the LiveKit Server. <code>V2COMPAT_REDIS_HOST</code> Redis host used by the OpenVidu V2 Compatibility Server to store session data. <code>V2COMPAT_REDIS_PORT</code> Redis port used by the OpenVidu V2 Compatibility Server to connect to the Redis server. <code>V2COMPAT_REDIS_PASSWORD</code> Redis password used by the OpenVidu V2 Compatibility Server to connect to the Redis server. <code>V2COMPAT_REDIS_SENTINEL_HOST_LIST</code> Redis Sentinel host list used by the OpenVidu V2 Compatibility Server to connect to Redis Sentinel servers. <code>V2COMPAT_REDIS_SENTINEL_PASSWORD</code> Redis Sentinel password used by the OpenVidu V2 Compatibility Server to connect to Redis Sentinel servers. <code>V2COMPAT_REDIS_MASTER_NAME</code> Redis Sentinel master name used by the OpenVidu V2 Compatibility Server to connect to Redis Sentinel servers. <code>V2COMPAT_REDIS_DB</code> Redis database used by the OpenVidu V2 Compatibility Server. Default value is <code>0</code>. <code>V2COMPAT_OPENVIDU_RECORDING_PATH</code> Path where the OpenVidu V2 Compatibility Server will store recordings locally. By default in the deployments is <code>/opt/openvidu/recordings</code>. <code>V2COMPAT_OPENVIDU_PRO_RECORDING_STORAGE</code> Where to store the recordings. Valid values are: <ul><li><code>local</code>: Store the recordings in the local filesystem at the path <code>V2COMPAT_OPENVIDU_RECORDING_PATH</code></li><li><code>s3</code>: Store the recordings in the configured S3 bucket</li></ul> Default value is <code>local</code> <code>V2COMPAT_OPENVIDU_RECORDING_CUSTOM_LAYOUT_URL</code> URL of the custom layout used by the OpenVidu V2 Compatibility Server to generate the recordings. <code>V2COMPAT_OPENVIDU_PRO_AWS_S3_WITH_PATH_STYLE_ACCESS</code> If <code>true</code>, use path-style access for S3. <code>V2COMPAT_OPENVIDU_RECORDING_ZIP_FILES</code> If <code>true</code>, save individual recordings as zip files <code>V2COMPAT_OPENVIDU_RECORDING_RAW_FILES</code> If <code>true</code>, save individual recordings as files directly <code>V2COMPAT_OPENVIDU_PRO_AWS_S3_BUCKET</code> Default bucket name for recordings <code>V2COMPAT_OPENVIDU_PRO_AWS_S3_SERVICE_ENDPOINT</code> S3 service endpoint for the recordings <code>V2COMPAT_OPENVIDU_PRO_AWS_ACCESS_KEY</code> Access key for the recordings S3 bucket <code>V2COMPAT_OPENVIDU_PRO_AWS_SECRET_KEY</code> Secret key for the recordings S3 bucket <code>V2COMPAT_OPENVIDU_PRO_AWS_REGION</code> AWS region of the recordings S3 bucket <code>V2COMPAT_OPENVIDU_WEBHOOK</code> If <code>true</code>, the OpenVidu V2 Compatibility Server will send webhooks to <code>V2COMPAT_OPENVIDU_WEBHOOK_ENDPOINT</code> <code>V2COMPAT_OPENVIDU_WEBHOOK_HEADERS</code> JSON Array list of headers to send in the OpenVidu V2 Webhook events. For example: <code>[\"Content-Type: application/json\"]</code> <code>V2COMPAT_OPENVIDU_WEBHOOK_EVENTS</code> Comma-separated list of OpenVidu V2 Webhook events to send. All available events are: <ul><li>sessionCreated</li><li>sessionDestroyed</li><li>participantJoined</li><li>participantLeft</li><li>webrtcConnectionCreated</li><li>webrtcConnectionDestroyed</li><li>recordingStatusChanged</li><li>signalSent</li></ul>","tags":["Platform"]},{"location":"docs/self-hosting/configuration/reference/#livekityaml","title":"<code>livekit.yaml</code>:","text":"<p>As OpenVidu Server is built on top of LiveKit, the configuration of OpenVidu Server is done in the <code>livekit.yaml</code> file in its own <code>openvidu</code> section in this file. The rest of the configuration is the same as the LiveKit server configuration .</p>","tags":["Platform"]},{"location":"docs/self-hosting/configuration/reference/#community-openvidu-server-configuration","title":"COMMUNITY OpenVidu Server Configuration:","text":"<pre><code>openvidu:\n    analytics: # (1)\n        enabled: true # (2)\n        mongo_url: mongodb://&lt;MONGO_ADMIN_USERNAME&gt;:&lt;MONGO_ADMIN_PASSWORD&gt;@localhost:20000/ # (3)\n        interval: 10s # (4)\n        expiration: 768h # (5)\n</code></pre> <ol> <li>The <code>analytics</code> configuration should be defined at the <code>openvidu</code> level in the <code>livekit.yaml</code> file.</li> <li>This must be set to <code>true</code> to send analytics data to MongoDB. If set to <code>false</code>, no analytics data will be sent.</li> <li>MongoDB connection string. In OpenVidu Single Node, the MongoDB service is running on the same machine, so you can use <code>localhost</code> as the hostname. The default port in OpenVidu for MongoDB is <code>20000</code>. <code>MONGO_ADMIN_USERNAME</code> and <code>MONGO_ADMIN_PASSWORD</code> are the credentials to access the MongoDB database.</li> <li>Time interval to send analytics data to MongoDB.</li> <li>Time to keep the analytics data in MongoDB. In this example, it is set to 32 days.</li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/configuration/reference/#pro-openvidu-server-configuration","title":"PRO OpenVidu Server Configuration:","text":"<p>Info</p> <p>Before deploying OpenVidu PRO, you need to create an OpenVidu account to get your license key. There's a 15-day free trial waiting for you!</p> <pre><code>openvidu:\n    license: &lt;YOUR_OPENVIDU_PRO_LICENSE&gt; # (1)\n    cluster_id: &lt;YOUR_DOMAIN_NAME&gt; # (2)\n    analytics: # (3)\n        enabled: true # (4)\n        interval: 10s # (5)\n        expiration: 768h # (6)\n        mongo_url: &lt;MONGO_URL&gt; # (7)\n    rtc:\n        engine: pion # (8)\n    mediasoup:\n        debug: \"\" # (9)\n        log_level: error # (10)\n        log_tags: [info, ice, rtp, rtcp, message] # (11)\n</code></pre> <ol> <li>Specify your OpenVidu Pro license key. If you don't have one, you can request one here.</li> <li>The cluster ID for the OpenVidu deployment. It is configured by default by OpenVidu Installer with the domain name of the deployment.</li> <li>The <code>analytics</code> configuration should be defined at the <code>openvidu</code> level in the <code>livekit.yaml</code> file.</li> <li>This must be set to <code>true</code> to send analytics data to MongoDB. If set to <code>false</code>, no analytics data will be sent.</li> <li>Time interval to send analytics data to MongoDB.</li> <li>Time to keep the analytics data in MongoDB. In this example, it is set to 32 days.</li> <li>MongoDB URL. This is the connection string to the MongoDB database where the analytics data will be stored.</li> <li>The <code>rtc.engine</code> parameter is set to <code>pion</code> by default. This is the WebRTC engine used by OpenVidu. Depending on your requirements, you can use:<ul> <li><code>pion</code></li> <li><code>mediasoup</code></li> </ul> </li> <li>Global toggle to enable debugging logs from Mediasoup. In most debugging cases, using just an asterisk (\"*\") here is enough, but this can be fine-tuned for specific log levels. More info .<ul> <li>Default is an empty string.</li> </ul> </li> <li>Logging level for logs generated by Mediasoup. More info .<ul> <li>Valid values are: <code>debug</code>, <code>warn</code>, <code>error</code>, <code>none</code>.</li> <li>Default is <code>error</code>.</li> </ul> </li> <li>Comma-separated list of log tag names, for debugging. More info .<ul> <li>Valid values are: <code>info</code>, <code>ice</code>, <code>dtls</code>, <code>rtp</code>, <code>srtp</code>, <code>rtcp</code>, <code>rtx</code>, <code>bwe</code>, <code>score</code>, <code>simulcast</code>, <code>svc</code>, <code>sctp</code>, <code>message</code>.</li> <li>Default is <code>[info, ice, rtp, rtcp, message]</code>.</li> </ul> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/configuration/reference/#other-services-configuration","title":"Other Services Configuration","text":"<p>OpenVidu comes with other services configured to work in the deployment. These are the configuration files for each service:</p> Service Description Reference documentation OpenVidu Server Manage Rooms and Media Streams. <ul><li>OpenVidu Config</li><li>LiveKit Config </li></ul> Ingress Service Imports video from other sources into OpenVidu rooms. LiveKit Ingress Config  Egress Service Exports video from OpenVidu rooms for recording or streaming. LiveKit Egress Config  Caddy Server Serves OpenVidu services and handles HTTPS. Caddy JSON Structure  Grafana Service Used for visualizing monitoring data. Grafana Config  Mimir Service Service for long-term prometheus storage Mimir Config  Loki Service Used for log aggregation. Loki Config  Prometheus Service Used for monitoring. Prometheus Config  Promtail Service Collects logs and sends them to Loki. Promtail Config","tags":["Platform"]},{"location":"docs/self-hosting/elastic/","title":"OpenVidu Elastic","text":"","tags":["Platform"]},{"location":"docs/self-hosting/elastic/#openvidu-elastic-installation","title":"OpenVidu Elastic installation","text":"<p>OpenVidu Elastic is part of the PRO edition of OpenVidu. You have the following deployment options:</p> <ul> <li>On-premises installation: Set up OpenVidu Elastic on your own servers.</li> <li>AWS installation: Deploy OpenVidu Elastic on Amazon Web Services.</li> <li>Azure installation: Deploy OpenVidu Elastic on Microsoft Azure.</li> </ul> <p>Once your deployment is complete, refer to the following sections for configuration and management:</p> <ul> <li>On-premises: configuration and administration</li> <li>AWS: configuration and administration</li> <li>Azure: configuration and administration</li> </ul> <p>If you want to upgrade your OpenVidu Elastic installation, refer to this section:</p> <ul> <li>Upgrade OpenVidu Elastic On-premises</li> <li>Upgrade OpenVidu Elastic AWS</li> <li>Upgrade OpenVidu Elastic Azure</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/aws/admin/","title":"OpenVidu Elastic administration on AWS","text":"","tags":["Platform"]},{"location":"docs/self-hosting/elastic/aws/admin/#openvidu-elastic-administration-aws","title":"OpenVidu Elastic administration: AWS","text":"<p>The deployment of OpenVidu Elastic on AWS is automated using AWS CloudFormation, with Media Nodes managed within an Auto Scaling Group . This group dynamically adjusts the number of instances based on a target average CPU utilization. Internally, the AWS deployment mirrors the on-premises setup, allowing you to follow the same administration and configuration guidelines provided in the On Premises Elastic documentation. However, there are specific considerations unique to the AWS environment that are worth taking into account.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/aws/admin/#cluster-shutdown-and-startup","title":"Cluster Shutdown and Startup","text":"<p>The Master Node is an EC2 instance, while the Media Nodes are part of an Auto Scaling Group. The process for starting and stopping these components differs. The following sections detail the procedures.</p> Shutdown the ClusterStartup the Cluster <p>To shut down the cluster, you need to stop the Media Nodes first and then stop the Master Node. This way, any ongoing session will not be interrupted.</p> <ol> <li>Navigate to the CloudFormation Dashboard  on AWS.</li> <li>Select the CloudFormation Stack that you used to deploy OpenVidu Elastic.</li> <li>In the \"Resources\" tab, locate the resource with the logical ID: <code>OpenViduMediaNodeASG</code>, and click on it to go to the Auto Scaling Group Dashboard with the Auto Scaling Group of the Media Nodes selected.      </li> <li>Click on \"Actions &gt; Edit\".      </li> <li>Set the \"Desired capacity\", \"Min desired capacity\", and \"Max desired capacity\" to 0, and click on \"Update\".      </li> <li> <p>Wait until the \"Instance Management\" tab shows that there are no instances in the Auto Scaling Group.     </p> <p></p> <p>Warning</p> <p>It may happen that some instances are still in the \"Terminating:Wait\" lifecycle state after setting the desired capacity to 0. This is because the Auto Scaling Group waits for the instances to finish processing any ongoing room, ingress, or egress operations before terminating them. This can take a few minutes. If you want to force the termination of the instances, you can manually terminate them from the EC2 Dashboard.</p> </li> <li> <p>After confirming that all Media Node instances are terminated, go back to the CloudFormation Stack and locate the resource with the logical ID: <code>OpenViduMasterNode</code>. Click on it to go to the EC2 Dashboard with the Master Node instance selected.     </p> <p></p> </li> <li>Right-click on the instance and select \"Stop instance\".      </li> </ol> <p>To start the cluster, we recommend starting the Master Node first and then the Media Nodes.</p> <ol> <li>Navigate to the CloudFormation Dashboard  on AWS.</li> <li>Select the CloudFormation Stack that you used to deploy OpenVidu Elastic.</li> <li>Locate the resource with the logical ID: <code>OpenViduMasterNode</code>. Click on it to go to the EC2 Dashboard with the Master Node instance selected.      </li> <li>Right-click on the instance and select \"Start instance\".      </li> <li>Wait until the instance is running.</li> <li>Go back to the CloudFormation Stack and locate the resource with the logical ID: <code>OpenViduMediaNodeASG</code>. Click on it to go to the Auto Scaling Group Dashboard with the Auto Scaling Group of the Media Nodes selected.      </li> <li>Click on \"Actions &gt; Edit\".      </li> <li>Set the \"Desired capacity\", \"Min desired capacity\", and \"Max desired capacity\" to the desired number of Media Nodes, and click on \"Update\". In this example, we set the desired capacity to 2.      </li> <li>Wait until the \"Instance Management\" tab shows that there are the desired number of instances in the Auto Scaling Group.      </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/aws/admin/#change-the-instance-type","title":"Change the instance type","text":"<p>It is possible to change the instance type of both the Master Node and the Media Nodes. However, since the Media Nodes are part of an Auto Scaling Group, the process differs. The following section details the procedures.</p> Master NodesMedia Nodes <p>Warning</p> <p>This procedure requires downtime, as it involves stopping the Master Node.</p> <ol> <li> <p>Shutdown the cluster.</p> <p>Info</p> <p>You can stop only the Master Node instance to change its instance type, but it is recommended to stop the whole cluster to avoid any issues.</p> </li> <li> <p>Go to the CloudFormation Stack and locate the resource with the logical ID: <code>OpenViduMasterNode</code>. Click on it to go to the EC2 Dashboard with the Master Node instance selected.     </p> <p></p> </li> <li>Right-click on the instance and select \"Instance Settings &gt; Change Instance Type\".      </li> <li>Select the new instance type and click on \"Apply\".</li> <li>Start the cluster.</li> </ol> <ol> <li>Go to the CloudFormation Dashboard  on AWS.</li> <li>Select the CloudFormation Stack that you used to deploy OpenVidu Elastic.</li> <li>Locate the resource with the logical ID: <code>OpenViduMediaNodeLaunchTemplate</code>. Click on it to go to the Launch Template Dashboard with the Launch Template of the Media Nodes selected.      </li> <li>Click on \"Actions &gt; Modify template (Create new version)\".      </li> <li>In the \"Instance type\" section, select the new instance type and click on \"Create template version\".      </li> <li>Go to the CloudFormation Stack and locate the resource with the logical ID: <code>OpenViduMediaNodeASG</code>. Click on it to go to the Auto Scaling Group Dashboard with the Auto Scaling Group of the Media Nodes selected.      </li> <li>Click on \"Actions &gt; Edit\".      </li> <li> <p>In the Launch Template section, select the new version of the launch template we just created at step 5, which is the highest version number.</p> <p>Then, click on \"Update\".</p> <p>Info</p> <p>By configuring \"Latest\" as the launch template version, you no longer need to update the Auto Scaling Group every time you modify the launch template. The Auto Scaling Group will automatically use the latest version of the launch template.</p> <p></p> </li> <li> <p>Terminate the old instances manually from the EC2 Dashboard if you want to force the termination of the instances. New instances will be launched with the new instance type.</p> <p>Info</p> <p>If you want to avoid downtime, you can wait until the Auto Scaling Group replaces the old instances with the new ones. But you will need to increase the desired capacity to force the replacement of the instances and then decrease it to the desired number of instances.</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/aws/admin/#media-nodes-autoscaling-configuration","title":"Media Nodes Autoscaling Configuration","text":"<p>To configure the Auto Scaling settings for the Media Nodes, follow the steps outlined below. This configuration allows you to set the parameters that control how the Auto Scaling Group will scale based on the target average CPU utilization.</p> Media Nodes Autoscaling Configuration <ol> <li>Navigate to the CloudFormation Dashboard  on AWS.</li> <li>Select the CloudFormation Stack that you used to deploy OpenVidu Elastic.</li> <li>In the \"Resources\" tab, locate the resource with the logical ID: <code>OpenViduMediaNodeASG</code> and click on it to go to the Auto Scaling Group Dashboard.      </li> <li>Click on \"Actions &gt; Edit\".      </li> <li>To configure scaling policies, navigate to the \"Automatic scaling\" tab within the Auto Scaling Group Dashboard, select the unique \"Target tracking scaling\" autoscaling policy, and click on \"Actions &gt; Edit\".      </li> <li> <p>It will open a panel where you can configure multiple parameters. In this example, we set the target average CPU utilization to 30%. Then, click on \"Update\".     </p> <p></p> <p>Info</p> <p>OpenVidu Elastic is by default configured with a \"Target tracking scaling\" policy that scales based on the target average CPU utilization, however, you can configure different autoscaling policies according to your needs. For more information on the various types of autoscaling policies and how to implement them, refer to the AWS Auto Scaling documentation .</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/aws/admin/#fixed-number-of-media-nodes","title":"Fixed Number of Media Nodes","text":"<p>If you need to maintain a fixed number of Media Nodes instead of allowing the Auto Scaling Group to dynamically adjust based on CPU utilization, you can configure the desired capacity settings accordingly. Follow the steps below to set a fixed number of Media Nodes:</p> Set Fixed Number of Media Nodes <ol> <li>Navigate to the CloudFormation Dashboard  on AWS.</li> <li>Select the CloudFormation Stack that you used to deploy OpenVidu Elastic.</li> <li>In the \"Resources\" tab, locate the resource with the logical ID: <code>OpenViduMediaNodeASG</code> and click on it to go to the Auto Scaling Group Dashboard.      </li> <li>Click on \"Actions &gt; Edit\".      </li> <li>Set the \"Desired capacity\", \"Min desired capacity\", and \"Max desired capacity\" to the fixed number of Media Nodes you require, and click on \"Update\". In this example, we set the desired capacity to 2.      </li> <li>Wait until the \"Instance Management\" tab shows that the Auto Scaling Group has the fixed number of instances running.      </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/aws/admin/#administration-and-configuration","title":"Administration and configuration","text":"<p>For administration, you can follow the instructions from the On Premises Elastic Administration section.</p> <p>Regarding the configuration, in AWS it is managed similarly to an on-premises deployment. For detailed instructions, please refer to the Changing Configuration section. Additionally, the How to Guides offer multiple resources to assist with specific configuration changes.</p> <p>In addition to these, an AWS deployment provides the capability to manage global configurations via the AWS Console using AWS Secrets created during the deployment. To manage configurations this way, follow these steps:</p> Changing Configuration through AWS Secrets <ol> <li>Navigate to the CloudFormation Dashboard  on AWS.</li> <li>Select the CloudFormation Stack that you used to deploy OpenVidu Elastic.</li> <li>In the \"Outputs\" tab, click the Link at \"ServicesAndCredentials\". This will open the AWS Secrets Manager which contains all the configurations of the OpenVidu Elastic Deployment.      </li> <li>Click on the \"Retrieve secret value\" button to get the JSON with all the information.      </li> <li>Modify the parameter you want to change and click on \"Save\".</li> <li>Go to the EC2 Console and click on \"Reboot instance\" in the Master Node instance to apply the changes.      </li> </ol> <p>Changes will be applied automatically in all the nodes of your OpenVidu Elastic deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/aws/install/","title":"OpenVidu Elastic installation on AWS","text":"","tags":["Platform"]},{"location":"docs/self-hosting/elastic/aws/install/#openvidu-elastic-installation-aws","title":"OpenVidu Elastic installation: AWS","text":"<p>Info</p> <p>OpenVidu Elastic is part of OpenVidu PRO. Before deploying, you need to create an OpenVidu account to get your license key. There's a 15-day free trial waiting for you!</p> <p>This section contains the instructions to deploy a production-ready OpenVidu Elastic deployment in AWS. Deployed services are the same as the On Premises Elastic installation but automate the process with AWS CloudFormation.</p> <p>First of all, import the template in the AWS CloudFormation console. You can click the following button...</p> <p> Deploy to AWS</p> <p>...or access your AWS CloudFormation console  and manually set this S3 URL in the <code>Specify template</code> section:</p> <pre><code>https://s3.eu-west-1.amazonaws.com/get.openvidu.io/pro/elastic/latest/aws/cf-openvidu-elastic.yaml\n</code></pre> <p>Info</p> <p>If you want to deploy a specific version of OpenVidu High Availability, replace <code>latest</code> with the version you want to deploy. For example, to deploy version <code>3.4.0</code>, use the following URL:</p> <pre><code>https://s3.eu-west-1.amazonaws.com/get.openvidu.io/pro/elastic/3.4.0/aws/cf-openvidu-elastic.yaml\n</code></pre> Architecture overview <p>This is how the architecture of the deployment looks:</p> <p></p> OpenVidu Elastic AWS Architecture <p></p> <ul> <li>The Master Node acts as a Load Balancer, managing the traffic and distributing it among the Media Nodes and deployed services in the Master Node.</li> <li>The Master Node has its own Caddy server acting as a Layer 4 (for TURN with TLS and RTMPS) and Layer 7 (for OpenVidu Dashboard, OpenVidu Meet, etc., APIs) reverse proxy.</li> <li>WebRTC traffic (SRTP/SCTP/STUN/TURN) is routed directly to the Media Nodes.</li> <li>An autoscaling group of Media Nodes is created to scale the number of Media Nodes based on the system load.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/aws/install/#cloudformation-parameters","title":"CloudFormation Parameters","text":"<p>Depending on your needs, you need to fill in the following CloudFormation parameters:</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/aws/install/#domain-and-ssl-certificate-configuration","title":"Domain and SSL Certificate Configuration","text":"<p>There are three possible scenarios for this section:</p> Let's Encrypt Without Domain NameLet's Encrypt With Domain Name (recommended)Custom CertificatesSelf-Signed Certificate <p>If you don't have a Domain Name and want to quickly test OpenVidu on AWS, you can use this option, simply selecting the CertificateType as letsencrypt and keep the rest of parameters empty.</p> <p>It will deploy OpenVidu with a Let's Encrypt certificate generated using sslip.io based on the public IP created for the deployment.</p> <p></p> <p>For a production environment, it is highly recommended to use this option. It allows you to deploy OpenVidu on AWS with a valid Let's Encrypt certificate for your Fully Qualified Domain Name (FQDN).</p> <p>You need to previously create an Elastic IP and have a Domain Name pointing to that Elastic IP.</p> <p></p> <p>You can specify the DomainName with your FQDN and optionally the PublicElasticIP with the Elastic IP that the domain points to.</p> <p>Opt for this method if you possess your own certificate for an existing FQDN. It enables you to deploy OpenVidu on AWS using your certificates.</p> <p>You need to have a Fully Qualified Domain Name (FQDN) pointing to a previously created Elastic IP.</p> <p>Also, you need a temporary HTTP server hosting your private and public certificate under a specific URL. These URLs are needed for the instance to be able to download and install your certificates.</p> <p>The configured parameters would look like this:</p> <p></p> <p>You need to specify at OwnPublicCertificate and OwnPrivateCertificate the URLs where the public and private certificates are hosted, respectively. The DomainName and PublicElasticIP are mandatory parameters.</p> <p>Certificates need to be in PEM format and the URLs must be accessible from the instance.</p> <p>This option is useful for development and testing purposes. It allows you to deploy OpenVidu on AWS with an autogenerated self-signed certificate. This way, you can quickly set up a secure connection without the need to obtain a certificate from a trusted Certificate Authority (CA).</p> <p>However, this convenience comes with the caveat that users will need to manually accept the certificate in their web browsers. Please be aware that this configuration is solely for developmental and testing purposes and is not suitable for a production environment.</p> <p>These are the parameters needed in this section to use self-signed certificates:</p> <p></p> <p>You can optionally specify a DomainName. If no domain name is provided, sslip.io{:target=\"blank\"} will be used to generate a domain based on the public IP. Just select the CertificateType as _self-signed.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/aws/install/#openvidu-elastic-configuration","title":"OpenVidu Elastic Configuration","text":"<p>In this section, you need to specify some properties needed for the OpenVidu Elastic deployment.</p> OpenVidu Elastic Configuration <p>Parameters of this section look like this:</p> <p></p> <p>Make sure to provide the OpenViduLicense parameter with the license key. If you don't have one, you can request one here.</p> <p>For the RTCEngine parameter, you can choose between Pion (the default engine used by LiveKit) and Mediasoup (with a boost in performance). Learn more about the differences here.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/aws/install/#openvidu-meet-credentials","title":"OpenVidu Meet Credentials","text":"<p>Configure the initial credentials for accessing OpenVidu Meet:</p> OpenVidu Meet credentials <p>Parameters in this section look like this:</p> <p></p> <ul> <li>InitialMeetAdminPassword: Initial password for the \"admin\" user in OpenVidu Meet. If not provided, a random password will be generated and stored in the AWS Secret Manager.</li> <li>InitialMeetApiKey: Initial API key for OpenVidu Meet. If not provided, no API key will be set and the user can configure it later from the Meet Console.</li> </ul> <p>Both parameters are optional. If you don't specify them, you can retrieve the generated credentials from the AWS Secret Manager after deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/aws/install/#ec2-instance-configuration","title":"EC2 Instance Configuration","text":"<p>You need to specify some properties for the EC2 instances that will be created.</p> EC2 Instance configuration <p>Parameters in this section look like this:</p> <p></p> <p>Simply select the type of instance you want to deploy at MasterNodeInstanceType and MediaNodeInstanceType, the SSH key you want to use to access the machine at KeyName, and the Amazon Image ID (AMI) to use at AmiId.</p> <p>By default, the parameter AmiId is configured to use the latest LTS Ubuntu AMI, so ideally you don\u2019t need to modify this.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/aws/install/#media-nodes-autoscaling-group-configuration","title":"Media Nodes Autoscaling Group Configuration","text":"<p>The number of Media Nodes can scale up or down based on the system load. You can configure the minimum and maximum number of Media Nodes and a target CPU utilization to trigger the scaling up or down.</p> Media Nodes Autoscaling Group Configuration <p>Parameters in this section look like this:</p> <p></p> <p>The InitialNumberOfMediaNodes parameter specifies the initial number of Media Nodes to deploy. The MinNumberOfMediaNodes and MaxNumberOfMediaNodes parameters specify the minimum and maximum number of Media Nodes that you want to be deployed.</p> <p>The ScaleTargetCPU parameter specifies the target CPU utilization to trigger the scaling up or down. The goal is to keep the CPU utilization of the Media Nodes close to this value. The autoscaling policy is based on Target Tracking Scaling Policy .</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/aws/install/#s3-bucket-for-application-data-and-recordings","title":"S3 bucket for application data and recordings","text":"<p>You can specify an S3 bucket to store the recordings and application data. If this parameter is not specified, a new S3 bucket will be created by the CloudFormation stack.</p> S3 bucket for application data and recordings <p>Parameters in this section look like this:</p> <p></p> <p>You can specify an existing S3 bucket or leave it empty to create a new one.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/aws/install/#vpc-configuration","title":"VPC Configuration","text":"<p>In this section, you need to specify the VPC and Subnet configuration for the deployment.</p> VPC Configuration <p>Parameters in this section look like this:</p> <p></p> <p>The OpenViduVPC parameter specifies the VPC where the deployment will be created.</p> <p>The OpenViduMasterNodeSubnet and OpenViduMediaNodeSubnet parameters specify the subnets where the Master and Media Nodes will be deployed. All of them must be in the previously specified OpenViduVPC.</p> <p>Warning</p> <p>You must use public subnets for the Master Nodes and Media Nodes and have enabled the auto-assign public IP option.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/aws/install/#optional-turn-server-configuration-with-tls","title":"(Optional) TURN server configuration with TLS","text":"<p>This section is optional. It is useful when your users are behind a restrictive firewall that blocks UDP traffic. This parameter will only work if you are using <code>letsencrypt</code> or <code>owncert</code> as the CertificateType parameter.</p> <p>Note that if you are not using any Domain Name in the Domain and SSL Certificate Configuration section, this section will be ignored and a generated domain based on the public IP and sslip.io will be used instead.</p> TURN server configuration with TLS <p>Parameters in this section look like this:</p> <p></p> <p>Set the TurnDomainName parameter to the domain name you intend to use for your TURN server. It should be pointing to the <code>PublicElasticIP</code> specified in the previous section.</p> <p>If you are using <code>letsencrypt</code> as the CertificateType parameter, you can leave the TurnOwnPublicCertificate and TurnOwnPrivateCertificate parameters empty. If you are using <code>owncert</code>, you need to specify the URLs where the public and private certificates are hosted.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/aws/install/#deploying-the-stack","title":"Deploying the stack","text":"<p>When you are ready with your CloudFormation parameters, just click on \"Next\", specify in \"Stack failure options\" the option \"Preserve successfully provisioned resources\" to be able to troubleshoot the deployment in case of error, click on \"Next\" again, and finally \"Submit\".</p> <p>When everything is ready, you will see the following links in the \"Outputs\" section of CloudFormation:</p> CloudFormation Outputs <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/aws/install/#configure-your-application-to-use-the-deployment","title":"Configure your application to use the deployment","text":"<p>The Output Key ServicesAndCredentials of the previous section points to an AWS Secret Manager secret that contains all URLs and credentials to access the services deployed. You can access the secret by clicking on the link in the Output Value column.</p> <p>Then, click on Retrieve secret value to get the JSON with all the information.</p> <p></p> <p></p> <p>To use your OpenVidu deployment, check the values of the JSON secret. All access credentials of all services are defined in this object. The most relevant ones are:</p> <p>OpenVidu Meet:</p> <ul> <li><code>OPENVIDU_URL</code>: The URL to access OpenVidu Meet, which is always <code>https://yourdomain.example.io/</code></li> <li><code>MEET_INITIAL_ADMIN_USER</code>: User to access OpenVidu Meet Console. It is always <code>admin</code>.</li> <li><code>MEET_INITIAL_ADMIN_PASSWORD</code>: Password to access OpenVidu Meet Console.</li> <li><code>MEET_INITIAL_API_KEY</code>: API key to use OpenVidu Meet Embedded and OpenVidu Meet REST API.</li> </ul> <p>Note</p> <p>The <code>MEET_INITIAL_ADMIN_USER</code>, <code>MEET_INITIAL_ADMIN_PASSWORD</code>, and <code>MEET_INITIAL_API_KEY</code> values are initial settings that cannot be changed from AWS Secret Manager. They can only be changed from the Meet Console.</p> <p>OpenVidu Platform:</p> <ul> <li><code>LIVEKIT_URL</code>: The URL to use LiveKit SDKs, which can be <code>wss://yourdomain.example.io/</code> or <code>https://yourdomain.example.io/</code> depending on the client library you are using.</li> <li><code>LIVEKIT_API_KEY</code>: API Key for LiveKit SDKs.</li> <li><code>LIVEKIT_API_SECRET</code>: API Secret for LiveKit SDKs.</li> </ul> <p>OpenVidu V2 Compatibility Credentials</p> <p>This section is only needed if you want to use OpenVidu v2 compatibility.</p> <ul> <li>URL: The URL to access OpenVidu, which is the value of <code>OPENVIDU_URL</code> (e.g., <code>https://yourdomain.example.io/</code>)</li> <li>Username: Basic auth user for OpenVidu v2 compatibility. It is always <code>OPENVIDUAPP</code>.</li> <li>Password: Basic auth password for OpenVidu v2 compatibility is the same as <code>LIVEKIT_API_SECRET</code>.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/aws/install/#troubleshooting-initial-cloudformation-stack-creation","title":"Troubleshooting Initial CloudFormation Stack Creation","text":"<p>If something goes wrong during the initial CloudFormation stack creation, your stack may reach the <code>CREATE_FAILED</code> status for multiple reasons. It could be due to a misconfiguration in the parameters, a lack of permissions, or a problem with the AWS services. When this happens, the following steps can help you troubleshoot the issue and identify what went wrong:</p> <ol> <li> <p>While deploying the stack, make sure at \"Stack failure options\" you have selected the option \"Preserve successfully provisioned resources\" to be able to troubleshoot the deployment in case of an error.</p> Disable Rollback on failure <p></p> <p></p> </li> <li> <p>Check if the EC2 instance or instances are running. If they are not, check the CloudFormation events for any error messages.</p> </li> <li> <p>If the EC2 instance or instances are running, SSH into the instance and check the logs of the following files:</p> <ul> <li><code>/var/log/cloud-init-output.log</code></li> <li><code>/var/log/cloud-init.log</code></li> </ul> <p>These logs will give you more information about the CloudFormation stack creation process.</p> </li> <li> <p>If everything seems fine, check the status and the logs of the installed OpenVidu services in the Master Node and Media Nodes.</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/aws/install/#configuration-and-administration","title":"Configuration and administration","text":"<p>When your CloudFormation stack reaches the <code>CREATE_COMPLETE</code> status, your OpenVidu Elastic deployment is ready to use. You can check the Administration section to learn how to manage your OpenVidu Elastic deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/aws/upgrade/","title":"Upgrade OpenVidu Elastic - AWS","text":"","tags":["Platform"]},{"location":"docs/self-hosting/elastic/aws/upgrade/#upgrade-openvidu-elastic-aws","title":"Upgrade OpenVidu Elastic - AWS","text":"<p>In AWS environments, we recommend upgrading by redeploying the OpenVidu Elastic CloudFormation stack using the latest version. This approach ensures that all components are updated accurately and consistently, as CloudFormation templates and related configurations may vary between releases. Redeploying guarantees that all necessary changes are properly applied.</p> <p>However, if you prefer not to redeploy, it is also possible to upgrade OpenVidu Elastic in place. The following steps outline how to perform an in-place upgrade of your OpenVidu Elastic deployment on AWS:</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/aws/upgrade/#upgrading-openvidu-elastic-on-aws","title":"Upgrading OpenVidu Elastic on AWS","text":"<ol> <li>SSH into your Master Node server.</li> <li> <p>Execute the following command in the Master Node:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/update/latest/update.sh)\n</code></pre> <p>Info</p> <p>If instead of upgrading to the latest version you want to upgrade to a specific version, you can execute the following command:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/update/&lt;VERSION&gt;/update.sh)\n</code></pre> <p>Where <code>&lt;VERSION&gt;</code> is the version you want to upgrade to.</p> </li> <li> <p>This will execute an update script which will guide you from the version you have installed to the latest one. The first thing you will see in the output is the following:</p> <pre><code>Stopping OpenVidu service...\nBacking up files...\n\n    - Backing up file '/opt/openvidu/config' to '/opt/openvidu/backups/&lt;DATE&gt;_&lt;VERSION&gt;/config'\n    ... More files ...\n\n--------------------\n\ud83d\udce6 Backup directory: /opt/openvidu/backups/&lt;DATE&gt;_&lt;VERSION&gt;/\n--------------------\n\n--------------------\n\ud83d\ude80 Updating OpenVidu from 3.x.x to 3.y.y\n--------------------\n\n? Do you want to update from 3.x.x to 3.y.y? \u203a\n\u2022 Yes\n  No\n</code></pre> </li> <li> <p>Answer <code>Yes</code> to the question and your OpenVidu Elastic will be upgraded to the asked version. For each version, the system will ask you to confirm the upgrade.</p> </li> <li>A <code>diff</code> will be shown with the changes made in the configuration files. You can review the changes and decide if you want to apply them or not. If you want to apply the changes, answer <code>Yes</code> to the question. If you want to discard the changes and stop the upgrading process, simply answer <code>No</code>.</li> <li>Once the upgrade is finished, it will ask you to pull the images of the services. Answer <code>Yes</code> if you want to do it.</li> <li>After the upgrade, you need to terminate the Media Nodes to apply the changes to run the Media Nodes with the new version. Go to your EC2 Panel, select the Media Nodes instances, and terminate them. The Auto Scaling Group will automatically launch new Media Nodes with the updated configuration.</li> <li> <p>Once the Media Nodes are up and running, you can start OpenVidu Elastic again by executing the following command in the Master Node:</p> <pre><code>systemctl start openvidu &amp;&amp; journalctl -f -u openvidu\n</code></pre> <p>The <code>journalctl</code> command will show you the logs of the OpenVidu services. You can stop the logs by pressing <code>Ctrl + C</code>.</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/aws/upgrade/#backups-and-rollback","title":"Backups and Rollback","text":"<p>When you finish the upgrade process, you will have a backup of the previous version in the <code>/opt/openvidu/backups</code> directory. The backup only contains the previous configuration files that have changed in the upgrade process. To roll back to the previous version, you have to copy the files from the backup to the OpenVidu directory. You can do it with the following command:</p> <pre><code>cp -r /opt/openvidu/backups/&lt;DATE&gt;_&lt;VERSION&gt;/* /opt/openvidu\n/usr/local/bin/store_secret.sh save OPENVIDU_VERSION \"&lt;VERSION&gt;\"\n</code></pre> <p>Where <code>&lt;DATE&gt;</code> and <code>&lt;VERSION&gt;</code> are the date and version of the backup you want to restore. For example:</p> <pre><code>cp -r /opt/openvidu/backups/2025-02-12-09-50-46_3.0.0/* /opt/openvidu\n/usr/local/bin/store_secret.sh save OPENVIDU_VERSION \"3.0.0\"\n</code></pre> <p>Notice the <code>store_secret.sh</code> command at the end. This command is necessary to update the <code>OPENVIDU_VERSION</code> secret in the AWS Secrets Manager, which is used by the AWS deployment to know which version of OpenVidu should be running in Media Nodes. You need to do this in the Master Node only.</p> <p>Remember to terminate the Media Nodes after rolling back to the previous version so the Auto Scaling Group can launch new Media Nodes with the restored configuration. You can do this by going to your EC2 Panel, selecting the Media Nodes instances, and terminating them.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/aws/upgrade/#recommendations","title":"Recommendations","text":"<ul> <li>Always upgrade all the nodes of your OpenVidu Elastic deployment. Otherwise, you may face compatibility issues between the different versions of OpenVidu running in your deployment.</li> <li>On any upgrade problem, a redeployment is always recommended for a clean installation.</li> <li>Keep your Docker and Docker Compose versions updated.</li> <li> <p>Remove non-used images and containers to free up disk space. For example, after the upgrade, when OpenVidu is running, you can remove the old images with the following command:</p> <pre><code>docker image prune -a\n</code></pre> <p>This command will remove all the images that are not being used by any container.</p> </li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/admin/","title":"OpenVidu Elastic administration on Azure","text":"","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/admin/#openvidu-elastic-administration-azure","title":"OpenVidu Elastic administration: Azure","text":"<p>The deployment of OpenVidu Elastic on Azure is automated using Azure Resource Manager Templates, with Media Nodes managed within a Virtual Machine Scale Set . This group dynamically adjusts the number of instances based on a target average CPU usage.</p> <p>Internally, the Azure Elastic deployment mirrors the On Premises Elastic deployment, allowing you to follow the same administration and configuration guidelines of the On Premises Elastic documentation. However, there are specific considerations unique to the Azure environment that are worth taking into account:</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/admin/#cluster-shutdown-and-startup","title":"Cluster shutdown and startup","text":"<p>The Master Node is a Virtual Machine Instance, while the Media Nodes are part of a Virtual Machine Scale Set. The process for starting and stopping these components differs:</p> Shutting down the clusterStarting up the cluster <p>To shut down the cluster, you need to stop the Media Nodes and then stop the Master Node.</p> <p>Gracefully stopping Media Nodes</p> <p>There is currently a limitation with Media Nodes that prevents them from stopping gracefully. Please exercise caution when stopping Media Nodes, as they will terminate immediately without waiting for active Rooms to complete. You may want to wait for your active Rooms to finish before stopping the cluster. We are working to implement the same graceful shutdown behavior offered by AWS and On Premises deployments. In the meantime, Media Nodes include a script that allows for a graceful shutdown. To use it, SSH to the Media Node you want to stop and execute script <code>./usr/local/bin/stop_media_node.sh</code></p> <ol> <li>Navigate to the Azure Portal Dashboard  and go to the Resource Group where you deployed OpenVidu Elastic.</li> <li>Then click into the Virtual Machine Scale Set resource called <code>&lt;STACK_NAME&gt;-mediaNodeScaleSet</code> and click \"Availability + scale\" on the left panel, here click on \"Scaling\" option.      </li> <li>On this tab, go at the very bottom and modify the \"Instance Limits\" to 0.      </li> <li>Click on save and wait until is completed, you can check how is going in the \"Instances\" tab.      </li> <li>After confirming that all Media Node instances are terminated, go back to the Resource Group and locate the resource called \"stackName-VM-MasterNode\". Click on it to go to the Master Node instance. There, click on \"Stop\" to stop the instance.      </li> </ol> <p>To start the cluster, first start the Master Node and then the Media Nodes.</p> <ol> <li>Navigate to the Azure Portal Dashboard  and go to the Resource Group where you deployed OpenVidu Elastic.</li> <li>In the resource group click on the resource called \"stackName-VM-MasterNode\", here click on start to start the Master Node.      </li> <li>Wait until the instance is running.</li> <li>Go back to the Resource Group, and there click into the Virtual Machine Scale Set resource called \"stackName-mediaNodeScaleSet\" and click \"Availability + scale\" on the left panel, here click on \"Scaling\" option.      </li> <li>On this tab, modify the \"Instance Limits\" to your desired ones.      </li> <li>Click on save and wait until is completed. You can check the progress in the \"Instances\" tab.      </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/admin/#change-the-instance-type","title":"Change the instance type","text":"<p>It is possible to change the instance type of both the Master Node and the Media Nodes. However, since the Media Nodes are part of a Virtual Machine Scale Set, the process differs. The following section details the procedures:</p> Master NodesMedia Nodes <p>Warning</p> <p>This procedure requires downtime, as it involves stopping the Master Node.</p> <ol> <li> <p>Shutdown the cluster.</p> <p>Info</p> <p>You can stop only the Master Node instance to change its instance type, but it is recommended to stop the whole cluster to avoid any issues.</p> </li> <li> <p>Go to the Azure Resource Group where you deployed and locate the resource with the name \"stackName-VM-MasterNode\" and click on it.</p> </li> <li>On the left panel click on \"Availability + scale\" tab and inside click on \"Size\" tab. Then select the size you desire and click on \"Resize\" </li> <li>Start the cluster.</li> </ol> <p>Info</p> <p>This will forcely restart the Media Nodes. If you want to stop them gracefully to avoid the disruption of active Rooms, check the Shutting downd the cluster tab.</p> <ol> <li>Go to the Azure Portal Dashboard  on Azure.</li> <li>Select the Resource Group where you deployed OpenVidu Elastic.</li> <li>Locate the resource with the name \"stackName-mediaNodeScaleSet\". Click on it to navigate to the Virtual Machine Scale Set.</li> <li>On the left panel click on \"Availability + scale\" tab, then on \"Size\".      </li> <li>Select the new instance type and click on \"Resize\".</li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/admin/#media-nodes-autoscaling-configuration","title":"Media Nodes Autoscaling Configuration","text":"<p>You can modify the autoscaling configuration of the Media Nodes by adjusting the scaling rules of the Virtual Machine Scale Set:</p> Media Nodes Autoscaling Configuration <ol> <li>Go to the Azure Portal Dashboard  on Azure.</li> <li>Select the Resource Group where you deployed OpenVidu Elastic.</li> <li>Locate the resource with the name \"stackName-mediaNodeScaleSet\" and click on it.</li> <li>On the left panel click on \"Availability + scale\" tab and inside click on \"Scaling\" option.      </li> <li> <p>In the \"Default\" box you will find a section called \"Rules\". Here you can add new rules or modify existing ones.</p> <p>Info</p> <p>Currently there is only one rule to scale out. We are actively working in providing a graceful scale in process for Media Nodes to avoid active Rooms disruption.</p> <p></p> <p></p> </li> </ol> Modify existing rulesAdd a new rule <p>Click on the rule you want to modify and change the Criteria as desired. To accept the changes click on \"Update\". </p> <p></p> <p>Click on \"Add a rule\" option and fill the Criteria as desired. To add the rule click on \"Add\". </p> <p></p> <p>Info</p> <p>OpenVidu Elastic is by default configured with a \"Target tracking scaling\" policy that scales based on the target average CPU usage. However, you can configure different autoscaling policies according to your needs. For more information on the various types of autoscaling policies and how to implement them, refer to the Azure Scaling Set documentation .</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/admin/#fixed-number-of-media-nodes","title":"Fixed Number of Media Nodes","text":"<p>If you prefer to maintain a fixed number of Media Nodes instead of allowing the Virtual Machine Scale Set to perform dynamic scaling:</p> Set Fixed Number of Media Nodes <ol> <li>Go to the Azure Portal Dashboard  on Azure.</li> <li>Select the Resource Group where you deployed OpenVidu Elastic, locate the resource with the name \"stackName-mediaNodeScaleSet\" and click on it</li> <li>On the left panel click on \"Availability + scale\" and then in \"Scaling\" tab.      </li> <li>On this tab, go at the very bottom and modify the \"Instance Limits\" to the value of fixed number of Media Nodes you want. In this case is set to 2.      </li> <li>Click on save and wait until is completed, you can check how is going in the \"Instances\" tab.      </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/admin/#administration-and-configuration","title":"Administration and configuration","text":"<p>Regarding the administration of your deployment, you can follow the instructions in section On Premises Elastic Administration.</p> <p>Regarding the configuration of your deployment, you can follow the instructions in section Changing Configuration. Additionally, the How to Guides offer multiple resources to assist with specific configuration changes.</p> <p>In addition to these, an Azure deployment provides the capability to manage global configurations via the Azure portal using Key Vault Secrets created during the deployment:</p> Changing configuration through Key Vault secrets <ol> <li>Navigate to the Azure Portal Dashboard  on Azure.</li> <li>Select the Resource Group where you deployed OpenVidu Elastic.</li> <li>In the \"stackname-keyvault\" resource, click on \"Objects\" -&gt; \"Secrets\" on the left panel. This will show you all the secrets that are stored in the Key Vault of the OpenVidu Elastic deployment.      </li> <li>Click on the desired secret you want to change and click on \"New Version\".      </li> <li>Enter the new secret value on \"Secret Value\" filed and click on \"Create\".      </li> <li>Go to the Master Node resource and click on \"Restart\" to apply the changes to the OpenVidu Elastic deployment.      </li> </ol> <p>Changes will be applied automatically.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/install/","title":"OpenVidu Elastic installation on Azure","text":"","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/install/#openvidu-elastic-installation-azure","title":"OpenVidu Elastic installation: Azure","text":"<p>Info</p> <p>OpenVidu Elastic is part of OpenVidu PRO. Before deploying, you need to create an OpenVidu account to get your license key. There's a 15-day free trial waiting for you!</p> <p>This section contains the instructions to deploy a production-ready OpenVidu Elastic deployment in Azure. Deployed services are the same as the On Premises Elastic installation but they will be resources in Azure and you can automate the process with the Template Spec of ARM.</p> <p>To import the template into Azure you just need to click the button below and you will be redirected to azure.</p> <p></p> Architecture overview <p>This is how the architecture of the deployment looks like:</p> <p></p> OpenVidu Elastic Azure Architecture <p></p> <ul> <li>The Master Node acts as a Load Balancer, managing the traffic and distributing it among the Media Nodes and deployed services in the Master Node.</li> <li>The Master Node has its own Caddy server acting as a Layer 4 (for TURN with TLS and RTMPS) and Layer 7 (for OpenVidu Dashboard, OpenVidu Meet, etc., APIs) reverse proxy.</li> <li>WebRTC traffic (SRTP/SCTP/STUN/TURN) is routed directly to the Media Nodes.</li> <li>A Scaling Set of Media Nodes is created to scale the number of Media Nodes based on the system load.</li> </ul> <p>We use a custom scale-in strategy to allow the graceful shutdown of Media Nodes. In this way we ensure no disruption of active Rooms when the cluster tries to remove a Media Node.</p> Custom scale-in strategy <ul> <li>All instances in the Media Node scale set are protected to prevent their automatic shutdown.</li> <li>We receive and use the shutdown event to execute acustom Automation runbook.</li> <li>The Automation runbook determines the instance that has to be terminated and executes the appropriate commands in all internal services to prevent them of accepting new jobs (new Rooms, new Egresses, new Ingresses, new Agents...).</li> <li>Only when all the jobs hosted by the selected instance finish, it is automatically terminated.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/install/#template-parameters","title":"Template Parameters","text":"<p>To deploy the template you need to fill the following parameters.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/install/#resource-group-and-stack-name","title":"Resource Group and Stack Name","text":"<p>Select your Subscription and the Resource Group where you want to deploy OpenVidu.</p> <p></p> <p>Warning</p> <p>It is highly recommended to deploy OpenVidu in a brand new Azure Resource Group. Reusing an existing Resource Group can lead to conflicts. The only reason to reuse an existing Resource Group is to use the same IP and Azure Blob Storage Account as a previous OpenVidu deployment. The rest of resources are not reusable and should be eliminated before deploying OpenVidu in the same Resource Group.</p> <p>Select the Region and choose a descriptive Stack Name. It will be used as a prefix in the name of all the resources created by the template.</p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/install/#domain-and-ssl-certificate-configuration","title":"Domain and SSL Certificate Configuration","text":"<p>There are three possible scenarios for this section:</p> Let's Encrypt Without Domain NameLet's Encrypt With Domain Name (recommended)Custom CertificatesSelf-Signed Certificate <p>If you don't have a Domain Name and want to quickly test OpenVidu on Azure, you can use this option, simply selecting the Certificate Type as letsencrypt and keep the rest of parameters empty.</p> <p>It will deploy OpenVidu with a Let's Encrypt certificate generated using sslip.io based on the public IP created for the deployment.</p> <p></p> <p>For a production-ready setup, this scenario is ideal when you have an FQDN (Fully Qualified Domain Name) and a Public IP at your disposal. It leverages the services of Let's Encrypt to automatically generate valid certificates.</p> <p>First, you need to have the FQDN pointing to the Public IP you are going to use.</p> <p>Then, you need to fill in the following parameters:</p> <p></p> <p></p> <p>As you can see, you need to specify the Public Ip Address with the Public IP that the domain points to, the Domain Name with your FQDN, and the Lets Encrypt Email with your email address for Let\u2019s Encrypt notifications. These parameters are mandatory.</p> <p>To deploy OpenVidu in Azure under your Fully Qualified Domain Name (FQDN) using already existing certificates, follow this method.</p> <p>You need to have your FQDN pointing to a previously created Public Ip.</p> <p>Also, you need a temporary HTTP server hosting your private and public certificate under a specific URL. These URLs are needed for the instance to be able to securely download and install your certificates.</p> <p>The configured parameters would look like this:</p> <p></p> <p></p> <p>You need to specify at Own Public Certificate and Own Private Certificate the URLs where the public and private certificates are hosted, respectively. The Domain Name, Public Ip Address are mandatory parameters.</p> <p>Certificates need to be in PEM format and the URLs must be accessible from the instance.</p> <p>This is the most straightforward option for deploying OpenVidu on Azure when you do not have a Fully Qualified Domain Name (FQDN). This method allows for the immediate use of OpenVidu with ARM Templates.</p> <p>However, this convenience comes with the caveat that users will need to manually accept the certificate in their web browsers. Please be aware that this configuration is solely for developmental and testing purposes and is not suitable for a real production environment.</p> <p>These are the parameters needed in this section to use self-signed certificates:</p> <p></p> <p></p> <p>You don\u2019t need to specify any parameters; just select the CertificateType as self-signed. The domain name used will be an Azure-generated one.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/install/#openvidu-meet-credentials","title":"OpenVidu Meet Credentials","text":"<p>Configure the initial credentials for accessing OpenVidu Meet:</p> OpenVidu Meet credentials <p>Parameters in this section look like this:</p> <p></p> <ul> <li>InitialMeetAdminPassword: Initial password for the \"admin\" user in OpenVidu Meet. If not provided, a random password will be generated and stored in the Azure Key Vault.</li> <li>InitialMeetApiKey: Initial API key for OpenVidu Meet. If not provided, no API key will be set and the user can configure it later from the Meet Console.</li> </ul> <p>Both parameters are optional. If you don't specify them, you can retrieve the generated credentials from the Azure Key Vault after deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/install/#openvidu-elastic-configuration","title":"OpenVidu Elastic Configuration","text":"<p>In this section, you need to specify some properties needed for the OpenVidu Elastic deployment.</p> OpenVidu Elastic Configuration <p>Parameters of this section look like this:</p> <p></p> <p></p> <p>Make sure to provide the OpenVidu License parameter with the license key. If you don't have one, you can request one here.</p> <p>For the RTC Engine parameter, you can choose between Pion (the default engine used by LiveKit) and Mediasoup (with a boost in performance). Learn more about the differences here.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/install/#azure-instance-configuration","title":"Azure Instance Configuration","text":"<p>You need to specify some properties for the Azure instances that will be created.</p> Azure Instance configuration <p>Parameters in this section look like this:</p> <p></p> <p></p> <p>Simply select the type of instance you want for your Master Node at Master Node Instance Type and select the type of instance you want for your Media Nodes at Media Node Instance Type. Fill in the parameter Admin Username that will be set as admin username in the instance. Select the SSH key you've created previously in SSH public key source (or create a new one in the same drop down) to allow you to SSH into the instances.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/install/#media-nodes-scaling-set-configuration","title":"Media Nodes Scaling Set Configuration","text":"<p>The number of Media Nodes can scale up based on the system load. You can configure the minimum and maximum number of Media Nodes and a target CPU utilization to trigger the scaling up.</p> Media Nodes Scaling Set Configuration <p>Parameters in this section look like this:</p> <p></p> <p></p> <p>The Initial Number Of Media Nodes parameter specifies the initial number of Media Nodes to deploy. The Min Number Of Media Nodes and Max Number Of Media Nodes parameters specify the minimum and maximum number of Media Nodes that you want to be deployed.</p> <p>The Scale Target CPU parameter specifies the target CPU utilization to trigger the scaling up or down. The goal is to keep the CPU utilization of the Media Nodes close to this value. The autoscaling policy is based on Azure Monitor autoscale metrics .</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/install/#scale-in","title":"Scale In","text":"<p>Azure instances may only wait at most 15 minutes when the Scale Set flags them for termination after detecting a surplus of CPU capacity. This is a problem for those active Rooms hosted by the instance that can last longer than that. To avoid the disruption of active Rooms, we have implemented a custom scale-in strategy that gracefully shuts down flagged instances only after all active jobs have finished.</p> <p>Due to Azure limitations, this strategy has the minor drawback that it can take up to 5 minutes from the time an instance is flagged for termination until the shutdown process is gracefully initiated.</p> Automation Account Configuration <p>The name of an Automation Account, needed to execute the scale-in runbook. It must be unique for the resource group it belongs to (leave it blank to use an autogenerated name). This resource cannot be reused between deployments.</p> <p></p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/install/#storage-account","title":"Storage Account","text":"<p>You need to fill some parameters about the storage account that the deployment will use to save the recordings.</p> <p>Warning</p> <p>Recordings are not available in OpenVidu v2 Compatibility mode (v2compat) for OpenVidu Azure deployments.</p> Azure Storage Account configuration <p>Parameters in this section look like this:</p> <p></p> <p></p> <p>Storage Account Name: leave blank to create a new Storage Account for this deployment. You can specify an already existing Storage Account name  if you want (remember it must belong to the same resource group as your deployment).</p> <p>Container Name is the name that you desire for the container that of the storage account where the recordings will be saved. If you leave it blank it will create the container with name <code>openvidu-appdata</code>.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/install/#optional-additional-flags","title":"(Optional) Additional flags","text":"<p>Additional optional flags to pass to the OpenVidu installer (comma-separated, e.g., <code>--flag1=value, --flag2</code>).</p> (Optional) Additional flags <p>Parameters in this section look like this:</p> <p></p> <p>For example, you can use <code>--experimental-turn-tls-with-main-domain</code> to use the same domain as the main one for the TURN server with TLS, instead of specifying a different one in the TURN server configuration with TLS section.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/install/#optional-turn-server-configuration-with-tls","title":"(Optional) TURN server configuration with TLS","text":"<p>This section is optional. It is useful when your users are behind a restrictive firewall that blocks UDP traffic. This parameter will only work if you are using <code>letsencrypt</code> or <code>owncert</code> as the Certificate Type parameter.</p> TURN server configuration with TLS <p>Parameters in this section look like this:</p> <p></p> <p></p> <p>Set the Turn Domain Name parameter to the domain name you intend to use for your TURN server. It should be pointing to the <code>Public Ip Address</code> specified in the previous section.</p> <p>If you are using <code>letsencrypt</code> as the Certificate Type parameter, you can leave the Turn Own Public Certificate and Turn Own Private Certificate parameters empty. If you are using <code>owncert</code>, you need to specify the URLs where the public and private certificates are hosted.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/install/#deploying-the-stack","title":"Deploying the stack","text":"<p>Whenever you are satisfied with your Template paremeters, just click on \"Next\" to trigger the validation process. If correct, click on \"Create\" to start the deployment process (which will take about 7 to 12 minutes).</p> <p>Warning</p> <p>In case of failure, it might be that some role failed to create. In this case redeploy in a new resource group and change the Stack Name. To remove a role in a resource group visit Remove Azure role assignments .</p> <p>When everything is ready, you can check the output secrets on the Key Vault or by connecting through SSH to the instance:</p> Check deployment outputs in Azure Key VaultCheck deployment outputs in the instance <ol> <li> <p>Go to the Key Vault created called yourstackname-keyvault in the Resource Group that you deployed. You can access it from the Azure Portal Dashboard .</p> </li> <li> <p>Once you are in the Key Vault on the left panel click on \"Objects\" \ud83e\udc52 \"Secrets\".</p> <p></p> <p></p> </li> <li> <p>Here click on the secret of your choice or whatever you need to check and click again in the current version of that secret</p> <p></p> <p></p> </li> <li> <p>Now you will see a lot of properties but the one you are searching for is located at the bottom and it will be revealed by clicking in \"Show Secret Value\".</p> <p></p> <p></p> </li> </ol> <p>SSH to the Master Node instance and navigate to the config folder <code>/opt/openvidu/config/cluster</code>. Files with the access credentials outputs are:</p> <ul> <li><code>openvidu.env</code></li> <li><code>master_node/meet.env</code></li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/install/#configure-your-application-to-use-the-deployment","title":"Configure your application to use the deployment","text":"<p>You need your Azure deployment outputs to configure your OpenVidu application. If you have permissions to access the Key Vault you will be able to check there all the outputs (Check deployment outputs in Azure Key Vault). If you don't have permissions to access the Key Vault you can still check the outputs directly in the instance through SSH (Check deployment outputs in the instance).</p> <p>Your authentication credentials and URL to point your applications would be:</p> <p>OpenVidu Meet:</p> <ul> <li><code>OPENVIDU-URL</code>: The URL to access OpenVidu Meet, which is always <code>https://yourdomain.example.io/</code></li> <li><code>MEET-INITIAL-ADMIN-USER</code>: User to access OpenVidu Meet Console. It is always <code>admin</code>.</li> <li><code>MEET-INITIAL-ADMIN-PASSWORD</code>: Password to access OpenVidu Meet Console.</li> <li><code>MEET-INITIAL-API-KEY</code>: API key to use OpenVidu Meet Embedded and OpenVidu Meet REST API.</li> </ul> <p>Note</p> <p>The <code>MEET-INITIAL-ADMIN-USER</code>, <code>MEET-INITIAL-ADMIN-PASSWORD</code>, and <code>MEET-INITIAL-API-KEY</code> values are initial settings that cannot be changed from Azure Key Vault. They can only be changed from the Meet Console.</p> <p>OpenVidu Platform:</p> <ul> <li><code>LIVEKIT-URL</code>: The URL to use LiveKit SDKs, which can be <code>wss://yourdomain.example.io/</code> or <code>https://yourdomain.example.io/</code> depending on the client library you are using.</li> <li><code>LIVEKIT-API-KEY</code>: API Key for LiveKit SDKs.</li> <li><code>LIVEKIT-API-SECRET</code>: API Secret for LiveKit SDKs.</li> </ul> <p>OpenVidu V2 Compatibility Credentials</p> <p>This section is only needed if you want to use OpenVidu v2 compatibility.</p> <ul> <li>URL: The URL to access OpenVidu, which is the value of <code>OPENVIDU-URL</code> (e.g., <code>https://yourdomain.example.io/</code>)</li> <li>Username: Basic auth user for OpenVidu v2 compatibility. It is always <code>OPENVIDUAPP</code>.</li> <li>Password: Basic auth password for OpenVidu v2 compatibility is the same as <code>LIVEKIT-API-SECRET</code>.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/install/#troubleshooting-initial-azure-stack-creation","title":"Troubleshooting initial Azure stack creation","text":"<p>If something goes wrong during the initial Azure stack creation, your stack may reach some failed status for multiple reasons. It could be due to a misconfiguration in the parameters, a lack of permissions, or a problem with Azure services. When this happens, the following steps can help you troubleshoot the issue and identify what went wrong:</p> <ol> <li>Check if the instance or instances are running. If they are not, check the Azure deployment events for any error messages.</li> <li> <p>If the instance or instances are running, SSH into the instance and check the logs of the following files:</p> <ul> <li><code>/var/log/cloud-init-output.log</code></li> <li><code>/var/log/cloud-init.log</code></li> </ul> <p>These logs will give you more information about the Azure stack creation process.</p> </li> <li> <p>If everything seems fine, check the status and the logs of the installed OpenVidu services.</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/install/#configuration-and-administration","title":"Configuration and administration","text":"<p>When your Azure stack reaches the <code>Succeeded</code> status, it means that all the resources have been created. You will need to wait about 5 to 10 minutes to let the instance install OpenVidu. When this time has elapsed, try connecting to the deployment URL. If it doesn't work, we recommend checking the previous section. Once finished you can check the Administration section to learn how to manage your deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/upgrade/","title":"Upgrade OpenVidu Elastic - Azure","text":"","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/upgrade/#upgrade-openvidu-elastic-azure","title":"Upgrade OpenVidu Elastic - Azure","text":"<p>In Azure environments, we recommend upgrading by redeploying OpenVidu Elastic Azure stack using the latest version. This approach ensures that all components are updated accurately and consistently, as Azure templates and related configurations may vary between releases. Redeploying guarantees that all necessary changes are properly applied.</p> <p>However, if you prefer not to redeploy, it is also possible to upgrade OpenVidu Elastic in place. The following steps outline how to perform an in-place upgrade of your OpenVidu Elastic deployment on Azure:</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/upgrade/#upgrading-openvidu-elastic-on-azure","title":"Upgrading OpenVidu Elastic on Azure","text":"<ol> <li>SSH into your Master Node server.</li> <li> <p>Execute the following command in the Master Node:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/update/latest/update.sh)\n</code></pre> <p>Info</p> <p>If instead of upgrading to the latest version you want to upgrade to a specific version, you can execute the following command:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/update/&lt;VERSION&gt;/update.sh)\n</code></pre> <p>Where <code>&lt;VERSION&gt;</code> is the version you want to upgrade to.</p> </li> <li> <p>This will execute an update script which will guide you from the version you have installed to the latest one. The first thing you will see in the output is the following:</p> <pre><code>Stopping OpenVidu service...\nBacking up files...\n\n    - Backing up file '/opt/openvidu/config' to '/opt/openvidu/backups/&lt;DATE&gt;_&lt;VERSION&gt;/config'\n    ... More files ...\n\n--------------------\n\ud83d\udce6 Backup directory: /opt/openvidu/backups/&lt;DATE&gt;_&lt;VERSION&gt;/\n--------------------\n\n--------------------\n\ud83d\ude80 Updating OpenVidu from 3.x.x to 3.y.y\n--------------------\n\n? Do you want to update from 3.x.x to 3.y.y? \u203a\n\u2022 Yes\n  No\n</code></pre> </li> <li> <p>Answer <code>Yes</code> to the question and your OpenVidu Elastic will be upgraded to the asked version. For each version, the system will ask you to confirm the upgrade.</p> </li> <li>A <code>diff</code> will be shown with the changes made in the configuration files. You can review the changes and decide if you want to apply them or not. If you want to apply the changes, answer <code>Yes</code> to the question. If you want to discard the changes and stop the upgrading process, simply answer <code>No</code>.</li> <li>Once the upgrade is finished, it will ask you to pull the images of the services. Answer <code>Yes</code> if you want to do it.</li> <li>After the upgrade, you need to terminate the Media Nodes to apply the changes to run the Media Nodes with the new version. Go to your Azure Instances Panel, select the Media Nodes instances, and terminate them. The Scale Set will automatically launch new Media Nodes with the updated configuration.</li> <li> <p>Once the Media Nodes are up and running, you can start OpenVidu Elastic again by executing the following command in the Master Node:</p> <pre><code>systemctl start openvidu &amp;&amp; journalctl -f -u openvidu\n</code></pre> <p>The <code>journalctl</code> command will show you the logs of the OpenVidu services. You can stop the logs by pressing <code>Ctrl + C</code>.</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/upgrade/#backups-and-rollback","title":"Backups and Rollback","text":"<p>When you finish the upgrade process, you will have a backup of the previous version in the <code>/opt/openvidu/backups</code> directory. The backup only contains the previous configuration files that have changed in the upgrade process. To roll back to the previous version, you have to copy the files from the backup to the OpenVidu directory. You can do it with the following command:</p> <pre><code>cp -r /opt/openvidu/backups/&lt;DATE&gt;_&lt;VERSION&gt;/* /opt/openvidu\n/usr/local/bin/store_secret.sh save OPENVIDU_VERSION \"&lt;VERSION&gt;\"\n</code></pre> <p>Where <code>&lt;DATE&gt;</code> and <code>&lt;VERSION&gt;</code> are the date and version of the backup you want to restore. For example:</p> <pre><code>cp -r /opt/openvidu/backups/2025-02-12-09-50-46_3.0.0/* /opt/openvidu\n/usr/local/bin/store_secret.sh save OPENVIDU_VERSION \"3.0.0\"\n</code></pre> <p>Notice the <code>store_secret.sh</code> command at the end. This command is necessary to update the <code>OPENVIDU_VERSION</code> secret in the Azure Key Vault, which is used by the Azure deployment to know which version of OpenVidu should be running in Media Nodes. You need to do this in the Master Node only.</p> <p>Remember to terminate the Media Nodes after rolling back to the previous version so the Scale Set can launch new Media Nodes with the restored configuration. You can do this by going to your Azure Instances Panel, selecting the Media Nodes instances, and terminating them.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/azure/upgrade/#recommendations","title":"Recommendations","text":"<ul> <li>Always upgrade all the nodes of your OpenVidu Elastic deployment. Otherwise, you may face compatibility issues between the different versions of OpenVidu running in your deployment.</li> <li>On any upgrade problem, a redeployment is always recommended for a clean installation.</li> <li>Keep your Docker and Docker Compose versions updated.</li> <li> <p>Remove non-used images and containers to free up disk space. For example, after the upgrade, when OpenVidu is running, you can remove the old images with the following command:</p> <pre><code>docker image prune -a\n</code></pre> <p>This command will remove all the images that are not being used by any container.</p> </li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/on-premises/admin/","title":"OpenVidu Elastic administration on-premises","text":"","tags":["Platform"]},{"location":"docs/self-hosting/elastic/on-premises/admin/#openvidu-elastic-administration-on-premises","title":"OpenVidu Elastic administration: On-premises","text":"<p>The OpenVidu installer offers an easy way to deploy OpenVidu Elastic on-premises. However, once the deployment is complete, you may need to perform administrative tasks based on your specific requirements, such as changing passwords, specifying custom configurations, and starting or stopping services.</p> <p>This section provides details on configuration parameters and common administrative tasks for on-premises OpenVidu Elastic deployments.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/on-premises/admin/#starting-stopping-and-restarting-openvidu","title":"Starting, stopping, and restarting OpenVidu","text":"<p>To start, stop, or restart any Node in your OpenVidu Elastic deployment, you can use the following commands:</p> <p>Start OpenVidu</p> <pre><code>sudo systemctl start openvidu\n</code></pre> <p>Stop OpenVidu</p> <pre><code>sudo systemctl stop openvidu\n</code></pre> <p>Restart OpenVidu</p> <pre><code>sudo systemctl restart openvidu\n</code></pre>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/on-premises/admin/#checking-the-status-of-services","title":"Checking the status of services","text":"<p>You can check the status of the OpenVidu services using the following command:</p> <pre><code>cd /opt/openvidu/\ndocker compose ps\n</code></pre> <p>Depending on the node type, you will see different services running.</p> Master NodeMedia Node <p>The services are operating correctly if you see an output similar to the following and there are no restarts from any of the services:</p> <pre><code>NAME                       IMAGE                                              COMMAND                  SERVICE                    CREATED          STATUS\nmeet                       docker.io/openvidu/openvidu-meet                   \"docker-entrypoint.s\u2026\"   openvidu-meet              12 seconds ago   Up 10 seconds\ncaddy                      docker.io/openvidu/openvidu-pro-caddy              \"/bin/caddy run --co\u2026\"   caddy                      12 seconds ago   Up 10 seconds\ndashboard                  docker.io/openvidu/openvidu-pro-dashboard          \"./openvidu-dashboard\"   dashboard                  12 seconds ago   Up 10 seconds\ngrafana                    docker.io/grafana/grafana                          \"/run.sh\"                grafana                    11 seconds ago   Up 8 seconds\nloki                       docker.io/grafana/loki                             \"/usr/bin/loki -conf\u2026\"   loki                       11 seconds ago   Up 9 seconds\nmimir                      docker.io/grafana/mimir                            \"/bin/mimir -config.\u2026\"   mimir                      11 seconds ago   Up 9 seconds\nminio                      docker.io/bitnami/minio                            \"/opt/bitnami/script\u2026\"   minio                      11 seconds ago   Up 9 seconds\nmongo                      docker.io/mongo                                    \"docker-entrypoint.s\u2026\"   mongo                      11 seconds ago   Up 9 seconds\nopenvidu-v2compatibility   docker.io/openvidu/openvidu-v2compatibility        \"/bin/server\"            openvidu-v2compatibility   12 seconds ago   Up 10 seconds\noperator                   docker.io/openvidu/openvidu-operator               \"/bin/operator\"          operator                   12 seconds ago   Up 10 seconds\npromtail                   docker.io/grafana/promtail                         \"/usr/bin/promtail -\u2026\"   promtail                   11 seconds ago   Up 9 seconds\nredis                      docker.io/redis                                    \"docker-entrypoint.s\u2026\"   redis                      12 seconds ago   Up 10 seconds\n</code></pre> <p>The services are operating correctly if you see an output similar to the following and there are no restarts from any of the services:</p> <pre><code>NAME         IMAGE                                          COMMAND                  SERVICE      CREATED          STATUS\negress       docker.io/livekit/egress                       \"/entrypoint.sh\"         egress       53 seconds ago   Up 51 seconds\ningress      docker.io/livekit/ingress                      \"ingress\"                ingress      53 seconds ago   Up 52 seconds\nopenvidu     docker.io/openvidu/openvidu-server-pro         \"/livekit-server --c\u2026\"   openvidu     53 seconds ago   Up 52 seconds\nprometheus   docker.io/prom/prometheus                      \"/bin/prometheus --c\u2026\"   prometheus   53 seconds ago   Up 51 seconds\npromtail     docker.io/grafana/promtail                     \"/usr/bin/promtail -\u2026\"   promtail     53 seconds ago   Up 52 seconds\n</code></pre>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/on-premises/admin/#checking-logs","title":"Checking logs","text":"<p>If any of the services are not working as expected, you can check the logs of the services using the following command:</p> <pre><code>cd /opt/openvidu/\ndocker compose logs &lt;service-name&gt;\n</code></pre> <p>Replace <code>&lt;service-name&gt;</code> with the name of the service you want to check. For example, to check the logs of the OpenVidu Server, use the following command:</p> <pre><code>cd /opt/openvidu/\ndocker compose logs openvidu\n</code></pre> <p>To check the logs of all services, use the following command:</p> <pre><code>cd /opt/openvidu/\ndocker compose logs\n</code></pre> <p>Or use journalctl:</p> <pre><code>journalctl -f -u openvidu\n</code></pre> <p>You can also review your logs using the Grafana dashboard provided with OpenVidu. To access it, go to https://&lt;your-domain.com&gt;/grafana and use the credentials located in <code>/opt/openvidu/.env</code> to log in. Once inside, navigate to the \"Home\" section, select \"Dashboard\", and then click on:</p> <ul> <li>\"OpenVidu &gt; OpenVidu Cluster Nodes Logs\": To check the logs of the OpenVidu services organized per node.</li> <li>\"OpenVidu &gt; OpenVidu Cluster Services Logs\": To check the logs of the OpenVidu services organized per service.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/on-premises/admin/#adding-media-nodes","title":"Adding Media Nodes","text":"<p>To add a new Media Node, simply spin up a new VM and run the OpenVidu installer script to integrate it into the existing cluster. Run the installation command on the new Media Node.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/on-premises/admin/#removing-media-nodes-gracefully","title":"Removing Media Nodes Gracefully","text":"<p>To stop a Media Node gracefully, you need to stop the containers <code>openvidu</code>, <code>ingress</code>, and <code>egress</code> with a <code>SIGQUIT</code> signal. Here is a simple script that you can use to stop all these containers gracefully:</p> <pre><code>#!/bin/bash\n# Stop OpenVidu, Ingress, and Egress containers gracefully (1)\ndocker container kill --signal=SIGQUIT openvidu || true\ndocker container kill --signal=SIGQUIT ingress || true\ndocker container kill --signal=SIGQUIT egress || true\nfor agent_container in $(docker ps --filter \"label=openvidu-agent=true\" --format '{{.Names}}'); do\n    docker container kill --signal=SIGQUIT \"$agent_container\"\ndone\n\n# Wait for the containers to stop (2)\nwhile [ $(docker ps --filter \"label=openvidu-agent=true\" -q | wc -l) -gt 0 ] || \\\n    [ $(docker inspect -f '{{.State.Running}}' openvidu 2&gt;/dev/null) == \"true\" ] || \\\n    [ $(docker inspect -f '{{.State.Running}}' ingress 2&gt;/dev/null) == \"true\" ] || \\\n    [ $(docker inspect -f '{{.State.Running}}' egress 2&gt;/dev/null) == \"true\" ]; do\n    echo \"Waiting for containers to stop...\"\n    sleep 5\ndone\n</code></pre> <ol> <li>This script stops the OpenVidu, Ingress, Egress and AI Agents containers gracefully. The <code>true</code> at the end of each command is to avoid the script from stopping if the container is not running.</li> <li>This script waits for the containers to stop before exiting.</li> </ol> <p>When all the containers are stopped, you can then stop the systemd service and remove the VM:</p> <pre><code>sudo systemctl stop openvidu\n</code></pre>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/on-premises/admin/#removing-media-nodes-forcefully","title":"Removing Media Nodes Forcefully","text":"<p>To remove a Media Node forcefully, without considering the rooms, ingress, egress and agents hosted by the node, you can simply stop the OpenVidu service in the Media Node and delete the VM.</p> <pre><code>sudo systemctl stop openvidu\n</code></pre>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/on-premises/admin/#changing-the-configuration","title":"Changing the configuration","text":"<p>You can check how to change the configuration in the Changing Configuration section. Also, there are multiple guides in the How to Guides section that can help you with specific configuration changes.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/on-premises/admin/#uninstalling-openvidu","title":"Uninstalling OpenVidu","text":"<p>To uninstall any OpenVidu Node, just execute the following commands:</p> <pre><code>sudo su\nsystemctl stop openvidu\nrm -rf /opt/openvidu/\nrm /etc/systemd/system/openvidu.service\nrm /etc/sysctl.d/50-openvidu.conf\n</code></pre>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/on-premises/install/","title":"OpenVidu Elastic installation on-premises","text":"","tags":["Platform"]},{"location":"docs/self-hosting/elastic/on-premises/install/#openvidu-elastic-installation-on-premises","title":"OpenVidu Elastic installation: On-premises","text":"<p>Info</p> <p>OpenVidu Elastic is part of OpenVidu PRO. Before deploying, you need to create an OpenVidu account to get your license key. There's a 15-day free trial waiting for you!</p> <p>This section contains the instructions to deploy a production-ready OpenVidu Elastic deployment on-premises. The deployment requires one Master Node and any number of Media Nodes. Media Nodes are elastic and can be scaled up and down according to the workload.</p> Architecture overview <p>This is how the architecture of the deployment looks like:</p> <p></p> OpenVidu Elastic On Premises <p></p> <ul> <li>The Master Node acts as a Load Balancer, managing the traffic and distributing it among the Media Nodes and deployed services in the Master Node.</li> <li>The Master Node has its own Caddy server acting as a Layer 4 (for TURN with TLS and RTMPS) and Layer 7 (for OpenVidu Dashboard, OpenVidu Meet, etc., APIs) reverse proxy.</li> <li>WebRTC traffic (SRTP/SCTP/STUN/TURN) is routed directly to the Media Nodes.</li> </ul> <p>For the Master Node, the following services are configured:</p> <ul> <li>OpenVidu Dashboard, a web application interface to visualize your Rooms, Ingress, and Egress services.</li> <li>MinIO as an S3 storage service for recordings.</li> <li>Redis as a shared database for OpenVidu Server PRO and Ingress/Egress services.</li> <li>MongoDB as a database for storing analytics and monitoring data.</li> <li>Caddy as a reverse proxy. It can be deployed with self-signed certificates, Let's Encrypt certificates, or custom certificates. Provides optional TLS for the TURN server.</li> <li>OpenVidu Meet, an optional high-quality video calling service.</li> <li>OpenVidu V2 Compatibility (v2compatibility module) is an optional service that provides an API designed to maintain compatibility for applications developed with OpenVidu version 2.</li> <li>Grafana, Mimir, Promtail, and Loki (Observability module) form an optional observability stack for monitoring, allowing you to keep track of logs and deployment statistics for OpenVidu.</li> </ul> <p>For the Media Nodes, the following services are configured:</p> <ul> <li>OpenVidu Server PRO (LiveKit compatible).</li> <li>Ingress and Egress services.</li> <li>Prometheus and Loki (Observability module). Used to send metrics and logs to the observability stack.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/on-premises/install/#prerequisites","title":"Prerequisites","text":"<ul> <li>At least 2 machines, each with a minimum of 4GB RAM, 4 CPU cores, and Linux installed (Ubuntu is recommended). One machine will serve as the Master Node, while the others will function as Media Nodes.</li> <li>Significant disk space on the Master Node, with 100GB recommended, especially if you plan to record your sessions (Egress). Media Nodes require less space; however, account for the space needed for ongoing recordings on these nodes.</li> <li>Each machine must be assigned a Public IP. An FQDN (Fully Qualified Domain Name) is optional for the Master Node. If not provided, an autogenerated domain using sslip.io will be used.</li> <li> <p>All machines must have access to the following addresses and ports:</p> Host Port <code>accounts.openvidu.io</code> <code>443</code> <code>global.stun.twilio.com</code> <code>3478</code> <code>stun.l.google.com</code> <code>19302</code> <code>stun1.l.google.com</code> <code>19302</code> <p>Info</p> <p>If you are behind a very restrictive corporate firewall that doesn't allow outgoing traffic to those addresses, please contact us through commercial@openvidu.io.</p> </li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/on-premises/install/#port-rules-master-node","title":"Port rules (Master Node)","text":"<p>Ensure all these rules are configured in your firewall, security group, or any kind of network configuration that you have in your Master Node.</p> <p>Inbound port rules:</p> Protocol Ports Source Description TCP 80 0.0.0.0/0, ::/0 Redirect HTTP traffic to HTTPS and Let's Encrypt validation. TCP 443 0.0.0.0/0, ::/0 Allows access to the following: <ul><li>Livekit API.</li><li>OpenVidu v2 Compatibility API</li><li>OpenVidu Dashboard.</li><li>OpenVidu Meet.</li><li>WHIP API.</li><li>TURN with TLS.</li><li>Custom layouts</li></ul> TCP 1935 0.0.0.0/0, ::/0 Needed if you want to ingest RTMP streams using Ingress service. TCP 9000 0.0.0.0/0, ::/0 Needed if you want to expose MinIO publicly. TCP 4443 Media Nodes Needed when 'OpenVidu v2 Compatibility' module is used (<code>v2compatibility</code> in <code>ENABLED_MODULES</code> global parameter). Media Nodes need access to this port to reach OpenVidu V2 compatibility service TCP 6080 Media Nodes Needed when 'OpenVidu Meet'  module is used (<code>openviduMeet</code> in <code>ENABLED_MODULES</code> global parameter). Media Nodes need access to this port to reach OpenVidu Meet. TCP 3100 Media Nodes Needed when 'Observability' module is used (<code>observability</code> in <code>ENABLED_MODULES</code> global parameter) Media Nodes need access to this port to reach Loki. TCP 9009 Media Nodes Needed when 'Observability' module is used. (<code>observability</code> in <code>ENABLED_MODULES</code> global parameter) Media Nodes need access to this port to reach Mimir. TCP 7000 Media Nodes Media Nodes need access to this port to reach Redis Service. TCP 9100 Media Nodes Media Nodes need access to this port to reach MinIO. TCP 20000 Media Nodes Media Nodes need access to this port to reach MongoDB. <p>Outbound port rules:</p> <p>Typically, all outbound traffic is allowed.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/on-premises/install/#port-rules-media-nodes","title":"Port rules (Media Nodes)","text":"<p>Ensure all these rules are configured in your firewall, security group, or any kind of network configuration that you have in your Media Nodes:</p> <p>Inbound port rules:</p> Protocol Ports Source Description UDP 443 0.0.0.0/0, ::/0 STUN/TURN over UDP. TCP 7881 0.0.0.0/0, ::/0 Needed for WebRTC media traffic over TCP with Pion. UDP 7885 0.0.0.0/0, ::/0 Needed if you want to ingest WebRTC using WHIP. UDP 50000-60000 0.0.0.0/0, ::/0 Needed for WebRTC media traffic over UDP. TCP 50000-60000 0.0.0.0/0, ::/0 Needed for WebRTC media traffic over TCP with Mediasoup. TCP 1935 Master Node Needed if you want to ingest RTMP streams using Ingress service. Master Node needs access to this port to reach Ingress RTMP service and expose it using TLS (RTMPS). TCP 5349 Master Node Needed if you have configured TURN with a domain for TLS. Master Node needs access to this port to reach TURN service and expose it using TLS (TURNS). TCP 7880 Master Node LiveKit API. Master Node needs access to load balance LiveKit API and expose it through HTTPS. TCP 8080 Master Node Needed if you want to ingest WebRTC streams using WHIP. Master Node needs access to this port to reach WHIP HTTP service. <p>Outbound port rules:</p> <p>Typically, all outbound traffic is allowed.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/on-premises/install/#guided-installation","title":"Guided installation","text":"<p>Before the installation, ensure that all your machines meet the prerequisites and the port rules for the Master Node and Media Nodes are correctly configured.</p> <p>To install OpenVidu Elastic, begin by generating the commands required for setting up all nodes in the cluster. This is a simple and straightforward process; simply run the following command on any machine that has Docker installed:</p> <pre><code>docker run --pull always --rm -it \\\n    openvidu/openvidu-installer:latest \\\n    --deployment-type=elastic\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <p>A wizard will guide you through the installation process. You will be asked for the following information:</p> <ul> <li>Write the 'Master Node' Private IP: Write the private IP of the machine where you are going to install the Master Node.</li> <li>Write your OpenVidu PRO License: Write your OpenVidu PRO License.</li> </ul> <p>Info</p> <p>If you don't have a license key for OpenVidu PRO, you can get a 15-day free trial license key by creating an OpenVidu account.</p> <ul> <li>Domain name (Optional): The domain name for your deployment. If left empty, an autogenerated domain using sslip.io (e.g., <code>10-20-30-40.sslip.io</code>) will be used based on your Master Node's public IP. For production environments, it's recommended to provide your own FQDN.</li> <li> <p>Select which certificate type to use:</p> <ul> <li>Self Signed Certificate: It will generate a self-signed certificate. It is not recommended for production environments, but it is useful for testing or development purposes.</li> <li>Let's Encrypt: It will automatically generate a certificate for your domain. The Let's Encrypt email is required and will be asked later in the wizard.</li> <li>ZeroSSL: It will automatically generate a certificate for your domain using ZeroSSL. An API Key is required and will be asked later in the wizard.</li> <li>Own Certificate: It will ask you for the certificate and key files. Just copy and paste the content of the files when the wizard asks for them.</li> </ul> <p>Note</p> <p>If you want to manage the certificate in your proxy own proxy server instead of relaying in the Caddy server deployed with OpenVidu, take a look to this How-to guide: How to deploy OpenVidu with an external proxy.</p> </li> <li> <p>(Optional) Turn domain name: The domain name for your TURN server with TLS. If no main domain is provided and this is also left empty, an autogenerated domain using sslip.io will be used. This is recommended if users who are going to connect to your OpenVidu deployment are behind restrictive firewalls.</p> </li> <li>Select which RTC engine to use: Select the WebRTC engine you want to use. You can choose between Pion (the default engine used by LiveKit) and Mediasoup (with a boost in performance). Learn more about the differences here.</li> <li>Modules to enable: Select the modules you want to enable. You can enable the following modules:<ul> <li>OpenVidu Meet: A high-quality video calling service based on OpenVidu.</li> <li>Observability: Grafana stack, which includes logs and monitoring stats.</li> <li>OpenVidu V2 Compatibility: Compatibility API for applications developed with OpenVidu v2.</li> </ul> </li> </ul> <p>The rest of the parameters are secrets, usernames, and passwords. If empty, the wizard will generate random values for them.</p> <p>This command will output the following instructions, which you should follow:</p> <ol> <li>Firewall Configuration for 'Master Node': These rules are the same as those specified in the instructions. Depending on the modules you have selected, some rules defined at Port rules (Master Node) may not appear (Optional ports). Double-check and modify it if you see something that can be enabled/disabled in your current port rules.</li> <li> <p>Installation Commands for 'Master Node': This is the command needed to install your Master Node. It should look like this:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/pro/elastic/latest/install_ov_master_node.sh) \\\n    --no-tty --install \\\n    --deployment-type='elastic' \\\n    --node-role='master-node' \\\n...\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <p>Execute that command in your Master Node to install it. When the installation process finishes, you will see the following output:</p> <pre><code>&gt; - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - &lt;\n&gt;                                                                             &lt;\n&gt;  \ud83c\udf89 OpenVidu Elastic 'Master Node' Installation Finished Successfully! \ud83c\udf89   &lt;\n&gt;                                                                             &lt;\n&gt; - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - &lt;\n</code></pre> <p>The Master Node will be installed at <code>/opt/openvidu</code> and configured as a systemd service. You can start the service with the following command:</p> <pre><code>systemctl start openvidu\n</code></pre> </li> <li> <p>Firewall Configuration for 'Media Nodes': These rules are the same as those defined previously as with the Master Node. Double-check the Port rules (Media Nodes) and modify them if you see something that can be enabled/disabled in your current port rules.</p> </li> <li> <p>Installation Commands for 'Media Nodes': This is the command needed to install your Media Nodes. It should look like this:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/pro/elastic/latest/install_ov_media_node.sh) \\\n    --no-tty --install \\\n    --deployment-type='elastic' \\\n    --node-role='media-node' \\\n...\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <p>Execute that command on your Media Nodes to install them. When the installation process finishes, you will see the following output:</p> <pre><code>&gt; - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - &lt;\n&gt;                                                                             &lt;\n&gt;  \ud83c\udf89 OpenVidu Elastic 'Media Node' Installation Finished Successfully! \ud83c\udf89    &lt;\n&gt;                                                                             &lt;\n&gt; - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - &lt;\n</code></pre> <p>The Media Node in each machine will be installed at <code>/opt/openvidu</code> and configured as a systemd service. You can start the service with the following command:</p> <pre><code>systemctl start openvidu\n</code></pre> </li> </ol> <p>If everything goes well, all containers will be up and running without restarts, and you will be able to access any of the following services:</p> <ul> <li>OpenVidu Meet: https://openvidu.example.io/</li> <li>OpenVidu Dashboard: https://openvidu.example.io/dashboard</li> <li>MinIO: https://openvidu.example.io/minio-console</li> <li>Grafana: https://openvidu.example.io/grafana</li> </ul> <p>OpenVidu Server PRO URL (LiveKit compatible) will be available also in:</p> <ul> <li>OpenVidu Server PRO: https://openvidu.example.io/</li> <li>LiveKit API: https://openvidu.example.io/ and wss://openvidu.example.io/</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/on-premises/install/#configure-your-application-to-use-the-deployment","title":"Configure your application to use the deployment","text":"<p>To point your applications to your OpenVidu deployment, check the following files:</p> <ul> <li><code>/opt/openvidu/config/cluster/master_node/meet.env</code>: Contains the OpenVidu Meet parameters.</li> <li><code>/opt/openvidu/config/cluster/openvidu.env</code>: Contains all the credentials of services deployed with OpenVidu Platform.</li> </ul> <p>The most relevant parameters are:</p> <p>OpenVidu Meet:</p> <ul> <li><code>MEET_INITIAL_ADMIN_USER</code>: User to access OpenVidu Meet Console. It is always <code>admin</code>.</li> <li><code>MEET_INITIAL_ADMIN_PASSWORD</code>: Password to access OpenVidu Meet Console.</li> <li><code>MEET_INITIAL_API_KEY</code>: API key to use OpenVidu Meet Embedded and OpenVidu Meet REST API.</li> </ul> <p>Note</p> <p>The <code>MEET_INITIAL_ADMIN_USER</code>, <code>MEET_INITIAL_ADMIN_PASSWORD</code>, and <code>MEET_INITIAL_API_KEY</code> values are initial and cannot be changed from the <code>meet.env</code> file. They can only be changed from the Meet Console.</p> <p>OpenVidu Platform:</p> <ul> <li><code>LIVEKIT_URL</code>: The URL to use LiveKit SDKs, which can be <code>wss://yourdomain.example.io/</code> or <code>https://yourdomain.example.io/</code> depending on the client library you are using.</li> <li><code>LIVEKIT_API_KEY</code>: API Key for LiveKit SDKs.</li> <li><code>LIVEKIT_API_SECRET</code>: API Secret for LiveKit SDKs.</li> </ul> <p>OpenVidu V2 Compatibility Credentials</p> <p>This section is only needed if you want to use OpenVidu v2 compatibility.</p> <ul> <li>URL: The URL to access OpenVidu, which is formed by the <code>DOMAIN_NAME</code> as <code>https://yourdomain.example.io/</code></li> <li>Username: Basic auth user for OpenVidu v2 compatibility. It is always <code>OPENVIDUAPP</code>.</li> <li>Password: Basic auth password for OpenVidu v2 compatibility is the same as <code>LIVEKIT_API_SECRET</code>.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/on-premises/install/#non-interactive-installation","title":"Non-interactive installation","text":"<p>To automate the installation process, you just need to execute the specified command in the Guided installation section and execute the generated commands.</p> <p>Each installation command for each type of node looks like this:</p> Master NodeMedia Node Without Domain NameWith Domain Name <p>The Master Node can be configured with multiple kinds of certificates. Here are the examples for each type of certificate that is allowed when no FQDN is provided:</p> Let's Encrypt certificatesSelf-signed certificates <p>Example using Let's Encrypt certificates with autogenerated sslip.io domain:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/pro/elastic/latest/install_ov_master_node.sh) \\\n    --no-tty --install \\\n    --node-role='master-node' \\\n    --openvidu-pro-license='xxxxx' \\\n    --enabled-modules='observability,v2compatibility,openviduMeet' \\\n    --rtc-engine='pion' \\\n    --livekit-api-key='xxxxx' \\\n    --livekit-api-secret='xxxxx' \\\n    --dashboard-admin-user='xxxxx' \\\n    --dashboard-admin-password='xxxxx' \\\n    --redis-password='xxxxx' \\\n    --minio-access-key='xxxxx' \\\n    --minio-secret-key='xxxxx' \\\n    --mongo-admin-user='xxxxx' \\\n    --mongo-admin-password='xxxxx' \\\n    --mongo-replica-set-key='xxxxx' \\\n    --grafana-admin-user='xxxxx' \\\n    --grafana-admin-password='xxxxx' \\\n    --meet-initial-admin-password='xxxxx' \\\n    --meet-initial-api-key='xxxxx' \\\n    --private-ip='1.2.3.4' \\\n    --certificate-type='letsencrypt'\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <ul> <li><code>--openvidu-pro-license</code> is mandatory. You can get a 15-day free trial license key by creating an OpenVidu account.</li> <li>Depending on the RTC engine, the argument <code>--rtc-engine</code> can be <code>pion</code> or <code>mediasoup</code>.</li> <li><code>--private-ip</code> is very important. It should not change and Media Nodes should be able to reach the Master Node using this IP.</li> </ul> <p>Example using self-signed certificates with autogenerated sslip.io domain:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/pro/elastic/latest/install_ov_master_node.sh) \\\n    --no-tty --install \\\n    --node-role='master-node' \\\n    --openvidu-pro-license='xxxxx' \\\n    --enabled-modules='observability,v2compatibility,openviduMeet' \\\n    --rtc-engine='pion' \\\n    --livekit-api-key='xxxxx' \\\n    --livekit-api-secret='xxxxx' \\\n    --dashboard-admin-user='xxxxx' \\\n    --dashboard-admin-password='xxxxx' \\\n    --redis-password='xxxxx' \\\n    --minio-access-key='xxxxx' \\\n    --minio-secret-key='xxxxx' \\\n    --mongo-admin-user='xxxxx' \\\n    --mongo-admin-password='xxxxx' \\\n    --mongo-replica-set-key='xxxxx' \\\n    --grafana-admin-user='xxxxx' \\\n    --grafana-admin-password='xxxxx' \\\n    --meet-initial-admin-password='xxxxx' \\\n    --meet-initial-api-key='xxxxx' \\\n    --private-ip='1.2.3.4' \\\n    --certificate-type='selfsigned'\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <ul> <li><code>--openvidu-pro-license</code> is mandatory. You can get a 15-day free trial license key by creating an OpenVidu account.</li> <li>Depending on the RTC engine, the argument <code>--rtc-engine</code> can be <code>pion</code> or <code>mediasoup</code>.</li> <li><code>--private-ip</code> is very important. It should not change and Media Nodes should be able to reach the Master Node using this IP.</li> </ul> <p>The Master Node can be configured with multiple kinds of certificates. Here are the examples for each type of certificate:</p> Let's Encrypt certificatesSelf-signed certificatesCustom certificates <p>Example using Let's Encrypt certificates:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/pro/elastic/latest/install_ov_master_node.sh) \\\n    --no-tty --install \\\n    --node-role='master-node' \\\n    --openvidu-pro-license='xxxxx' \\\n    --domain-name='openvidu.example.io' \\\n    --enabled-modules='observability,v2compatibility,openviduMeet' \\\n    --rtc-engine='pion' \\\n    --turn-domain-name='turn.example.io' \\\n    --livekit-api-key='xxxxx' \\\n    --livekit-api-secret='xxxxx' \\\n    --dashboard-admin-user='xxxxx' \\\n    --dashboard-admin-password='xxxxx' \\\n    --redis-password='xxxxx' \\\n    --minio-access-key='xxxxx' \\\n    --minio-secret-key='xxxxx' \\\n    --mongo-admin-user='xxxxx' \\\n    --mongo-admin-password='xxxxx' \\\n    --mongo-replica-set-key='xxxxx' \\\n    --grafana-admin-user='xxxxx' \\\n    --grafana-admin-password='xxxxx' \\\n    --meet-initial-admin-password='xxxxx' \\\n    --meet-initial-api-key='xxxxx' \\\n    --private-ip='1.2.3.4' \\\n    --certificate-type='letsencrypt'\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <p>Notes:</p> <ul> <li><code>--openvidu-pro-license</code> is mandatory. You can get a 15-day free trial license key by creating an OpenVidu account.</li> <li>Depending on the RTC engine, the argument <code>--rtc-engine</code> can be <code>pion</code> or <code>mediasoup</code>.</li> <li><code>--private-ip</code> is very important. It should not change and Media Nodes should be able to reach the Master Node using this IP.</li> </ul> <p>Example using self-signed certificates:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/pro/elastic/latest/install_ov_master_node.sh) \\\n    --no-tty --install \\\n    --node-role='master-node' \\\n    --openvidu-pro-license='xxxxx' \\\n    --domain-name='openvidu.example.io' \\\n    --enabled-modules='observability,v2compatibility,openviduMeet' \\\n    --rtc-engine='pion' \\\n    --turn-domain-name='turn.example.io' \\\n    --livekit-api-key='xxxxx' \\\n    --livekit-api-secret='xxxxx' \\\n    --dashboard-admin-user='xxxxx' \\\n    --dashboard-admin-password='xxxxx' \\\n    --redis-password='xxxxx' \\\n    --minio-access-key='xxxxx' \\\n    --minio-secret-key='xxxxx' \\\n    --mongo-admin-user='xxxxx' \\\n    --mongo-admin-password='xxxxx' \\\n    --mongo-replica-set-key='xxxxx' \\\n    --grafana-admin-user='xxxxx' \\\n    --grafana-admin-password='xxxxx' \\\n    --meet-initial-admin-password='xxxxx' \\\n    --meet-initial-api-key='xxxxx' \\\n    --private-ip='1.2.3.4' \\\n    --certificate-type='selfsigned'\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <ul> <li><code>--openvidu-pro-license</code> is mandatory. You can get a 15-day free trial license key by creating an OpenVidu account.</li> <li>Depending on the RTC engine, the argument <code>--rtc-engine</code> can be <code>pion</code> or <code>mediasoup</code>.</li> <li><code>--private-ip</code> is very important. It should not change and Media Nodes should be able to reach the Master Node using this IP.</li> </ul> <p>Example using custom certificates:</p> <pre><code>CERT_PRIVATE_KEY=$(cat privkey.pem | base64 -w 0)\nCERT_PUBLIC_KEY=$(cat fullchain.pem | base64 -w 0)\n\n# Optional, only if you want to enable TURN with TLS\nCERT_TURN_PRIVATE_KEY=$(cat turn-privkey.pem | base64 -w 0)\nCERT_TURN_PUBLIC_KEY=$(cat turn-fullchain.pem | base64 -w 0)\n\nsh &lt;(curl -fsSL http://get.openvidu.io/pro/elastic/latest/install_ov_master_node.sh) \\\n    --no-tty --install \\\n    --node-role='master-node' \\\n    --openvidu-pro-license='xxxxx' \\\n    --domain-name='openvidu.example.io' \\\n    --enabled-modules='observability,v2compatibility,openviduMeet' \\\n    --rtc-engine='pion' \\\n    --turn-domain-name='turn.example.io' \\\n    --livekit-api-key='xxxxx' \\\n    --livekit-api-secret='xxxxx' \\\n    --dashboard-admin-user='xxxxx' \\\n    --dashboard-admin-password='xxxxx' \\\n    --redis-password='xxxxx' \\\n    --minio-access-key='xxxxx' \\\n    --minio-secret-key='xxxxx' \\\n    --mongo-admin-user='xxxxx' \\\n    --mongo-admin-password='xxxxx' \\\n    --mongo-replica-set-key='xxxxx' \\\n    --grafana-admin-user='xxxxx' \\\n    --grafana-admin-password='xxxxx' \\\n    --meet-initial-admin-password='xxxxx' \\\n    --meet-initial-api-key='xxxxx' \\\n    --private-ip='1.2.3.4' \\\n    --certificate-type='owncert' \\\n    --owncert-private-key=\"$CERT_PRIVATE_KEY\" \\\n    --owncert-public-key=\"$CERT_PUBLIC_KEY\" \\\n    --turn-owncert-private-key=\"$CERT_TURN_PRIVATE_KEY\" \\\n    --turn-owncert-public-key=\"$CERT_TURN_PUBLIC_KEY\"\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <ul> <li>Note that you just need to pass <code>--owncert-private-key</code> and <code>--owncert-public-key</code> with the content of the private and public key files in base64 format. The installation script will decode them and save them in the proper files.</li> <li><code>--openvidu-pro-license</code> is mandatory. You can get a 15-day free trial license key by creating an OpenVidu account.</li> <li>Depending on the RTC engine, the argument <code>--rtc-engine</code> can be <code>pion</code> or <code>mediasoup</code>.</li> <li><code>--private-ip</code> is very important. It should not change and Media Nodes should be able to reach the Master Node using this IP.</li> <li><code>--turn-owncert-private-key</code> and <code>--turn-owncert-public-key</code> are optional. You only need to pass them if you want to enable TURN with TLS.</li> </ul> <p>To install a Media Node, you can use the following command:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/pro/elastic/latest/install_ov_media_node.sh) \\\n    --no-tty --install \\\n    --node-role='media-node' \\\n    --master-node-private-ip='1.2.3.4' \\\n    --redis-password='xxxxx'\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <ul> <li>The <code>--master-node-private-ip</code> is the private IP of the Master Node. Media Nodes should be able to reach the Master Node using this IP.</li> <li>The <code>--redis-password</code> is the password defined in the Master Node installation. It is used to connect to the Redis service in the Master Node and register itself as a Media Node in the cluster.</li> <li>If no media appears in your conference, reinstall specifying the <code>--public-ip</code> parameter with your machine's public IP. OpenVidu usually auto-detects the public IP, but it can fail. This IP is used by clients to send and receive media. If you decide to install the Media Node with <code>--public-ip</code>, you must reinstall the Master Node with <code>--force-media-node-public-ip</code>.</li> </ul> <p>You can run these commands in a CI/CD pipeline or in a script to automate the installation process.</p> <p>Some notes about the Master Node installation command:</p> <ul> <li>The argument <code>--domain-name</code> is optional. If not provided, an autogenerated domain using sslip.io will be used based on your machine's public IP.</li> <li>The argument <code>--turn-domain-name</code> is optional. You define it only if you want to enable TURN with TLS in case users are behind restrictive firewalls. If no main domain is provided and this is also left empty, an autogenerated domain using sslip.io will be used.</li> <li>When using autogenerated domains (no FQDN (Fully Qualified Domain Name) provided), only <code>selfsigned</code> and <code>letsencrypt</code> certificate types are available.</li> <li>The argument <code>--turn-domain-name</code> is optional. You define it only if you want to enable TURN with TLS in case users are behind restrictive firewalls.</li> <li>At the argument <code>--enabled-modules</code>, you can enable the modules you want to deploy. You can enable <code>openviduMeet</code> OpenVidu Meet service, <code>observability</code> (Grafana stack) and <code>v2compatibility</code> (OpenVidu v2 compatibility API).</li> </ul> <p>To start each node, remember to execute the following command in each node:</p> <pre><code>systemctl start openvidu\n</code></pre>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/on-premises/install/#configuration-and-administration","title":"Configuration and administration","text":"<p>Once you have OpenVidu deployed, you can check the Administration section to learn how to manage your OpenVidu Elastic deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/on-premises/upgrade/","title":"Upgrade OpenVidu Elastic - On premises","text":"","tags":["Platform"]},{"location":"docs/self-hosting/elastic/on-premises/upgrade/#upgrade-openvidu-elastic-on-premises","title":"Upgrade OpenVidu Elastic - On premises","text":"<p>OpenVidu offers an updater that allows you to upgrade your OpenVidu deployment in an easy and automated way. The updater will take care of the whole process, from stopping the services to updating the configuration files.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/on-premises/upgrade/#upgrading-openvidu-elastic","title":"Upgrading OpenVidu Elastic","text":"<p>Upgrade OpenVidu Elastic is very simple. These are the steps you need to follow:</p> <ol> <li> <p>First, ensure to shut down OpenVidu Elastic. SSH into all the nodes and execute the following command:</p> <pre><code>systemctl stop openvidu\n</code></pre> </li> <li> <p>SSH into your Master Node and your Media Nodes and execute on each of them the following command:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/update/latest/update.sh)\n</code></pre> <p>Info</p> <p>If instead of upgrading to the latest version you want to upgrade to a specific version, you can execute the following command:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/update/&lt;VERSION&gt;/update.sh)\n</code></pre> <p>Where <code>&lt;VERSION&gt;</code> is the version you want to upgrade to.</p> </li> <li> <p>In all the nodes, you will see the following output:</p> <pre><code>Stopping OpenVidu service...\nBacking up files...\n\n    - Backing up file '/opt/openvidu/config' to '/opt/openvidu/backups/&lt;DATE&gt;_&lt;VERSION&gt;/config'\n    ... More files ...\n\n--------------------\n\ud83d\udce6 Backup directory: /opt/openvidu/backups/&lt;DATE&gt;_&lt;VERSION&gt;/\n--------------------\n\n--------------------\n\ud83d\ude80 Updating OpenVidu from 3.x.x to 3.y.y\n--------------------\n\n? Do you want to update from 3.x.x to 3.y.y? \u203a\n\u2022 Yes\n  No\n</code></pre> </li> <li> <p>Answer <code>Yes</code> to the question and your OpenVidu Master Node will be upgraded to asked version. For each version the system will ask you to confirm the upgrade.</p> </li> <li>A <code>diff</code> will be shown with the changes made in the configuration files. You can review the changes and decide if you want to apply them or not. If you want to apply the changes, answer <code>Yes</code> to the question. If you want to discard the changes and stop the upgrading process, simply answer <code>No</code>.</li> <li>Once the upgrade is finished, it will ask you to pull the images of the services. Answer <code>Yes</code> if you want to do it.</li> <li>Execute the following command in all the nodes:</li> </ol> <pre><code>systemctl start openvidu &amp;&amp; journalctl -f -u openvidu\n</code></pre> <p>The <code>journalctl</code> command will show you the logs of the OpenVidu services. You can stop the logs by pressing <code>Ctrl + C</code>.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/on-premises/upgrade/#backups-and-rollback","title":"Backups and Rollback","text":"<p>When you finish the upgrade process on each node, you will have a backup of the previous version in the <code>/opt/openvidu/backups</code> directory. The backup only contains the previous configuration files that have changed in the upgrade process. To roll back to the previous version, you have to copy the files from the backup to the OpenVidu directory. You can do it with the following command:</p> <pre><code>cp -r /opt/openvidu/backups/&lt;DATE&gt;_&lt;VERSION&gt;/* /opt/openvidu\n</code></pre> <p>Where <code>&lt;DATE&gt;</code> and <code>&lt;VERSION&gt;</code> are the date and version of the backup you want to restore. For example:</p> <pre><code>cp -r /opt/openvidu/backups/2025-02-12-09-50-46_3.0.0/* /opt/openvidu\n</code></pre> <p>You need to do this in all the nodes of your OpenVidu Elastic deployment to restore to the previous version.</p>","tags":["Platform"]},{"location":"docs/self-hosting/elastic/on-premises/upgrade/#recommendations","title":"Recommendations","text":"<ul> <li>Always upgrade all the nodes of your OpenVidu Elastic deployment. Otherwise, you may face compatibility issues between the different versions of OpenVidu running in your deployment.</li> <li>On any upgrade problem, a redeployment is always recommended for a clean installation.</li> <li>Keep your Docker and Docker Compose versions updated.</li> <li> <p>Remove non-used images and containers to free up disk space. For example, after the upgrade, when OpenVidu is running, you can remove the old images with the following command:</p> <pre><code>docker image prune -a\n</code></pre> <p>This command will remove all the images that are not being used by any container.</p> </li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/ha/","title":"OpenVidu High Availability","text":"","tags":["Platform"]},{"location":"docs/self-hosting/ha/#openvidu-high-availability-installation","title":"OpenVidu High Availability installation","text":"<p>OpenVidu High Availability is part of the PRO edition of OpenVidu. You have the following deployment options:</p> <ul> <li>On-premises installation (DNS Load Balancing): Set up OpenVidu High Availability on your own servers with a DNS Load Balancing mechanism.</li> <li>On-premises installation (Network Load Balancer): Set up OpenVidu High Availability on your own servers with a Network Load Balancer.</li> <li>AWS installation: Deploy OpenVidu High availability on Amazon Web Services.</li> <li>Azure installation: Deploy OpenVidu High Availability on Microsoft Azure.</li> </ul> <p>Once your deployment is complete, refer to the following sections for configuration and management:</p> <ul> <li>On-premises: configuration and administration</li> <li>AWS: configuration and administration</li> <li>Azure: configuration and administration</li> </ul> <p>If you want to upgrade your OpenVidu High Availability installation, refer to this section:</p> <ul> <li>Upgrade OpenVidu High Availability On-premises</li> <li>Upgrade OpenVidu High Availability AWS</li> <li>Upgrade OpenVidu High Availability Azure</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/admin/","title":"OpenVidu High Availability administration on AWS","text":"","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/admin/#openvidu-high-availability-administration-aws","title":"OpenVidu High Availability administration: AWS","text":"<p>The deployment of OpenVidu High Availability on AWS is automated using AWS CloudFormation, with 4 EC2 Instances as Master Nodes and any number of Media Nodes managed within an Auto Scaling Group . The Auto Scaling Group of Media Nodes is configured to scale based on the target average CPU utilization.</p> <p>Internally, the AWS deployment mirrors the on-premises setup, allowing you to follow the same administration and configuration guidelines provided in the On Premises High Availability documentation. However, there are specific considerations unique to the AWS environment that are worth taking into account.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/admin/#cluster-shutdown-and-startup","title":"Cluster Shutdown and Startup","text":"<p>You can start and stop the OpenVidu High Availability cluster at any time. The following sections detail the procedures.</p> Shutdown the ClusterStartup the Cluster <p>To shut down the cluster, you need to stop the Media Nodes first and then stop the Master Nodes; this way, any ongoing session will not be interrupted.</p> <ol> <li>Navigate to the CloudFormation Dashboard  on AWS.</li> <li>Select the CloudFormation Stack that you used to deploy OpenVidu High Availability.</li> <li>In the \"Resources\" tab, locate the resource with the logical ID: <code>OpenViduMediaNodeASG</code>, and click on it to go to the Auto Scaling Group Dashboard with the Auto Scaling Group of the Media Nodes selected.      </li> <li>Click on \"Actions &gt; Edit\".      </li> <li>Set the \"Desired capacity\", \"Min desired capacity\", and \"Max desired capacity\" to 0, and click on \"Update\".      </li> <li> <p>Wait until the \"Instance Management\" tab shows that there are no instances in the Auto Scaling Group.     </p> <p></p> <p>Warning</p> <p>It may happen that some instances are still in the \"Terminating:Wait\" lifecycle state after setting the desired capacity to 0. This is because the Auto Scaling Group waits for the instances to finish processing any ongoing room, ingress, or egress operations before terminating them. This can take a few minutes. If you want to force the termination of the instances, you can manually terminate them from the EC2 Dashboard.</p> </li> <li> <p>Navigate to the EC2 Dashboard  on AWS.</p> </li> <li>Stop all the Master Nodes instances by selecting them and clicking on \"Stop instance\".      </li> <li>Wait until the instances are stopped.</li> </ol> <p>To start the cluster, we recommend starting the Master Node first and then the Media Nodes.</p> <ol> <li>Navigate to the EC2 Dashboard  on AWS.</li> <li>Start all the Master Nodes instances by selecting them and clicking on \"Start instance\".      </li> <li>Wait until the instances are running.</li> <li>Go to the CloudFormation Dashboard  on AWS.</li> <li>Select the CloudFormation Stack that you used to deploy OpenVidu High Availability.</li> <li>Locate the resource with the logical ID: <code>OpenViduMasterNodeASG</code>. Click on it to go to the Auto Scaling Group Dashboard with the Auto Scaling Group of the Master Nodes selected.      </li> <li>Click on \"Actions &gt; Edit\".      </li> <li>Set the \"Desired capacity\", \"Min desired capacity\", and \"Max desired capacity\" to the desired number of Media Nodes, and click on \"Update\". For the Master Nodes auto scaling group, the number of instances must be 4.      </li> <li>Wait until the \"Instance Management\" tab shows that there are the desired number of instances in the Auto Scaling Group.      </li> <li>Go back to the CloudFormation Stack and locate the resource with the logical ID: <code>OpenViduMediaNodeASG</code>. Click on it to go to the Auto Scaling Group Dashboard with the Auto Scaling Group of the Media Nodes selected.      </li> <li>Click on \"Actions &gt; Edit\".      </li> <li>Set the \"Desired capacity\", \"Min desired capacity\", and \"Max desired capacity\" to the desired number of Media Nodes, and click on \"Update\". In this example, we set the desired capacity to 2.      </li> <li>Wait until the \"Instance Management\" tab shows that there are the desired number of instances in the Auto Scaling Group.      </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/admin/#change-the-instance-type","title":"Change the instance type","text":"<p>It is possible to change the instance type of both the Master Node and the Media Nodes. The following section details the procedures.</p> Master NodesMedia Nodes <p>Warning</p> <p>This procedure requires downtime, as it involves stopping all the Master Nodes and starting them again with the new instance type.</p> <ol> <li>Navigate to the EC2 Dashboard  on AWS.</li> <li>Stop all the Master Nodes instances by selecting them and clicking on \"Stop instance\".      </li> <li>Wait until the instances are stopped.</li> <li>For each node you want to change the instance type, select it, and click on \"Instance settings &gt; Change instance type\".      </li> <li>Select the new instance type and click on \"Change\".</li> <li>Repeat the process for all the Master Nodes.</li> </ol> <ol> <li>Go to the CloudFormation Dashboard  on AWS.</li> <li>Select the CloudFormation Stack that you used to deploy OpenVidu High Availability.</li> <li>Locate the resource with the logical ID: <code>OpenViduMediaNodeLaunchTemplate</code>. Click on it to go to the Launch Template Dashboard with the Launch Template of the Media Nodes selected.      </li> <li>Click on \"Actions &gt; Modify template (Create new version)\".      </li> <li>In the \"Instance type\" section, select the new instance type and click on \"Create template version\".      </li> <li>Go to the CloudFormation Stack and locate the resource with the logical ID: <code>OpenViduMediaNodeASG</code>. Click on it to go to the Auto Scaling Group Dashboard with the Auto Scaling Group of the Media Nodes selected.      </li> <li>Click on \"Actions &gt; Edit\".      </li> <li> <p>In the Launch Template section, select the new version of the launch template we just created at step 5 which is the highest version number.</p> <p>Then, click on \"Update\".</p> <p>Info</p> <p>By configuring \"Latest\" as the launch template version,  you no longer need to update the Auto Scaling Group every time you modify the launch template. The Auto Scaling Group will automatically use the latest version of the launch template.</p> <p></p> </li> <li> <p>Terminate the old instances manually from the EC2 Dashboard if you want to force the termination of the instances. New instances will be launched with the new instance type.</p> <p>Info</p> <p>If you want to avoid downtime, you can wait until the Auto Scaling Group replaces the old instances with the new ones. But you will need to increase the desired capacity to force the replacement of the instances and then decrease it to the desired number of instances.</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/admin/#media-nodes-autoscaling-configuration","title":"Media Nodes Autoscaling Configuration","text":"<p>To configure the Auto Scaling settings for the Media Nodes, follow the steps outlined below. This configuration allows you to set the parameters that control how the Auto Scaling Group will scale based on the target average CPU utilization.</p> Media Nodes Autoscaling Configuration <ol> <li>Navigate to the CloudFormation Dashboard  on AWS.</li> <li>Select the CloudFormation Stack that you used to deploy OpenVidu High Availability.</li> <li>In the \"Resources\" tab, locate the resource with the logical ID: <code>OpenViduMediaNodeASG</code> and click on it to go to the Auto Scaling Group Dashboard.      </li> <li>Click on \"Actions &gt; Edit\".      </li> <li>To configure scaling policies, navigate to the \"Automatic scaling\" tab within the Auto Scaling Group Dashboard, select the unique \"Target tracking scaling\" autoscaling policy, and click on \"Actions &gt; Edit\".      </li> <li> <p>It will open a panel where you can configure multiple parameters. In this example, we set the target average CPU utilization to 30%. Then, click on \"Update\".     </p> <p></p> <p>Info</p> <p>OpenVidu High Availability is by default configured with a \"Target tracking scaling\" policy that scales based on the target average CPU utilization, however, you can configure different autoscaling policies according to your needs. For more information on the various types of autoscaling policies and how to implement them, refer to the AWS Auto Scaling documentation .</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/admin/#fixed-number-of-media-nodes","title":"Fixed Number of Media Nodes","text":"<p>If you need to maintain a fixed number of Media Nodes instead of allowing the Auto Scaling Group to dynamically adjust based on CPU utilization, you can configure the desired capacity settings accordingly. Follow the steps below to set a fixed number of Media Nodes:</p> Set Fixed Number of Media Nodes <ol> <li>Navigate to the CloudFormation Dashboard  on AWS.</li> <li>Select the CloudFormation Stack that you used to deploy OpenVidu High Availability.</li> <li>In the \"Resources\" tab, locate the resource with the logical ID: <code>OpenViduMediaNodeASG</code> and click on it to go to the Auto Scaling Group Dashboard.      </li> <li>Click on \"Actions &gt; Edit\".      </li> <li>Set the \"Desired capacity\", \"Min desired capacity\", and \"Max desired capacity\" to the fixed number of Media Nodes you require, and click on \"Update\". In this example, we set the desired capacity to 2.      </li> <li>Wait until the \"Instance Management\" tab shows that the Auto Scaling Group has the fixed number of instances running.      </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/admin/#administration-and-configuration","title":"Administration and configuration","text":"<p>For administration, you can follow the instructions from the On Premises High Availability Administration section.</p> <p>Regarding the configuration, in AWS it is managed similarly to an on-premises deployment. For detailed instructions, please refer to the Changing Configuration section. Additionally, the How to Guides offer multiple resources to assist with specific configuration changes.</p> <p>In addition to these, an AWS deployment provides the capability to manage global configurations via the AWS Console using AWS Secrets created during the deployment. To manage configurations this way, follow these steps:</p> Changing Configuration through AWS Secrets <ol> <li>Navigate to the CloudFormation Dashboard  on AWS.</li> <li>Select the CloudFormation Stack that you used to deploy OpenVidu High Availability.</li> <li>In the \"Outputs\" tab, click the Link at \"ServicesAndCredentials\". This will open the AWS Secrets Manager which contains all the configurations of the OpenVidu High Availability Deployment.      </li> <li>Click on the \"Retrieve secret value\" button to get the JSON with all the information.      </li> <li>Modify the parameter you want to change and click on \"Save\".</li> <li>Go to the EC2 Console and click on \"Reboot instance\" in the Master Node instance to apply the changes.      </li> </ol> <p>Changes will be applied automatically in all the nodes of your OpenVidu High Availability deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/install/","title":"OpenVidu High Availability installation on AWS","text":"","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/install/#openvidu-high-availability-installation-aws","title":"OpenVidu High Availability installation: AWS","text":"<p>Info</p> <p>OpenVidu High Availability is part of OpenVidu PRO. Before deploying, you need to create an OpenVidu account to get your license key. There's a 15-day free trial waiting for you!</p> <p>This section contains the instructions to deploy a production-ready OpenVidu High Availability deployment in AWS. Deployed services are the same as the On Premises High Availability installation but automate the process with AWS CloudFormation.</p> <p>First of all, import the template in the AWS CloudFormation console. You can click the following button...</p> <p> Deploy to AWS</p> <p>...or access your AWS CloudFormation console  and manually set this S3 URL in the <code>Specify template</code> section:</p> <pre><code>https://s3.eu-west-1.amazonaws.com/get.openvidu.io/pro/ha/latest/aws/cf-openvidu-ha.yaml\n</code></pre> <p>Info</p> <p>If you want to deploy a specific version of OpenVidu HA, replace <code>latest</code> with the version you want to deploy. For example, to deploy version <code>3.4.0</code>, use the following URL:</p> <pre><code>https://s3.eu-west-1.amazonaws.com/get.openvidu.io/pro/ha/3.4.0/aws/cf-openvidu-ha.yaml\n</code></pre> <p>This is how the architecture of the deployment looks like.</p> Architecture overviewArchitecture overview with TURN over TLS <p></p> OpenVidu High Availability AWS Architecture <p></p> <ul> <li>The Load Balancer distributes HTTPS traffic to the Master Nodes.</li> <li>If RTMP media is ingested, the Load Balancer also routes this traffic to the Media Nodes.</li> <li>WebRTC traffic (SRTP/SCTP/STUN/TURN) is routed directly to the Media Nodes.</li> <li>4 fixed EC2 Instances are created for the Master Nodes. It must always be 4 Master Nodes to ensure high availability.</li> <li>An autoscaling group of Media Nodes is created to scale the number of Media Nodes based on the system load.</li> </ul> <p></p> OpenVidu High Availability AWS Architecture with TURN over TLS <p></p> <ul> <li>The Load Balancer distributes HTTPS traffic to the Master Nodes.</li> <li>If RTMP media is ingested, the Load Balancer also routes this traffic to the Media Nodes.</li> <li>WebRTC traffic (SRTP/SCTP/STUN/TURN) is routed directly to the Media Nodes.</li> <li>An additional Load Balancer is created to route TURN over TLS traffic to the TURN server running on the Media Nodes. It is used to allow users behind restrictive firewalls to connect to the Media Nodes.</li> <li>4 fixed EC2 Instances are created for the Master Nodes. It must always be 4 Master Nodes to ensure high availability.</li> <li>An autoscaling group of Media Nodes is created to scale the number of Media Nodes based on the system load.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/install/#cloudformation-parameters","title":"CloudFormation Parameters","text":"<p>Depending on your needs, you need to fill the following CloudFormation parameters:</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/install/#domain-and-load-balancer-configuration","title":"Domain and Load Balancer configuration","text":"<p>In this section, you need to specify the domain name and the SSL certificate to use from AWS Certificate Manager.</p> Domain and Load Balancer configuration <p>The parameters in this section might look like this:</p> <p></p> <p>Set the DomainName parameter to the domain name you intend to use for your OpenVidu deployment. Ensure this domain is not currently pointing to any other service; you can temporarily point it elsewhere.</p> <p>For the OpenViduCertificateARN parameter, specify the ARN of the SSL certificate you wish to use. This certificate should be created in the AWS Certificate Manager and configured for the domain specified in DomainName.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/install/#openvidu-ha-configuration","title":"OpenVidu HA Configuration","text":"<p>In this section, you need to specify some properties needed for the OpenVidu HA deployment.</p> OpenVidu HA Configuration <p>Parameters of this section look like this:</p> <p></p> <p>Make sure to provide the OpenViduLicense parameter with the license key. If you don't have one, you can request one here.</p> <p>For the RTCEngine parameter, you can choose between Pion (the default engine used by LiveKit) and Mediasoup (with a boost in performance). Learn more about the differences here.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/install/#openvidu-meet-credentials","title":"OpenVidu Meet Credentials","text":"<p>Configure the initial credentials for accessing OpenVidu Meet:</p> OpenVidu Meet credentials <p>Parameters in this section look like this:</p> <p></p> <ul> <li>InitialMeetAdminPassword: Initial password for the \"admin\" user in OpenVidu Meet. If not provided, a random password will be generated and stored in the AWS Secret Manager.</li> <li>InitialMeetApiKey: Initial API key for OpenVidu Meet. If not provided, no API key will be set and the user can configure it later from the Meet Console.</li> </ul> <p>Both parameters are optional. If you don't specify them, you can retrieve the generated credentials from the AWS Secret Manager after deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/install/#ec2-instance-configuration","title":"EC2 Instance Configuration","text":"<p>You need to specify some properties for the EC2 instances that will be created.</p> EC2 Instance configuration <p>Parameters in this section look like this:</p> <p></p> <p>Simply select the type of instance you want to deploy at MasterNodeInstanceType and MediaNodeInstanceType, the SSH key you want to use to access the machine at KeyName, and the Amazon Image ID (AMI) to use at AmiId.</p> <p>By default, the parameter AmiId is configured to use the latest Amazon Linux AMI, so ideally you don\u2019t need to modify this.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/install/#media-nodes-autoscaling-group-configuration","title":"Media Nodes Autoscaling Group Configuration","text":"<p>The number of Media Nodes can scale up or down based on the system load. You can configure the minimum and maximum number of Media Nodes and a target CPU utilization to trigger the scaling up or down.</p> Media Nodes Autoscaling Group Configuration <p>Parameters in this section look like this:</p> <p></p> <p>The InitialNumberOfMediaNodes parameter specifies the initial number of Media Nodes to deploy. The MinNumberOfMediaNodes and MaxNumberOfMediaNodes parameters specify the minimum and maximum number of Media Nodes that you want to be deployed.</p> <p>The ScaleTargetCPU parameter specifies the target CPU utilization to trigger the scaling up or down. The goal is to keep the CPU utilization of the Media Nodes close to this value. The autoscaling policy is based on Target Tracking Scaling Policy .</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/install/#s3-bucket-for-application-data-cluster-data-and-recordings","title":"S3 bucket for application data, cluster data and recordings","text":"<p>You can specify two S3 buckets to store the application data, cluster data, and recordings.</p> S3 bucket for application data and recordings <p>Parameters in this section look like this:</p> <p></p> <p>If these parameters are not specified, new S3 buckets will be created by the CloudFormation stack.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/install/#vpc-configuration","title":"VPC Configuration","text":"<p>In this section, you need to specify the VPC and Subnet configuration for the deployment.</p> VPC Configuration <p>Parameters in this section look like this:</p> <p></p> <p>The OpenViduVPC parameter specifies the VPC where the deployment will be created.</p> <p>The OpenViduMasterNodeSubnets specifies the subnets where the Master Nodes will be deployed. You can specify a maximum of 4 subnets.</p> <p>The OpenViduMediaNodeSubnets specifies the subnets where the Media Nodes will be deployed. There is no limit on the number of subnets you can specify.</p> <p>Warning</p> <ul> <li>It is recommended to deploy in a region with at least 4 availability zones and deploy the Master Nodes in 4 subnets, one in each availability zone. This is to ensure high availability.</li> <li>You must use public subnets for the Master Nodes and Media Nodes and have enabled the auto-assign public IP option.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/install/#volumes-configuration","title":"Volumes Configuration","text":"<p>In this section, you need to specify the configuration for the EBS volumes that will be created for the Master Nodes. Master Nodes will host all the recordings and metrics data replicated across all of them. The disk size of the EBS volumes is the same for all Master Nodes.</p> Volumes Configuration <p>Parameters in this section look like this:</p> <p></p> <p>The MasterNodesDiskSize parameter specifies the size of the EBS volumes in GB.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/install/#optional-additional-flags","title":"(Optional) Additional flags","text":"<p>Additional optional flags to pass to the OpenVidu installer (comma-separated, e.g., <code>--flag1=value, --flag2</code>).</p> (Optional) Additional flags <p>Parameters in this section look like this:</p> <p></p> <p>For example, you can use <code>--experimental-turn-tls-with-main-domain</code> to use the same domain as the main one for the TURN server with TLS, instead of specifying a different one in the TURN server configuration with TLS section.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/install/#optional-turn-server-configuration-with-tls","title":"(Optional) TURN server configuration with TLS","text":"<p>This section is optional. It is useful when your users are behind a restrictive firewall that blocks UDP traffic.</p> TURN server configuration with TLS <p>Parameters in this section look like this:</p> <p></p> <p>Set the TurnDomainName parameter to the domain name you intend to use for your TURN server. Ensure this domain is not currently pointing to any other service; you can temporarily point it elsewhere.</p> <p>For the TurnCertificateARN parameter, specify the ARN of the SSL certificate you wish to use. This certificate should be created in the AWS Certificate Manager and configured for the domain specified in TurnDomainName.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/install/#deploying-the-stack","title":"Deploying the stack","text":"<p>When you are ready with your CloudFormation parameters, just click on \"Next\", specify in \"Stack failure options\" the option \"Preserve successfully provisioned resources\" to be able to troubleshoot the deployment in case of error, click on \"Next\" again, and finally \"Submit\".</p> <p>When everything is ready, you will see the following links in the \"Outputs\" section of CloudFormation:</p> CloudFormation Outputs <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/install/#configure-your-application-to-use-the-deployment","title":"Configure your application to use the deployment","text":"<p>The Output Key ServicesAndCredentials of the previous section points to an AWS Secret Manager secret that contains all URLs and credentials to access the services deployed. You can access the secret by clicking on the link in the Output Value column.</p> <p>Then, click on Retrieve secret value to get the JSON with all the information.</p> <p></p> <p></p> <p>To use your OpenVidu deployment, check the values of the JSON secret. All access credentials of all services are defined in this object. The most relevant ones are:</p> <p>OpenVidu Meet:</p> <ul> <li><code>OPENVIDU_URL</code>: The URL to access OpenVidu Meet, which is always <code>https://yourdomain.example.io/</code></li> <li><code>MEET_INITIAL_ADMIN_USER</code>: User to access OpenVidu Meet Console. It is always <code>admin</code>.</li> <li><code>MEET_INITIAL_ADMIN_PASSWORD</code>: Password to access OpenVidu Meet Console.</li> <li><code>MEET_INITIAL_API_KEY</code>: API key to use OpenVidu Meet Embedded and OpenVidu Meet REST API.</li> </ul> <p>Note</p> <p>The <code>MEET_INITIAL_ADMIN_USER</code>, <code>MEET_INITIAL_ADMIN_PASSWORD</code>, and <code>MEET_INITIAL_API_KEY</code> values are initial settings that cannot be changed from AWS Secret Manager. They can only be changed from the Meet Console.</p> <p>OpenVidu Platform:</p> <ul> <li><code>LIVEKIT_URL</code>: The URL to use LiveKit SDKs, which can be <code>wss://yourdomain.example.io/</code> or <code>https://yourdomain.example.io/</code> depending on the client library you are using.</li> <li><code>LIVEKIT_API_KEY</code>: API Key for LiveKit SDKs.</li> <li><code>LIVEKIT_API_SECRET</code>: API Secret for LiveKit SDKs.</li> </ul> <p>OpenVidu V2 Compatibility Credentials</p> <p>This section is only needed if you want to use OpenVidu v2 compatibility.</p> <ul> <li>URL: The URL to access OpenVidu, which is the value of <code>OPENVIDU_URL</code> (e.g., <code>https://yourdomain.example.io/</code>)</li> <li>Username: Basic auth user for OpenVidu v2 compatibility. It is always <code>OPENVIDUAPP</code>.</li> <li>Password: Basic auth password for OpenVidu v2 compatibility is the same as <code>LIVEKIT_API_SECRET</code>.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/install/#troubleshooting-initial-cloudformation-stack-creation","title":"Troubleshooting Initial CloudFormation Stack Creation","text":"<p>If something goes wrong during the initial CloudFormation stack creation, your stack may reach the <code>CREATE_FAILED</code> status for multiple reasons. It could be due to a misconfiguration in the parameters, a lack of permissions, or a problem with the AWS services. When this happens, the following steps can help you troubleshoot the issue and identify what went wrong:</p> <ol> <li> <p>While deploying the stack, make sure at \"Stack failure options\" you have selected the option \"Preserve successfully provisioned resources\" to be able to troubleshoot the deployment in case of an error.</p> Disable Rollback on failure <p></p> <p></p> </li> <li> <p>Check if the EC2 instance or instances are running. If they are not, check the CloudFormation events for any error messages.</p> </li> <li> <p>If the EC2 instance or instances are running, SSH into the instance and check the logs of the following files:</p> <ul> <li><code>/var/log/cloud-init-output.log</code></li> <li><code>/var/log/cloud-init.log</code></li> </ul> <p>These logs will give you more information about the CloudFormation stack creation process.</p> </li> <li> <p>If everything seems fine, check the status and the logs of the installed OpenVidu services in all the Master Nodes and Media Nodes.</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/install/#configuration-and-administration","title":"Configuration and administration","text":"<p>When your CloudFormation stack reaches the <code>CREATE_COMPLETE</code> status, your OpenVidu High Availability deployment is ready to use. You can check the Administration section to learn how to manage your deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/upgrade/","title":"Upgrade OpenVidu High Availability - AWS","text":"","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/upgrade/#upgrade-openvidu-high-availability-aws","title":"Upgrade OpenVidu High Availability - AWS","text":"<p>In AWS environments, we recommend upgrading by redeploying the OpenVidu High Availability CloudFormation stack using the latest version. This approach ensures that all components are updated accurately and consistently, as CloudFormation templates and related configurations may vary between releases. Redeploying guarantees that all necessary changes are properly applied.</p> <p>However, if you prefer not to redeploy, it is also possible to upgrade OpenVidu High Availability in place. The following steps outline how to perform an in-place upgrade of your OpenVidu High Availability deployment on AWS:</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/upgrade/#upgrading-openvidu-high-availability-on-aws","title":"Upgrading OpenVidu High Availability on AWS","text":"<ol> <li>SSH into one of your Master Node server.</li> <li> <p>Execute the following command in the Master Node:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/update/latest/update.sh)\n</code></pre> <p>Info</p> <p>If instead of upgrading to the latest version you want to upgrade to a specific version, you can execute the following command:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/update/&lt;VERSION&gt;/update.sh)\n</code></pre> <p>Where <code>&lt;VERSION&gt;</code> is the version you want to upgrade to.</p> </li> <li> <p>This will execute an update script which will guide you from the version you have installed to the latest one. The first thing you will see in the output is the following:</p> <pre><code>Stopping OpenVidu service...\nBacking up files...\n\n    - Backing up file '/opt/openvidu/config' to '/opt/openvidu/backups/&lt;DATE&gt;_&lt;VERSION&gt;/config'\n    ... More files ...\n\n--------------------\n\ud83d\udce6 Backup directory: /opt/openvidu/backups/&lt;DATE&gt;_&lt;VERSION&gt;/\n--------------------\n\n--------------------\n\ud83d\ude80 Updating OpenVidu from 3.x.x to 3.y.y\n--------------------\n\n? Do you want to update from 3.x.x to 3.y.y? \u203a\n\u2022 Yes\n  No\n</code></pre> </li> <li> <p>Answer <code>Yes</code> to the question and your Master Node will be upgraded to the asked version. For each version, the system will ask you to confirm the upgrade.</p> </li> <li>A <code>diff</code> will be shown with the changes made in the configuration files. You can review the changes and decide if you want to apply them or not. If you want to apply the changes, answer <code>Yes</code> to the question. If you want to discard the changes and stop the upgrading process, simply answer <code>No</code>.</li> <li>Once the upgrade is finished, it will ask you to pull the images of the services. Answer <code>Yes</code> if you want to do it.</li> <li>Repeat the steps 1 to 6 in all the Master Nodes of your deployment. This is important because the Master Nodes need to be running the same version of OpenVidu.</li> <li>After upgrading all your Master Nodes, you need to terminate the Media Nodes to apply the changes to run the Media Nodes with the new version. Go to your EC2 Panel, select the Media Nodes instances, and terminate them. The Auto Scaling Group will automatically launch new Media Nodes with the updated configuration.</li> <li> <p>Once the Media Nodes are up and running, execute the following command in every Master Node to start OpenVidu High Availability again:</p> <pre><code>systemctl start openvidu &amp;&amp; journalctl -f -u openvidu\n</code></pre> <p>The <code>journalctl</code> command will show you the logs of the OpenVidu services. You can stop the logs by pressing <code>Ctrl + C</code>.</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/upgrade/#backups-and-rollback","title":"Backups and Rollback","text":"<p>When you finish the upgrade process, you will have a backup of the previous version in the <code>/opt/openvidu/backups</code> directory. The backup only contains the previous configuration files that have changed in the upgrade process. To roll back to the previous version, you have to copy the files from the backup to the OpenVidu directory on each Master Node. You can do it with the following command:</p> <pre><code>cp -r /opt/openvidu/backups/&lt;DATE&gt;_&lt;VERSION&gt;/* /opt/openvidu\n/usr/local/bin/store_secret.sh save OPENVIDU_VERSION \"&lt;VERSION&gt;\"\n</code></pre> <p>Where <code>&lt;DATE&gt;</code> and <code>&lt;VERSION&gt;</code> are the date and version of the backup you want to restore. For example:</p> <pre><code>cp -r /opt/openvidu/backups/2025-02-12-09-50-46_3.0.0/* /opt/openvidu\n/usr/local/bin/store_secret.sh save OPENVIDU_VERSION \"3.0.0\"\n</code></pre> <p>Notice the <code>store_secret.sh</code> command at the end. This command is necessary to update the <code>OPENVIDU_VERSION</code> secret in the AWS Secrets Manager, which is used by the AWS deployment to know which version of OpenVidu should be running in Media Nodes. You need to do this in the Master Node only.</p> <p>Remember to terminate the Media Nodes after rolling back to the previous version so the Auto Scaling Group can launch new Media Nodes with the restored configuration. You can do this by going to your EC2 Panel, selecting the Media Nodes instances, and terminating them.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/aws/upgrade/#recommendations","title":"Recommendations","text":"<ul> <li>Always upgrade all the nodes of your OpenVidu High Availability deployment. Otherwise, you may face compatibility issues between the different versions of OpenVidu running in your deployment.</li> <li>On any upgrade problem, a redeployment is always recommended for a clean installation.</li> <li>Keep your Docker and Docker Compose versions updated.</li> <li> <p>Remove non-used images and containers to free up disk space. For example, after the upgrade, when OpenVidu is running, you can remove the old images with the following command:</p> <pre><code>docker image prune -a\n</code></pre> <p>This command will remove all the images that are not being used by any container.</p> </li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/admin/","title":"OpenVidu High Availability administration on Azure","text":"","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/admin/#openvidu-high-availability-administration-azure","title":"OpenVidu High Availability administration: Azure","text":"<p>The deployment of OpenVidu High Availability on Azure is automated using Azure Resource Manager Templates, with 4 Virtual Machine Instances as Master Nodes and any number of Media Nodes managed within a Virtual Machine Scale Set . The Virtual Machine Scale Set of Media Nodes is configured to scale based on the target average CPU usage.</p> <p>Internally, the Azure High Availability deployment mirrors the On Premises High Availability deployment, allowing you to follow the same administration and configuration guidelines provided in the On Premises High Availability documentation. However, there are specific considerations unique to the Azure environment that are worth taking into account:</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/admin/#cluster-shutdown-and-startup","title":"Cluster Shutdown and Startup","text":"<p>You can start and stop the OpenVidu High Availability cluster at any time. The following sections detail the procedures:</p> Shutdown the ClusterStartup the Cluster <p>To shut down the cluster, you need to stop the Media Nodes and then stop the Master Nodes.</p> <p>Gracefully stopping Media Nodes</p> <p>There is currently a limitation with Media Nodes that prevents them from stopping gracefully. Please exercise caution when stopping Media Nodes, as they will terminate immediately without waiting for active Rooms to complete. You may want to wait for your active Rooms to finish before stopping the cluster. We are working to implement the same graceful shutdown behavior offered by AWS and On Premises deployments. In the meantime, Media Nodes include a script that allows for a graceful shutdown. To use it, SSH to the Media Node you want to stop and execute script <code>./usr/local/bin/stop_media_node.sh</code></p> <ol> <li>Navigate to the Azure Portal Dashboard  and go to the Resource Group where you deployed OpenVidu HA.</li> <li>Click into the Virtual Machine Scale Set resource called \"stackName-mediaNodeScaleSet\" and click \"Availability + scale\" on the left panel, then click on \"Scaling\" option.      </li> <li>On this tab, modify the \"Instance Limits\" to 0.      </li> <li>Click on save and wait until it is completed. You can check the progress in the \"Instances\" tab.      </li> <li>After confirming that all Media Node instances are terminated, go back to the Resource Group and locate the resource called \"stackName-VM-MasterNode1\". Click on it to go to the Master Node 1 instance. There, click on \"Stop\" to stop the instance.      </li> <li>Repeat step 5 for all the Master Nodes.</li> </ol> <p>To start the cluster, start the Master Nodes first and then the Media Nodes.</p> <ol> <li>Navigate to the Azure Portal Dashboard  and go to the Resource Group where you deployed OpenVidu HA.</li> <li>In the resource group click on the resource called \"stackName-VM-MasterNode1\" and click on start to start the Master Node 1.      </li> <li>Wait until the instance is running.</li> <li>Repeat step 2 and 3 for all the Master Nodes until they are all up and running.</li> <li>Go back to the Resource Group, and there click into the Virtual Machine Scale Set resource called \"stackName-mediaNodeScaleSet\" and click \"Availability + scale\" on the left panel, here click on \"Scaling\" option.      </li> <li>On this tab, modify the \"Instance Limits\" to your desired ones.      </li> <li>Click on save and wait until is completed. You can check the progress in the \"Instances\" tab.      </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/admin/#change-the-instance-type","title":"Change the instance type","text":"<p>It is possible to change the instance type of both the Master Node and the Media Nodes. The following section details the procedures.</p> Master NodesMedia Nodes <p>Warning</p> <p>This procedure requires downtime, as it involves stopping the Master Node.</p> <ol> <li>Shutdown the cluster.</li> <li>Go to the Azure Resource Group where you deployed and locate the resource with the name \"stackName-VM-MasterNode1\" and click on it.</li> <li>On the left panel click on \"Availability + scale\" tab and inside click on \"Size\" tab. Then select the size you desire and click on \"Resize\" </li> <li>Repeat steps 2 and 3 for all the Master Nodes just in case you want to resize all of them, if not just do it for the ones you want.</li> <li>Start the cluster.</li> </ol> <p>Info</p> <p>This will restart the media nodes without the graceful delete option, if you want to stop them gracefully check the Shutdown the Cluster tab</p> <ol> <li>Go to the Azure Portal Dashboard  on Azure.</li> <li>Select the Resource Group where you deployed OpenVidu High Availability.</li> <li>Locate the resource with the name \"stackName-mediaNodeScaleSet\". Click on it to go to the Virtual Machine Scale Set.</li> <li>On the left panel click on \"Availability + scale\" tab and inside click on \"Size\".      </li> <li>Select the new instance type and click on \"Resize\".</li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/admin/#media-nodes-autoscaling-configuration","title":"Media Nodes Autoscaling Configuration","text":"<p>You can modify the autoscaling configuration of the Media Nodes by adjusting the scaling rules of the Virtual Machine Scale Set:</p> Media Nodes Autoscaling Configuration <ol> <li>Go to the Azure Portal Dashboard  on Azure.</li> <li>Select the Resource Group where you deployed OpenVidu High Availavility.</li> <li>Locate the resource with the name \"stackName-mediaNodeScaleSet\" and click on it.</li> <li>On the left panel click on \"Availability + scale\" tab and inside click on \"Scaling\" option.      </li> <li> <p>In the \"Default\" box you will find a section called \"Rules\". Here you can add new rules or modify existing ones.</p> <p>Warning</p> <p>Currently there is only one rule to scale out. We are actively working in providing a graceful scale in process for Media Nodes to avoid active Rooms disruption.</p> <p></p> <p></p> </li> </ol> Modify existing rulesAdd a new rule <p>Click on the rule you want to modify and change the Criteria as desired. To accept the changes click on \"Update\". </p> <p></p> <p>Click on \"Add a rule\" option and fill the Criteria as desired. To add the rule click on \"Add\". </p> <p></p> <p>Info</p> <p>OpenVidu High Availability is by default configured with a \"Target tracking scaling\" policy that scales based on the target average CPU usage. However, you can configure different autoscaling policies according to your needs. For more information on the various types of autoscaling policies and how to implement them, refer to the Azure Scaling Set documentation .</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/admin/#fixed-number-of-media-nodes","title":"Fixed Number of Media Nodes","text":"<p>If you prefer to maintain a fixed number of Media Nodes instead of allowing the Virtual Machine Scale Set to perform dynamic scaling:</p> Set Fixed Number of Media Nodes <ol> <li>Go to the Azure Portal Dashboard  on Azure.</li> <li>Select the Resource Group where you deployed OpenVidu High Availability, locate the resource with the name \"stackName-mediaNodeScaleSet\" and click on it</li> <li>On the left panel click on \"Availability + scale\" and then in \"Scaling\" tab.      </li> <li>On this tab, go at the very bottom and modify the \"Instance Limits\" to the value of fixed number of media nodes you want. In this case is set to 2.      </li> <li>Click on save and wait until is completed, you can check how is going in the \"Instances\" tab.      </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/admin/#administration-and-configuration","title":"Administration and configuration","text":"<p>Regarding the administration of your deployment, you can follow the instructions in section On Premises High Availability Administration section.</p> <p>Regarding the configuration of your deployment, you can follow the instructions in section Changing Configuration. Additionally, the How to Guides offer multiple resources to assist with specific configuration changes.</p> <p>In addition to these, an Azure deployment provides the capability to manage global configurations via the Azure portal using Key Vault Secrets created during the deployment:</p> Changing configuration through Key Vault secrets <ol> <li>Navigate to the Azure Portal Dashboard  on Azure.</li> <li>Select the Resource Group where you deployed your OpenVidu HA Stack.</li> <li>In the \"stackname-keyvault\" resource, click on \"Objects\" -&gt; \"Secrets\" on the left panel. This will show you all the secrets that are stored in the Key Vault of the OpenVidu HA deployment.      </li> <li>Click on the desired secret you want to change and click on \"New Version\".      </li> <li>Enter the new secret value on \"Secret Value\" filed and click on \"Create\".      </li> <li>Go to the Master Node resource you've want to change the secrets on and click on \"Restart\" to apply the changes to the OpenVidu HA deployment.      </li> </ol> <p>Changes will be applied automatically.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/install/","title":"OpenVidu High Availability installation on Azure","text":"","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/install/#openvidu-high-availability-installation-azure","title":"OpenVidu High Availability installation: Azure","text":"<p>Info</p> <p>OpenVidu High Availability is part of OpenVidu PRO. Before deploying, you need to create an OpenVidu account to get your license key. There's a 15-day free trial waiting for you!</p> <p>This section contains the instructions to deploy a production-ready OpenVidu High Availability deployment in Azure. Deployed services are almost the same as the On Premises High Availability installation  but they will be resources in Azure and you can automate the process with the Template Spec of ARM.</p> <p>To import the template into Azure you just need to click the button below and you will be redirected to azure.   </p> <p></p> <p>This is how the architecture of the deployment looks like:</p> Architecture overviewArchitecture overview with TURN over TLS <p></p> OpenVidu High Availability Azure Architecture <p></p> <ul> <li>The Load Balancer distributes HTTPS traffic to the Master Nodes.</li> <li>If RTMP media is ingested, the Load Balancer also routes this traffic to the Master Nodes that they act as a bridge, because it exists a limitation in Azure.</li> <li>WebRTC traffic (SRTP/SCTP/STUN/TURN) is routed directly to the Media Nodes.</li> <li>4 fixed Virtual Machine Instances are created for the Master Nodes. It must always be 4 Master Nodes to ensure high availability.</li> <li>A Scaling Set of Media Nodes is created to scale the number of Media Nodes based on the system load.</li> </ul> <p></p> OpenVidu High Availability Azure Architecture with TURN over TLS <p></p> <ul> <li>The Load Balancer distributes HTTPS traffic to the Master Nodes.</li> <li>If RTMP media is ingested, the Load Balancer also routes this traffic to the Master Nodes that they act as a bridge, because it exists a limitation in Azure.</li> <li>WebRTC traffic (SRTP/SCTP/STUN/TURN) is routed directly to the Media Nodes.</li> <li>An additional Load Balancer is created to route TURN over TLS traffic to the TURN server running on the Media Nodes. It is used to allow users behind restrictive firewalls to connect to the Media Nodes.</li> <li>4 fixed Virtual Machine Instances are created for the Master Nodes. It must always be 4 Master Nodes to ensure high availability.</li> <li>An Scaling Set of Media Nodes is created to scale the number of Media Nodes based on the system load.</li> </ul> <p>We use a custom scale-in strategy to allow the graceful shutdown of Media Nodes. In this way we ensure no disruption of active Rooms when the cluster tries to remove a Media Node.</p> Custom scale-in strategy <ul> <li>All instances in the Media Node scale set are protected to prevent their automatic shutdown.</li> <li>We receive and use the shutdown event to execute acustom Automation runbook.</li> <li>The Automation runbook determines the instance that has to be terminated and executes the appropriate commands in all internal services to prevent them of accepting new jobs (new Rooms, new Egresses, new Ingresses, new Agents...).</li> <li>Only when all the jobs hosted by the selected instance finish, it is automatically terminated.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/install/#template-parameters","title":"Template Parameters","text":"<p>To deploy the template you need to fill the following parameters.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/install/#resource-group-and-stack-name","title":"Resource Group and Stack Name","text":"<p>Select your Subscription and the Resource Group where you want to deploy OpenVidu.</p> <p></p> <p>Warning</p> <p>It is highly recommended to deploy OpenVidu in a brand new Azure Resource Group. Reusing an existing Resource Group can lead to conflicts. The only reason to reuse an existing Resource Group is to use the same IP and Azure Blob Storage Account as a previous OpenVidu deployment. The rest of resources are not reusable and should be eliminated before deploying OpenVidu in the same Resource Group.</p> <p>Select the Region and choose a descriptive Stack Name. It will be used as a prefix in the name of all the resources created by the template.</p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/install/#domain-and-ssl-certificate-configuration","title":"Domain and SSL Certificate Configuration","text":"<p>There are three possible scenarios for this section:</p> Let's Encrypt Without Domain NameLet's Encrypt With Domain Name (recommended)Custom CertificatesSelf-Signed Certificate <p>If you don't have a Domain Name and want to quickly test OpenVidu on Azure, you can use this option, simply selecting the Certificate Type as letsencrypt and keep the rest of parameters empty.</p> <p>It will deploy OpenVidu with a Let's Encrypt certificate generated using sslip.io based on the public IP created for the deployment.</p> <p></p> <p>For a production-ready setup, this scenario is ideal when you have an FQDN (Fully Qualified Domain Name) and a Public IP at your disposal. It leverages the services of Let's Encrypt to automatically generate valid certificates.</p> <p>First, you need to have the FQDN pointing to the Public IP you are going to use.</p> <p>Then, you need to fill in the following parameters:</p> <p></p> <p></p> <p>As you can see, you need to specify the Public Ip Address with the Public IP that the domain points to, the Domain Name with your FQDN, and the Lets Encrypt Email with your email address for Let\u2019s Encrypt notifications. These parameters are mandatory.</p> <p>To deploy OpenVidu in Azure under your Fully Qualified Domain Name (FQDN) using already existing certificates, follow this method.</p> <p>You need to have your FQDN pointing to a previously created Public Ip.</p> <p>Also, you need a temporary HTTP server hosting your private and public certificate under a specific URL. These URLs are needed for the instance to be able to securely download and install your certificates.</p> <p>The configured parameters would look like this:</p> <p></p> <p></p> <p>You need to specify at Own Public Certificate and Own Private Certificate the URLs where the public and private certificates are hosted, respectively. The Domain Name, Public Ip Address are mandatory parameters.</p> <p>Certificates need to be in PEM format and the URLs must be accessible from the instance.</p> <p>This is the most straightforward option for deploying OpenVidu on Azure when you do not have a Fully Qualified Domain Name (FQDN). This method allows for the immediate use of OpenVidu with ARM Templates.</p> <p>However, this convenience comes with the caveat that users will need to manually accept the certificate in their web browsers. Please be aware that this configuration is solely for developmental and testing purposes and is not suitable for a real production environment.</p> <p>These are the parameters needed in this section to use self-signed certificates:</p> <p></p> <p></p> <p>You don\u2019t need to specify any parameters; just select the CertificateType as self-signed. The domain name used will be an Azure-generated one.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/install/#openvidu-meet-credentials","title":"OpenVidu Meet Credentials","text":"<p>Configure the initial credentials for accessing OpenVidu Meet:</p> OpenVidu Meet credentials <p>Parameters in this section look like this:</p> <p></p> <ul> <li>InitialMeetAdminPassword: Initial password for the \"admin\" user in OpenVidu Meet. If not provided, a random password will be generated and stored in the Azure Key Vault.</li> <li>InitialMeetApiKey: Initial API key for OpenVidu Meet. If not provided, no API key will be set and the user can configure it later from the Meet Console.</li> </ul> <p>Both parameters are optional. If you don't specify them, you can retrieve the generated credentials from the Azure Key Vault after deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/install/#openvidu-ha-configuration","title":"OpenVidu HA Configuration","text":"<p>In this section, you need to specify some properties needed for the OpenVidu HA deployment.</p> OpenVidu HA Configuration <p>Parameters of this section look like this:</p> <p></p> <p></p> <p>Make sure to provide the OpenVidu License parameter with the license key. If you don't have one, you can request one here.</p> <p>For the RTC Engine parameter, you can choose between Pion (the default engine used by LiveKit) and Mediasoup (with a boost in performance). Learn more about the differences here.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/install/#azure-instance-configuration","title":"Azure Instance Configuration","text":"<p>You need to specify some properties for the Azure instances that will be created.</p> Azure Instance configuration <p>Parameters in this section look like this:</p> <p></p> <p></p> <p>Simply select the type of instance you want for your Master Nodes at Master Node Instance Type and select the type of instance you want for your Media Nodes at Media Node Instance Type. Fill in the parameter Admin Username that will be set as admin username in the instance. Select the SSH key you've created previously in SSH public key source (or create a new one in the same drop down) to allow you to SSH into the instances.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/install/#media-nodes-scaling-set-configuration","title":"Media Nodes Scaling Set Configuration","text":"<p>The number of Media Nodes can scale up based on the system load. You can configure the minimum and maximum number of Media Nodes and a target CPU utilization to trigger the scaling up.</p> Media Nodes Scaling Set Configuration <p>Parameters in this section look like this:</p> <p></p> <p></p> <p>The Initial Number Of Media Nodes parameter specifies the initial number of Media Nodes to deploy. The Min Number Of Media Nodes and Max Number Of Media Nodes parameters specify the minimum and maximum number of Media Nodes that you want to be deployed.</p> <p>The Scale Target CPU parameter specifies the target CPU utilization to trigger the scaling up or down. The goal is to keep the CPU utilization of the Media Nodes close to this value. The autoscaling policy is based on Azure Monitor autoscale metrics .</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/install/#scale-in","title":"Scale In","text":"<p>Azure instances may only wait at most 15 minutes when the Scale Set flags them for termination after detecting a surplus of CPU capacity. This is a problem for those active Rooms hosted by the instance that can last longer than that. To avoid the disruption of active Rooms, we have implemented a custom scale-in strategy that gracefully shuts down flagged instances only after all active jobs have finished.</p> <p>Due to Azure limitations, this strategy has the minor drawback that it can take up to 5 minutes from the time an instance is flagged for termination until the shutdown process is gracefully initiated.</p> Automation Account Configuration <p>The name of an Automation Account, needed to execute the scale-in runbook. It must be unique for the resource group it belongs to (leave it blank to use an autogenerated name). This resource cannot be reused between deployments.</p> <p></p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/install/#storage-account","title":"Storage Account","text":"<p>You need to fill some parameters about the storage account that the deployment will use to save the recordings.</p> <p>Warning</p> <p>Recordings are not available in OpenVidu v2 Compatibility mode (v2compat) for OpenVidu Azure deployments.</p> Azure Storage Account configuration <p>Parameters in this section look like this:</p> <p></p> <p></p> <p>Storage Account Name: leave blank to create a new Storage Account for this deployment. You can specify an already existing Storage Account name  if you want (remember it must belong to the same resource group as your deployment).</p> <p>Container Name is the name that you desire for the container that of the storage account where the recordings will be saved. If you leave it blank it will create the container with name <code>openvidu-appdata</code>.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/install/#optional-additional-flags","title":"(Optional) Additional flags","text":"<p>Additional optional flags to pass to the OpenVidu installer (comma-separated, e.g., <code>--flag1=value, --flag2</code>).</p> (Optional) Additional flags <p>Parameters in this section look like this:</p> <p></p> <p>For example, you can use <code>--experimental-turn-tls-with-main-domain</code> to use the same domain as the main one for the TURN server with TLS, instead of specifying a different one in the TURN server configuration with TLS section.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/install/#optional-turn-server-configuration-with-tls","title":"(Optional) TURN server configuration with TLS","text":"<p>This section is optional. It is useful when your users are behind a restrictive firewall that blocks UDP traffic.</p> TURN server configuration with TLS <p>Parameters in this section look like this:</p> <p></p> <p></p> <p>Set the Turn Domain Name parameter to the domain name you intend to use for your TURN server. Ensure this domain is not currently pointing to any other service; you can temporarily point it elsewhere.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/install/#deploying-the-stack","title":"Deploying the stack","text":"<p>Whenever you are satisfied with your Template paremeters, just click on \"Next\" to trigger the validation process. If correct, click on \"Create\" to start the deployment process (which will take about 10 to 15 minutes).</p> <p>Warning</p> <p>In case of failure, it might be that some role failed to create. In this case redeploy in a new resource group and change the Stack Name. To remove a role in a resource group visit Remove Azure role assignments .</p> <p>In case that the error is related to a conflict in the creation of a network interface, just redeploy in another resource group with a different Stack Name.</p> <p>When everything is ready, you can check the output secrets on the Key Vault or by connecting through SSH to the instance:</p> Check deployment outputs in Azure Key VaultCheck deployment outputs in the instance <ol> <li> <p>Go to the Key Vault created called yourstackname-keyvault in the Resource Group that you deployed. You can access it from the Azure Portal Dashboard .</p> </li> <li> <p>Once you are in the Key Vault on the left panel click on \"Objects\" \ud83e\udc52 \"Secrets\".</p> <p></p> <p></p> </li> <li> <p>Here click on the secret of your choice or whatever you need to check and click again in the current version of that secret</p> <p></p> <p></p> </li> <li> <p>Now you will see a lot of properties but the one you are searching for is located at the bottom and it will be revealed by clicking in \"Show Secret Value\".</p> <p></p> <p></p> </li> </ol> <p>You must connect through SSH to any of the Master Nodes. It is not an regular SSH process, because Master Nodes do not have a public IP address. The easiest way is by connecting through a Bastion resource:</p> <ol> <li>Go to the resource group where you deployed OpenVidu High Availability and click on one (any) of the Master Nodes Virtual Machines.</li> <li> <p>Inside the Virtual Machine resource, click on \"Connect\" \ud83e\udc52 \"Connect via Bastion\".     </p> <p></p> </li> <li> <p>Click on \"Deploy Bastion\" button.     </p> <p></p> </li> <li> <p>Change Authentication Type to \"SSH Private Key from Local File\", set the same username used when you deployed OpenVidu, and select the local file corresponding to the SSH Private Key of the SSH Key used when deploying.     </p> <p></p> </li> <li> <p>Click on connect and you will be inside the Virtual Machine of the Master Node. This process works the same way for any of the Master Nodes.</p> </li> </ol> <p>Once inside the Master Node, navigate to the config folder <code>/opt/openvidu/config/cluster</code>. Files with the access credentials outputs are:</p> <ul> <li><code>openvidu.env</code></li> <li><code>master_node/meet.env</code></li> </ul> <p>Warning</p> <p>We recommend to delete the Bastion resource once you no longer require SSH access to your Master Node, as it will incur in additional costs in your Azure account.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/install/#configure-your-application-to-use-the-deployment","title":"Configure your application to use the deployment","text":"<p>You need your Azure deployment outputs to configure your OpenVidu application. If you have permissions to access the Key Vault you will be able to check there all the outputs (Check deployment outputs in Azure Key Vault). If you don't have permissions to access the Key Vault you can still check the outputs directly in the instance through SSH (Check deployment outputs in the instance).</p> <p>Your authentication credentials and URL to point your applications would be:</p> <p>OpenVidu Meet:</p> <ul> <li><code>OPENVIDU-URL</code>: The URL to access OpenVidu Meet, which is always <code>https://yourdomain.example.io/</code></li> <li><code>MEET-INITIAL-ADMIN-USER</code>: User to access OpenVidu Meet Console. It is always <code>admin</code>.</li> <li><code>MEET-INITIAL-ADMIN-PASSWORD</code>: Password to access OpenVidu Meet Console.</li> <li><code>MEET-INITIAL-API-KEY</code>: API key to use OpenVidu Meet Embedded and OpenVidu Meet REST API.</li> </ul> <p>Note</p> <p>The <code>MEET-INITIAL-ADMIN-USER</code>, <code>MEET-INITIAL-ADMIN-PASSWORD</code>, and <code>MEET-INITIAL-API-KEY</code> values are initial settings that cannot be changed from Azure Key Vault. They can only be changed from the Meet Console.</p> <p>OpenVidu Platform:</p> <ul> <li><code>LIVEKIT-URL</code>: The URL to use LiveKit SDKs, which can be <code>wss://yourdomain.example.io/</code> or <code>https://yourdomain.example.io/</code> depending on the client library you are using.</li> <li><code>LIVEKIT-API-KEY</code>: API Key for LiveKit SDKs.</li> <li><code>LIVEKIT-API-SECRET</code>: API Secret for LiveKit SDKs.</li> </ul> <p>OpenVidu V2 Compatibility Credentials</p> <p>This section is only needed if you want to use OpenVidu v2 compatibility.</p> <ul> <li>URL: The URL to access OpenVidu, which is the value of <code>OPENVIDU-URL</code> (e.g., <code>https://yourdomain.example.io/</code>)</li> <li>Username: Basic auth user for OpenVidu v2 compatibility. It is always <code>OPENVIDUAPP</code>.</li> <li>Password: Basic auth password for OpenVidu v2 compatibility is the same as <code>LIVEKIT-API-SECRET</code>.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/install/#troubleshooting-initial-azure-stack-creation","title":"Troubleshooting initial Azure stack creation","text":"<p>Info</p> <p>If you need to connect through SSH to a Master Node check Check deployment outputs in the instance.</p> <p>If something goes wrong during the initial Azure stack creation, your stack may reach some failed status for multiple reasons. It could be due to a misconfiguration in the parameters, a lack of permissions, or a problem with Azure services. When this happens, the following steps can help you troubleshoot the issue and identify what went wrong:</p> <ol> <li>Check if the instance or instances are running. If they are not, check the Azure deployment events for any error messages.</li> <li> <p>If the instance or instances are running, SSH into the instance and check the logs of the following files:</p> <ul> <li><code>/var/log/cloud-init-output.log</code></li> <li><code>/var/log/cloud-init.log</code></li> </ul> <p>These logs will give you more information about the Azure stack creation process.</p> </li> <li> <p>If everything seems fine, check the status and the logs of the installed OpenVidu services.</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/install/#configuration-and-administration","title":"Configuration and administration","text":"<p>When your Azure stack reaches the <code>Succeeded</code> status, it means that all the resources have been created. You will need to wait about 5 to 10 minutes to let the instance install OpenVidu. When this time has elapsed, try connecting to the deployment URL. If it doesn't work, we recommend checking the previous section. Once finished you can check the Administration section to learn how to manage your deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/upgrade/","title":"Upgrade OpenVidu High Availability - Azure","text":"","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/upgrade/#upgrade-openvidu-high-availability-azure","title":"Upgrade OpenVidu High Availability - Azure","text":"<p>In Azure environments, we recommend upgrading by redeploying OpenVidu High Availability Azure stack using the latest version. This approach ensures that all components are updated accurately and consistently, as Azure templates and related configurations may vary between releases. Redeploying guarantees that all necessary changes are properly applied.</p> <p>However, if you prefer not to redeploy, it is also possible to upgrade OpenVidu High Availability in place. The following steps outline how to perform an in-place upgrade of your OpenVidu High Availability deployment on Azure:</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/upgrade/#upgrading-openvidu-high-availability-on-azure","title":"Upgrading OpenVidu High Availability on Azure","text":"<ol> <li>SSH into one of your Master Node server.</li> <li> <p>Execute the following command in the Master Node:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/update/latest/update.sh)\n</code></pre> <p>Info</p> <p>If instead of upgrading to the latest version you want to upgrade to a specific version, you can execute the following command:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/update/&lt;VERSION&gt;/update.sh)\n</code></pre> <p>Where <code>&lt;VERSION&gt;</code> is the version you want to upgrade to.</p> </li> <li> <p>This will execute an update script which will guide you from the version you have installed to the latest one. The first thing you will see in the output is the following:</p> <pre><code>Stopping OpenVidu service...\nBacking up files...\n\n    - Backing up file '/opt/openvidu/config' to '/opt/openvidu/backups/&lt;DATE&gt;_&lt;VERSION&gt;/config'\n    ... More files ...\n\n--------------------\n\ud83d\udce6 Backup directory: /opt/openvidu/backups/&lt;DATE&gt;_&lt;VERSION&gt;/\n--------------------\n\n--------------------\n\ud83d\ude80 Updating OpenVidu from 3.x.x to 3.y.y\n--------------------\n\n? Do you want to update from 3.x.x to 3.y.y? \u203a\n\u2022 Yes\n  No\n</code></pre> </li> <li> <p>Answer <code>Yes</code> to the question and your Master Node will be upgraded to the asked version. For each version, the system will ask you to confirm the upgrade.</p> </li> <li>A <code>diff</code> will be shown with the changes made in the configuration files. You can review the changes and decide if you want to apply them or not. If you want to apply the changes, answer <code>Yes</code> to the question. If you want to discard the changes and stop the upgrading process, simply answer <code>No</code>.</li> <li>Once the upgrade is finished, it will ask you to pull the images of the services. Answer <code>Yes</code> if you want to do it.</li> <li>Repeat the steps 1 to 6 in all the Master Nodes of your deployment. This is important because the Master Nodes need to be running the same version of OpenVidu.</li> <li>After upgrading all your Master Nodes, you need to terminate the Media Nodes to apply the changes to run the Media Nodes with the new version. Go to your Azure Instances Panel, select the Media Nodes instances, and terminate them. The Scale Set will automatically launch new Media Nodes with the updated configuration.</li> <li> <p>Once the Media Nodes are up and running, execute the following command in every Master Node to start OpenVidu High Availability again:</p> <pre><code>systemctl start openvidu &amp;&amp; journalctl -f -u openvidu\n</code></pre> <p>The <code>journalctl</code> command will show you the logs of the OpenVidu services. You can stop the logs by pressing <code>Ctrl + C</code>.</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/upgrade/#backups-and-rollback","title":"Backups and Rollback","text":"<p>When you finish the upgrade process, you will have a backup of the previous version in the <code>/opt/openvidu/backups</code> directory. The backup only contains the previous configuration files that have changed in the upgrade process. To roll back to the previous version, you have to copy the files from the backup to the OpenVidu directory on each Master Node. You can do it with the following command:</p> <pre><code>cp -r /opt/openvidu/backups/&lt;DATE&gt;_&lt;VERSION&gt;/* /opt/openvidu\n/usr/local/bin/store_secret.sh save OPENVIDU_VERSION \"&lt;VERSION&gt;\"\n</code></pre> <p>Where <code>&lt;DATE&gt;</code> and <code>&lt;VERSION&gt;</code> are the date and version of the backup you want to restore. For example:</p> <pre><code>cp -r /opt/openvidu/backups/2025-02-12-09-50-46_3.0.0/* /opt/openvidu\n/usr/local/bin/store_secret.sh save OPENVIDU_VERSION \"3.0.0\"\n</code></pre> <p>Notice the <code>store_secret.sh</code> command at the end. This command is necessary to update the <code>OPENVIDU_VERSION</code> secret in the Key Vault, which is used by the Azure deployment to know which version of OpenVidu should be running in Media Nodes. You need to do this in the Master Node only.</p> <p>Remember to terminate the Media Nodes after rolling back to the previous version so the Scale Set can launch new Media Nodes with the restored configuration. You can do this by going to your Azure Instances Panel, selecting the Media Nodes instances, and terminating them.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/azure/upgrade/#recommendations","title":"Recommendations","text":"<ul> <li>Always upgrade all the nodes of your OpenVidu High Availability deployment. Otherwise, you may face compatibility issues between the different versions of OpenVidu running in your deployment.</li> <li>On any upgrade problem, a redeployment is always recommended for a clean installation.</li> <li>Keep your Docker and Docker Compose versions updated.</li> <li> <p>Remove non-used images and containers to free up disk space. For example, after the upgrade, when OpenVidu is running, you can remove the old images with the following command:</p> <pre><code>docker image prune -a\n</code></pre> <p>This command will remove all the images that are not being used by any container.</p> </li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/admin/","title":"OpenVidu High Availability administration on-premises","text":"","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/admin/#openvidu-high-availability-administration-on-premises","title":"OpenVidu High Availability administration: On-premises","text":"<p>The OpenVidu installer offers an easy way to deploy OpenVidu High Availability on-premises. However, once the deployment is complete, you may need to perform administrative tasks based on your specific requirements, such as changing passwords, specifying custom configurations, and starting or stopping services.</p> <p>This section provides details on configuration parameters and common administrative tasks for on-premises OpenVidu High Availability deployments.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/admin/#starting-stopping-and-restarting-openvidu","title":"Starting, stopping, and restarting OpenVidu","text":"<p>To start, stop, or restart any Node in your OpenVidu High Availability deployment, you can use the following commands:</p> <p>Start OpenVidu</p> <pre><code>sudo systemctl start openvidu\n</code></pre> <p>Stop OpenVidu</p> <pre><code>sudo systemctl stop openvidu\n</code></pre> <p>Restart OpenVidu</p> <pre><code>sudo systemctl restart openvidu\n</code></pre>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/admin/#checking-the-status-of-services","title":"Checking the status of services","text":"<p>You can check the status of the OpenVidu services using the following command:</p> <pre><code>cd /opt/openvidu/\ndocker compose ps\n</code></pre> <p>Depending on the node type, you will see different services running.</p> Master NodeMedia Node <p>The services are operating correctly if you see an output similar to the following and there are no restarts from any of the services:</p> <pre><code>NAME                       IMAGE                                              COMMAND                  SERVICE                    CREATED          STATUS\nopenvidu-meet              docker.io/openvidu/openvidu-call                   \"docker-entrypoint.s\u2026\"   openvidu-meet              12 seconds ago   Up 10 seconds\ncaddy                      docker.io/openvidu/openvidu-pro-caddy              \"/bin/caddy run --co\u2026\"   caddy                      12 seconds ago   Up 10 seconds\ndashboard                  docker.io/openvidu/openvidu-pro-dashboard          \"./openvidu-dashboard\"   dashboard                  12 seconds ago   Up 10 seconds\ngrafana                    docker.io/grafana/grafana                          \"/run.sh\"                grafana                    11 seconds ago   Up 8 seconds\nloki                       docker.io/grafana/loki                             \"/usr/bin/loki -conf\u2026\"   loki                       11 seconds ago   Up 9 seconds\nmimir                      docker.io/grafana/mimir                            \"/bin/mimir -config.\u2026\"   mimir                      11 seconds ago   Up 9 seconds\nminio                      docker.io/bitnami/minio                            \"/opt/bitnami/script\u2026\"   minio                      11 seconds ago   Up 9 seconds\nmongo                      docker.io/mongo                                    \"docker-entrypoint.s\u2026\"   mongo                      11 seconds ago   Up 9 seconds\nopenvidu-v2compatibility   docker.io/openvidu/openvidu-v2compatibility        \"/bin/server\"            openvidu-v2compatibility   12 seconds ago   Up 10 seconds\noperator                   docker.io/openvidu/openvidu-operator               \"/bin/operator\"          operator                   12 seconds ago   Up 10 seconds\npromtail                   docker.io/grafana/promtail                         \"/usr/bin/promtail -\u2026\"   promtail                   11 seconds ago   Up 9 seconds\nredis-sentinel             docker.io/redis                                    \"docker-entrypoint.s\u2026\"   redis-sentinel             10 seconds ago   Up 10 seconds\nredis-server               docker.io/redis                                    \"docker-entrypoint.s\u2026\"   redis-server               10 seconds ago   Up 10 seconds\n</code></pre> <p>The services are operating correctly if you see an output similar to the following and there are no restarts from any of the services:</p> <pre><code>NAME         IMAGE                                          COMMAND                  SERVICE      CREATED          STATUS\ncaddy        docker.io/openvidu/openvidu-caddy:main         \"/bin/caddy run --co\u2026\"   caddy        53 seconds ago   Up 53 seconds\negress       docker.io/livekit/egress                       \"/entrypoint.sh\"         egress       53 seconds ago   Up 51 seconds\ningress      docker.io/livekit/ingress                      \"ingress\"                ingress      53 seconds ago   Up 52 seconds\nopenvidu     docker.io/openvidu/openvidu-server-pro         \"/livekit-server --c\u2026\"   openvidu     53 seconds ago   Up 52 seconds\nprometheus   docker.io/prom/prometheus                      \"/bin/prometheus --c\u2026\"   prometheus   53 seconds ago   Up 51 seconds\npromtail     docker.io/grafana/promtail                     \"/usr/bin/promtail -\u2026\"   promtail     53 seconds ago   Up 52 seconds\n</code></pre>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/admin/#checking-logs","title":"Checking logs","text":"<p>If any of the services are not working as expected, you can check the logs of the services using the following command:</p> <pre><code>cd /opt/openvidu/\ndocker compose logs &lt;service-name&gt;\n</code></pre> <p>Replace <code>&lt;service-name&gt;</code> with the name of the service you want to check. For example, to check the logs of the OpenVidu Server, use the following command:</p> <pre><code>cd /opt/openvidu/\ndocker compose logs openvidu\n</code></pre> <p>To check the logs of all services, use the following command:</p> <pre><code>cd /opt/openvidu/\ndocker compose logs\n</code></pre> <p>Or use journalctl:</p> <pre><code>journalctl -f -u openvidu\n</code></pre> <p>You can also review your logs using the Grafana dashboard provided with OpenVidu. To access it, go to https://&lt;your-domain.com&gt;/grafana and use the credentials located in <code>/opt/openvidu/.env</code> to log in. Once inside, navigate to the \"Home\" section, select \"Dashboard\", and then click on:</p> <ul> <li>\"OpenVidu &gt; OpenVidu Cluster Nodes Logs\": To check the logs of the OpenVidu services organized per node.</li> <li>\"OpenVidu &gt; OpenVidu Cluster Services Logs\": To check the logs of the OpenVidu services organized per service.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/admin/#adding-media-nodes","title":"Adding Media Nodes","text":"<p>To add a new Media Node, simply spin up a new VM and run the OpenVidu installer script to integrate it into the existing cluster. Run the installation command on the new Media Node.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/admin/#removing-media-nodes-gracefully","title":"Removing Media Nodes Gracefully","text":"<p>To stop a Media Node gracefully, you need to stop the containers <code>openvidu</code>, <code>ingress</code>, and <code>egress</code> with a <code>SIGQUIT</code> signal. Here is a simple script that you can use to stop all these containers gracefully:</p> <pre><code>#!/bin/bash\n# Stop OpenVidu, Ingress, and Egress containers gracefully (1)\ndocker container kill --signal=SIGQUIT openvidu || true\ndocker container kill --signal=SIGQUIT ingress || true\ndocker container kill --signal=SIGQUIT egress || true\nfor agent_container in $(docker ps --filter \"label=openvidu-agent=true\" --format '{{.Names}}'); do\n    docker container kill --signal=SIGQUIT \"$agent_container\"\ndone\n\n# Wait for the containers to stop (2)\nwhile [ $(docker ps --filter \"label=openvidu-agent=true\" -q | wc -l) -gt 0 ] || \\\n    [ $(docker inspect -f '{{.State.Running}}' openvidu 2&gt;/dev/null) == \"true\" ] || \\\n    [ $(docker inspect -f '{{.State.Running}}' ingress 2&gt;/dev/null) == \"true\" ] || \\\n    [ $(docker inspect -f '{{.State.Running}}' egress 2&gt;/dev/null) == \"true\" ]; do\n    echo \"Waiting for containers to stop...\"\n    sleep 5\ndone\n</code></pre> <ol> <li>This script stops the OpenVidu, Ingress, Egress and AI Agents containers gracefully. The <code>true</code> at the end of each command is to avoid the script from stopping if the container is not running.</li> <li>This script waits for the containers to stop before exiting.</li> </ol> <p>When all the containers are stopped, you can then stop the systemd service and remove the VM:</p> <pre><code>sudo systemctl stop openvidu\n</code></pre>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/admin/#removing-media-nodes-forcefully","title":"Removing Media Nodes Forcefully","text":"<p>To remove a Media Node forcefully, without considering the rooms, ingress, egress and agents hosted by the node, you can simply stop the OpenVidu service in the Media Node and delete the VM.</p> <pre><code>sudo systemctl stop openvidu\n</code></pre>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/admin/#changing-the-configuration","title":"Changing the configuration","text":"<p>You can check how to change the configuration in the Changing Configuration section. Also, there are multiple guides in the How to Guides section that can help you with specific configuration changes.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/admin/#uninstalling-openvidu","title":"Uninstalling OpenVidu","text":"<p>To uninstall any OpenVidu Node, just execute the following commands:</p> <pre><code>sudo su\nsystemctl stop openvidu\nrm -rf /opt/openvidu/\nrm /etc/systemd/system/openvidu.service\nrm /etc/sysctl.d/50-openvidu.conf\n</code></pre>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/install-dlb/","title":"OpenVidu Elastic installation on-premises with DNS Load Balancing","text":"","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/install-dlb/#openvidu-high-availability-installation-on-premises-with-dns-load-balancing","title":"OpenVidu High Availability installation: On-premises with DNS Load Balancing","text":"<p>Info</p> <p>OpenVidu High Availability is part of OpenVidu PRO. Before deploying, you need to create an OpenVidu account to get your license key. There's a 15-day free trial waiting for you!</p> <p>This section provides instructions for deploying a production-ready OpenVidu High Availability setup on-premises, utilizing DNS for load balancing traffic. DNS allows multiple records, even of the same kind, to be registered, enabling the listing of multiple hosts under the same domain name. Such a mechanism allows for the distribution of traffic among the Master Nodes, offering an alternative to Network Load Balancers.</p> <p>Advantages of DNS Load Balancing:</p> <ul> <li>Simplicity: Easier to configure compared to Network Load Balancing.</li> <li>Cost: More cost-effective than Network Load Balancing.</li> </ul> <p>Disadvantages of DNS Load Balancing:</p> <ul> <li>Health Checks: Less reliable for health checks compared to Network Load Balancing.</li> <li>Caching Issues: IP addresses of the Master Nodes can be cached, causing issues if the server's IP changes.</li> <li>DNS Round Robin: Some clients may not adhere to DNS Round Robin, potentially leading to uneven traffic distribution.</li> </ul> Architecture overview <p>This is how the architecture of the deployment looks like:</p> <p></p> OpenVidu High Availability Architecture with DNS Load Balancing <p></p> <ul> <li>The Master Nodes act as Load Balancers, managing the traffic and distributing it among the other Master Nodes and Media Nodes.</li> <li>Each Master Node has its own Caddy server acting as a Layer 4 (for TURN with TLS and RTMPS) and Layer 7 (for OpenVidu Dashboard, OpenVidu Meet, etc., APIs) reverse proxy.</li> <li>WebRTC traffic (SRTP/SCTP/STUN/TURN) is routed directly to the Media Nodes.</li> </ul> <p>For the Master Node, the following services are configured:</p> <ul> <li>OpenVidu Dashboard, a web application interface to visualize your Rooms, Ingress, and Egress services.</li> <li>MinIO as an S3 storage service for recordings.</li> <li>Redis as a shared database for OpenVidu Server PRO and Ingress/Egress services.</li> <li>MongoDB as a database for storing analytics and monitoring data.</li> <li>Caddy as an internal reverse proxy for all services.</li> <li>OpenVidu V2 Compatibility (v2compatibility module) is an optional service that provides an API designed to maintain compatibility for applications developed with OpenVidu version 2.</li> <li>OpenVidu Meet, an optional high-quality video calling service.</li> <li>Grafana, Mimir, Promtail, and Loki (Observability module) form an optional observability stack for monitoring, allowing you to keep track of logs and deployment statistics for OpenVidu.</li> </ul> <p>For the Media Nodes, the following services are configured:</p> <ul> <li>OpenVidu Server PRO (LiveKit compatible).</li> <li>Ingress and Egress services.</li> <li>Prometheus, Promtail, and Loki (Observability module). Used to send metrics and logs to the observability stack.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/install-dlb/#prerequisites","title":"Prerequisites","text":"<ul> <li>At least 6 machines:<ul> <li>4 machines for the Master Nodes.</li> <li>2 machines for the Media Nodes.</li> </ul> </li> <li>Each machine must have:<ul> <li>A minimum of 4GB RAM and 4 CPU cores.</li> <li>Linux installed (Ubuntu is recommended).</li> </ul> </li> <li>All machines must have their own public IP.</li> <li>Significant disk space in all the Master Nodes, with 100GB recommended, especially if you plan to record your sessions (Egress). Media Nodes require less space; however, account for the space needed for ongoing recordings on these nodes.</li> <li>A Fully Qualified Domain Name (FQDN) pointing to all the public IPs of the Master Nodes. Simply create 4 A records in your DNS provider pointing to the public IPs of the Master Nodes using the same domain name.</li> <li> <p>All machines must have access to the following addresses and ports:</p> Host Port <code>accounts.openvidu.io</code> <code>443</code> <code>global.stun.twilio.com</code> <code>3478</code> <code>stun.l.google.com</code> <code>19302</code> <code>stun1.l.google.com</code> <code>19302</code> <p>Info</p> <p>If you are behind a very restrictive corporate firewall that doesn't allow outgoing traffic to those addresses, please contact us through commercial@openvidu.io.</p> </li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/install-dlb/#port-rules-master-nodes","title":"Port rules (Master Nodes)","text":"<p>Ensure all these rules are configured in your firewall, security group, or any kind of network configuration that you have in your Master Nodes:</p> <p>Inbound port rules:</p> Protocol Ports Source Description TCP 80 0.0.0.0/0, ::/0 Redirect HTTP to HTTPS and Let's Encrypt validation. TCP 443 0.0.0.0/0, ::/0 Allows access to the following: <ul><li>Livekit API.</li><li>OpenVidu v2 Compatibility API</li><li>OpenVidu Dashboard.</li><li>OpenVidu Meet.</li><li>WHIP API.</li><li>TURN with TLS.</li><li>Custom layouts</li></ul> TCP 1935 0.0.0.0/0, ::/0 Needed if you want to ingest RTMP streams using Ingress service. TCP 9000 0.0.0.0/0, ::/0 Needed if you want to expose MinIO publicly. TCP 3000 Master Nodes Needed when 'Observability' module is used (<code>observability</code> in <code>ENABLED_MODULES</code> global parameter). It is used to load balance requests to Grafana. TCP 5000 Master Nodes Needed when 'Observability' module is used (<code>observability</code> in <code>ENABLED_MODULES</code> global parameter). It is used to load balance requests to OpenVidu Dashboard. TCP 9101 Master Nodes Needed to load balance requests to MinIO Console. TCP 7946-7947 Master Nodes Needed when 'Observability' module is used (<code>observability</code> in <code>ENABLED_MODULES</code> global parameter). Master nodes need access to this port for cluster communication. TCP 9095-9096 Master Nodes Needed when 'Observability' module is used (<code>observability</code> in <code>ENABLED_MODULES</code> global parameter). It is used for Mimir and Loki cluster communication. TCP 3100 Media Nodes Needed when 'Observability' module is used (<code>observability</code> in <code>ENABLED_MODULES</code> global parameter). It is used by Loki service. TCP 9009 Media Nodes Needed when 'Observability' module is used (<code>observability</code> in <code>ENABLED_MODULES</code> global parameter). It is used by Mimir service. TCP 4443 Master Nodes, Media Nodes Needed when 'OpenVidu v2 Compatibility' module is used (<code>v2compatibility</code> in <code>ENABLED_MODULES</code> global parameter). It is used by OpenVidu V2 compatibility service. TCP 6080 Master Nodes, Media Nodes Needed when 'OpenVidu Meet' module is used (<code>openviduMeet</code> in <code>ENABLED_MODULES</code> global parameter). It is used by OpenVidu Meet. TCP 7000-7001 Master Nodes, Media Nodes For internal Redis communication TCP 9100 Master Nodes, Media Nodes For internal MinIO communication TCP 20000 Master Nodes, Media Nodes For internal Mongo communication <p>Outbound port rules:</p> <p>Typically, all outbound traffic is allowed.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/install-dlb/#port-rules-media-nodes","title":"Port rules (Media Nodes)","text":"<p>Ensure all these rules are configured in your firewall, security group, or any kind of network configuration that you have in your Media Nodes:</p> <p>Inbound port rules:</p> Protocol Ports Source Description UDP 443 0.0.0.0/0, ::/0 STUN/TURN over UDP. TCP 7881 0.0.0.0/0, ::/0 Needed for WebRTC media traffic over TCP with Pion. UDP 7885 0.0.0.0/0, ::/0 Needed if you want to ingest WebRTC using WHIP. UDP 50000-60000 0.0.0.0/0, ::/0 Needed for WebRTC media traffic over UDP. TCP 50000-60000 0.0.0.0/0, ::/0 Needed for WebRTC media traffic over TCP with Mediasoup. TCP 1935 Master Nodes Needed if you want to ingest RTMP streams using Ingress service. Master Nodes need access to this port to reach Ingress RTMP service and expose it using TLS (RTMPS). TCP 5349 Master Nodes Needed if you have configured TURN with a domain for TLS. Master Node needs access to this port to reach TURN service and expose it using TLS. (TURNS) TCP 7880 Master Nodes LiveKit API. Master Nodes need access to load balance LiveKit API and expose it through HTTPS. TCP 8080 Master Nodes Needed if you want to ingest WebRTC streams using WHIP. Master Nodes need access to this port to reach WHIP HTTP service. <p>Outbound port rules:</p> <p>Typically, all outbound traffic is allowed.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/install-dlb/#guided-installation","title":"Guided installation","text":"<p>Before the installation, ensure that all your machines meet the prerequisites and the port rules for the Master Nodes and Media Nodes are correctly configured.</p> <p>To install OpenVidu High Availability, begin by generating the commands required for setting up all nodes in the cluster. This is a simple and straightforward process; simply run the following command on any machine that has Docker installed:</p> <pre><code>docker run --pull always --rm -it \\\n    openvidu/openvidu-installer:latest \\\n    --deployment-type=ha\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <p>A wizard will guide you through the installation process. You will be asked for the following information:</p> <ul> <li>Write all 'Master Node' Private IPs separated by commas: Write the private IP of each Master Node separated by commas.</li> <li>Write your OpenVidu PRO License: Write your OpenVidu PRO License.</li> </ul> <p>Info</p> <p>If you don't have a license key for OpenVidu PRO, you can get a 15-day free trial license key by creating an OpenVidu account.</p> <ul> <li>Do you want to use an external load balancer?: Select No. It means that you are going to use DNS Load Balancing.</li> <li> <p>Select which certificate type to use:</p> <ul> <li>Self Signed Certificate: It will generate a self-signed certificate. It is not recommended for production environments, but it is useful for testing or development purposes.</li> <li>Let's Encrypt: It will automatically generate a certificate for your domain. The Let's Encrypt email is required and will be asked for later in the wizard.</li> <li>ZeroSSL: It will automatically generate a certificate for your domain using ZeroSSL. An API Key is required and will be asked for later in the wizard.</li> <li>Own Certificate: It will ask you for the certificate and key files. Just copy and paste the content of the files when the wizard asks for them.</li> </ul> <p>Note</p> <p>If you want to manage the certificate in your proxy own proxy server instead of relaying in the Caddy server deployed with OpenVidu, take a look to this How-to guide: How to deploy OpenVidu with an external proxy.</p> </li> <li> <p>Domain name: The domain name for your deployment. It must be an FQDN pointing to the machine where you are deploying OpenVidu.</p> </li> <li>(Optional) Turn domain name: The domain name for your TURN server with TLS. It must be an FQDN pointing to the machine where you are deploying OpenVidu and must be different from the OpenVidu domain name. Recommended if users who are going to connect to your OpenVidu deployment are behind restrictive firewalls.</li> <li>Select which RTC engine to use: Select the WebRTC engine you want to use. You can choose between Pion (the default engine used by LiveKit) or Mediasoup (with a boost in performance). Learn more about the differences here.</li> <li>Modules to enable: Select the modules you want to enable. You can enable the following modules:<ul> <li>OpenVidu Meet: A high-quality video calling service based on OpenVidu.</li> <li>Observability: Grafana stack, which includes logs and monitoring stats.</li> <li>OpenVidu V2 Compatibility: Compatibility API for applications developed with OpenVidu v2.</li> </ul> </li> </ul> <p>The rest of the parameters are secrets, usernames, and passwords. If empty, the wizard will generate random values for them.</p> <p>This command will output the following instructions, which you should follow:</p> <ol> <li>Firewall Configuration for 'Master Nodes': These rules are the same as the ones specified in the instructions. Depending on the modules you have selected, some rules defined at Port rules (Master Nodes) may not appear (Optional ports). Double-check them and modify them if you see something that can be enabled/disabled in your current port rules.</li> <li> <p>Installation Commands for 'Master Nodes': This is the command needed to install your Master Node. It should look like this:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/pro/ha/latest/install_ov_master_node.sh) \\\n    --no-tty --install \\\n    --deployment-type='ha' \\\n    --node-role='master-node' \\\n...\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <p>Execute that command on all your Master Nodes to install them. When the installation process finishes, you will see the following output:</p> <pre><code>&gt; - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - &lt;\n&gt;                                                                             &lt;\n&gt;  \ud83c\udf89\ud83c\udf89 OpenVidu HA 'Master Node' Installation Finished Successfully! \ud83c\udf89\ud83c\udf89    &lt;\n&gt;                                                                             &lt;\n&gt; - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - &lt;\n</code></pre> <p>The Master Node will be installed in <code>/opt/openvidu</code> and configured as a systemd service. To start the service, use the following command:</p> <pre><code>systemctl start openvidu\n</code></pre> <p>Your Master Nodes will be ready once all of them have been started.</p> </li> <li> <p>Firewall Configuration for 'Media Nodes': These rules are the same as the ones defined previously as with Master Nodes. Double-check the Port rules (Media Nodes) and modify them if you see something that can be enabled/disabled in your current port rules.</p> </li> <li> <p>Installation Commands for 'Media Nodes': This is the command needed to install your Media Nodes. It should look like this:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/pro/ha/latest/install_ov_media_node.sh) \\\n    --no-tty --install \\\n    --deployment-type='ha' \\\n    --node-role='media-node' \\\n...\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <p>Execute that command on your Media Nodes to install them. When the installation process finishes, you will see the following output:</p> <pre><code>&gt; - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - &lt;\n&gt;                                                                             &lt;\n&gt;  \ud83c\udf89 OpenVidu HA 'Media Node' Installation Finished Successfully! \ud83c\udf89         &lt;\n&gt;                                                                             &lt;\n&gt; - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - &lt;\n</code></pre> <p>The Media Node on each machine will be installed at <code>/opt/openvidu</code> and configured as a systemd service. You can start the service with the following command:</p> <pre><code>systemctl start openvidu\n</code></pre> </li> </ol> <p>If everything goes well, all containers will be up and running without restarts, and you will be able to access any of the following services:</p> <ul> <li>OpenVidu Meet: https://openvidu.example.io/</li> <li>OpenVidu Dashboard: https://openvidu.example.io/dashboard</li> <li>MinIO: https://openvidu.example.io/minio-console</li> <li>Grafana: https://openvidu.example.io/grafana</li> </ul> <p>OpenVidu Server PRO URL (LiveKit compatible) will be available also in:</p> <ul> <li>OpenVidu Server PRO: https://openvidu.example.io/</li> <li>LiveKit API: https://openvidu.example.io/ and wss://openvidu.example.io/</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/install-dlb/#configure-your-application-to-use-the-deployment","title":"Configure your application to use the deployment","text":"<p>To point your applications to your OpenVidu deployment, check the following files:</p> <ul> <li><code>/opt/openvidu/config/cluster/master_node/meet.env</code>: Contains the OpenVidu Meet parameters.</li> <li><code>/opt/openvidu/config/cluster/openvidu.env</code>: Contains all the credentials of services deployed with OpenVidu Platform.</li> </ul> <p>The most relevant parameters are:</p> <p>OpenVidu Meet:</p> <ul> <li><code>MEET_INITIAL_ADMIN_USER</code>: User to access OpenVidu Meet Console. It is always <code>admin</code>.</li> <li><code>MEET_INITIAL_ADMIN_PASSWORD</code>: Password to access OpenVidu Meet Console.</li> <li><code>MEET_INITIAL_API_KEY</code>: API key to use OpenVidu Meet Embedded and OpenVidu Meet REST API.</li> </ul> <p>Note</p> <p>The <code>MEET_INITIAL_ADMIN_USER</code>, <code>MEET_INITIAL_ADMIN_PASSWORD</code>, and <code>MEET_INITIAL_API_KEY</code> values are initial and cannot be changed from the <code>meet.env</code> file. They can only be changed from the Meet Console.</p> <p>OpenVidu Platform:</p> <ul> <li><code>LIVEKIT_URL</code>: The URL to use LiveKit SDKs, which can be <code>wss://yourdomain.example.io/</code> or <code>https://yourdomain.example.io/</code> depending on the client library you are using.</li> <li><code>LIVEKIT_API_KEY</code>: API Key for LiveKit SDKs.</li> <li><code>LIVEKIT_API_SECRET</code>: API Secret for LiveKit SDKs.</li> </ul> <p>OpenVidu V2 Compatibility Credentials</p> <p>This section is only needed if you want to use OpenVidu v2 compatibility.</p> <ul> <li>URL: The URL to access OpenVidu, which is formed by the <code>DOMAIN_NAME</code> as <code>https://yourdomain.example.io/</code></li> <li>Username: Basic auth user for OpenVidu v2 compatibility. It is always <code>OPENVIDUAPP</code>.</li> <li>Password: Basic auth password for OpenVidu v2 compatibility is the same as <code>LIVEKIT_API_SECRET</code>.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/install-dlb/#non-interactive-installation","title":"Non-interactive installation","text":"<p>To automate the installation process, you just need to execute the specified command in the Guided installation section and execute the generated commands.</p> <p>Each installation command for each type of node looks like this:</p> Master NodeMedia Node <p>The Master Node can be configured with multiple kinds of certificates. Here are the examples for each type of certificate:</p> Let's Encrypt certificatesSelf-signed certificatesCustom certificates <p>Example using Let's Encrypt certificates:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/pro/ha/latest/install_ov_master_node.sh) \\\n    --no-tty --install \\\n    --node-role='master-node' \\\n    --master-node-private-ip-list='10.5.0.1,10.5.0.2,10.5.0.3,10.5.0.4' \\\n    --openvidu-pro-license='xxxxx' \\\n    --domain-name='openvidu.example.io' \\\n    --enabled-modules='observability,v2compatibility,openviduMeet' \\\n    --rtc-engine='pion' \\\n    --turn-domain-name='turn.example.io' \\\n    --livekit-api-key='xxxxx' \\\n    --livekit-api-secret='xxxxx' \\\n    --dashboard-admin-user='xxxxx' \\\n    --dashboard-admin-password='xxxxx' \\\n    --redis-password='xxxxx' \\\n    --minio-access-key='xxxxx' \\\n    --minio-secret-key='xxxxx' \\\n    --mongo-admin-user='xxxxx' \\\n    --mongo-admin-password='xxxxx' \\\n    --mongo-replica-set-key='xxxxx' \\\n    --grafana-admin-user='xxxxx' \\\n    --grafana-admin-password='xxxxx' \\\n    --meet-initial-admin-password='xxxxx' \\\n    --meet-initial-api-key='xxxxx' \\\n    --certificate-type='letsencrypt'\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <p>Notes:</p> <ul> <li><code>--openvidu-pro-license</code> is mandatory. You can get a 15-day free trial license key by creating an OpenVidu account.</li> <li>Depending on the RTC engine, the argument <code>--rtc-engine</code> can be <code>pion</code> or <code>mediasoup</code>.</li> <li><code>--master-node-private-ip-list</code> is the list of private IPs of all Master Nodes separated by commas. It should not change and Media Nodes should be able to reach all Master Nodes using these IPs.</li> </ul> <p>Example using self-signed certificates:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/pro/ha/latest/install_ov_master_node.sh) \\\n    --no-tty --install \\\n    --node-role='master-node' \\\n    --master-node-private-ip-list='10.5.0.1,10.5.0.2,10.5.0.3,10.5.0.4' \\\n    --openvidu-pro-license='xxxxx' \\\n    --domain-name='openvidu.example.io' \\\n    --enabled-modules='observability,v2compatibility,openviduMeet' \\\n    --rtc-engine='pion' \\\n    --turn-domain-name='turn.example.io' \\\n    --livekit-api-key='xxxxx' \\\n    --livekit-api-secret='xxxxx' \\\n    --dashboard-admin-user='xxxxx' \\\n    --dashboard-admin-password='xxxxx' \\\n    --redis-password='xxxxx' \\\n    --minio-access-key='xxxxx' \\\n    --minio-secret-key='xxxxx' \\\n    --mongo-admin-user='xxxxx' \\\n    --mongo-admin-password='xxxxx' \\\n    --mongo-replica-set-key='xxxxx' \\\n    --grafana-admin-user='xxxxx' \\\n    --grafana-admin-password='xxxxx' \\\n    --meet-initial-admin-password='xxxxx' \\\n    --meet-initial-api-key='xxxxx' \\\n    --certificate-type='selfsigned'\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <ul> <li><code>--openvidu-pro-license</code> is mandatory. You can get a 15-day free trial license key by creating an OpenVidu account.</li> <li>Depending on the RTC engine, the argument <code>--rtc-engine</code> can be <code>pion</code> or <code>mediasoup</code>.</li> <li><code>--master-node-private-ip-list</code> is the list of private IPs of all Master Nodes separated by commas. It should not change and Media Nodes should be able to reach all Master Nodes using these IPs.</li> </ul> <p>Example using custom certificates:</p> <pre><code>CERT_PRIVATE_KEY=$(cat privkey.pem | base64 -w 0)\nCERT_PUBLIC_KEY=$(cat fullchain.pem | base64 -w 0)\n\n# Optional, only if you want to enable TURN with TLS\nCERT_TURN_PRIVATE_KEY=$(cat turn-privkey.pem | base64 -w 0)\nCERT_TURN_PUBLIC_KEY=$(cat turn-fullchain.pem | base64 -w 0)\n\nsh &lt;(curl -fsSL http://get.openvidu.io/pro/ha/latest/install_ov_master_node.sh) \\\n    --no-tty --install \\\n    --node-role='master-node' \\\n    --master-node-private-ip-list='10.5.0.1,10.5.0.2,10.5.0.3,10.5.0.4' \\\n    --openvidu-pro-license='xxxxx' \\\n    --domain-name='openvidu.example.io' \\\n    --enabled-modules='observability,v2compatibility,openviduMeet' \\\n    --rtc-engine='pion' \\\n    --turn-domain-name='turn.example.io' \\\n    --livekit-api-key='xxxxx' \\\n    --livekit-api-secret='xxxxx' \\\n    --dashboard-admin-user='xxxxx' \\\n    --dashboard-admin-password='xxxxx' \\\n    --redis-password='xxxxx' \\\n    --minio-access-key='xxxxx' \\\n    --minio-secret-key='xxxxx' \\\n    --mongo-admin-user='xxxxx' \\\n    --mongo-admin-password='xxxxx' \\\n    --mongo-replica-set-key='xxxxx' \\\n    --grafana-admin-user='xxxxx' \\\n    --grafana-admin-password='xxxxx' \\\n    --meet-initial-admin-password='xxxxx' \\\n    --meet-initial-api-key='xxxxx' \\\n    --certificate-type='owncert' \\\n    --owncert-private-key=\"$CERT_PRIVATE_KEY\" \\\n    --owncert-public-key=\"$CERT_PUBLIC_KEY\" \\\n    --turn-owncert-private-key=\"$CERT_TURN_PRIVATE_KEY\" \\\n    --turn-owncert-public-key=\"$CERT_TURN_PUBLIC_KEY\"\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <ul> <li>Note that you just need to pass <code>--owncert-private-key</code> and <code>--owncert-public-key</code> with the content of the private and public key files in base64 format. The installation script will decode them and save them in the proper files.</li> <li><code>--openvidu-pro-license</code> is mandatory. You can get a 15-day free trial license key by creating an OpenVidu account.</li> <li>Depending on the RTC engine, the argument <code>--rtc-engine</code> can be <code>pion</code> or <code>mediasoup</code>.</li> <li><code>--master-node-private-ip-list</code> is the list of private IPs of all Master Nodes separated by commas. It should not change and Media Nodes should be able to reach all Master Nodes using these IPs.</li> <li><code>--turn-owncert-private-key</code> and <code>--turn-owncert-public-key</code> are optional. You only need to pass them if you want to enable TURN with TLS.</li> </ul> <p>To install a Media Node, you can use the following command:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/pro/ha/latest/install_ov_media_node.sh) \\\n    --no-tty --install \\\n    --node-role='media-node' \\\n    --master-node-private-ip-list='10.5.0.1,10.5.0.2,10.5.0.3,10.5.0.4' \\\n    --redis-password='xxxxx'\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <ul> <li><code>--master-node-private-ip</code> must be the same list of private IPs of all Master Nodes separated by commas. It should not change and Media Nodes should be able to reach all Master Nodes using these IPs.</li> <li><code>--redis-password</code> must be the same password as the one used in the Master Nodes. It is used to connect to the Redis service in the Master Nodes and register itself as a Media Node in the cluster.</li> <li>If no media appears in your conference, reinstall specifying the <code>--public-ip</code> parameter with your machine's public IP. OpenVidu usually auto-detects the public IP, but it can fail. This IP is used by clients to send and receive media. If you decide to install the Media Node with <code>--public-ip</code>, you must reinstall the Master Node with <code>--force-media-node-public-ip</code>.</li> </ul> <p>You can run these commands in a CI/CD pipeline or in a script to automate the installation process.</p> <p>Some general notes about all the Master Node commands:</p> <ul> <li>The argument <code>--turn-domain-name</code> is optional. Define it only if you want to enable TURN with TLS in case users are behind restrictive firewalls.</li> <li>In the argument <code>--enabled-modules</code>, you can enable the modules you want to deploy. You can enable <code>observability</code> (Grafana stack), <code>openviduMeet</code> (OpenVidu Meet), and <code>v2compatibility</code> (OpenVidu v2 compatibility API).</li> </ul> <p>To start each node, remember to execute the following command in each node:</p> <pre><code>systemctl start openvidu\n</code></pre>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/install-dlb/#configuration-and-administration","title":"Configuration and administration","text":"<p>Once you have OpenVidu deployed, you can check the Administration section to learn how to manage your OpenVidu High Availability deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/install-nlb/","title":"OpenVidu Elastic installation on-premises with Network Load Balancer","text":"","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/install-nlb/#openvidu-high-availability-installation-on-premises-with-network-load-balancer","title":"OpenVidu High Availability installation: On-premises with Network Load Balancer","text":"<p>Info</p> <p>OpenVidu High Availability is part of OpenVidu PRO. Before deploying, you need to create an OpenVidu account to get your license key. There's a 15-day free trial waiting for you!</p> <p>This section provides instructions for deploying a production-ready OpenVidu High Availability setup on-premises, utilizing a Network Load Balancer in front of the cluster. Network Load Balancing is a method of distributing incoming network traffic across multiple servers. It is a highly available, scalable, and fault-tolerant solution that ensures your OpenVidu deployment is always up and running. Compared to DNS Load Balancing, Network Load Balancing is more reliable for health checks and ensures that traffic is evenly distributed across all nodes.</p> <p>Advantages of Network Load Balancing:</p> <ul> <li>More control over the load balancing process.</li> <li>Possibility to use custom health checks to determine the status of the nodes.</li> </ul> <p>Disadvantages of Network Load Balancing:</p> <ul> <li>More complex to set up than DNS Load Balancing.</li> <li>Requires a Load Balancer to be deployed in front of the cluster.</li> <li>More expensive than DNS Load Balancing.</li> </ul> Architecture overview <p>This is how the architecture of the deployment looks:</p> <p></p> OpenVidu High Availability Architecture with Network Load Balancer <p></p> <ul> <li>The Load Balancer must be a Network Load Balancer that supports TCP and UDP traffic.</li> <li>The Load Balancer distributes traffic across all Master Nodes.</li> <li>If RTMP or TURN with TLS is enabled, the Load Balancer must also distribute traffic across all Media Nodes. (You can use a different Load Balancer for this purpose)</li> <li>WebRTC traffic (SRTP/SCTP/STUN/TURN) is routed directly to the Media Nodes.</li> </ul> <p>For the Master Node, the following services are configured:</p> <ul> <li>OpenVidu Dashboard, a web application interface to visualize your Rooms, Ingress, and Egress services.</li> <li>MinIO as an S3 storage service for recordings.</li> <li>Redis as a shared database for OpenVidu Server PRO and Ingress/Egress services.</li> <li>MongoDB as a database for storing analytics and monitoring data.</li> <li>Caddy as an internal reverse proxy for all services.</li> <li>OpenVidu V2 Compatibility (v2compatibility module) is an optional service that provides an API designed to maintain compatibility for applications developed with OpenVidu version 2.</li> <li>OpenVidu Meet, an optional high-quality video calling service.</li> <li>Grafana, Mimir, Promtail, and Loki (Observability module) form an optional observability stack for monitoring, allowing you to keep track of logs and deployment statistics for OpenVidu.</li> </ul> <p>For the Media Nodes, the following services are configured:</p> <ul> <li>OpenVidu Server PRO (LiveKit compatible).</li> <li>Ingress and Egress services.</li> <li>Prometheus, Promtail, and Loki (Observability module). Used to send metrics and logs to the observability stack.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/install-nlb/#prerequisites","title":"Prerequisites","text":"<ul> <li>At least 6 machines:<ul> <li>4 machines for the Master Nodes.</li> <li>2 machines for the Media Nodes.</li> </ul> </li> <li>Each machine must have:<ul> <li>A minimum of 4GB RAM and 4 CPU cores.</li> <li>Linux installed (Ubuntu is recommended).</li> </ul> </li> <li>Significant disk space in all the Master Nodes, with 100GB recommended, especially if you plan to record your sessions (Egress). Media Nodes require less space; however, account for the space needed for ongoing recordings on these nodes.</li> <li>Media Nodes must have a public IP. This is required because Media traffic is sent directly to these nodes. Master Nodes can have private IPs and will be accessed through the Load Balancer.</li> <li>A Load Balancer that supports TCP and UDP traffic. You can use a hardware load balancer or a software load balancer like HAProxy, Nginx, or AWS Network Load Balancer.</li> <li>A Fully Qualified Domain Name (FQDN) pointing to the Load Balancer. This domain name will be used to access the OpenVidu services.</li> <li> <p>All machines must have access to the following addresses and ports:</p> Host Port <code>accounts.openvidu.io</code> <code>443</code> <code>global.stun.twilio.com</code> <code>3478</code> <code>stun.l.google.com</code> <code>19302</code> <code>stun1.l.google.com</code> <code>19302</code> <p>Info</p> <p>If you are behind a very restrictive corporate firewall that doesn't allow outgoing traffic to those addresses, please contact us through commercial@openvidu.io.</p> </li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/install-nlb/#port-rules-master-nodes","title":"Port rules (Master Nodes)","text":"<p>Ensure all these rules are configured in your firewall, security group, or any kind of network configuration that you have in your Master Nodes:</p> <p>Inbound port rules:</p> Protocol Ports Source Description TCP 1945 Load Balancer Needed for RTMP Ingress service. Master Nodes need access to this port to reach Ingress RTMP service and expose it using TLS (RTMPS). TCP 5349 Load Balancer Needed for TURN with TLS. Master Nodes need access to this port to reach TURN service and expose it using TLS (TURNS). TCP 7880 Load Balancer Allows access to the following to the Load Balancer: <ul><li>Livekit API.</li><li>OpenVidu v2 Compatibility API</li><li>OpenVidu Dashboard.</li><li>OpenVidu Meet.</li><li>WHIP API.</li><li>Custom layouts</li></ul> TCP 3000 Master Nodes Needed when 'Observability' module is used (<code>observability</code> in <code>ENABLED_MODULES</code> global parameter). It is used to load balance requests to Grafana. TCP 5000 Master Nodes Needed when 'Observability' module is used (<code>observability</code> in <code>ENABLED_MODULES</code> global parameter). It is used to load balance requests to OpenVidu Dashboard. TCP 9101 Master Nodes Needed to load balance requests to MinIO Console. TCP 7946-7947 Master Nodes Needed when 'Observability' module is used (<code>observability</code> in <code>ENABLED_MODULES</code> global parameter). Master nodes need access to this port for cluster communication. TCP 9095-9096 Master Nodes Needed when 'Observability' module is used (<code>observability</code> in <code>ENABLED_MODULES</code> global parameter). It is used for Mimir and Loki cluster communication. TCP 3100 Media Nodes Needed when 'Observability' module is used (<code>observability</code> in <code>ENABLED_MODULES</code> global parameter). It is used by Loki service. TCP 9009 Media Nodes Needed when 'Observability' module is used (<code>observability</code> in <code>ENABLED_MODULES</code> global parameter). It is used by Mimir service. TCP 4443 Master Nodes, Media Nodes Needed when 'OpenVidu v2 Compatibility' module is used (<code>v2compatibility</code> in <code>ENABLED_MODULES</code> global parameter). It is used by OpenVidu V2 compatibility service. TCP 6080 Master Nodes, Media Nodes Needed when 'OpenVidu Meet' module is used (<code>openviduMeet</code> in <code>ENABLED_MODULES</code> global parameter). It is used by OpenVidu Meet. TCP 7000-7001 Master Nodes, Media Nodes For internal Redis communication TCP 9100 Master Nodes, Media Nodes For internal MinIO communication TCP 20000 Master Nodes, Media Nodes For internal Mongo communication <p>Outbound port rules:</p> <p>Typically, all outbound traffic is allowed.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/install-nlb/#port-rules-media-nodes","title":"Port rules (Media Nodes)","text":"<p>Ensure all these rules are configured in your firewall, security group, or any kind of network configuration that you have in your Media Nodes:</p> <p>Inbound port rules:</p> Protocol Ports Source Description UDP 443 0.0.0.0/0, ::/0 STUN/TURN over UDP. TCP 7881 0.0.0.0/0, ::/0 Needed for WebRTC media traffic over TCP with Pion. UDP 7885 0.0.0.0/0, ::/0 Needed if you want to ingest WebRTC using WHIP. UDP 50000-60000 0.0.0.0/0, ::/0 Needed for WebRTC media traffic over UDP. TCP 50000-60000 0.0.0.0/0, ::/0 Needed for WebRTC media traffic over TCP with Mediasoup. TCP 1935 Master Nodes Needed if you want to ingest RTMP streams using Ingress service. Master Nodes need access to this port to reach Ingress RTMP service and expose it using TLS (RTMPS). TCP 5349 Master Nodes Needed if you have configured TURN with a domain for TLS. Master Node needs access to this port to reach TURN service and expose it using TLS. (TURNS) TCP 7880 Master Nodes LiveKit API. Master Nodes need access to load balance LiveKit API and expose it through HTTPS. TCP 8080 Master Nodes Needed if you want to ingest WebRTC streams using WHIP. Master Nodes need access to this port to reach WHIP HTTP service. <p>Outbound port rules:</p> <p>Typically, all outbound traffic is allowed.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/install-nlb/#guided-installation","title":"Guided installation","text":"<p>Before the installation, ensure that all your machines meet the prerequisites and the port rules for the Master Nodes and Media Nodes are correctly configured.</p> <p>To install OpenVidu High Availability, begin by generating the commands required for setting up all nodes in the cluster. This is a simple and straightforward process; simply run the following command on any machine that has Docker installed:</p> <pre><code>docker run --pull always --rm -it \\\n    openvidu/openvidu-installer:latest \\\n    --deployment-type=ha\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <p>A wizard will guide you through the installation process. You will be asked for the following information:</p> <ul> <li>Write all 'Master Node' Private IPs separated by commas: Write the private IP of each Master Node separated by commas.</li> <li>Write your OpenVidu PRO License: Write your OpenVidu PRO License.</li> </ul> <p>Info</p> <p>If you don't have a license key for OpenVidu PRO, you can get a 15-day free trial license key by creating an OpenVidu account.</p> <ul> <li>Do you want to use an external load balancer?: Select Yes. We will use a Network Load Balancer in front of the cluster.</li> <li>Domain name: The domain name for your deployment. It must be an FQDN pointing to the machine where you are deploying OpenVidu.</li> <li>(Optional) TURN domain name: The domain name for your TURN server with TLS. It must be an FQDN pointing to the Load Balancer you will use and must be different from the OpenVidu domain name. Recommended if users who are going to connect to your OpenVidu deployment are behind restrictive firewalls.</li> <li>Select which RTC engine to use: Select the WebRTC engine you want to use. You can choose between Pion (the default engine used by LiveKit) and Mediasoup (with a boost in performance). Learn more about the differences here.</li> <li>Modules to enable: Select the modules you want to enable. You can enable the following modules:<ul> <li>Observability: Grafana stack, which includes logs and monitoring stats.</li> <li>OpenVidu Meet: A high-quality video calling service based on OpenVidu.</li> <li>OpenVidu V2 Compatibility: Compatibility API for applications developed with OpenVidu v2.</li> </ul> </li> </ul> <p>The rest of the parameters are secrets, usernames, and passwords. If empty, the wizard will generate random values for them.</p> <p>This command will output the following instructions, which you should follow:</p> <ol> <li>Firewall Configuration for 'Master Nodes': These rules are the same as the ones specified in the instructions. Depending on the modules you have selected, some rules defined at Port rules (Master Nodes) may not appear (Optional ports). Double-check and modify them if you see something that can be enabled/disabled in your current port rules.</li> <li> <p>Installation Commands for 'Master Nodes': This is the command needed to install your Master Node. It should look like this:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/pro/ha/latest/install_ov_master_node.sh) \\\n    --no-tty --install \\\n    --deployment-type='ha' \\\n    --node-role='master-node' \\\n...\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <p>Execute that command on all your Master Nodes to install them. When the installation process finishes, you will see the following output:</p> <pre><code>&gt; - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - &lt;\n&gt;                                                                             &lt;\n&gt;  \ud83c\udf89\ud83c\udf89 OpenVidu HA 'Master Node' Installation Finished Successfully! \ud83c\udf89\ud83c\udf89    &lt;\n&gt;                                                                             &lt;\n&gt; - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - &lt;\n</code></pre> <p>The Master Node will be installed in <code>/opt/openvidu</code> and configured as a systemd service. To start the service, use the following command:</p> <pre><code>systemctl start openvidu\n</code></pre> <p>Your Master Nodes will be ready once all of them have been started.</p> </li> <li> <p>Firewall Configuration for 'Media Nodes': These rules are the same as the ones defined previously as with Master Nodes. Double-check the Port rules (Media Nodes) and modify them if you see something that can be enabled/disabled in your current port rules.</p> </li> <li> <p>Installation Commands for 'Media Nodes': This is the command needed to install your Media Nodes. It should look like this:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/pro/ha/latest/install_ov_media_node.sh) \\\n    --no-tty --install \\\n    --deployment-type='ha' \\\n    --node-role='media-node' \\\n...\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <p>Execute that command on your Media Nodes to install them. When the installation process finishes, you will see the following output:</p> <pre><code>&gt; - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - &lt;\n&gt;                                                                             &lt;\n&gt;  \ud83c\udf89 OpenVidu HA 'Media Node' Installation Finished Successfully! \ud83c\udf89         &lt;\n&gt;                                                                             &lt;\n&gt; - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - &lt;\n</code></pre> <p>The Media Node in each machine will be installed at <code>/opt/openvidu</code> and configured as a systemd service. You can start the service with the following command:</p> <pre><code>systemctl start openvidu\n</code></pre> </li> </ol> <p>If everything goes well, all containers will be up and running without restarts, and you will be able to access any of the following services:</p> <ul> <li>OpenVidu Meet: https://openvidu.example.io/</li> <li>OpenVidu Dashboard: https://openvidu.example.io/dashboard</li> <li>MinIO: https://openvidu.example.io/minio-console</li> <li>Grafana: https://openvidu.example.io/grafana</li> </ul> <p>OpenVidu Server PRO URL (LiveKit compatible) will be available also in:</p> <ul> <li>OpenVidu Server PRO: https://openvidu.example.io/</li> <li>LiveKit API: https://openvidu.example.io/ and wss://openvidu.example.io/</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/install-nlb/#load-balancer-configuration","title":"Load Balancer Configuration","text":"<p>To configure the Load Balancer, you must create a new TCP listener for each port that the Master Nodes use. The Load Balancer should be set up to distribute traffic evenly across all Master Nodes, targeting their private IP addresses. Additionally, optional features like RTMP and TURN with TLS should be directed to use the private IP addresses of the Media Nodes. This ensures that traffic for these services is properly routed to the Media Nodes.</p> <p>Below is an example using NGINX as a Load Balancer:</p> NGINX Load Balancer ConfigurationNGINX Load Balancer Configuration (With TLS for TURN) <p>Example configuration for NGINX Load Balancer:</p> <pre><code>events {\n    worker_connections 10240;\n}\n\n# Redirect HTTP to HTTPS\nhttp {\n    server {\n        listen 80;\n        listen [::]:80;\n        return 301 https://$host$request_uri;\n    }\n}\n\nstream {\n\n    upstream api_backend {\n        server &lt;MASTER_NODE_IP_1&gt;:7880;\n        server &lt;MASTER_NODE_IP_2&gt;:7880;\n        server &lt;MASTER_NODE_IP_3&gt;:7880;\n        server &lt;MASTER_NODE_IP_4&gt;:7880;\n    }\n\n    upstream rtmp_backend {\n        server &lt;MASTER_NODE_IP_1&gt;:1945;\n        server &lt;MASTER_NODE_IP_2&gt;:1945;\n        server &lt;MASTER_NODE_IP_3&gt;:1945;\n        server &lt;MASTER_NODE_IP_4&gt;:1945;\n    }\n\n    # Proxy for API and TURN\n    server {\n        listen 443 ssl;\n        listen [::]:443 ssl;\n        ssl_protocols TLSv1.2 TLSv1.3;\n\n        proxy_connect_timeout 10s;\n        proxy_timeout 30s;\n\n        ssl_certificate /etc/nginx/ssl/openvidu-cert.pem;\n        ssl_certificate_key /etc/nginx/ssl/openvidu-key.pem;\n\n        proxy_pass api_backend;\n    }\n\n    # RTMP\n    server {\n        listen 1935 ssl;\n        listen [::]:1935 ssl;\n        ssl_protocols TLSv1.2 TLSv1.3;\n\n        proxy_connect_timeout 10s;\n        proxy_timeout 30s;\n\n        ssl_certificate /etc/nginx/ssl/openvidu-cert.pem;\n        ssl_certificate_key /etc/nginx/ssl/openvidu-key.pem;\n\n        proxy_pass rtmp_backend;\n    }\n}\n</code></pre> <ul> <li>Notice that <code>openvidu-cert.pem</code> and <code>openvidu-key.pem</code> must be valid SSL certificates for your domain. </li> <li>The domain name should be pointing to the NGINX Load Balancer.</li> <li>Replace <code>&lt;MASTER_NODE_IP_X&gt;</code> with the private IP addresses of your Master Nodes and <code>&lt;MEDIA_NODE_IP_X&gt;</code> with the private IP addresses of your Media Nodes.</li> </ul> <p>Example configuration for NGINX Load Balancer:</p> <pre><code>events {\n    worker_connections 10240;\n}\n\n# Redirect HTTP to HTTPS\nhttp {\n    server {\n        listen 80;\n        listen [::]:80;\n        return 301 https://$host$request_uri;\n    }\n}\n\nstream {\n\n    upstream api_backend {\n        server &lt;MASTER_NODE_IP_1&gt;:7880;\n        server &lt;MASTER_NODE_IP_2&gt;:7880;\n        server &lt;MASTER_NODE_IP_3&gt;:7880;\n        server &lt;MASTER_NODE_IP_4&gt;:7880;\n    }\n\n    upstream turn_backend {\n        server &lt;MASTER_NODE_IP_1&gt;:5349;\n        server &lt;MASTER_NODE_IP_2&gt;:5349;\n        server &lt;MASTER_NODE_IP_3&gt;:5349;\n        server &lt;MASTER_NODE_IP_4&gt;:5349;\n    }\n\n    upstream rtmp_backend {\n        server &lt;MASTER_NODE_IP_1&gt;:1945;\n        server &lt;MASTER_NODE_IP_2&gt;:1945;\n        server &lt;MASTER_NODE_IP_3&gt;:1945;\n        server &lt;MASTER_NODE_IP_4&gt;:1945;\n    }\n\n    # Use SNI to determine which upstream server to proxy to\n    map $ssl_server_name $upstream {\n        openvidu.example.com api_backend;\n        turn.example.com turn_backend;\n    }\n\n    # Use SNI to determine which certificate to use\n    map $ssl_server_name $certificate {\n        openvidu.example.com /etc/nginx/ssl/openvidu-cert.pem;\n        turn.example.com /etc/nginx/ssl/turn-cert.pem;\n    }\n\n    # Use SNI to determine which private key to use\n    map $ssl_server_name $private_key {\n        openvidu.example.com /etc/nginx/ssl/openvidu-key.pem;\n        turn.example.com /etc/nginx/ssl/turn-key.pem;\n    }\n\n    # Proxy for API and TURN\n    server {\n        listen 443 ssl;\n        listen [::]:443 ssl;\n        ssl_protocols TLSv1.2 TLSv1.3;\n\n        proxy_connect_timeout 10s;\n        proxy_timeout 30s;\n\n        ssl_certificate $certificate;\n        ssl_certificate_key $private_key;\n\n        proxy_pass $upstream;\n    }\n\n    # RTMP\n    server {\n        listen 1935 ssl;\n        listen [::]:1935 ssl;\n        ssl_protocols TLSv1.2 TLSv1.3;\n\n        proxy_connect_timeout 10s;\n        proxy_timeout 30s;\n\n        ssl_certificate /certs/domain_fullchain.pem;\n        ssl_certificate_key /certs/domain_privkey.pem;\n\n        proxy_pass rtmp_backend;\n    }\n}\n</code></pre> <ul> <li>Notice that <code>openvidu.example.com</code> is the domain name you have chosen for your OpenVidu deployment and <code>turn.example.com</code> is the domain name you have chosen for your TURN with TLS. Both domains should be configured in your DNS to point to the Load Balancer. Also, the <code>openvidu-cert.pem</code>, <code>openvidu-key.pem</code>, <code>turn-cert.pem</code>, and <code>turn-key.pem</code> must be valid SSL certificates for your domains.</li> <li>Replace <code>&lt;MASTER_NODE_IP_X&gt;</code> with the private IP addresses of your Master Nodes and <code>&lt;MEDIA_NODE_IP_X&gt;</code> with the private IP addresses of your Media Nodes.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/install-nlb/#configure-your-application-to-use-the-deployment","title":"Configure your application to use the deployment","text":"<p>To point your applications to your OpenVidu deployment, check the following files:</p> <ul> <li><code>/opt/openvidu/config/cluster/master_node/meet.env</code>: Contains the OpenVidu Meet parameters.</li> <li><code>/opt/openvidu/config/cluster/openvidu.env</code>: Contains all the credentials of services deployed with OpenVidu Platform.</li> </ul> <p>The most relevant parameters are:</p> <p>OpenVidu Meet:</p> <ul> <li><code>MEET_INITIAL_ADMIN_USER</code>: User to access OpenVidu Meet Console. It is always <code>admin</code>.</li> <li><code>MEET_INITIAL_ADMIN_PASSWORD</code>: Password to access OpenVidu Meet Console.</li> <li><code>MEET_INITIAL_API_KEY</code>: API key to use OpenVidu Meet Embedded and OpenVidu Meet REST API.</li> </ul> <p>Note</p> <p>The <code>MEET_INITIAL_ADMIN_USER</code>, <code>MEET_INITIAL_ADMIN_PASSWORD</code>, and <code>MEET_INITIAL_API_KEY</code> values are initial and cannot be changed from the <code>meet.env</code> file. They can only be changed from the Meet Console.</p> <p>OpenVidu Platform:</p> <ul> <li><code>LIVEKIT_URL</code>: The URL to use LiveKit SDKs, which can be <code>wss://yourdomain.example.io/</code> or <code>https://yourdomain.example.io/</code> depending on the client library you are using.</li> <li><code>LIVEKIT_API_KEY</code>: API Key for LiveKit SDKs.</li> <li><code>LIVEKIT_API_SECRET</code>: API Secret for LiveKit SDKs.</li> </ul> <p>OpenVidu V2 Compatibility Credentials</p> <p>This section is only needed if you want to use OpenVidu v2 compatibility.</p> <ul> <li>URL: The URL to access OpenVidu, which is formed by the <code>DOMAIN_NAME</code> as <code>https://yourdomain.example.io/</code></li> <li>Username: Basic auth user for OpenVidu v2 compatibility. It is always <code>OPENVIDUAPP</code>.</li> <li>Password: Basic auth password for OpenVidu v2 compatibility is the same as <code>LIVEKIT_API_SECRET</code>.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/install-nlb/#non-interactive-installation","title":"Non-interactive installation","text":"<p>To automate the installation process, you just need to execute the specified command in the Guided installation section and execute the generated commands.</p> <p>Each installation command for each type of node looks like this:</p> Master NodeMedia Node <p>To install a Master Node, you can use the following command:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/pro/ha/latest/install_ov_master_node.sh) \\\n    --no-tty --install \\\n    --node-role='master-node' \\\n    --master-node-private-ip-list='10.5.0.1,10.5.0.2,10.5.0.3,10.5.0.4' \\\n    --openvidu-pro-license='xxxxx' \\\n    --domain-name='openvidu.example.io' \\\n    --enabled-modules='observability,v2compatibility,openviduMeet' \\\n    --rtc-engine='pion' \\\n    --turn-domain-name='turn.example.io' \\\n    --livekit-api-key='xxxxx' \\\n    --livekit-api-secret='xxxxx' \\\n    --dashboard-admin-user='xxxxx' \\\n    --dashboard-admin-password='xxxxx' \\\n    --redis-password='xxxxx' \\\n    --minio-access-key='xxxxx' \\\n    --minio-secret-key='xxxxx' \\\n    --mongo-admin-user='xxxxx' \\\n    --mongo-admin-password='xxxxx' \\\n    --mongo-replica-set-key='xxxxx' \\\n    --grafana-admin-user='xxxxx' \\\n    --grafana-admin-password='xxxxx' \\\n    --meet-initial-admin-password='xxxxx' \\\n    --meet-initial-api-key='xxxxx' \\\n    --external-load-balancer\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <p>Notes:</p> <ul> <li><code>--openvidu-pro-license</code> is mandatory. You can get a 15-day free trial license key by creating an OpenVidu account.</li> <li>Depending on the RTC engine, the argument <code>--rtc-engine</code> can be <code>pion</code> or <code>mediasoup</code>.</li> <li><code>--master-node-private-ip-list</code> is the list of private IPs of all Master Nodes separated by commas. It should not change, and Media Nodes should be able to reach all Master Nodes using these IPs.</li> </ul> <p>To install a Media Node, you can use the following command:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/pro/ha/latest/install_ov_media_node.sh) \\\n    --no-tty --install \\\n    --node-role='media-node' \\\n    --master-node-private-ip-list='10.5.0.1,10.5.0.2,10.5.0.3,10.5.0.4' \\\n    --redis-password='xxxxx'\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <ul> <li><code>--master-node-private-ip</code> must be the same list of private IPs of all Master Nodes separated by commas. It should not change, and Media Nodes should be able to reach all Master Nodes using these IPs.</li> <li><code>--redis-password</code> must be the same password as the one used in the Master Nodes. It is used to connect to the Redis service in the Master Nodes and register itself as a Media Node in the cluster.</li> <li>If no media appears in your conference, reinstall specifying the <code>--public-ip</code> parameter with your machine's public IP. OpenVidu usually auto-detects the public IP, but it can fail. This IP is used by clients to send and receive media. If you decide to install the Media Node with <code>--public-ip</code>, you must reinstall the Master Node with <code>--force-media-node-public-ip</code>.</li> </ul> <p>You can run these commands in a CI/CD pipeline or in a script to automate the installation process.</p> <p>Some general notes about all the Master Node commands:</p> <ul> <li>The argument <code>--turn-domain-name</code> is optional. You define it only if you want to enable TURN with TLS in case users are behind restrictive firewalls.</li> <li>At the argument <code>--enabled-modules</code>, you can enable the modules you want to deploy. You can enable <code>openviduMeet</code> OpenVidu Meet service, <code>observability</code> (Grafana stack) and <code>v2compatibility</code> (OpenVidu v2 compatibility API).</li> </ul> <p>To start each node, remember to execute the following command in each node:</p> <pre><code>systemctl start openvidu\n</code></pre>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/install-nlb/#configuration-and-administration","title":"Configuration and administration","text":"<p>Once you have OpenVidu deployed, you can check the Administration section to learn how to manage your OpenVidu High Availability deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/upgrade/","title":"Upgrade OpenVidu High Availability - On premises","text":"","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/upgrade/#upgrade-openvidu-high-availability-on-premises","title":"Upgrade OpenVidu High Availability - On premises","text":"<p>OpenVidu offers an updater that allows you to upgrade your OpenVidu deployment in an easy and automated way. The updater will take care of the whole process, from stopping the services to updating the configuration files.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/upgrade/#upgrading-openvidu-high-availability","title":"Upgrading OpenVidu High Availability","text":"<p>Upgrade OpenVidu High Availability is very simple. These are the steps you need to follow:</p> <ol> <li> <p>First, ensure to shut down OpenVidu High Availability. SSH into all the nodes and execute the following command:</p> <pre><code>systemctl stop openvidu\n</code></pre> </li> <li> <p>SSH into your Master Nodes and your Media Nodes and execute on each of them the following command:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/update/latest/update.sh)\n</code></pre> <p>Info</p> <p>If instead of upgrading to the latest version you want to upgrade to a specific version, you can execute the following command:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/update/&lt;VERSION&gt;/update.sh)\n</code></pre> <p>Where <code>&lt;VERSION&gt;</code> is the version you want to upgrade to.</p> </li> <li> <p>In all the nodes, you will see the following output:</p> <pre><code>Stopping OpenVidu service...\nBacking up files...\n\n    - Backing up file '/opt/openvidu/config' to '/opt/openvidu/backups/&lt;DATE&gt;_&lt;VERSION&gt;/config'\n    ... More files ...\n\n--------------------\n\ud83d\udce6 Backup directory: /opt/openvidu/backups/&lt;DATE&gt;_&lt;VERSION&gt;/\n--------------------\n\n--------------------\n\ud83d\ude80 Updating OpenVidu from 3.x.x to 3.y.y\n--------------------\n\n? Do you want to update from 3.x.x to 3.y.y? \u203a\n\u2022 Yes\n  No\n</code></pre> </li> <li> <p>Answer <code>Yes</code> to the question and your OpenVidu will be upgraded to the asked version. For each version the system will ask you to confirm the upgrade.</p> </li> <li>A <code>diff</code> will be shown with the changes made in the configuration files. You can review the changes and decide if you want to apply them or not. If you want to apply the changes, answer <code>Yes</code> to the question. If you want to discard the changes and stop the upgrading process, simply answer <code>No</code>.</li> <li>Once the upgrade is finished, it will ask you to pull the images of the services. Answer <code>Yes</code> if you want to do it.</li> <li>Execute the following command in all the nodes:</li> </ol> <pre><code>systemctl start openvidu &amp;&amp; journalctl -f -u openvidu\n</code></pre> <p>The <code>journalctl</code> command will show you the logs of the OpenVidu services. You can stop the logs by pressing <code>Ctrl + C</code>.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/upgrade/#backups-and-rollback","title":"Backups and Rollback","text":"<p>When you finish the upgrade process on each node, you will have a backup of the previous version in the <code>/opt/openvidu/backups</code> directory. The backup only contains the previous configuration files that have changed in the upgrade process. To roll back to the previous version, you have to copy the files from the backup to the OpenVidu directory. You can do it with the following command:</p> <pre><code>cp -r /opt/openvidu/backups/&lt;DATE&gt;_&lt;VERSION&gt;/* /opt/openvidu\n</code></pre> <p>Where <code>&lt;DATE&gt;</code> and <code>&lt;VERSION&gt;</code> are the date and version of the backup you want to restore. For example:</p> <pre><code>cp -r /opt/openvidu/backups/2025-02-12-09-50-46_3.0.0/* /opt/openvidu\n</code></pre> <p>You need to do this in all the nodes of your OpenVidu Elastic deployment to restore to the previous version.</p>","tags":["Platform"]},{"location":"docs/self-hosting/ha/on-premises/upgrade/#recommendations","title":"Recommendations","text":"<ul> <li>Always upgrade all the nodes of your OpenVidu High Availability deployment. Otherwise, you may face compatibility issues between the different versions of OpenVidu running in your deployment.</li> <li>On any upgrade problem, a redeployment is always recommended for a clean installation.</li> <li>Keep your Docker and Docker Compose versions updated.</li> <li> <p>Remove non-used images and containers to free up disk space. For example, after the upgrade, when OpenVidu is running, you can remove the old images with the following command:</p> <pre><code>docker image prune -a\n</code></pre> <p>This command will remove all the images that are not being used by any container.</p> </li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/how-to-guides/","title":"How To Guides","text":"","tags":["Platform"]},{"location":"docs/self-hosting/how-to-guides/#how-to-guides","title":"How To Guides","text":"<p>OpenVidu deployments are installed with sane defaults, but you may want to customize your deployment to suit your needs. This section contains guides on how to configure OpenVidu for specific use cases, so you can get the most out of your deployment.</p> <ul> <li>How to configure an external S3 bucket for recordings instead of the default MinIO</li> <li>Force all traffic including WebRTC to go through 443 with TLS</li> <li>Enable webhooks</li> <li>Enable and disable modules</li> <li>How to deploy and configure OpenVidu with an existing external proxy</li> <li>Create and configurate AWS certificate for HA deployment</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/how-to-guides/create-configure-AWS-certificate/","title":"Create AWS certificate for HA deployment","text":"","tags":["Platform"]},{"location":"docs/self-hosting/how-to-guides/create-configure-AWS-certificate/#create-aws-certificate-for-openvidu-ha-deployment","title":"Create AWS certificate for OpenVidu HA deployment","text":"<p>You will need this certificate to be able to deploy the High Availability deployment. This guide is meant to show you how to do it.</p>","tags":["Platform"]},{"location":"docs/self-hosting/how-to-guides/create-configure-AWS-certificate/#prerequisites","title":"Prerequisites","text":"<p>Is important to notice that in your AWS you will need to have access to the Certificate Manager. As well as having access to a domain provider.  You will need to have one domain to be able to create and vinculate the certificate.</p>","tags":["Platform"]},{"location":"docs/self-hosting/how-to-guides/create-configure-AWS-certificate/#creation","title":"Creation","text":"AWS Certificate creation <p>Those are the steps you need to follow to create the AWS certificate, keep in mind that you need a domain.   </p> <p>First go to AWS Certificate Manager and request a new public certificate. The following parameter is the most important. </p> Domain configuration <p></p> <p>You need to replace <code>yourdesiredname</code> for whatever name you want and <code>yourdomain</code> for the name of the domain that you own.  </p> <p>Next leave the rest of the parameters as they are and click request.</p> <p>The next page will prompt out the certificate status, here you will need to create a record in your domain provider to validate the status, first you will have status pending.</p> Create record in your domain providerCreate record in Route 53 <p>Here you will need to create a new CNAME record in the domain you own by using as subdomain the CNAME name until the domain name and the CNAME value as the value of that record.</p> <p>In AWS Certificate Manager you can check the CNAME name and value clicking into the certificate you want.</p> <p></p> Create record in Route 53 <p></p> <p>You need to click the button called <code>Create records in Route 53</code>. This will lead you to the next image where you just click Create records and that's it.</p> <p></p> Create record for certificate <p></p> <p>Please verify that you have a new entry in the records table of the specified Hosted Zone in Route 53 with the CNAME of the certificate you just created.   </p> <p>Try to refresh until you reach the Issued status in green.</p> <p>Finally when deploying the HA stack in CloudFormation follow these steps</p> Configuration of Load Balancer <p></p> Load balancer configuration <p></p> <p>Those are parameters related to the certificate you just created.    </p> <p>You have to fill field <code>DomainName</code> with the domain name that appears in the certificate that you created, the one that matches yourdesiredname.yourdomain mentioned earlier.  </p> <p>Next for the <code>OpenViduCertificateARN</code>, you can find it at the top of the same page I mentioned earlier, it is called <code>ARN</code>, as you can see in the image below.   </p> <p></p> Domain name and ARN location <p></p> <p>When everything is up and running you will need to create a new record in the Hosted Zone referring to the Load Balancer resource created in the stack.   </p> Vinculating Load Balancer <p></p> Create Load Balancer record <p></p> <p>Note that Alias is checked.   </p> <p>In <code>subdomain</code> you just have to put the same as you put in yourdesiredname creating the AWS certificate.  In <code>Choose endpoint</code> you just have to select Alias to Network Load Balancer, and in <code>Choose Region</code> select your region where the stack is deployed.  After selecting the endpoint and region a new field will appear, select there the load balancer that belongs to the stack you have deployed.   </p> <p>For the other fields, leave them as they are.</p>","tags":["Platform"]},{"location":"docs/self-hosting/how-to-guides/deploy-with-external-proxy/","title":"Deploy and configure with an external proxy","text":"","tags":["Platform"]},{"location":"docs/self-hosting/how-to-guides/deploy-with-external-proxy/#how-to-deploy-and-configure-openvidu-with-an-existing-external-proxy","title":"How to deploy and configure OpenVidu with an existing external proxy","text":"<p>By default, OpenVidu is deployed with an internal Caddy server  to configure and manage SSL certificates. However, there are certain scenarios where using an external proxy might be preferable:</p> <ul> <li>You wish to manage SSL certificates manually.</li> <li>A specific proxy server is required for enhanced security.</li> <li>You need to integrate a proxy server already in your infrastructure.</li> </ul> <p>If none of these scenarios apply to you and you prefer to use the default internal Caddy server, please refer to the official installation guides.</p> <p>For those needing to deploy OpenVidu using an external proxy, this guide offers detailed steps to deploy it and configure the external proxy.</p> <ul> <li>External Proxy for OpenVidu Single Node</li> <li>External Proxy for OpenVidu Elastic</li> <li>External Proxy for OpenVidu High Availability</li> </ul> Single NodeElasticHigh Availability <p>Note</p> <p>The Single Node deployment with an external proxy is based on the same instructions as the Single Node COMMUNITY Deployment and the Single Node PRO Deployment, but with some modifications to the installation command and port rules. We recommend you to read the installation guides before proceeding with this guide to have a better understanding of the deployment.</p> <p>This is how the architecture of the deployment looks like:</p> <p></p> OpenVidu Single Node On Premises Architecture with External Proxy <p></p> <p>1. Prerequisites</p> <p>To deploy OpenVidu with an external proxy, ensure you have the following prerequisites:</p> <ul> <li>A machine with at least 4GB RAM and 4 CPU cores and Linux installed (Ubuntu recommended). This machine will serve as the OpenVidu server.</li> <li>An additional machine for the proxy server is recommended. Alternatively, you can use the same machine as OpenVidu, but be aware that the proxy server will consume resources. Note that some ports will be used by OpenVidu, except for the ports utilized by the proxy server (TCP 80, 443, and 1935).</li> <li>Generous disk space (100GB recommended) if you are going to record your sessions.</li> <li>The machine where OpenVidu is installed must have a Public IP or a reachable IP from the users.</li> <li>The proxy server also must have a Public IP or a reachable IP from the users.</li> <li>A domain name for your OpenVidu deployment pointing to the machine where the proxy server is running. In this guide, we will use <code>openvidu.example.io</code>.</li> <li>Optionally (but recommended), you need an additional domain name pointing to the proxy machine where the proxy server is running. It will be used for TURN with TLS which is useful in case your users are behind restrictive firewalls to be able to connect to OpenVidu. In this guide, we will use <code>turn.example.io</code>.</li> </ul> <p>2. Port Rules</p> <p>You can follow the same rule ports of the Single Node Deployment but some ports are used by the proxy server and others are not needed. The inbound rules for the OpenVidu proxy would be as follows:</p> OpenVidu MachineProxy Server <p>Inbound Rules</p> Protocol Ports Source Description TCP 7880 External proxy Allows access to the following: <ul><li>LiveKit API.</li><li>OpenVidu Dashboard.</li><li>OpenVidu Meet.</li><li>WHIP API.</li><li>Custom layouts</li></ul> TCP 1945 External proxy Needed if you want to ingest RTMP streams using Ingress service. TCP 5349 External proxy Optional and needed only if you have a domain for TURN and you want to use TURN with TLS UDP 443 0.0.0.0/0, ::/0 STUN/TURN server over UDP. TCP 9000 0.0.0.0/0, ::/0 Needed if you want to expose MinIO publicly. TCP 7881 0.0.0.0/0, ::/0 Needed for WebRTC media traffic over TCP with Pion. UDP 7885 0.0.0.0/0, ::/0 Needed if you want to ingest WebRTC using WHIP. UDP 50000-60000 0.0.0.0/0, ::/0 Needed for WebRTC media traffic over UDP. TCP 50000-60000 0.0.0.0/0, ::/0 Needed for WebRTC media traffic over TCP with Mediasoup. <p>Outbound Rules</p> <p>Typically, all outbound traffic is allowed.</p> <p>Inbound Rules</p> Protocol Ports Source Description TCP 80 0.0.0.0/0, ::/0 HTTP redirection to HTTPS. TCP 443 0.0.0.0/0, ::/0 HTTPS access to the OpenVidu API and TURN with TLS. TCP 1935 0.0.0.0/0, ::/0 RTMP with TLS. <p>3. Install OpenVidu Single Node with <code>--external-proxy</code> flag</p> <p>To deploy OpenVidu with an external proxy, you must use the CLI installation command with the <code>--external-proxy</code> flag. The command to install OpenVidu with an external proxy is as follows:</p> Single Node COMMUNITYSingle Node PRO <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/community/singlenode/latest/install.sh) \\\n    --no-tty --install \\\n    --domain-name='openvidu.example.io' \\\n    --turn-domain-name='turn.example.io' \\\n    --enabled-modules='observability,openviduMeet' \\\n    --livekit-api-key='xxxxx' \\\n    --livekit-api-secret='xxxxx' \\\n    --dashboard-admin-user='xxxxx' \\\n    --dashboard-admin-password='xxxxx' \\\n    --redis-password='xxxxx' \\\n    --minio-access-key='xxxxx' \\\n    --minio-secret-key='xxxxx' \\\n    --mongo-admin-user='xxxxx' \\\n    --mongo-admin-password='xxxxx' \\\n    --mongo-replica-set-key='xxxxx' \\\n    --grafana-admin-user='xxxxx' \\\n    --grafana-admin-password='xxxxx' \\\n    --meet-initial-admin-password='xxxxx' \\\n    --meet-initial-api-key='xxxxx' \\\n    --external-proxy\n</code></pre> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/pro/singlenode/latest/install.sh) \\\n    --no-tty --install \\\n    --openvidu-pro-license='xxxxx' \\\n    --domain-name='openvidu.example.io' \\\n    --turn-domain-name='turn.example.io' \\\n    --enabled-modules='observability,openviduMeet,v2compatibility' \\\n    --rtc-engine='pion' \\\n    --livekit-api-key='xxxxx' \\\n    --livekit-api-secret='xxxxx' \\\n    --dashboard-admin-user='xxxxx' \\\n    --dashboard-admin-password='xxxxx' \\\n    --redis-password='xxxxx' \\\n    --minio-access-key='xxxxx' \\\n    --minio-secret-key='xxxxx' \\\n    --mongo-admin-user='xxxxx' \\\n    --mongo-admin-password='xxxxx' \\\n    --mongo-replica-set-key='xxxxx' \\\n    --grafana-admin-user='xxxxx' \\\n    --grafana-admin-password='xxxxx' \\\n    --meet-initial-admin-password='xxxxx' \\\n    --meet-initial-api-key='xxxxx' \\\n    --external-proxy\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <p>Notes:</p> <ul> <li>Replace <code>openvidu.example.io</code> with your FQDN.</li> <li>The <code>turn-domain-name</code> parameter is optional. You define it only if you want to enable TURN with TLS in case users are behind restrictive firewalls.If you don't have a TURN server, you can remove it from the command. If you want to use TURN with TLS, replace <code>turn.example.io</code> with your TURN server FQDN.</li> <li>In PRO edition, the <code>--openvidu-pro-license</code> parameter is mandatory. You can get your license key here.</li> <li>In PRO edition, depending on the RTC engine, the argument <code>--rtc-engine</code> can be <code>pion</code> or <code>mediasoup</code>.</li> </ul> <p>4. Configure the external proxy</p> <p>We will use Nginx  as the proxy server, but the configuration can be adapted to other proxy servers. The configuration for the proxy server is as follows:</p> Nginx ConfigurationNginx Configuration (withouth optional TURN domain) <p>If you have installed OpenVidu with both domains (<code>openvidu.example.io</code> and <code>turn.example.io</code>) and both domains are pointing to the same proxy, the proxy needs to be configured as a Layer 4 proxy (TCP) because the TURN and HTTP traffic share the same port (443). We will use the Server Name Indication (SNI) of the TLS handshake to discern the traffic. The rules would be as follows:</p> <ol> <li>Configure a redirect rule to redirect HTTP traffic to HTTPS in port 80.</li> <li>Configure a rule to proxy all Layer 4 TLS incoming proxy traffic in port 443 to the OpenVidu Master Node in port 7880 for domain <code>openvidu.example.io</code>. This is for the HTTP traffic of the OpenVidu API and other services.</li> <li>Configure a rule to proxy all Layer 4 TLS incoming proxy traffic in port 443 to the OpenVidu Master Node in port 5349 for domain <code>turn.example.io</code>. This is for the TURN service.</li> <li>Configure a rule to proxy all Layer 4 TLS incoming proxy traffic in port 1935 to the OpenVidu Master Node in port 1945 for RTMP traffic.</li> </ol> <p>The following is an example of an Nginx configuration file that includes all the rules mentioned above:</p> <pre><code>events {\n    worker_connections 10240;\n}\n\n# Redirect HTTP to HTTPS\nhttp {\n    server {\n        listen 80;\n        listen [::]:80;\n        return 301 https://$host$request_uri;\n    }\n}\n\nstream {\n\n    upstream api_backend {\n        server &lt;MASTER_NODE_PRIVATE_IP&gt;:7880;\n    }\n\n    upstream turn_backend {\n        server &lt;MASTER_NODE_PRIVATE_IP&gt;:5349;\n    }\n\n    upstream rtmp_backend {\n        server &lt;MASTER_NODE_PRIVATE_IP&gt;:1945;\n    }\n\n    # Use SNI to determine which upstream server to proxy to\n    map $ssl_server_name $upstream {\n        openvidu.example.io api_backend;\n        turn.example.io turn_backend;\n    }\n\n    # Use SNI to determine which certificate to use\n    map $ssl_server_name $certificate {\n        openvidu.example.io /etc/nginx/ssl/openvidu-cert.pem;\n        turn.example.io /etc/nginx/ssl/turn-cert.pem;\n    }\n\n    # Use SNI to determine which private key to use\n    map $ssl_server_name $private_key {\n        openvidu.example.io /etc/nginx/ssl/openvidu-privkey.pem;\n        turn.example.io /etc/nginx/ssl/turn-privkey.pem;\n    }\n\n    # Proxy for API and TURN\n    server {\n        listen 443 ssl;\n        listen [::]:443 ssl;\n        ssl_protocols TLSv1.2 TLSv1.3;\n\n        proxy_connect_timeout 10s;\n        proxy_timeout 30s;\n\n        ssl_certificate $certificate;\n        ssl_certificate_key $private_key;\n\n        proxy_pass $upstream;\n    }\n\n    # RTMP\n    server {\n        listen 1935 ssl;\n        listen [::]:1935 ssl;\n        ssl_protocols TLSv1.2 TLSv1.3;\n\n        proxy_connect_timeout 10s;\n        proxy_timeout 30s;\n\n        ssl_certificate /etc/nginx/ssl/openvidu-cert.pem;\n        ssl_certificate_key /etc/nginx/ssl/openvidu-privkey.pem;\n\n        proxy_pass rtmp_backend;\n    }\n}\n</code></pre> <ul> <li>Replace <code>openvidu.example.io</code> and <code>turn.example.io</code> with your domain names. These domain names must be configured in your DNS to point to the proxy server.</li> <li>Replace <code>&lt;MASTER_NODE_PRIVATE_IP&gt;</code> with the private IP of the OpenVidu server.</li> <li>You can also have a proxy in the same machine as OpenVidu, simply replace <code>&lt;MASTER_NODE_PRIVATE_IP&gt;</code> with <code>127.0.0.1</code>.</li> </ul> <p>If you only configure the main domain <code>openvidu.example.com</code> to be served by OpenVidu, you simply need to:</p> <ol> <li>Configure a rule to redirect HTTP traffic to HTTPS in port 80.</li> <li>Configure a rule to proxy all Layer 7 HTTPS incoming proxy traffic in port 443 to the OpenVidu Master Node in port 7880.</li> <li>Configure a rule to proxy all Layer 4 TLS incoming proxy traffic in port 1935 to the OpenVidu Master Node in port 1945.</li> </ol> <p>As RTMP is a Layer 4 protocol, you need to configure a separate <code>stream</code> block in the Nginx configuration file, while the rest of the rules can be configured in the <code>http</code> block.</p> <p>The following is an example of an Nginx configuration file that includes all the rules mentioned above:</p> <pre><code>events {\n    worker_connections 10240;\n}\n\nhttp {\n\n    upstream api_backend {\n        server &lt;MASTER_NODE_PRIVATE_IP&gt;:7880;\n    }\n\n    # Redirect HTTP to HTTPS\n    server {\n        listen 80;\n        listen [::]:80;\n        return 301 https://$host$request_uri;\n    }\n\n    # HTTPS Layer 7 proxy\n    server {\n        listen 443 ssl;\n        listen [::]:443 ssl;\n        ssl_protocols TLSv1.2 TLSv1.3;\n\n        ssl_certificate /etc/nginx/ssl/openvidu-cert.pem;\n        ssl_certificate_key /etc/nginx/ssl/openvidu-privkey.pem;\n\n        location / {\n            # Proxy to OpenVidu\n            proxy_pass http://api_backend;\n\n            # Add WebSocket support\n            proxy_http_version 1.1;\n            proxy_set_header Upgrade $http_upgrade;\n            proxy_set_header Connection \"upgrade\";\n\n            # Proxy headers\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n\n            # Timeouts\n            proxy_connect_timeout 10s;\n            proxy_read_timeout 30s;\n            proxy_send_timeout 30s;\n        }\n    }\n}\n\nstream {\n\n    upstream rtmp_backend {\n        server &lt;MASTER_NODE_PRIVATE_IP&gt;:1945;\n    }\n\n    # RTMP Layer 4 proxy\n    server {\n        listen 1935 ssl;\n        listen [::]:1935 ssl;\n        ssl_protocols TLSv1.2 TLSv1.3;\n\n        proxy_connect_timeout 10s;\n        proxy_timeout 30s;\n\n        ssl_certificate /etc/nginx/ssl/openvidu-cert.pem;\n        ssl_certificate_key /etc/nginx/ssl/openvidu-privkey.pem;\n\n        proxy_pass rtmp_backend;\n    }\n}\n</code></pre> <p>You can create an <code>stream</code> block for the HTTPS rule as well for consistency instead of creating an <code>http</code> block. In this way all rules are in the <code>stream</code> block. The rules would be these:</p> <ol> <li>Configure a rule to redirect HTTP traffic to HTTPS in port 80.</li> <li>Configure a rule to proxy all Layer 4 TLS incoming proxy traffic in port 443 to the OpenVidu Master Node in port 7880.</li> <li>Configure a rule to proxy all Layer 4 TLS incoming proxy traffic in port 1935 to the OpenVidu Master Node in port 1945.</li> </ol> <p>The following is an example of an Nginx configuration file that includes all the rules mentioned above:</p> <pre><code>events {\n    worker_connections 10240;\n}\n\n# Redirect HTTP to HTTPS\nhttp {\n    server {\n        listen 80;\n        listen [::]:80;\n        return 301 https://$host$request_uri;\n    }\n}\n\nstream {\n\n    upstream api_backend {\n        server &lt;MASTER_NODE_PRIVATE_IP&gt;:7880;\n    }\n\n    upstream rtmp_backend {\n        server &lt;MASTER_NODE_PRIVATE_IP&gt;:1945;\n    }\n\n    # Proxy for API and TURN\n    server {\n        listen 443 ssl;\n        listen [::]:443 ssl;\n        ssl_protocols TLSv1.2 TLSv1.3;\n\n        proxy_connect_timeout 10s;\n        proxy_timeout 30s;\n\n        ssl_certificate /etc/nginx/ssl/openvidu-cert.pem;\n        ssl_certificate_key /etc/nginx/ssl/openvidu-privkey.pem;\n\n        proxy_pass api_backend;\n    }\n\n    # RTMP\n    server {\n        listen 1935 ssl;\n        listen [::]:1935 ssl;\n        ssl_protocols TLSv1.2 TLSv1.3;\n\n        proxy_connect_timeout 10s;\n        proxy_timeout 30s;\n\n        ssl_certificate /etc/nginx/ssl/openvidu-cert.pem;\n        ssl_certificate_key /etc/nginx/ssl/openvidu-privkey.pem;\n\n        proxy_pass rtmp_backend;\n    }\n}\n</code></pre> <ul> <li>Replace <code>openvidu.example.io</code> with your domain name. This domain name must be configured in your DNS to point to the proxy server.</li> <li>Replace <code>&lt;MASTER_NODE_PRIVATE_IP&gt;</code> with the private IP of the OpenVidu server.</li> <li>You can also have a proxy in the same machine as OpenVidu, simply replace <code>&lt;MASTER_NODE_PRIVATE_IP&gt;</code> with <code>127.0.0.1</code>.</li> </ul> <p>Note</p> <p>The Elastic deployment with an external proxy is based on the same instructions as the Elastic Deployment, but with some modifications to the installation command and port rules. We recommend you to read the Elastic Deployment guide before proceeding with this guide to have a better understanding of the deployment.</p> <p>This is how the architecture of the deployment looks like:</p> <p></p> OpenVidu Elastic On Premises Architecture with External Proxy <p></p> <p>1. Prerequisites</p> <p>To deploy OpenVidu Elastic with an external proxy, ensure you have the following prerequisites:</p> <ul> <li>At least 2 machines for OpenVidu, each with a minimum of 4GB RAM, 4 CPU cores, and Linux installed (Ubuntu is recommended). One machine will serve as the Master Node, while the others will function as Media Nodes.</li> <li>An additional machine for the proxy server is recommended. Alternatively, you can use the same machine as the Master Node, but be aware that the proxy server will consume resources. Note that some ports will be used by OpenVidu, except for the ports utilized by the proxy server (TCP 80, 443, and 1935).</li> <li>Significant disk space on the Master Node, with 100GB recommended, especially if you plan to record your sessions (Egress). Media Nodes require less space; however, account for the space needed for ongoing recordings on these nodes.</li> <li>Each machine must have a Public IP or a reachable IP from the users.</li> <li>The proxy server must have a Public IP or a reachable IP from the users.</li> <li>A domain name for your OpenVidu deployment pointing to the proxy server. In this guide, we will use <code>openvidu.example.io</code>.</li> <li>Optionally (but recommended), you need an additional domain name pointing to the proxy server. It will be used for TURN with TLS which is useful in case your users are behind restrictive firewalls. In this guide, we will use <code>turn.example.io</code>.</li> </ul> <p>2. Port Rules</p> <p>You can follow the same rule ports of the Elastic Deployment for the Master Node and for the Media Nodes but some ports are used by the proxy server and others are not needed. The inbound rules for the OpenVidu proxy would be as follows:</p> Master NodeMedia NodesProxy Server <p>Inbound Rules</p> Protocol Ports Source Description TCP 7880 External Proxy Allows access to the following: <ul><li>Livekit API.</li><li>OpenVidu v2 Compatibility API</li><li>OpenVidu Dashboard.</li><li>OpenVidu Meet.</li><li>WHIP API.</li><li>Custom layouts</li></ul> TCP 1935 External Proxy Needed if you want to ingest RTMP streams using Ingress service. TCP 5349 External proxy Optional and needed only if you have a domain for TURN and you want to use TURN with TLS TCP 4443 Media Nodes Needed when 'OpenVidu v2 Compatibility' module is used (<code>v2compatibility</code> in <code>ENABLED_MODULES</code> global parameter). Media Nodes need access to this port to reach OpenVidu V2 compatibility service TCP 6080 Media Nodes Needed when 'OpenVidu Meet'  module is used (<code>openviduMeet</code> in <code>ENABLED_MODULES</code> global parameter). Media Nodes need access to this port to reach OpenVidu Meet. TCP 3100 Media Nodes Needed when 'Observability' module is used (<code>observability</code> in <code>ENABLED_MODULES</code> global parameter) Media Nodes need access to this port to reach Loki. TCP 9009 Media Nodes Needed when 'Observability' module is used. (<code>observability</code> in <code>ENABLED_MODULES</code> global parameter) Media Nodes need access to this port to reach Mimir. TCP 7000 Media Nodes Media Nodes need access to this port to reach Redis Service. TCP 9100 Media Nodes Media Nodes need access to this port to reach MinIO. TCP 20000 Media Nodes Media Nodes need access to this port to reach MongoDB. <p>Outbound Rules</p> <p>Typically, all outbound traffic is allowed.</p> <p>Inbound Rules</p> Protocol Ports Source Description UDP 443 0.0.0.0/0, ::/0 STUN/TURN over UDP. TCP 7881 0.0.0.0/0, ::/0 Needed for WebRTC media traffic over TCP with Pion. UDP 7885 0.0.0.0/0, ::/0 Needed if you want to ingest WebRTC using WHIP. UDP 50000-60000 0.0.0.0/0, ::/0 Needed for WebRTC media traffic over UDP. TCP 50000-60000 0.0.0.0/0, ::/0 Needed for WebRTC media traffic over TCP with Mediasoup. TCP 1935 Master Node Needed if you want to ingest RTMP streams using Ingress service. Master Node needs access to this port to reach Ingress RTMP service and expose it using TLS (RTMPS). TCP 5349 Master Node Needed if you have configured TURN with a domain for TLS. Master Node needs access to this port to reach TURN service and expose it using TLS (TURNS). TCP 7880 Master Node LiveKit API. Master Node needs access to load balance LiveKit API and expose it through HTTPS. TCP 8080 Master Node Needed if you want to ingest WebRTC streams using WHIP. Master Node needs access to this port to reach WHIP HTTP service. <p>Outbound Rules</p> <p>Typically, all outbound traffic is allowed.</p> <p>And the inbound rules for the proxy server would be as follows:</p> Protocol Ports Source Description TCP 80 0.0.0.0/0, ::/0 HTTP redirection to HTTPS. TCP 443 0.0.0.0/0, ::/0 HTTPS access to the OpenVidu API and TURN with TLS. TCP 1935 0.0.0.0/0, ::/0 RTMP with TLS. <p>3. Install OpenVidu Elastic with <code>--external-proxy</code> flag</p> <p>To deploy OpenVidu Elastic with an external proxy, you must use the CLI installation command with the <code>--external-proxy</code> flag. The command to install OpenVidu Elastic with an external proxy is as follows:</p> Install Master NodeInstall Media Nodes <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/pro/elastic/latest/install_ov_master_node.sh) \\\n    --no-tty --install \\\n    --node-role='master-node' \\\n    --openvidu-pro-license='xxxxx' \\\n    --domain-name='openvidu.example.io' \\\n    --turn-domain-name='turn.example.io' \\\n    --enabled-modules='observability,v2compatibility,openviduMeet' \\\n    --rtc-engine='pion' \\\n    --livekit-api-key='xxxxx' \\\n    --livekit-api-secret='xxxxx' \\\n    --dashboard-admin-user='xxxxx' \\\n    --dashboard-admin-password='xxxxx' \\\n    --redis-password='xxxxx' \\\n    --minio-access-key='xxxxx' \\\n    --minio-secret-key='xxxxx' \\\n    --mongo-admin-user='xxxxx' \\\n    --mongo-admin-password='xxxxx' \\\n    --mongo-replica-set-key='xxxxx' \\\n    --grafana-admin-user='xxxxx' \\\n    --grafana-admin-password='xxxxx' \\\n    --meet-initial-admin-password='xxxxx' \\\n    --meet-initial-api-key='xxxxx' \\\n    --private-ip='&lt;MASTER_NODE_PRIVATE_IP&gt;' \\\n    --external-proxy\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <p>Notes:</p> <ul> <li><code>--openvidu-pro-license</code> is mandatory. You can get a 15-day free trial license key by creating an OpenVidu account.</li> <li>Replace <code>openvidu.example.io</code> with your FQDN.</li> <li>The <code>turn-domain-name</code> parameter is optional. You define it only if you want to enable TURN with TLS in case users are behind restrictive firewalls. If you don't have a TURN server, you can remove it from the command. If you want to use TURN with TLS, replace <code>turn.example.io</code> with your TURN server FQDN.</li> <li><code>--private-ip</code> is very important. It should not change and Media Nodes should be able to reach the Master Node using this IP. Replace <code>&lt;MASTER_NODE_PRIVATE_IP&gt;</code> with the private IP of the Master Node.</li> <li>Depending on the RTC engine, the argument <code>--rtc-engine</code> can be <code>pion</code> or <code>mediasoup</code>.</li> </ul> <p>To install a Media Node, you can use the following command:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/pro/elastic/latest/install_ov_media_node.sh) \\\n    --no-tty --install \\\n    --node-role='media-node' \\\n    --master-node-private-ip='&lt;MASTER_NODE_PRIVATE_IP&gt;' \\\n    --redis-password='xxxxx'\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <ul> <li>The <code>--master-node-private-ip</code> is the private IP of the Master Node. Replace <code>&lt;MASTER_NODE_PRIVATE_IP&gt;</code> with the private IP of the Master Node.</li> <li>The <code>--redis-password</code> is the password used to connect to the Redis service. Replace <code>xxxxx</code> with the same password used in the Master Node installation.</li> </ul> <p>4. Configure the external proxy</p> <p>We will use Nginx  as the proxy server, but the configuration can be adapted to other proxy servers. The configuration for the proxy server is as follows:</p> Nginx ConfigurationNginx Configuration (withouth optional TURN domain) <p>If you have installed OpenVidu with both domains (<code>openvidu.example.io</code> and <code>turn.example.io</code>) and both domains are pointing to the same proxy, the proxy needs to be configured as a Layer 4 proxy (TCP) because the TURN and HTTP traffic share the same port (443). We will use the Server Name Indication (SNI) of the TLS handshake to discern the traffic. The rules would be as follows:</p> <ol> <li>Configure a redirect rule to redirect HTTP traffic to HTTPS in port 80.</li> <li>Configure a rule to proxy all Layer 4 TLS incoming proxy traffic in port 443 to the OpenVidu Master Node in port 7880 for domain <code>openvidu.example.io</code>. This is for the HTTP traffic of the OpenVidu API and other services.</li> <li>Configure a rule to proxy all Layer 4 TLS incoming proxy traffic in port 443 to the OpenVidu Master Node in port 5349 for domain <code>turn.example.io</code>. This is for the TURN service.</li> <li>Configure a rule to proxy all Layer 4 TLS incoming proxy traffic in port 1935 to the OpenVidu Master Node in port 1945 for RTMP traffic.</li> </ol> <p>The following is an example of an Nginx configuration file that includes all the rules mentioned above:</p> <pre><code>events {\n    worker_connections 10240;\n}\n\n# Redirect HTTP to HTTPS\nhttp {\n    server {\n        listen 80;\n        listen [::]:80;\n        return 301 https://$host$request_uri;\n    }\n}\n\nstream {\n\n    upstream api_backend {\n        server &lt;MASTER_NODE_PRIVATE_IP&gt;:7880;\n    }\n\n    upstream turn_backend {\n        server &lt;MASTER_NODE_PRIVATE_IP&gt;:5349;\n    }\n\n    upstream rtmp_backend {\n        server &lt;MASTER_NODE_PRIVATE_IP&gt;:1945;\n    }\n\n    # Use SNI to determine which upstream server to proxy to\n    map $ssl_server_name $upstream {\n        openvidu.example.io api_backend;\n        turn.example.io turn_backend;\n    }\n\n    # Use SNI to determine which certificate to use\n    map $ssl_server_name $certificate {\n        openvidu.example.io /etc/nginx/ssl/openvidu-cert.pem;\n        turn.example.io /etc/nginx/ssl/turn-cert.pem;\n    }\n\n    # Use SNI to determine which private key to use\n    map $ssl_server_name $private_key {\n        openvidu.example.io /etc/nginx/ssl/openvidu-privkey.pem;\n        turn.example.io /etc/nginx/ssl/turn-privkey.pem;\n    }\n\n    # Proxy for API and TURN\n    server {\n        listen 443 ssl;\n        listen [::]:443 ssl;\n        ssl_protocols TLSv1.2 TLSv1.3;\n\n        proxy_connect_timeout 10s;\n        proxy_timeout 30s;\n\n        ssl_certificate $certificate;\n        ssl_certificate_key $private_key;\n\n        proxy_pass $upstream;\n    }\n\n    # RTMP\n    server {\n        listen 1935 ssl;\n        listen [::]:1935 ssl;\n        ssl_protocols TLSv1.2 TLSv1.3;\n\n        proxy_connect_timeout 10s;\n        proxy_timeout 30s;\n\n        ssl_certificate /etc/nginx/ssl/openvidu-cert.pem;\n        ssl_certificate_key /etc/nginx/ssl/openvidu-privkey.pem;\n\n        proxy_pass rtmp_backend;\n    }\n}\n</code></pre> <ul> <li>Replace <code>openvidu.example.io</code> and <code>turn.example.io</code> with your domain names. These domain names must be configured in your DNS to point to the proxy server.</li> <li>Replace <code>&lt;MASTER_NODE_PRIVATE_IP&gt;</code> with the private IP of the Master Node.</li> <li>You can also have a proxy in the same machine as the Master Node, simply replace <code>&lt;MASTER_NODE_PRIVATE_IP&gt;</code> with <code>127.0.0.1</code>.</li> </ul> <p>If you only configure the main domain <code>openvidu.example.com</code> to be served by OpenVidu, you simply need to:</p> <ol> <li>Configure a rule to redirect HTTP traffic to HTTPS in port 80.</li> <li>Configure a rule to proxy all Layer 7 HTTPS incoming proxy traffic in port 443 to the OpenVidu Master Node in port 7880.</li> <li>Configure a rule to proxy all Layer 4 TLS incoming proxy traffic in port 1935 to the OpenVidu Master Node in port 1945.</li> </ol> <p>As RTMP is a Layer 4 protocol, you need to configure a separate <code>stream</code> block in the Nginx configuration file, while the rest of the rules can be configured in the <code>http</code> block.</p> <p>The following is an example of an Nginx configuration file that includes all the rules mentioned above:</p> <pre><code>events {\n    worker_connections 10240;\n}\n\nhttp {\n\n    upstream api_backend {\n        server &lt;MASTER_NODE_PRIVATE_IP&gt;:7880;\n    }\n\n    # Redirect HTTP to HTTPS\n    server {\n        listen 80;\n        listen [::]:80;\n        return 301 https://$host$request_uri;\n    }\n\n    # HTTPS Layer 7 proxy\n    server {\n        listen 443 ssl;\n        listen [::]:443 ssl;\n        ssl_protocols TLSv1.2 TLSv1.3;\n\n        ssl_certificate /etc/nginx/ssl/openvidu-cert.pem;\n        ssl_certificate_key /etc/nginx/ssl/openvidu-privkey.pem;\n\n        location / {\n            # Proxy to OpenVidu\n            proxy_pass http://api_backend;\n\n            # Add WebSocket support\n            proxy_http_version 1.1;\n            proxy_set_header Upgrade $http_upgrade;\n            proxy_set_header Connection \"upgrade\";\n\n            # Proxy headers\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n\n            # Timeouts\n            proxy_connect_timeout 10s;\n            proxy_read_timeout 30s;\n            proxy_send_timeout 30s;\n        }\n    }\n}\n\nstream {\n\n    upstream rtmp_backend {\n        server &lt;MASTER_NODE_PRIVATE_IP&gt;:1945;\n    }\n\n    # RTMP Layer 4 proxy\n    server {\n        listen 1935 ssl;\n        listen [::]:1935 ssl;\n        ssl_protocols TLSv1.2 TLSv1.3;\n\n        proxy_connect_timeout 10s;\n        proxy_timeout 30s;\n\n        ssl_certificate /etc/nginx/ssl/openvidu-cert.pem;\n        ssl_certificate_key /etc/nginx/ssl/openvidu-privkey.pem;\n\n        proxy_pass rtmp_backend;\n    }\n}\n</code></pre> <p>You can create an <code>stream</code> block for the HTTPS rule as well for consistency instead of creating an <code>http</code> block. In this way all rules are in the <code>stream</code> block. The rules would be these:</p> <ol> <li>Configure a rule to redirect HTTP traffic to HTTPS in port 80.</li> <li>Configure a rule to proxy all Layer 4 TLS incoming proxy traffic in port 443 to the OpenVidu Master Node in port 7880.</li> <li>Configure a rule to proxy all Layer 4 TLS incoming proxy traffic in port 1935 to the OpenVidu Master Node in port 1945.</li> </ol> <p>The following is an example of an Nginx configuration file that includes all the rules mentioned above:</p> <pre><code>events {\n    worker_connections 10240;\n}\n\n# Redirect HTTP to HTTPS\nhttp {\n    server {\n        listen 80;\n        listen [::]:80;\n        return 301 https://$host$request_uri;\n    }\n}\n\nstream {\n\n    upstream api_backend {\n        server &lt;MASTER_NODE_PRIVATE_IP&gt;:7880;\n    }\n\n    upstream rtmp_backend {\n        server &lt;MASTER_NODE_PRIVATE_IP&gt;:1945;\n    }\n\n    # Proxy for API and TURN\n    server {\n        listen 443 ssl;\n        listen [::]:443 ssl;\n        ssl_protocols TLSv1.2 TLSv1.3;\n\n        proxy_connect_timeout 10s;\n        proxy_timeout 30s;\n\n        ssl_certificate /etc/nginx/ssl/openvidu-cert.pem;\n        ssl_certificate_key /etc/nginx/ssl/openvidu-privkey.pem;\n\n        proxy_pass api_backend;\n    }\n\n    # RTMP\n    server {\n        listen 1935 ssl;\n        listen [::]:1935 ssl;\n        ssl_protocols TLSv1.2 TLSv1.3;\n\n        proxy_connect_timeout 10s;\n        proxy_timeout 30s;\n\n        ssl_certificate /etc/nginx/ssl/openvidu-cert.pem;\n        ssl_certificate_key /etc/nginx/ssl/openvidu-privkey.pem;\n\n        proxy_pass rtmp_backend;\n    }\n}\n</code></pre> <ul> <li>Replace <code>openvidu.example.io</code> with your domain name. This domain name must be configured in your DNS to point to the proxy server.</li> <li>Replace <code>&lt;MASTER_NODE_PRIVATE_IP&gt;</code> with the private IP of the Master Node.</li> <li>You can also have a proxy in the same machine as the Master Node, simply replace <code>&lt;MASTER_NODE_PRIVATE_IP&gt;</code> with <code>127.0.0.1</code>.</li> </ul> <p>The High Availability deployment already has a way to configure an external proxy (described as a Network Load Balancer), which is explained  in this section.</p>","tags":["Platform"]},{"location":"docs/self-hosting/how-to-guides/deploy-with-external-proxy/#can-i-force-all-traffic-including-webrtc-to-go-through-the-external-proxy","title":"Can I force all traffic including WebRTC to go through the external proxy?","text":"<p>Yes, but you need to use a domain name for TURN (<code>--turn-domain-name</code> parameter) and ensure that the following ports are explicitly closed in OpenVidu:</p> <p>Single Node closed Ports</p> Node Port Protocol OpenVidu Server 443 UDP OpenVidu Server 50000-60000 UDP <p>Elastic and High Availability closed Ports</p> Node Port Protocol Media Node 443 UDP Media Node 50000-60000 UDP <p>This configuration will force traffic to use TURN, so all traffic will go through the external proxy using the TURN domain name configured in the installation process. But you need to understand some considerations:</p> <ul> <li> <p>Media over UDP using WebRTC does not mean that the media is not encrypted. WebRTC encrypts the media using SRTP and DTLS. WebRTC is designed to be encrypted by default.</p> </li> <li> <p>Media going through 443 with TLS has a penalty in the media quality and CPU usage. This is because of the TLS roundtrip, TCP being used and media processed twice by the TURN server and the Media Server. This can lead to a worse user experience and higher CPU usage in the Media Server. We recommend using this configuration only if it is strictly necessary.</p> </li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/how-to-guides/enable-disable-modules/","title":"Enable and disable modules","text":"","tags":["Platform"]},{"location":"docs/self-hosting/how-to-guides/enable-disable-modules/#enable-and-disable-modules","title":"Enable and disable modules","text":"<p>OpenVidu allows you to enable or disable modules to customize your deployment. These modules are:</p> <ul> <li><code>openviduMeet</code>: The OpenVidu Meet service.</li> <li><code>observability</code>: Grafana, Loki, Mimir, and Promtail observability services.</li> <li><code>v2compatibility</code>: OpenVidu V2 Compatibility. (Only available in OpenVidu Pro)</li> </ul> <p>These modules are configured in the parameter <code>ENABLED_MODULES</code>.</p> <ul> <li>Single Node: <code>/opt/openvidu/config/openvidu.env</code></li> <li>Elastic / High Availability: <code>/opt/openvidu/config/cluster/openvidu.env</code></li> </ul> <p>The environment variable <code>ENABLED_MODULES</code> will all the modules enabled would look like this:</p> <pre><code>ENABLED_MODULES=app,observability,v2compatibility\n</code></pre> <p>Simply go to one of your Master Nodes or the only node in a Single Node deployment, edit the <code>openvidu.env</code> file, modify the <code>ENABLED_MODULES</code> and restart the Master Node or the Single Node deployment with:</p> <pre><code>systemctl restart openvidu\n</code></pre>","tags":["Platform"]},{"location":"docs/self-hosting/how-to-guides/enable-disable-modules/#about-modules-configuration","title":"About modules configuration","text":"<p>If you've installed OpenVidu with all modules enabled, you may not need to change these configurations. But in case you've installed openvidu with some modules disabled, you may need to configure some parameters when enabling them.</p> appv2compatibilityobservability <p>You need to configure the Livekit configuration to send webhooks to the OpenVidu V2 Compatibility service.</p> Single NodeElasticHigh Availability <p>Location: <code>/opt/openvidu/config/livekit.yaml</code></p> <pre><code>webhook:\n    api_key: ${openvidu.LIVEKIT_API_KEY:?mandatory}\n    urls:\n        - http://localhost:${openvidu.DEFAULT_APP_INTERNAL_PORT:?mandatory}/livekit/webhook\n</code></pre> <p>With this configuration, the Livekit service will send webhooks to the OpenVidu Meet service which is necessary.</p> <p>Location: <code>/opt/openvidu/config/cluster/media_node/livekit.yaml</code></p> <pre><code>webhook:\n    api_key: ${openvidu.LIVEKIT_API_KEY:?mandatory}\n    urls:\n        - http://master-node:${openvidu.DEFAULT_APP_INTERNAL_PORT:?mandatory}/livekit/webhook\n</code></pre> <p>With this configuration, the Livekit service will send webhooks to the OpenVidu Meet service which is necessary.</p> <p>Location: <code>/opt/openvidu/config/cluster/media_node/livekit.yaml</code></p> <pre><code>webhook:\n    api_key: ${openvidu.LIVEKIT_API_KEY:?mandatory}\n    urls:\n        - http://localhost:${openvidu.DEFAULT_APP_INTERNAL_PORT:?mandatory}/livekit/webhook\n</code></pre> <p>With this configuration, the Livekit service will send webhooks to the OpenVidu Meet service which is necessary.</p> <p>You need to configure the Livekit configuration to send webhooks to the OpenVidu V2 Compatibility service.</p> ElasticHigh Availability <p>Location: <code>/opt/openvidu/config/cluster/media_node/livekit.yaml</code></p> <pre><code>webhook:\n    api_key: ${openvidu.LIVEKIT_API_KEY:?mandatory}\n    urls:\n        - http://master-node:${openvidu.OPENVIDU_V2COMPAT_INTERNAL_PORT:?mandatory}/livekit/webhook\n</code></pre> <p>With this configuration, the Livekit service will send webhooks to the OpenVidu V2 Compatibility service which is necessary.</p> <p>Location: <code>/opt/openvidu/config/cluster/media_node/livekit.yaml</code></p> <pre><code>webhook:\n    api_key: ${openvidu.LIVEKIT_API_KEY:?mandatory}\n    urls:\n        - http://localhost:${openvidu.OPENVIDU_V2COMPAT_INTERNAL_PORT:?mandatory}/livekit/webhook\n</code></pre> <p>With this configuration, the Livekit service will send webhooks to the OpenVidu V2 Compatibility service which is necessary.</p> <p>You need the following parameters defined in the <code>openvidu.env</code> file.</p> Single NodeElasticHigh Availability <p>Location: <code>/opt/openvidu/config/openvidu.env</code></p> <pre><code>GRAFANA_ADMIN_USERNAME=\"&lt;GRAFANA_ADMIN_USERNAME&gt;\"\nGRAFANA_ADMIN_PASSWORD=\"&lt;GRAFANA_ADMIN_PASSWORD&gt;\"\n</code></pre> <p>With these parameters, you set the username and password for the Grafana admin user.</p> <p>Location: <code>/opt/openvidu/config/cluster/openvidu.env</code></p> <pre><code>GRAFANA_ADMIN_USERNAME=\"&lt;GRAFANA_ADMIN_USERNAME&gt;\"\nGRAFANA_ADMIN_PASSWORD=\"&lt;GRAFANA_ADMIN_PASSWORD&gt;\"\n</code></pre> <p>With these parameters, you set the username and password for the Grafana admin user.</p> <p>Location: <code>/opt/openvidu/config/cluster/openvidu.env</code></p> <pre><code>GRAFANA_ADMIN_USERNAME=\"&lt;GRAFANA_ADMIN_USERNAME&gt;\"\nGRAFANA_ADMIN_PASSWORD=\"&lt;GRAFANA_ADMIN_PASSWORD&gt;\"\n</code></pre> <p>With these parameters, you set the username and password for the Grafana admin user.</p> <p>These configurations should be valid just by copying and pasting them into the <code>livekit.yaml</code> file. If you want to understand the <code>${openvidu.VARIABLE:?mandatory}</code> syntax, please refer to the Configuration section.</p>","tags":["Platform"]},{"location":"docs/self-hosting/how-to-guides/enable-disable-modules/#troubleshooting","title":"Troubleshooting","text":"<p>On any problem, check these sections:</p> <ul> <li>Config Troubleshooting</li> <li>Status and Checking Logs sections of Administration sections of each deployment type:<ul> <li>Single Node</li> <li>Elastic</li> <li>High Availability</li> </ul> </li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/how-to-guides/enable-webhooks/","title":"Enable webhooks","text":"","tags":["Platform"]},{"location":"docs/self-hosting/how-to-guides/enable-webhooks/#enable-webhooks","title":"Enable Webhooks","text":"<p>If you need to integrate OpenVidu with other services, you can use webhooks to send notifications about events that occur in your OpenVidu deployment. This guide explains how to enable webhooks.</p>","tags":["Platform"]},{"location":"docs/self-hosting/how-to-guides/enable-webhooks/#openvidu-server-configuration","title":"OpenVidu Server Configuration","text":"<ol> <li>SSH into one of your Master Nodes (or Single Node).</li> <li> <p>Add to the file <code>livekit.yaml</code> the following configuration:</p> <pre><code>webhook:\n    api_key: ${openvidu.LIVEKIT_API_KEY:?mandatory}\n    urls:\n    ...\n        - https://&lt;YOUR_WEBHOOK_URL&gt;\n</code></pre> <p>The file is located at:</p> <ul> <li>Single Node: <code>/opt/openvidu/config/livekit.yaml</code></li> <li>Elastic / High Availability: <code>/opt/openvidu/config/cluster/media_node/livekit.yaml</code></li> </ul> <p>Make sure the <code>webhook</code> section exists in the file, and if it doesn't, add it as stated in the previous snippet. Then, add the URL where you want to receive the webhook notifications. In this example, <code>&lt;YOUR_WEBHOOK_URL&gt;</code> is the URL where you want to receive the notifications.</p> </li> <li> <p>Restart the Master Node (or Single Node) to apply the changes:</p> <pre><code>systemctl restart openvidu\n</code></pre> <p>This command will restart the services which changed their configuration files in your entire OpenVidu deployment.</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/how-to-guides/enable-webhooks/#pro-v2-compatibility-configuration","title":"PRO V2 Compatibility Configuration","text":"<p>If you are using the V2 Compatibility module, you can also enable webhooks for the V2 Compatibility layer.</p> <ol> <li>SSH into one of your Master Nodes (or Single Node).</li> <li> <p>Add to the file <code>v2compatibility.env</code> the following parameters:</p> <pre><code>V2COMPAT_OPENVIDU_WEBHOOK=true\nV2COMPAT_OPENVIDU_WEBHOOK_ENDPOINT=https://&lt;YOUR_WEBHOOK_URL&gt;\n</code></pre> <p>Where <code>&lt;YOUR_WEBHOOK_URL&gt;</code> is the URL where you want to receive the notifications.</p> <p>Check in the Configuration Reference all the webhook events that you can receive setting up the parameter <code>V2COMPAT_OPENVIDU_WEBHOOK_EVENTS</code>.</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/how-to-guides/enable-webhooks/#send-webhooks-to-a-local-application-server","title":"Send Webhooks to a Local Application Server","text":"<p>When developing locally pointing to a production deployment and webhooks events are required by your application, you will face issues because OpenVidu cannot access your local application server.</p> <p>To receive webhooks from OpenVidu on your local machine, you need to expose your local application server to the internet. This exposure allows OpenVidu to send webhooks directly to your application server.</p> <p>The following images illustrate the difference between an unreachable and a reachable local application server:</p> <p> </p> Unreachable local application server <p> </p> Reachable local application server <p>Exposing your local application server to the internet is a common practice when developing applications locally. Tools like Ngrok , LocalTunnel , LocalXpose  and Zrok  can help you achieve this.</p> <p>These tools provide you with a public URL that forwards requests to your local application server. You can use this URL to receive webhooks from OpenVidu, configuring it in the OpenVidu Server as explained in the previous section.</p>","tags":["Platform"]},{"location":"docs/self-hosting/how-to-guides/external-s3/","title":"Configuring external S3 for OpenVidu recordings","text":"","tags":["Platform"]},{"location":"docs/self-hosting/how-to-guides/external-s3/#configuring-external-s3-for-openvidu-recordings","title":"Configuring external S3 for OpenVidu recordings","text":"<p>OpenVidu, by default, utilizes MinIO for recording storage, but it can be configured to use an external S3 provider instead. This guide provides the necessary steps to configure OpenVidu with an external S3 provider for your deployment.</p> <p>Info</p> <p>If you are deploying using AWS CloudFormation, the S3 bucket is configured automatically to use the AWS S3 service. In this case there is no need to follow this guide.</p>","tags":["Platform"]},{"location":"docs/self-hosting/how-to-guides/external-s3/#configuration","title":"Configuration","text":"<p>Configuring an external S3 bucket in OpenVidu is straightforward. Update the following parameters in the <code>openvidu.env</code> file on one of the Master Nodes or your Single Node deployment. Depending on your deployment type, the location of the <code>openvidu.env</code> file is as follows:</p> <ul> <li>Single Node: <code>/opt/openvidu/config/openvidu.env</code></li> <li>Elastic / High Availability: <code>/opt/openvidu/config/cluster/openvidu.env</code></li> </ul> <pre><code>EXTERNAL_S3_ENDPOINT=&lt;YOUR_S3_HTTP_ENDPOINT&gt;\nEXTERNAL_S3_ACCESS_KEY=&lt;YOUR_S3_ACCESS_KEY&gt;\nEXTERNAL_S3_SECRET_KEY=&lt;YOUR_S3_SECRET_KEY&gt;\nEXTERNAL_S3_REGION=&lt;YOUR_S3_REGION&gt;\nEXTERNAL_S3_PATH_STYLE_ACCESS=&lt;YOUR_S3_PATH_STYLE_ACCESS&gt;\nEXTERNAL_S3_BUCKET_APP_DATA=&lt;YOUR_APP_DATA_BUCKET&gt;\n# For High Availability deployments only\nEXTERNAL_S3_BUCKET_CLUSTER_DATA=&lt;YOUR_CLUSTER_DATA_BUCKET&gt;\n</code></pre> <p>Parameter Details:</p> <ul> <li><code>EXTERNAL_S3_ENDPOINT</code>: HTTP endpoint of your S3 provider.</li> <li><code>EXTERNAL_S3_ACCESS_KEY</code>: Access key for your S3 provider.</li> <li><code>EXTERNAL_S3_SECRET_KEY</code>: Secret key for your S3 provider.</li> <li><code>EXTERNAL_S3_REGION</code>: Region of your S3 provider.</li> <li><code>EXTERNAL_S3_PATH_STYLE_ACCESS</code>: Use path-style access for the S3 bucket (<code>true</code> or <code>false</code> based on provider requirements).</li> <li><code>EXTERNAL_S3_BUCKET_APP_DATA</code>: Bucket for storing OpenVidu recordings and data related to the OpenVidu Meet service.</li> <li><code>EXTERNAL_S3_BUCKET_CLUSTER_DATA</code> (High Availability only): Bucket for storing observability data and other data specific to a High Availability deployment.</li> </ul> <p>After updating the <code>openvidu.env</code> file, restart the Master Node or your Single Node deployment:</p> <pre><code>systemctl restart openvidu\n</code></pre> <p>Info</p> <p>Take into account that when using an external S3 bucket, the MinIO service will not be started, and will appear as <code>Exited (0)</code> when checking the status of the services.</p>","tags":["Platform"]},{"location":"docs/self-hosting/how-to-guides/external-s3/#example-with-aws-s3","title":"Example with AWS S3","text":"<p>Assume the region of your bucket is <code>eu-west-1</code> and you have an S3 bucket named <code>my-openvidu-bucket</code>. Your configuration should be:</p> <pre><code>EXTERNAL_S3_ENDPOINT=https://s3.eu-west-1.amazonaws.com\nEXTERNAL_S3_ACCESS_KEY=&lt;YOUR_AWS_ACCESS_KEY&gt;\nEXTERNAL_S3_SECRET_KEY=&lt;YOUR_AWS_SECRET_KEY&gt;\nEXTERNAL_S3_REGION=eu-west-1\nEXTERNAL_S3_PATH_STYLE_ACCESS=true\nEXTERNAL_S3_BUCKET_APP_DATA=my-openvidu-bucket\n\n# For High Availability deployments only\nEXTERNAL_S3_BUCKET_CLUSTER_DATA=my-openvidu-cluster-bucket\n</code></pre> <p>Warning</p> <p>Note that the region must be specified in the <code>EXTERNAL_S3_ENDPOINT</code> parameter for AWS S3. This may not be required for other S3 providers but is necessary for AWS S3.</p>","tags":["Platform"]},{"location":"docs/self-hosting/how-to-guides/external-s3/#about-the-path-style-parameter","title":"About the Path-Style parameter","text":"<p>The <code>EXTERNAL_S3_PATH_STYLE_ACCESS</code> parameter is used to specify whether to use path-style access if <code>true</code> or virtual-hosted-style access if <code>false</code>. Check this documentation for more information: Amazon S3 Path Style Access </p> <p>This parameter requires a specific value depending on the S3 provider. Here is a table with some examples:</p> S3 Provider <code>EXTERNAL_S3_PATH_STYLE_ACCESS</code> Value AWS S3 <code>true</code> or <code>false</code>  Recommend <code>true</code> MinIO <code>false</code> DigitalOcean Spaces <code>false</code> <p>Usually the value <code>false</code> is compatible with all S3 providers, but some providers may require <code>true</code>, so check the documentation of your S3 provider to confirm the correct value.</p>","tags":["Platform"]},{"location":"docs/self-hosting/how-to-guides/external-s3/#troubleshooting","title":"Troubleshooting","text":"<p>On any problem, check these sections:</p> <ul> <li>Config Troubleshooting</li> <li>Status and Checking Logs sections of Administration sections of each deployment type:<ul> <li>Single Node</li> <li>Elastic</li> <li>High Availability</li> </ul> </li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/how-to-guides/force-443-tls/","title":"Force traffic through 443 with TLS","text":"","tags":["Platform"]},{"location":"docs/self-hosting/how-to-guides/force-443-tls/#force-all-traffic-including-webrtc-to-go-through-443-with-tls","title":"Force all traffic including WebRTC to go through 443 with TLS","text":"<p>In certain scenarios, users may be behind restrictive firewalls or network policies that only permit traffic through port 443 using TLS. By default, OpenVidu is configured to allow traffic through port 443 with TLS if a TURN domain name is specified during the installation process. However, users in less restrictive environments can still utilize other ports to establish WebRTC connections.</p> <p>In some cases, it is necessary to ensure that all traffic, including WebRTC, is routed through port 443 with TLS due to network policies, security requirements, or other considerations.</p> <p>To enforce this configuration, OpenVidu must be installed with a TURN domain name, which is an optional step in the installation process. If this was not done initially, you will need to reinstall OpenVidu with a TURN domain name.</p> <p>Once OpenVidu is installed with a TURN domain name, ensure that the following ports are not open or are explicitly closed:</p> <p>Single Node closed Ports</p> Node Port Protocol OpenVidu Server 443 UDP OpenVidu Server 50000-60000 UDP <p>Elastic and High Availability closed Ports</p> Node Port Protocol Media Node 443 UDP Media Node 50000-60000 UDP <p>In this way, all the traffic will go through port 443 with TLS using the TURN domain name configured in the installation process.</p>","tags":["Platform"]},{"location":"docs/self-hosting/how-to-guides/force-443-tls/#considerations","title":"Considerations","text":"<ul> <li> <p>Media over UDP using WebRTC does not mean that the media is not encrypted. WebRTC encrypts the media using SRTP and DTLS. WebRTC is designed to be encrypted by default.</p> </li> <li> <p>Media going through 443 with TLS has a penalty in the media quality and CPU usage. This is because of the TLS roundtrip, TCP being used and media processed twice by the TURN server and the Media Server. This can lead to a worse user experience and higher CPU usage in the Media Server. We recommend using this configuration only if it is strictly necessary.</p> </li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/","title":"Production ready","text":"","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/#production-ready","title":"Production ready","text":"<p>OpenVidu is designed to be self-hosted, whether it is on premises or in a cloud provider. It brings to your own managed service advanced capabilities usually reserved only for SaaS solutions. There are two main reasons why you may need to self-host the real-time solution yourself:</p> <ul> <li>Privacy: you can't afford to let your client's data get out of your reach. OpenVidu allows you to meet all your privacy and regulatory requirements: no data at all is sent to any third-party server. Everything is self-contained on your own servers.</li> <li>Leverage your resources: your organization has access to its own infrastructure that can be used to host these services. SaaS solutions generally offer complete freedom from infrastructure management, but this comes with generally high prices that cover both the provider's infrastructure and their service surcharge. OpenVidu allows taking full advantage of your own infrastructure, reducing costs and increasing performance.</li> </ul> <p>It is important to mention that when we talk about self-hosting OpenVidu, we don't just mean installing it in bare-metal servers or private VPCs. OpenVidu also supports deployments in the most popular cloud providers, using their native services when possible. AWS and Azure are currently supported, and others are coming soon. You can learn more about the different options to deploy OpenVidu in the deployment types section.</p> <p>One of OpenVidu's main goals is offering a self-hosted, production-ready live-video platform with all the advanced capabilities typically reserved for SaaS solutions. This includes outstanding performance, scalability, fault tolerance and observability:</p> <ul> <li> <p> Performance</p> <p>OpenVidu is built to be incredibly powerful. It is based on the best open source WebRTC stacks: LiveKit  and mediasoup . By combining the best of both worlds, OpenVidu provides outstanding performance.</p> <p> Learn more about performance</p> </li> <li> <p> Scalability</p> <p>OpenVidu has been designed from the outset with scalability in mind. Host videoconference rooms and large live streams with hundreds of participants. Autoscale your cluster to adapt to the demand and optimize your resources.</p> <p> Learn more about scalability</p> </li> <li> <p> Fault Tolerance</p> <p>OpenVidu offers fault tolerance in all its components. Deploy a reliable high-availability cluster knowing that if one of your node goes down, others will be able to continue working with no downtime.</p> <p> Learn more about fault tolerance</p> </li> <li> <p> Observability</p> <p>OpenVidu brings everything necessary to monitor the status, health, load and history of your deployment. It automatically collects events, metrics and logs, and provides OpenVidu Dashboard and a Grafana stack to navigate them.</p> <p> Learn more about observability</p> </li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/fault-tolerance/","title":"Fault Tolerant","text":"","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/fault-tolerance/#fault-tolerance","title":"Fault Tolerance","text":"<p>Real-time media is particularly sensitive to downtime events, as they directly affect the user experience in a very disruptive way. OpenVidu is designed from the ground up to be fault tolerant in all its services in case of node downtime, especially in its High Availability deployment.</p> <p>The extent of fault tolerance depends on the OpenVidu deployment type:</p> <ul> <li>OpenVidu Single Node: it is not fault tolerant. Fault tolerance requires a multi-node deployment.</li> <li>OpenVidu Elastic: fault tolerant only for Media Nodes.</li> <li>OpenVidu High Availability: fault tolerant for both Media Nodes and Master Nodes.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/fault-tolerance/#fault-tolerance-in-openvidu-elastic","title":"Fault tolerance in OpenVidu Elastic","text":"","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/fault-tolerance/#master-node","title":"Master Node","text":"<p>An OpenVidu Elastic deployment has a single Master Node, so a failure on this node is fatal and any ongoing video Rooms will be interrupted. The service won't be restored until the Master Node is recovered.</p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/fault-tolerance/#media-nodes","title":"Media Nodes","text":"<p>You can have any number of Media Nodes in an OpenVidu Elastic deployment. Media Nodes are stateless, meaning that they do not store critical information about the Rooms, Egress or Ingress processes they are handling. This means that they can be easily replicated in any other Media Node in case of a failure.</p> <p>In the event of a Media Node failure, there are 3 services affected with the following behaviors:</p> <ul> <li>Active Rooms  hosted by the failed Media Node will suffer a temporary interruption of about 5 seconds (this is the time the clients take to realize the Media Node has crashed). After that time has elapsed, the Room will be automatically reconstructed in a healthy Media Node. Every participant and track will be recreated and the Room will be fully operational again.</li> <li>Active Egress  hosted by the failed Media Node will be interrupted. If the node's disk is still accessible, egress output files can still be recovered. See Recovering Egress from node failures.</li> <li>Active Ingress  hosted by the failed Media Node will be interrupted. The participants of the Room will receive the proper events indicating the Ingress participant has left the Room: <code>TrackUnpublished</code> and <code>ParticipantDisconnected</code>. Some famous tools for streaming such as OBS Studio will automatically try to reconnect the stream when they detect a connection loss, so in this case interruption will be minimal and the Ingress tracks will be restored on their own on a healthy Media Node.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/fault-tolerance/#fault-tolerance-in-openvidu-high-availability","title":"Fault tolerance in OpenVidu High Availability","text":"<p>OpenVidu High Availability delivers the highest possible degree of fault tolerance. This is achieved by running all of the services in the Master Nodes and the Media Nodes in their High Availability flavour.</p> <p>An OpenVidu High Availability deployment runs Master Nodes and Media Nodes in separated groups. Let's see the extent of fault tolerance for each node group:</p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/fault-tolerance/#master-nodes","title":"Master Nodes","text":"<p>The number of Master Nodes in an OpenVidu High Availability deployment is 4. This minimum number of nodes ensures that every service running in the Master Nodes is fault tolerant.</p> <p>If one Master Node fails, the service won't be affected. Some users may trigger event  <code>Reconnecting</code> closely followed by <code>Reconnected</code>, but the service will remain fully operational.</p> <p>When two or more Master Nodes fail simultaneously, there can be some degradation of the service:</p> <ul> <li>If two Master Nodes fail, the service will still be operational for the most part. Only active Egress  might be affected, as they won't be stored in the Minio storage. See Recovering Egress from node failures.</li> <li>If three or four Master Nodes fail, the service will be interrupted.</li> </ul> <p>In the event of Master Node failures, the service will be automatically restored as soon as the failed node(s) are recovered.</p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/fault-tolerance/#media-nodes_1","title":"Media Nodes","text":"<p>Fault tolerance of Media Nodes in OpenVidu High Availability behaves the same as in OpenVidu Elastic.</p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/fault-tolerance/#recovering-egress-from-node-failures","title":"Recovering Egress from node failures","text":"<p>Egress  processes can be affected by the crash of a Master Node or a Media Node. To recover Egress from...</p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/fault-tolerance/#from-master-node-failures","title":"From Master Node failures","text":"<p>This only applies to OpenVidu High Availability</p> <p>If 2 Master Nodes crash, the Egress process won't be able to use the Minio storage. This has different consequences depending on the configured outputs  for your Egress process:</p> <ul> <li>For MP4, OGG or WEBM files, if the Egress is stopped when 2 Master Nodes are down, the output files will not be uploaded to Minio.</li> <li>For HLS, the segments will stop being uploaded to Minio. If you are consuming these segments from another process, note that new segments will stop appearing.</li> </ul> <p>In both cases, files are not lost and can be recovered. They will be available in the Egress backup path of the Media Node hosting the Egress process (by default <code>/opt/openvidu/egress_data/home/egress/backup_storage</code>).</p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/fault-tolerance/#from-a-media-node-failure","title":"From a Media Node failure","text":"<p>This applies to both OpenVidu High Availability and OpenVidu Elastic</p> <p>If the Media Node hosting an ongoing Egress process crashes, then the Egress process will be immediately interrupted. But as long as the disk of the crashed Media Node is still accessible, you may recover the output files. They will be available in the Media Node at path <code>/opt/openvidu/egress_data/home/egress/tmp</code>.</p> <p>It is possible that if the crashed Egress had MP4 as configured output  (which is an option available for Room Composite  and Track Composite ) the recovered file may not be directly playable and it may require a repair process.</p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/performance/","title":"Performant","text":"","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/performance/#performance","title":"Performance","text":"<p>OpenVidu is able to handle up to 2x the load in a single server, doubling the amount of media Tracks that can be transmitted compared to base LiveKit. By not only building upon the giant Open-Source shoulders of LiveKit, but also pushing the bar further, OpenVidu uses the best-in-class technologies to bring considerable performance improvements to the table.</p> <p>The key element of any WebRTC server solution is the ability to exchange media between participants of a room, in the so-called WebRTC SFU. LiveKit implements its own SFU, and that's where OpenVidu makes a different choice by using mediasoup .</p> <p>The key points of how this works are:</p> <ul> <li>On the surface, OpenVidu is the same than LiveKit, and for the most part features work equally, such as connection establishment, participant management, and SDK support.</li> <li>Internally however, mediasoup is used to replace the original WebRTC engine implementation of LiveKit. mediasoup is built with the most efficient technologies and has outstanding low-level optimizations, which translates in a 2x improvement with respect to the original LiveKit Open Source performance.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/performance/#about-mediasoup-integration","title":"About mediasoup integration","text":"","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/performance/#architecture","title":"Architecture","text":"<p>LiveKit created its own WebRTC SFU, based on the Pion  library to route media between participants:</p> <p></p> <p>OpenVidu is built by a team of expert WebRTC developers who know all the ins and outs of low-level WebRTC development, so it was possible to replace LiveKit's own implementation with an alternative, and mediasoup was the clear best choice given its fantastic performance characteristics:</p> <p></p> <p>This means that applications built on top of LiveKit will continue to work exactly the same, while the internal WebRTC engine inside the server can be swapped at will and applications can benefit from that change, without having to be rebuilt.</p> <p>In terms of the signaling protocol, API and SDKs, OpenVidu maintains the original LiveKit implementation. LiveKit's API is very well designed, with a simple but powerful set of concepts, and the amount of SDKs available is very large.</p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/performance/#choice-of-technology","title":"Choice of technology","text":"<p>Both LiveKit and Pion are written in the Go programming language , and this has some implications for speed and efficiency. While Go is popular for its simplicity, readability, and approach to concurrency, when it comes to performance other alternatives rank higher in common benchmarks.</p> <p>First and foremost, the two most defining limitations of Go is that it requires a quite heavy runtime that is able to handle all of the low-level features of the language, such as goroutines and memory allocations. Also, speaking of memory management, Go requires a Garbage Collector, which knowledgeable readers will recognize as a hindrance for performance-critical applications.</p> <p>mediasoup, on the other hand, focuses all of its efforts on maximum efficiency. It is written in C++ , and it is ultra-optimized for the specific task of routing media packets. C++ is a language that provides fully manual management of all resources, and direct access to the hardware, with the benefit of software that is as fast as it can be on any machine.</p> <p>We believe that by combining the best of the LiveKit stack with a top-notch WebRTC engine like mediasoup, OpenVidu is the best option for those who need a self-hosted and high-performance real-time solution.</p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/performance/#limitations","title":"Limitations","text":"<p>OpenVidu developers are hard at work with integrating mediasoup as a WebRTC engine within LiveKit, aiming to provide feature parity with the original Pion engine.</p> <p>Currently there are two client SDK events  that are not triggered when using mediasoup:</p> <ul> <li>No <code>ConnectionQualityChanged</code> event (LiveKit JS reference ).</li> <li>No <code>TrackStreamStateChanged</code> event (LiveKit JS reference ).</li> </ul> <p>Also, there are other limitations that must be taken into account:</p> <ul> <li>All clients will use VP8 video codec.</li> <li>Ingress will force VP8 video codec and will disable simulcast.</li> <li>Screen sharing with simulcast may result in low-resolution video. It is recommended to disable simulcast for screen sharing video tracks to ensure good quality.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/performance/#benchmarking","title":"Benchmarking","text":"<p>Numerous load tests have been performed to determine the true capabilities of OpenVidu on different hardware. To do so we have developed the tool Openvidu LoadTest : an in development project that aims to improve the precision of load and performance tests in WebRTC systems.</p> <p>We have compared OpenVidu using the original Pion WebRTC engine (this is the default LiveKit Open Source implementation) and using mediasoup as WebRTC engine. We tested the performance for both cases in the scenario below.</p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/performance/#results-conference-rooms","title":"Results: Conference rooms","text":"<p>This tests increasingly adds Rooms of 8 Participants each, every one sending 1 video Track and 1 audio Track, and subscribing to all remote Tracks.</p> <p>The following plot shows the number of Participants that can be added to a Room in OpenVidu using Pion and using mediasoup as WebRTC engines:</p> <p></p> <p>The conclusion is that for multiple Rooms, mediasoup performs much better than Pion, almost doubling the total number of Participants (and Tracks) that fit in the server.</p> <p>Below there is the deatiled connection progression for each Participant in each test.</p> <p>The X axis reflects the point of time in seconds. For each Participant there is a bar indicating its connection status:</p> <ul> <li>An orange bar indicates that the browser is up, but the connection to the media server is still in progress.</li> <li>A green bar indicates that the connection is up and running.</li> <li>A red bar indicates that the connection has failed, indicating the time that it's down.</li> </ul> <p>CPU load of the server is also shown with a black marked plot (from 0 to 1, representing 0% to 100% CPU load).</p> <p></p> Progression of the connection of each Participant through the test execution. Benchmark test for Rooms with 8 Participants using OpenVidu with Pion <p></p> Progression of the connection of each Participant through the test execution. Benchmark test for Rooms with 8 Participants using OpenVidu with mediasoup","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/performance/#benchmarking-technical-details","title":"Benchmarking technical details","text":"<ul> <li>Each participant sending video and audio to the media server uses the following video in loop: Video . The video is in <code>YUV4MPEG2</code> format and with a <code>640x480</code> resolution. The audio is in WAV format: Audio .</li> <li>All tests were done using AWS EC2 instances. The media server runs with a <code>m6in.xlarge</code> instance type, an instance type with 4 vCPUs and better network capabilities compared to other instance types.</li> <li>The workers running the browsers that act as participants ran in <code>c5.xlarge</code> instances, an instance type with 4 vCPUs with better computing capabilities.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/performance/#benchmarking-methodology","title":"Benchmarking methodology","text":"<p>Each test begins with no participants on the media server. First, the test controller creates EC2 instances to host the browsers. The controller then sends a request to create a number of participants (this number is known as the batch size). After each browser sends confirmation to the controller that it is connected, the controller sends another request to add more participants (as many participants as the batch size specifies). A participant is considered connected to the room if:</p> <ul> <li>If the participants sends video and audio, the participant is connected after confirming that both local tracks are being sent correctly.</li> <li>If the participant acts as viewer (is only receiving video and audio from a different participant), the participant is connected when it confirms that it is receiving at least both tracks from a user in the room.</li> </ul> <p>The test stops when it determines that no more users can be added to a room. This happens when a user has 5 failed connections. A connection is considered to have failed when it terminates with a fatal error (in LiveKit this is captured when a <code>Disconnected</code>  event occurs) or when the connection times out. A failure in connection can occur when trying to join a room (ending usually in timeout) or during the connection (a <code>Disconnected</code> event is thrown). Each time a failure is communicated to the controller, it will kill that browser and restart it again, effectively restarting the connection (up to 5 times, as mentioned before).</p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/performance/#about-openvidu-loadtest","title":"About OpenVidu LoadTest","text":"<p>Tools like livekit-cli  simulate participants directly using WebRTC SDKs, but we found out that real browsers add significantly more load than these kind of systems. This makes Openvidu LoadTest give results that are closer to real-world scenarios. Using real browsers also allows for the collection of useful data related to connections, events and WebRTC statistics. On the other hand, tests performed with Openvidu LoadTest are more expensive, as they require real instances to host the browsers.</p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/scalability/","title":"Scalable","text":"","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/scalability/#scalability","title":"Scalability","text":"<p>Scalability is a very broad term with implications on many levels. In the case of real-time applications, it usually refers to the number of simultaneous Rooms you can host and the maximum number of participants in each Room, or more accurately, the number of media tracks sent and received in each Room.</p> <p>OpenVidu offers scalability out-of-the-box for typical videoconferencing use cases, but also for large low-latency live streams with hundreds of viewers. With OpenVidu Elastic and OpenVidu High Availability you can easily scale your deployment to host many simultaneous videoconferences and live streams. And it is also possible to scale automatically with our autoscaling feature, so you can truly adapt your resources to the demand.</p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/scalability/#scalability-depending-on-the-use-case","title":"Scalability depending on the use case","text":"","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/scalability/#small-and-medium-videoconferences","title":"Small and medium videoconferences","text":"<p>OpenVidu allows you to host multiple small and medium videoconferences (up to 10 participants). The number of simultaneous rooms depends on the deployment used and the power of machines.</p> <ul> <li> <p>Single Node deployment (OpenVidu Community): In this deployment, OpenVidu can manage up to 50 simultaneous videoconferences of 8 participants in a 4 CPU server. If you need more videoconferences at the same time, you can use more powerful server. This is known as vertical scalability. The limit here is usually the maximum computational power available for a single server and the maximum network bandwidth for it. You can read more about this benchmark scenario in the Performance benchmarks page.</p> </li> <li> <p>Elastic and High Availability deployments (OpenVidu Pro): In these deployments, OpenVidu is able to distribute the videoconferences in multiple media servers. This is known as horizontal scalability. In this case, the maximum number of simultaneous videoconferences depends on the number of media server used and the computational power of each of them. Also, other services used to coordinate and monitor the media servers (caches, data bases, proxies) can themselves become bottlenecks and limit the capacity of the system. In High Availability deployments, these services are distributed in 4 master nodes, so it is able to handle more load than in the Elastic deployment (with only 1 master node).</p> </li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/scalability/#big-live-streams","title":"Big live streams","text":"<p>Live streaming is different from a video conference. In a videoconference, usually all participants can publish audio and video. Instead, in a live stream, only one participant can publish audio and video (known as the publisher) and others can view it (known as viewers).</p> <p>OpenVidu is able to manage live streams with up to 1000 viewers (1 publisher and 1000 subscribers) in a single Room hosted in a server with 4 CPUs. To manage more than one live stream simultaneously, an Elastic or High Availability deployment is needed with several media servers.</p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/scalability/#big-videoconferences-and-massive-live-streams-working-on-it","title":"Big videoconferences and massive live streams (Working on it! )","text":"<p>For big videoconferences with many participants (in the order of 100- or even 1000-) and massive live streams with few publishers and thousands of viewers, OpenVidu will offer in the near future two distinct strategies:</p> <ul> <li>Distributing participants of one Room in multiple servers: By connecting multiple media servers between them, OpenVidu will be able to manage Rooms with unlimited number of participants and live streams with unlimited number of viewers.</li> <li>Only show last speakers: A browser or mobile app is able to show a limited number of participants. A powerful computer can visualize up to 10 simultaneous videoconference participants at the same time with high video quality. To allow big videoconferences, OpenVidu will provide features on its frontend SDKs to show only last speakers in the videoconference.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/scalability/#load-balancing-strategies-across-media-nodes","title":"Load balancing strategies across Media Nodes","text":"<p>In OpenVidu Elastic and OpenVidu High Availability, work is distributed across multiple Media Nodes. The distribution strategy varies depending on the type of job.</p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/scalability/#rooms","title":"Rooms","text":"<p>The Room allocation strategy can be configured in the <code>livekit.yaml</code> configuration file. Specifically, property <code>node_selector</code> defines the strategy to select the Media Node where a new Room will be hosted:</p> livekit.yaml<pre><code>node_selector:\n    kind: any # [any, cpuload, sysload]\n    sort_by: sysload # [random, sysload, cpuload, rooms, clients, tracks, bytespersec]\n    cpu_load_limit: 0.9 # used with kind cpuload\n    sysload_limit: 0.9 # used with kind sysload\n</code></pre> <p>Upon a new Room creation request:</p> <ol> <li> <p>First, property <code>kind</code> acts as a filter to remove non-eligible nodes:</p> <code>kind</code> Description any All nodes are eligible. cpuload Only nodes with CPU load below <code>cpu_load_limit</code> are eligible. cpuload states the current CPU load of the node. This is the default option. sysload Only nodes with system load below <code>sysload_limit</code> are eligible. sysload smooths CPU spikes in comparison to cpuload, as it takes the average load of the system in the last minute. </li> <li> <p>Then, property <code>sort_by</code> defines how to sort the eligible nodes. The first node in the sorted list will be chosen to host the new Room:</p> <code>sort_by</code> Description random A random node will be selected. cpuload The node with the lowest CPU load will be selected. This is the default option. sysload The node with the lowest system load will be selected. rooms The node with the lowest total number of Rooms hosted will be selected. clients The node with the lowest total number of clients connected will be selected. tracks The node with the lowest total number of media tracks being processed will be selected. bytespersec The node with the lowest bandwidth will be selected. <p>Room allocation never fails, as long as there is at least one Media Node connected to the cluster. Limits <code>cpu_load_limit</code> and <code>sysload_limit</code> will simply be ignored if no node is eligible.</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/scalability/#egress","title":"Egress","text":"<p>Info</p> <p>Check out the official Egress documentation of LiveKit here .</p> <p>The Egress allocation strategy can be configured in the <code>egress.yaml</code> configuration file. </p> egress.yaml<pre><code>cpu_cost:\n    max_cpu_utilization: 0.8\n    room_composite_cpu_cost: 2.0\n    audio_room_composite_cpu_cost: 1.0\n    web_cpu_cost: 2.0\n    audio_web_cpu_cost: 0.5\n    participant_cpu_cost: 1.0\n    track_composite_cpu_cost: 1.0\n    track_cpu_cost: 0.5\n\nopenvidu:\n    allocation_strategy: cpuload # [cpuload, binpack]\n</code></pre> <p>Upon a new Egress request:</p> <ol> <li> <p>First, OpenVidu filters eligible Media Nodes. A Media Node is eligible to host a new Egress request if:</p> <ol> <li>Its CPU load is below a certain threshold (by default 80%).</li> <li>It has enough free CPUs to handle the new Egress. The amount of free CPUs required depends on the type of Egress (room composite egress, web egress, participant egress, track composite egress, track egress). </li> </ol> <p>Sane defaults are provided by OpenVidu, but you can configure both the CPU load threshold and the amount of free CPUs required for each type of Egress in the <code>cpu_cost</code>:</p> egress.yaml<pre><code>cpu_cost:\n    max_cpu_utilization: 0.8\n    room_composite_cpu_cost: 2.0\n    audio_room_composite_cpu_cost: 1.0\n    web_cpu_cost: 2.0\n    audio_web_cpu_cost: 0.5\n    participant_cpu_cost: 1.0\n    track_composite_cpu_cost: 1.0\n    track_cpu_cost: 0.5\n</code></pre> </li> <li> <p>Then, OpenVidu chooses from the pool of eligible nodes the best one according to property <code>openvidu.allocation_strategy</code>:</p> egress.yaml<pre><code>openvidu:\n    allocation_strategy: cpuload # [cpuload, binpack]\n</code></pre> <code>sort_by</code> Description cpuload The node with the lowest CPU load will be selected. This strategy helps distributing the CPU load evenly across all available nodes. This is the default option. binpack Some node already hosting at least one Egress will be selected. If all eligible nodes are idle, a random one will be chosen. This strategy helps filling up nodes before assigning work to new ones. </li> <li> <p>If no Media Node is eligible, the Egress request fails with a <code>503 Service Unavailable</code> error.</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/scalability/#egress-cpu-overload-killer","title":"Egress CPU overload killer","text":"<p>By default the Egress service has the ability to automatically kill active egresses under high CPU load. If a &gt;95% CPU load is sustained over 10 seconds, the Egress service will automatically terminate the most CPU-intensive active egress.</p> <p>This helps preventing an egress process from overloading the entire Media Node. Nonetheless, this feature can be disabled by setting property <code>openvidu.disable_cpu_overload_killer</code> to <code>true</code> in the <code>egress.yaml</code> configuration file:</p> egress.yaml<pre><code>openvidu:\n    disable_cpu_overload_killer: true\n</code></pre>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/scalability/#ingress","title":"Ingress","text":"<p>Info</p> <p>Check out the official Ingress documentation of LiveKit here .</p> <p>The Ingress allocation strategy is fixed and cannot be changed. Upon a new Ingress request:</p> <ol> <li> <p>First, OpenVidu filters eligible Media Nodes. A Media Node is eligible to host a new Ingress request if it has enough free CPUs to handle it. The amount of free CPUs required depends on the type of Ingress (RTMP, WHIP, URL). Sane defaults are provided by OpenVidu, but you can tweak these values by modifying the following properties in the <code>ingress.yaml</code> configuration file:</p> ingress.yaml<pre><code>cpu_cost:\n    rtmp_cpu_cost: 2.0\n    whip_cpu_cost: 2.0\n    whip_bypass_transcoding_cpu_cost: 0.1\n    url_cpu_cost: 2.0\n    min_idle_ratio: 0.3\n</code></pre> </li> <li> <p>Then, OpenVidu chooses a random Media Node among the eligible ones. If no Media Node is eligible, the Ingress request fails with a <code>503 Service Unavailable</code> error.</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/scalability/#agents","title":"Agents","text":"<p>For AI agents the allocation strategy varies depending if the Agent is an OpenVidu agent or a custom agent.</p> <ul> <li> <p>For OpenVidu agents: the agent will be available to process a new request if the CPU load of its Media Node is below a threshold. The default threshold is 70%, but you can change it in the agent's YAML configuration file. For example, for the Speech Processing Agent, you can change it in  <code>agent-speech-processing.yaml</code>:</p> agent-speech-processing.yaml<pre><code># Maximum CPU load threshold for the agent to accept new jobs. Value between 0 and 1.\nload_threshold: 0.7\n</code></pre> </li> <li> <p>When developing a custom agent: the agent will be available to process a new request if its load does not exceed a specific threshold. Both the load metric and its threshold have the same defaults as for OpenVidu agents (average CPU load must be below 70%), but you can customize them in the <code>WorkerOptions</code> when developing your agent:</p>  Python Node.js <pre><code># Called to determine the current load of the worker. Must return a value between 0 and 1\ndef custom_load_function(worker: Worker) -&gt; float:\n    ...\n    return load_value\n\nworker_options = WorkerOptions(\n    ...\n    load_fnc=custom_load_function,\n    load_threshold=0.7,  # Maximum load to consider the worker available\n    ...\n)\n</code></pre> <pre><code>// Called to determine the current load of the worker. Must return a value between 0 and 1\nconst customLoadFunction = (worker: Worker): Promise&lt;number&gt; =&gt; {\n    ...\n    return loadValue;\n};\n\nconst workerOptions = {\n    ...\n    loadFunc: customLoadFunction,\n    loadThreshold: 0.7,  // Maximum load to consider the worker available\n    ...\n};\n</code></pre> </li> </ul> <p>In both cases, OpenVidu will assign the request to a random available agent. If no agent is available, the request will be ignored. The log of the OpenVidu Server service will show an INFO message stating <code>not dispatching agent job since no worker is available</code>.</p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/scalability/#autoscaling","title":"Autoscaling","text":"<p>OpenVidu Elastic and OpenVidu High Availability have multiple Media Nodes to handle the load.</p> <ul> <li>Rooms, Egress, Ingress and Agents are distributed across the Media Nodes according to different allocation strategies. Some strategies are configurable, others are fixed, but all of them have sane defaults  (see Load balancing strategies across Media Nodes).</li> <li>It is possible to dynamically add new Media Nodes to the cluster when the load increases. New nodes will automatically start accepting new jobs according to the allocation strategies.</li> <li>It is possible to dynamically remove Media Nodes from the cluster when the load decreases. If the Media Node is hosting ongoing jobs (Rooms, Egresses, Ingresses or Agents), it will enter in a draining state in which it will not accept new jobs, but will continue processing the ongoing ones until they finish. At that point, the Media Node will be removed from the cluster.</li> </ul> <p>The deployment environment determines how the autoscaling is managed:</p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/scalability/#autoscaling-in-cloud-providers","title":"Autoscaling in cloud providers","text":"<p>When deploying in a supported cloud provider using our official templates, OpenVidu will automatically add and remove Media Nodes according to load. Depending on the cloud provider:</p>  AWS Azure <p>Deploy OpenVidu using our official CloudFormation template:</p> <ul> <li>OpenVidu Elastic in AWS</li> <li>OpenVidu High Availability in AWS</li> </ul> <p>The cluster scales automatically thanks to AWS Auto Scaling Groups . You can configure the Auto Scaling Group parameters when deploying the CloudFormation stack, in section Media Nodes Autoscaling Group Configuration.</p> Media Nodes Autoscaling Group Configuration <p>Parameters in this section look like this:</p> <p></p> <p>The InitialNumberOfMediaNodes parameter specifies the initial number of Media Nodes to deploy. The MinNumberOfMediaNodes and MaxNumberOfMediaNodes parameters specify the minimum and maximum number of Media Nodes that you want to be deployed.</p> <p>The ScaleTargetCPU parameter specifies the target CPU utilization to trigger the scaling up or down. The goal is to keep the CPU utilization of the Media Nodes close to this value. The autoscaling policy is based on Target Tracking Scaling Policy .</p> <p>Deploy OpenVidu using our official ARM template:</p> <ul> <li>OpenVidu Elastic in Azure</li> <li>OpenVidu High Availability in Azure</li> </ul> <p>The cluster scales automatically thanks to Azure Virtual Machine Scale Sets . You can configure the Scale Set parameters when deploying the ARM template, in section Media Nodes Scaling Set Configuration.</p> Media Nodes Scaling Set Configuration <p>Parameters in this section look like this:</p> <p></p> <p></p> <p>The Initial Number Of Media Nodes parameter specifies the initial number of Media Nodes to deploy. The Min Number Of Media Nodes and Max Number Of Media Nodes parameters specify the minimum and maximum number of Media Nodes that you want to be deployed.</p> <p>The Scale Target CPU parameter specifies the target CPU utilization to trigger the scaling up or down. The goal is to keep the CPU utilization of the Media Nodes close to this value. The autoscaling policy is based on Azure Monitor autoscale metrics .</p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/scalability/#autoscaling-on-premises","title":"Autoscaling On Premises","text":"<p>When deploying an OpenVidu cluster On Premises you are responsible of monitoring the load of your Media Nodes and triggering the addition of new Media Nodes or removal of existing Media Nodes. Depending on your OpenVidu deployment type, you can do so like this:</p> <ul> <li>For OpenVidu Elastic On Premises:<ul> <li>Add a new Media Node</li> <li>Removing Media Nodes gracefully</li> <li>Removing Media Nodes forcefully</li> </ul> </li> <li>For OpenVidu High Availability On Premises:<ul> <li>Adding Media Nodes</li> <li>Removing Media Nodes gracefully</li> <li>Removing Media Nodes forcefully</li> </ul> </li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/observability/","title":"Observability","text":"","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/observability/#observability","title":"Observability","text":"<p>Any production software needs to be observable. But in real-time applications this becomes an absolute priority. You must be able to:</p> <ul> <li> Detect and solve networking issues that may prevent your users from connecting to your Rooms.</li> <li> Monitor the quality of the video and audio streams, that will reflect in your users' experience.</li> <li> Analyze the load in your hardware to detect bottlenecks and scale your deployment accordingly.</li> <li> Store historical data to analyze past issues and trends to make future decisions based on them.</li> </ul> <p>OpenVidu brings everything you need to fulfill these requirements. We collect events, metrics and logs from your deployment and provide OpenVidu Dashboard and a Grafana stack to navigate them.</p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/observability/grafana-stack/","title":"Grafana Stack","text":"","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/observability/grafana-stack/#grafana-stack","title":"Grafana Stack","text":"<p>OpenVidu also provides different Grafana dashboards to monitor metrics from OpenVidu Server and logs from your cluster.</p> <p>Grafana is available at https://your.domain/grafana/ and can be accessed using your Grafana admin credentials.</p> <p></p> <p>Dashboards can be found in the OpenVidu folder at https://your.domain/grafana/dashboards/f/openvidu-dashboards/openvidu.</p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/observability/grafana-stack/#services","title":"Services","text":"<p>The Grafana stack that comes with OpenVidu is composed of the following services:</p> <ul> <li>Grafana : Tool for querying, visualizing, alerting on and exploring metrics, logs and traces. It queries different data sources to show data in beautiful dashboards. In OpenVidu, contains all dashboards built from Mimir/Prometheus and Loki data sources to monitor OpenVidu Server and logs from your cluster.</li> <li>Prometheus : System monitoring and alerting toolkit. It collects and stores metrics from different targets as time series data. In OpenVidu, it collects metrics from OpenVidu Server of each Media Node and sends them to Mimir.</li> <li>Mimir: Grafana software project that provides multi-tenant, long-term storage for Prometheus metrics. In OpenVidu, it is used to store metrics collected by Prometheus.</li> <li>Promtail: Agent that ships the contents of local logs to a Loki instance. In OpenVidu, it is used to collect logs from all services in your cluster and send them to Loki.</li> <li>Loki: Horizontally-scalable, highly-available, multi-tenant log aggregation system inspired by Prometheus. In OpenVidu, it is used to store logs collected by Promtail.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/observability/grafana-stack/#dashboards","title":"Dashboards","text":"","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/observability/grafana-stack/#openvidu-server-metrics","title":"OpenVidu Server Metrics","text":"<p>This dashboard provides metrics about OpenVidu Server. It includes charts about active rooms, active participants, published tracks, subscribed tracks, send/receive bytes, packet loss percentage and quality score.</p> <p>In case you are using OpenVidu PRO and you have more than one Media Node deployed, you will see all metrics from all nodes combined in the same chart.</p> <p></p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/observability/grafana-stack/#openvidu-media-nodes-server-metrics","title":"OpenVidu Media Nodes Server Metrics","text":"<p>This dashboard is part of OpenVidu PRO edition.</p> <p>This dashboard provides the same metrics as the OpenVidu Server Metrics dashboard, but grouped by Media Node.</p> <p>You can select the Media Node you want to see metrics from in the media_node dropdown. You will see different charts in the same panel according to the selected Media Nodes.</p> <p></p> <p>Info</p> <p>If you add new Media Nodes to your OpenVidu deployment, you will have to refresh the page in order to see the new Media Nodes in the dropdown.</p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/observability/grafana-stack/#openvidu-logs","title":"OpenVidu Logs","text":"<p>In case you are using OpenVidu COMMUNITY, this dashboard provides different visualizations for logs from your OpenVidu Single Node deployment.</p> <p>There is a panel showing all containers logs,</p> <p></p> <p>another panel to filter logs by room_id and participant_id,</p> <p></p> <p></p> <p>and one row for each selected service, containing all logs, warnings and errors from that service.</p> <p></p> <p></p> <p>You can also filter logs containing a specific text by using the filter search box.</p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/observability/grafana-stack/#openvidu-cluster-nodes-logs","title":"OpenVidu Cluster Nodes Logs","text":"<p>This dashboard is part of OpenVidu PRO edition.</p> <p>In case you are using OpenVidu PRO, this dashboard provides different visualizations for logs from your OpenVidu Elastic or OpenVidu High Availability cluster, grouped by node.</p> <p>First of all, there is a panel showing all containers logs from all nodes.</p> <p></p> <p>Then, there is a row for each selected node, containing all logs, warnings and errors from that node. Besides, each row contains a panel for each selected container, showing all its logs.</p> <p></p> <p></p> <p></p> <p></p> <p>Info</p> <p>Note that some panels have no data. This is because some containers are running in Master Nodes and others in Media Nodes.</p> <p></p> <p></p> <p>You can also filter logs containing a specific text by using the filter search box.</p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/observability/grafana-stack/#openvidu-cluster-services-logs","title":"OpenVidu Cluster Services Logs","text":"<p>This dashboard is part of OpenVidu PRO edition.</p> <p>In case you are using OpenVidu PRO, this dashboard provides different visualizations for logs from your OpenVidu Elastic or OpenVidu High Availability cluster, grouped by service.</p> <p>First of all, there is a panel to filter logs by room_id and participant_id.</p> <p></p> <p></p> <p>Then, there is a row for each selected service, containing all logs, warnings and errors from that service.</p> <p></p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/observability/grafana-stack/#limitations","title":"Limitations","text":"<p>For now, in OpenVidu High Availability deployments, we have decided to not implement Grafana in High Availability (HA) mode. This decision is based on the fact that Grafana needs a configured HA MySQL or PostgreSQL database to work in HA mode, and we want to keep the deployment as simple as possible.</p> <p>There are 4 instances of Grafana in an OpenVidu High Availability deployment, one for each Master Node, but they are not synchronized between them. Therefore, if you make any change (change your admin password, create a new dashboard...) in one Grafana instance and the Master Node suddenly goes down, you will be redirected to another Grafana instance where the changes will not be reflected. That is the reason why we disable user signups and saving dashboard or datasource modifications in Grafana.</p> <p>However, all metrics and logs from all nodes are available in all Grafana instances, so you can monitor your OpenVidu cluster without any problem.</p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/observability/openvidu-dashboard/","title":"OpenVidu Dashboard","text":"","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/observability/openvidu-dashboard/#openvidu-dashboard","title":"OpenVidu Dashboard","text":"<p>It is a web application designed to provide OpenVidu administrators with a comprehensive view of usage statistics and real-time monitoring of video Rooms. OpenVidu Dashboard is included by default in any OpenVidu deployment.</p> <p>To access OpenVidu Dashboard, go to https://your.domain/dashboard/ and log in using your admin credentials.</p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/observability/openvidu-dashboard/#views","title":"Views","text":"","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/observability/openvidu-dashboard/#analytics","title":"Analytics","text":"<p>Display graphical analytics for client SDKs, connection types, bandwidth usage, unique participants, rooms and egresses created over different time periods (last 24 hours, last 7 days, last 28 days or current month).</p> <p></p> <p></p> <p></p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/observability/openvidu-dashboard/#rooms","title":"Rooms","text":"<p>Review the total count of active rooms and active participants, along with a roster of currently active rooms and a history of closed rooms within the last 28 days. Detailed information on each room is accessible by clicking on the respective row.</p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/observability/openvidu-dashboard/#room-details","title":"Room Details","text":"<p>This view is part of OpenVidu PRO edition.</p> <p>Retrieve in-depth information about a specific room, including its duration, bandwidth consumption, participants and related events. A chart illustrating the active participants count over time is also provided.</p> <p></p> <p></p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/observability/openvidu-dashboard/#participant-details","title":"Participant Details","text":"<p>This view is part of OpenVidu PRO edition.</p> <p>Obtain detailed insights into each participant, covering their duration, bandwidth usage, average audio and video quality score, information about the client they are connecting with, connection stats, published tracks and related events.</p> <p></p> <p></p> <p>A participant may connect and disconnect from a room multiple times while it remains open. Each instance of connection using the same participant identity is referred to as a <code>participant session</code>. If multiple sessions occur, we will aggregate all participant sessions together and organize them into a timeline at the top of the participant details view. You can easily switch between participant sessions by clicking on each corresponding row:</p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/observability/openvidu-dashboard/#egress-ingress","title":"Egress-Ingress","text":"<p>Review an overview of all egresses and ingresses, including their duration and status. Detailed information for each egress or ingress can be accessed by clicking on the respective row.</p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/observability/openvidu-dashboard/#egress-details","title":"Egress Details","text":"<p>This view is part of OpenVidu PRO edition.</p> <p>Access comprehensive details about a specific egress, including its duration, current status, type, associated room, destinations, status timeline and request information.</p> <p></p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/production-ready/observability/openvidu-dashboard/#ingress-details","title":"Ingress Details","text":"<p>This view is part of OpenVidu PRO edition.</p> <p>Explore detailed information about a specific ingress, including its total duration, status and a list of all associated rooms.</p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/","title":"OpenVidu Single Node Community","text":"","tags":["Platform"]},{"location":"docs/self-hosting/single-node/#openvidu-single-node-community-installation","title":"OpenVidu Single Node COMMUNITY installation","text":"<p>OpenVidu Single Node COMMUNITY is a production-ready deployment option that provides all the necessary features for running real-time applications with medium user load.</p> <p>Install OpenVidu Single Node COMMUNITY in your preferred environment:</p> <ul> <li>On-premises installation: set up on your own servers.</li> <li>AWS installation: deploy to Amazon Web Services.</li> <li>Azure installation: deploy to Microsoft Azure.</li> <li>Google Cloud Platform installation: deploy to Google Cloud Platform.</li> </ul> <p>Once your deployment is complete, refer to the following sections for configuration and management:</p> <ul> <li>On-premises: configuration and administration</li> <li>AWS: configuration and administration</li> <li>Azure: configuration and administration</li> <li>Google Cloud Platform: configuration and administration</li> </ul> <p>If you want to upgrade your OpenVidu Single Node COMMUNITY installation, refer to this section:</p> <ul> <li>On-premises: upgrade OpenVidu Single Node Community</li> <li>AWS: upgrade OpenVidu Single Node Community</li> <li>Azure: upgrade OpenVidu Single Node Community</li> <li>Google Cloud Platform: upgrade OpenVidu Single Node Community</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/aws/admin/","title":"OpenVidu Single Node administration on AWS","text":"","tags":["Platform"]},{"location":"docs/self-hosting/single-node/aws/admin/#openvidu-single-node-community-administration-aws","title":"OpenVidu Single Node COMMUNITY administration: AWS","text":"<p>AWS deployment of OpenVidu Single Node is internally identical to the on-premises deployment, so you can follow the same instructions from the On Premises Single Node for administration and configuration. The only difference is that the deployment is automated with AWS CloudFormation.</p> <p>However, there are certain things worth mentioning:</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/aws/admin/#start-and-stop-openvidu-through-aws-console","title":"Start and stop OpenVidu through AWS Console","text":"<p>You can start and stop all services as explained in the On Premises Single Node section. But you can also start and stop the EC2 instance directly from the AWS Console. This will stop all services running in the instance and reduce AWS costs.</p> Stop OpenVidu Single NodeStart OpenVidu Single Node <ol> <li>Go to the EC2 Dashboard  of AWS.</li> <li>Right-click on the instance you want to start and select \"Stop instance\".</li> </ol> <p></p> <p></p> <ol> <li>Go to the EC2 Dashboard  of AWS.</li> <li>Right-click on the instance you want to start and select \"Start instance\".</li> </ol> <p></p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/aws/admin/#change-the-instance-type","title":"Change the instance type","text":"<p>You can change the instance type of the OpenVidu Single Node instance to adapt it to your needs. To do this, follow these steps:</p> <ol> <li>Stop the instance.</li> <li> <p>Right-click on the instance and select \"Instance Settings &gt; Change Instance Type\".</p> Change instance type <p></p> <p></p> </li> <li> <p>Select the new instance type and click on \"Apply\".</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/aws/admin/#administration-and-configuration","title":"Administration and configuration","text":"<p>For administration, you can follow the instructions from the On Premises Single Node Administration section.</p> <p>Regarding the configuration, in AWS it is managed similarly to an on-premises deployment. For detailed instructions, please refer to the Changing Configuration section. Additionally, the How to Guides offer multiple resources to assist with specific configuration changes.</p> <p>In addition to these, an AWS deployment provides the capability to manage global configurations via the AWS Console using AWS Secrets created during the deployment. To manage configurations this way, follow these steps:</p> Changing Configuration through AWS Secrets <ol> <li>Navigate to the CloudFormation Dashboard  on AWS.</li> <li>Select the CloudFormation Stack that you used to deploy OpenVidu Single Node.</li> <li>In the \"Outputs\" tab, click the Link at \"ServicesAndCredentials\". This will open the AWS Secrets Manager which contains all the configurations of the OpenVidu Single Node deployment.      </li> <li>Click on the \"Retrieve secret value\" button to get the JSON with all the information.      </li> <li>Modify the parameter you want to change and click on \"Save\".</li> <li>Go to the EC2 Console and click on \"Reboot instance\" to apply the changes to the Master Node.      </li> </ol> <p>Changes will be applied automatically.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/aws/install/","title":"OpenVidu Single Node installation on AWS","text":"","tags":["Platform"]},{"location":"docs/self-hosting/single-node/aws/install/#openvidu-single-node-community-installation-aws","title":"OpenVidu Single Node COMMUNITY installation: AWS","text":"<p>This section contains the instructions to deploy a production-ready OpenVidu Single Node COMMUNITY deployment in AWS. Deployed services are the same as the On Premises Single Node installation but automate the process with AWS CloudFormation.</p> <p>First of all, import the template in the AWS CloudFormation console. You can click the following button...</p> <p> Deploy to AWS</p> <p>...or access your AWS CloudFormation console  and manually set this S3 URL in the <code>Specify template</code> section:</p> <pre><code>https://s3.eu-west-1.amazonaws.com/get.openvidu.io/community/singlenode/latest/aws/cf-openvidu-singlenode.yaml\n</code></pre> <p>Info</p> <p>If you want to deploy a specific version of OpenVidu Single Node, replace <code>latest</code> with the version you want to deploy. For example, to deploy version <code>3.4.0</code>, use the following URL:</p> <pre><code>https://s3.eu-west-1.amazonaws.com/get.openvidu.io/community/singlenode/3.4.0/aws/cf-openvidu-singlenode.yaml\n</code></pre> Architecture overview <p>This is how the architecture of the deployment looks like:</p> <p></p> OpenVidu Single Node AWS Architecture <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/aws/install/#cloudformation-parameters","title":"CloudFormation Parameters","text":"<p>Depending on your needs, you need to fill the following CloudFormation parameters:</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/aws/install/#domain-and-ssl-certificate-configuration","title":"Domain and SSL Certificate Configuration","text":"<p>There are three possible scenarios for this section:</p> Let's Encrypt Without Domain NameLet's Encrypt With Domain Name (recommended)Custom CertificatesSelf-Signed Certificate <p>If you don't have a Domain Name and want to quickly test OpenVidu on AWS, you can use this option, simply selecting the CertificateType as letsencrypt and keep the rest of parameters empty.</p> <p>It will deploy OpenVidu with a Let's Encrypt certificate generated using sslip.io based on the public IP created for the deployment.</p> <p></p> <p>For a production environment, it is highly recommended to use this option. It allows you to deploy OpenVidu on AWS with a valid Let's Encrypt certificate for your Fully Qualified Domain Name (FQDN).</p> <p>You need to previously create an Elastic IP and have a Domain Name pointing to that Elastic IP.</p> <p></p> <p>You can specify the DomainName with your FQDN and optionally the PublicElasticIP with the Elastic IP that the domain points to.</p> <p>Opt for this method if you possess your own certificate for an existing FQDN. It enables you to deploy OpenVidu on AWS using your certificates.</p> <p>You need to have a Fully Qualified Domain Name (FQDN) pointing to a previously created Elastic IP.</p> <p>Also, you need a temporary HTTP server hosting your private and public certificate under a specific URL. These URLs are needed for the instance to be able to download and install your certificates.</p> <p>The configured parameters would look like this:</p> <p></p> <p>You need to specify at OwnPublicCertificate and OwnPrivateCertificate the URLs where the public and private certificates are hosted, respectively. The DomainName and PublicElasticIP are mandatory parameters.</p> <p>Certificates need to be in PEM format and the URLs must be accessible from the instance.</p> <p>This option is useful for development and testing purposes. It allows you to deploy OpenVidu on AWS with an autogenerated self-signed certificate. This way, you can quickly set up a secure connection without the need to obtain a certificate from a trusted Certificate Authority (CA).</p> <p>However, this convenience comes with the caveat that users will need to manually accept the certificate in their web browsers. Please be aware that this configuration is solely for developmental and testing purposes and is not suitable for a production environment.</p> <p>These are the parameters needed in this section to use self-signed certificates:</p> <p></p> <p>You can optionally specify a DomainName. If no domain name is provided, sslip.io{:target=\"blank\"} will be used to generate a domain based on the public IP. Just select the CertificateType as _self-signed.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/aws/install/#openvidu-meet-credentials","title":"OpenVidu Meet Credentials","text":"<p>Configure the initial credentials for accessing OpenVidu Meet:</p> OpenVidu Meet credentials <p>Parameters in this section look like this:</p> <p></p> <ul> <li>InitialMeetAdminPassword: Initial password for the \"admin\" user in OpenVidu Meet. If not provided, a random password will be generated and stored in the AWS Secret Manager.</li> <li>InitialMeetApiKey: Initial API key for OpenVidu Meet. If not provided, no API key will be set and the user can configure it later from the Meet Console.</li> </ul> <p>Both parameters are optional. If you don't specify them, you can retrieve the generated credentials from the AWS Secret Manager after deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/aws/install/#ec2-instance-configuration","title":"EC2 Instance Configuration","text":"<p>You need to specify some properties for the EC2 instance that will be created.</p> EC2 Instance configuration <p>Parameters in this section look like this:</p> <p></p> <p>Simply select the type of instance you want to deploy at InstanceType, the SSH key you want to use to access the machine at KeyName, and the Amazon Image ID (AMI) to use at AmiId.</p> <p>By default, the parameter AmiId is configured to use the latest LTS Ubuntu AMI, so ideally you don\u2019t need to modify this.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/aws/install/#s3-bucket-for-application-data-and-recordings","title":"S3 bucket for application data and recordings","text":"<p>You can specify an S3 bucket to store the recordings and application data. If this parameter is not specified, a new S3 bucket will be created by the CloudFormation stack.</p> S3 bucket for application data and recordings <p>Parameters in this section look like this:</p> <p></p> <p>You can specify an existing S3 bucket or leave it empty to create a new one.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/aws/install/#optional-additional-flags","title":"(Optional) Additional flags","text":"<p>Additional optional flags to pass to the OpenVidu installer (comma-separated, e.g., <code>--flag1=value, --flag2</code>).</p> (Optional) Additional flags <p>Parameters in this section look like this:</p> <p></p> <p>For example, you can use <code>--experimental-turn-tls-with-main-domain</code> to use the same domain as the main one for the TURN server with TLS, instead of specifying a different one in the TURN server configuration with TLS section.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/aws/install/#optional-turn-server-configuration-with-tls","title":"(Optional) TURN server configuration with TLS","text":"<p>This section is optional. It is useful when your users are behind a restrictive firewall that blocks UDP traffic. This parameter will only work if you are using <code>letsencrypt</code> or <code>owncert</code> as the CertificateType parameter.</p> <p>Note that if you are not using any Domain Name in the Domain and SSL Certificate Configuration section, this section will be ignored and a generated domain based on the public IP and sslip.io will be used instead.</p> TURN server configuration with TLS <p>Parameters in this section look like this:</p> <p></p> <p>Set the TurnDomainName parameter to the domain name you intend to use for your TURN server. It should be pointing to the <code>PublicElasticIP</code> specified in the previous section.</p> <p>If you are using <code>letsencrypt</code> as the CertificateType parameter, you can leave the TurnOwnPublicCertificate and TurnOwnPrivateCertificate parameters empty. If you are using <code>owncert</code>, you need to specify the URLs where the public and private certificates are hosted.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/aws/install/#deploying-the-stack","title":"Deploying the stack","text":"<p>When you are ready with your CloudFormation parameters, just click on \"Next\", specify in \"Stack failure options\" the option \"Preserve successfully provisioned resources\" to be able to troubleshoot the deployment in case of error, click on \"Next\" again, and finally \"Submit\".</p> <p>When everything is ready, you will see the following links in the \"Outputs\" section of CloudFormation:</p> CloudFormation Outputs <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/aws/install/#configure-your-application-to-use-the-deployment","title":"Configure your application to use the deployment","text":"<p>The Output Key ServicesAndCredentials of the previous section points to an AWS Secret Manager secret that contains all URLs and credentials to access the services deployed. You can access the secret by clicking on the link in the Output Value column.</p> <p>Then, click on Retrieve secret value to get the JSON with all the information.</p> <p></p> <p></p> <p>To use your OpenVidu deployment, check the values of the JSON secret. All access credentials of all services are defined in this object. The most relevant ones are:</p> <p>OpenVidu Meet:</p> <ul> <li><code>OPENVIDU_URL</code>: The URL to access OpenVidu Meet, which is always <code>https://yourdomain.example.io/</code></li> <li><code>MEET_INITIAL_ADMIN_USER</code>: User to access OpenVidu Meet Console. It is always <code>admin</code>.</li> <li><code>MEET_INITIAL_ADMIN_PASSWORD</code>: Password to access OpenVidu Meet Console.</li> <li><code>MEET_INITIAL_API_KEY</code>: API key to use OpenVidu Meet Embedded and OpenVidu Meet REST API.</li> </ul> <p>Note</p> <p>The <code>MEET_INITIAL_ADMIN_USER</code>, <code>MEET_INITIAL_ADMIN_PASSWORD</code>, and <code>MEET_INITIAL_API_KEY</code> values are initial settings that cannot be changed from AWS Secret Manager. They can only be changed from the Meet Console.</p> <p>OpenVidu Platform:</p> <ul> <li><code>LIVEKIT_URL</code>: The URL to use LiveKit SDKs, which can be <code>wss://yourdomain.example.io/</code> or <code>https://yourdomain.example.io/</code> depending on the client library you are using.</li> <li><code>LIVEKIT_API_KEY</code>: API Key for LiveKit SDKs.</li> <li><code>LIVEKIT_API_SECRET</code>: API Secret for LiveKit SDKs.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/aws/install/#troubleshooting-initial-cloudformation-stack-creation","title":"Troubleshooting Initial CloudFormation Stack Creation","text":"<p>If something goes wrong during the initial CloudFormation stack creation, your stack may reach the <code>CREATE_FAILED</code> status for multiple reasons. It could be due to a misconfiguration in the parameters, a lack of permissions, or a problem with the AWS services. When this happens, the following steps can help you troubleshoot the issue and identify what went wrong:</p> <ol> <li> <p>While deploying the stack, make sure at \"Stack failure options\" you have selected the option \"Preserve successfully provisioned resources\" to be able to troubleshoot the deployment in case of an error.</p> Disable Rollback on failure <p></p> <p></p> </li> <li> <p>Check if the EC2 instance or instances are running. If they are not, check the CloudFormation events for any error messages.</p> </li> <li> <p>If the EC2 instance or instances are running, SSH into the instance and check the logs of the following files:</p> <ul> <li><code>/var/log/cloud-init-output.log</code></li> <li><code>/var/log/cloud-init.log</code></li> </ul> <p>These logs will give you more information about the CloudFormation stack creation process.</p> </li> <li> <p>If everything seems fine, check the status and the logs of the installed OpenVidu services.</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/aws/install/#configuration-and-administration","title":"Configuration and administration","text":"<p>When your CloudFormation stack reaches the <code>CREATE_COMPLETE</code> status, your OpenVidu Single Node deployment is ready to use. You can check the Administration section to learn how to manage your deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/aws/upgrade/","title":"Upgrade OpenVidu Single Node COMMUNITY - AWS","text":"","tags":["Platform"]},{"location":"docs/self-hosting/single-node/aws/upgrade/#upgrade-openvidu-single-node-community-aws","title":"Upgrade OpenVidu Single Node COMMUNITY - AWS","text":"<p>In AWS, we recommend upgrading by redeploying the OpenVidu Single Node CloudFormation with the latest version.</p> <p>However, if you prefer to upgrade the OpenVidu Single Node without redeploying, you can follow the steps outlined in the Upgrade OpenVidu Single Node - On Premises section.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/azure/admin/","title":"OpenVidu Single Node administration on Azure","text":"","tags":["Platform"]},{"location":"docs/self-hosting/single-node/azure/admin/#openvidu-single-node-community-administration-azure","title":"OpenVidu Single Node COMMUNITY administration: Azure","text":"<p>Azure OpenVidu Single Node deployments are internally identical to On Premises Single Node deployments, so you can follow the same instructions from On Premises Single Node documentation for administration and configuration. The only difference is that the deployment is automated with ARM Templates from Azure.</p> <p>However, there are certain things worth mentioning:</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/azure/admin/#start-and-stop-openvidu-through-azure-portal","title":"Start and stop OpenVidu through Azure Portal","text":"<p>You can start and stop all services as explained in the On Premises Single Node section. But you can also start and stop the Virtual Machine instance directly from Azure Portal. This will stop all services running in the instance and reduce Azure costs.</p> Stop OpenVidu Single NodeStart OpenVidu Single Node <ol> <li>Go to Azure Portal Dashboard  of Azure and enter into the resource group where you deployed OpenVidu Single Node.</li> <li>There, you will find the Virtual Machine that runs OpenVidu. Its name should be something like yourstackname-VM-CE. Click on it.</li> <li>In the section of the Virtual Machine click on stop button to stop the Virtual Mache (and therefore OpenVidu).</li> </ol> <p></p> <p></p> <ol> <li>Go to Azure Portal Dashboard  of Azure and enter into the resource group where you deployed OpenVidu Single Node.</li> <li>There, you will find the Virtual Machine that runs OpenVidu. Its name should be something like yourstackname-VM-CE.  Click on it.</li> <li>In the section of the Virtual Machine click on start button to start the Virtual Mache (and therefore OpenVidu).</li> </ol> <p></p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/azure/admin/#change-the-instance-type","title":"Change the instance type","text":"<p>You can change the instance type of the OpenVidu Single Node instance to adapt it to your needs. To do this, follow these steps:</p> <ol> <li>Go to Azure Portal Dashboard  of Azure and enter into the resource group where you deployed OpenVidu Single Node.</li> <li>There, you will find the Virtual Machine that runs OpenVidu. Its name should be something like yourstackname-VM-CE. Click on it.</li> <li> <p>In the left pannel click on \"Availability + scale\" -&gt; \"Size\".</p> Change instance type <p></p> <p></p> </li> <li> <p>Select the new instance type and click on \"Resize\".</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/azure/admin/#administration-and-configuration","title":"Administration and configuration","text":"<p>Regarding the administration of your deployment, you can follow the instructions in section On Premises Single Node Administration.</p> <p>Regarding the configuration of your deployment, you can follow the instructions in section Changing Configuration. Additionally, the How to Guides offer multiple resources to assist with specific configuration changes.</p> <p>In addition to these, an Azure deployment provides the capability to manage global configurations via the Azure portal using Key Vault Secrets created during the deployment:</p> Changing configuration through Key Vault secrets <ol> <li>Navigate to the Azure Portal Dashboard  on Azure.</li> <li>Select the Resource Group where you deployed your OpenVidu Single Node Stack.</li> <li>In the \"stackname-keyvault\" resource, click on \"Objects\" -&gt; \"Secrets\" on the left panel. This will show you all the secrets that are stored in the Key Vault of the OpenVidu deployment.      </li> <li>Click on the desired secret you want to change and click on \"New Version\".      </li> <li>Enter the new secret value on \"Secret Value\" filed and click on \"Create\".      </li> <li>Go to the Instance resource of OpenVidu and click on \"Restart\" to apply the changes to the OpenVidu Single Node deployment.      </li> </ol> <p>Changes will be applied automatically.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/azure/install/","title":"OpenVidu Single Node installation on Azure","text":"","tags":["Platform"]},{"location":"docs/self-hosting/single-node/azure/install/#openvidu-single-node-community-installation-azure","title":"OpenVidu Single Node COMMUNITY installation: Azure","text":"<p>This section contains the instructions to deploy a production-ready OpenVidu Single Node deployment in Azure. Deployed services are the same as the On Premises Single Node installation but they will be resources in Azure and you can automate the process with the Template Spec of ARM.</p> <p>To import the template into Azure you just need to click the button below (you will be redirected to Azure).</p> <p></p> Architecture overview <p>This is how the architecture of the deployment looks like:</p> <p></p> OpenVidu Single Node Azure Architecture <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/azure/install/#template-parameters","title":"Template Parameters","text":"<p>To deploy the template you need to fill the following parameters.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/azure/install/#resource-group-and-stack-name","title":"Resource Group and Stack Name","text":"<p>Select your Subscription and the Resource Group where you want to deploy OpenVidu.</p> <p></p> <p>Warning</p> <p>It is highly recommended to deploy OpenVidu in a brand new Azure Resource Group. Reusing an existing Resource Group can lead to conflicts. The only reason to reuse an existing Resource Group is to use the same IP and Azure Blob Storage Account as a previous OpenVidu deployment. The rest of resources are not reusable and should be eliminated before deploying OpenVidu in the same Resource Group.</p> <p>Select the Region and choose a descriptive Stack Name. It will be used as a prefix in the name of all the resources created by the template.</p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/azure/install/#domain-and-ssl-certificate-configuration","title":"Domain and SSL Certificate Configuration","text":"<p>There are three possible scenarios for this section:</p> Let's Encrypt Without Domain NameLet's Encrypt With Domain Name (recommended)Custom CertificatesSelf-Signed Certificate <p>If you don't have a Domain Name and want to quickly test OpenVidu on Azure, you can use this option, simply selecting the Certificate Type as letsencrypt and keep the rest of parameters empty.</p> <p>It will deploy OpenVidu with a Let's Encrypt certificate generated using sslip.io based on the public IP created for the deployment.</p> <p></p> <p>For a production-ready setup, this scenario is ideal when you have an FQDN (Fully Qualified Domain Name) and a Public IP at your disposal. It leverages the services of Let's Encrypt to automatically generate valid certificates.</p> <p>First, you need to have the FQDN pointing to the Public IP you are going to use.</p> <p>Then, you need to fill in the following parameters:</p> <p></p> <p></p> <p>As you can see, you need to specify the Public Ip Address with the Public IP that the domain points to, the Domain Name with your FQDN, and the Lets Encrypt Email with your email address for Let\u2019s Encrypt notifications. These parameters are mandatory.</p> <p>To deploy OpenVidu in Azure under your Fully Qualified Domain Name (FQDN) using already existing certificates, follow this method.</p> <p>You need to have your FQDN pointing to a previously created Public Ip.</p> <p>Also, you need a temporary HTTP server hosting your private and public certificate under a specific URL. These URLs are needed for the instance to be able to securely download and install your certificates.</p> <p>The configured parameters would look like this:</p> <p></p> <p></p> <p>You need to specify at Own Public Certificate and Own Private Certificate the URLs where the public and private certificates are hosted, respectively. The Domain Name, Public Ip Address are mandatory parameters.</p> <p>Certificates need to be in PEM format and the URLs must be accessible from the instance.</p> <p>This is the most straightforward option for deploying OpenVidu on Azure when you do not have a Fully Qualified Domain Name (FQDN). This method allows for the immediate use of OpenVidu with ARM Templates.</p> <p>However, this convenience comes with the caveat that users will need to manually accept the certificate in their web browsers. Please be aware that this configuration is solely for developmental and testing purposes and is not suitable for a real production environment.</p> <p>These are the parameters needed in this section to use self-signed certificates:</p> <p></p> <p></p> <p>You don\u2019t need to specify any parameters; just select the CertificateType as self-signed. The domain name used will be an Azure-generated one.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/azure/install/#openvidu-meet-credentials","title":"OpenVidu Meet Credentials","text":"<p>Configure the initial credentials for accessing OpenVidu Meet:</p> OpenVidu Meet credentials <p>Parameters in this section look like this:</p> <p></p> <ul> <li>InitialMeetAdminPassword: Initial password for the \"admin\" user in OpenVidu Meet. If not provided, a random password will be generated and stored in the Azure Key Vault.</li> <li>InitialMeetApiKey: Initial API key for OpenVidu Meet. If not provided, no API key will be set and the user can configure it later from the Meet Console.</li> </ul> <p>Both parameters are optional. If you don't specify them, you can retrieve the generated credentials from the Azure Key Vault after deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/azure/install/#azure-instance-configuration","title":"Azure Instance Configuration","text":"<p>Specify properties for the Azure instance that will host Openvidu.</p> Azure Instance configuration <p>Parameters in this section look like this:</p> <p></p> <p></p> <p>Simply select the type of instance you want to deploy at Type of Instance. Fill in the parameter Admin Username that will be set as admin username in the instance. Select the SSH key you've created previously in SSH public key source (or you can create a new one in the drop down) to allow you to SSH into the instance.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/azure/install/#storage-account","title":"Storage Account","text":"<p>You need to fill some parameters about the storage account that the deployment will use to save the recordings.</p> <p>Warning</p> <p>Recordings are not available in OpenVidu v2 Compatibility mode (v2compat) for OpenVidu Azure deployments.</p> Azure Storage Account configuration <p>Parameters in this section look like this:</p> <p></p> <p></p> <p>Storage Account Name: leave blank to create a new Storage Account for this deployment. You can specify an already existing Storage Account name  if you want (remember it must belong to the same resource group as your deployment).</p> <p>Container Name is the name that you desire for the container that of the storage account where the recordings will be saved. If you leave it blank it will create the container with name <code>openvidu-appdata</code>.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/azure/install/#optional-additional-flags","title":"(Optional) Additional flags","text":"<p>Additional optional flags to pass to the OpenVidu installer (comma-separated, e.g., <code>--flag1=value, --flag2</code>).</p> (Optional) Additional flags <p>Parameters in this section look like this:</p> <p></p> <p>For example, you can use <code>--experimental-turn-tls-with-main-domain</code> to use the same domain as the main one for the TURN server with TLS, instead of specifying a different one in the TURN server configuration with TLS section.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/azure/install/#optional-turn-server-configuration-with-tls","title":"(Optional) TURN server configuration with TLS","text":"<p>This section is optional. It is useful when your users are behind a restrictive firewall that blocks UDP traffic. This parameter will only work if you are using <code>letsencrypt</code> or <code>owncert</code> as the Certificate Type parameter.</p> TURN server configuration with TLS <p>Parameters in this section look like this:</p> <p></p> <p></p> <p>Set the Turn Domain Name parameter to the domain name you intend to use for your TURN server. It should be pointing to the <code>Public Ip Address</code> specified in the previous section.</p> <p>If you are using <code>letsencrypt</code> as the Certificate Type parameter, you can leave the Turn Own Public Certificate and Turn Own Private Certificate parameters empty. If you are using <code>owncert</code>, you need to specify the URLs where the public and private certificates are hosted.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/azure/install/#deploying-the-stack","title":"Deploying the stack","text":"<p>Whenever you are satisfied with your Template paremeters, just click on \"Next\" to trigger the validation process. If correct, click on \"Create\" to start the deployment process (which will take about 5 to 10 minutes).</p> <p>Warning</p> <p>In case of failure, it might be that some role failed to create. In this case redeploy in a new resource group and change the Stack Name. To remove a role in a resource group visit Remove Azure role assignments .</p> <p>When everything is ready, you can check the output secrets on the Key Vault or by connecting through SSH to the instance:</p> Check deployment outputs in Azure Key VaultCheck deployment outputs in the instance <ol> <li> <p>Go to the Key Vault created called yourstackname-keyvault in the Resource Group that you deployed. You can access it from the Azure Portal Dashboard .</p> </li> <li> <p>Once you are in the Key Vault on the left panel click on \"Objects\" \ud83e\udc52 \"Secrets\".</p> <p></p> <p></p> </li> <li> <p>Here click on the secret of your choice or whatever you need to check and click again in the current version of that secret</p> <p></p> <p></p> </li> <li> <p>Now you will see a lot of properties but the one you are searching for is located at the bottom and it will be revealed by clicking in \"Show Secret Value\".</p> <p></p> <p></p> </li> </ol> <p>SSH to the instance and navigate to the config folder <code>/opt/openvidu/config</code>. Files with the deployment outputs are:</p> <ul> <li><code>openvidu.env</code></li> <li><code>meet.env</code></li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/azure/install/#configure-your-application-to-use-the-deployment","title":"Configure your application to use the deployment","text":"<p>You need your Azure deployment outputs to configure your OpenVidu application. If you have permissions to access the Key Vault you will be able to check there all the outputs (Check deployment outputs in Azure Key Vault). If you don't have permissions to access the Key Vault you can still check the outputs directly in the instance through SSH (Check deployment outputs in the instance).</p> <p>Your authentication credentials and URL to point your applications would be:</p> <p>OpenVidu Meet:</p> <ul> <li><code>OPENVIDU-URL</code>: The URL to access OpenVidu Meet, which is always <code>https://yourdomain.example.io/</code></li> <li><code>MEET-INITIAL-ADMIN-USER</code>: User to access OpenVidu Meet Console. It is always <code>admin</code>.</li> <li><code>MEET-INITIAL-ADMIN-PASSWORD</code>: Password to access OpenVidu Meet Console.</li> <li><code>MEET-INITIAL-API-KEY</code>: API key to use OpenVidu Meet Embedded and OpenVidu Meet REST API.</li> </ul> <p>Note</p> <p>The <code>MEET-INITIAL-ADMIN-USER</code>, <code>MEET-INITIAL-ADMIN-PASSWORD</code>, and <code>MEET-INITIAL-API-KEY</code> values are initial settings that cannot be changed from Azure Key Vault. They can only be changed from the Meet Console.</p> <p>OpenVidu Platform:</p> <ul> <li><code>LIVEKIT-URL</code>: The URL to use LiveKit SDKs, which can be <code>wss://yourdomain.example.io/</code> or <code>https://yourdomain.example.io/</code> depending on the client library you are using.</li> <li><code>LIVEKIT-API-KEY</code>: API Key for LiveKit SDKs.</li> <li><code>LIVEKIT-API-SECRET</code>: API Secret for LiveKit SDKs.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/azure/install/#troubleshooting-initial-azure-stack-creation","title":"Troubleshooting initial Azure stack creation","text":"<p>If something goes wrong during the initial Azure stack creation, your stack may reach some failed status for multiple reasons. It could be due to a misconfiguration in the parameters, a lack of permissions, or a problem with Azure services. When this happens, the following steps can help you troubleshoot the issue and identify what went wrong:</p> <ol> <li>Check if the instance or instances are running. If they are not, check the Azure deployment events for any error messages.</li> <li> <p>If the instance or instances are running, SSH into the instance and check the logs of the following files:</p> <ul> <li><code>/var/log/cloud-init-output.log</code></li> <li><code>/var/log/cloud-init.log</code></li> </ul> <p>These logs will give you more information about the Azure stack creation process.</p> </li> <li> <p>If everything seems fine, check the status and the logs of the installed OpenVidu services.</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/azure/install/#configuration-and-administration","title":"Configuration and administration","text":"<p>When your Azure stack reaches the <code>Succeeded</code> status, it means that all the resources have been created. You will need to wait about 5 to 10 minutes to let the instance install OpenVidu as we mentioned before. When this time has elapsed, try connecting to the deployment URL. If it doesn't work, we recommend checking the previous section. Once finished you can check the Administration section to learn how to manage your deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/azure/upgrade/","title":"Upgrade OpenVidu Single Node COMMUNITY - Azure","text":"","tags":["Platform"]},{"location":"docs/self-hosting/single-node/azure/upgrade/#upgrade-openvidu-single-node-community-azure","title":"Upgrade OpenVidu Single Node COMMUNITY - Azure","text":"<p>In Azure, we recommend upgrading by redeploying OpenVidu Single Node Azure with the latest version.</p> <p>However, if you prefer to upgrade the OpenVidu Single Node without redeploying, you can follow the steps outlined in the Upgrade OpenVidu Single Node - On Premises section.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/gcp/admin/","title":"OpenVidu Single Node administration on Google Cloud Platform","text":"","tags":["Platform"]},{"location":"docs/self-hosting/single-node/gcp/admin/#openvidu-single-node-community-administration-google-cloud-platform","title":"OpenVidu Single Node COMMUNITY administration: Google Cloud Platform","text":"<p>Google Cloud Platform OpenVidu Single Node deployments are internally identical to On Premises Single Node deployments, so you can follow the same instructions from On Premises Single Node documentation for administration and configuration. The only difference is that the deployment is automated with terraform from Google Cloud Platform.</p> <p>However, there are certain things worth mentioning:</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/gcp/admin/#start-and-stop-openvidu-through-google-cloud-platform-console","title":"Start and stop OpenVidu through Google Cloud Platform Console","text":"<p>You can start and stop all services as explained in the On Premises Single Node section. But you can also start and stop the Virtual Machine instance directly from Google Cloud Platform Console. This will stop all services running in the instance and reduce Google Cloud Platform costs.</p> Stop OpenVidu Single NodeStart OpenVidu Single Node <ol> <li>Go to GCP Compute Engine Instances  of Google Cloud Platform.</li> <li>There, you will find the Virtual Machine that runs OpenVidu. Its name should be something like yourstackname-vm-ce. Click on it.</li> <li>In the section of the Virtual Machine click on stop button to stop the Virtual Mache (and therefore OpenVidu).</li> </ol> <p></p> <p></p> <ol> <li>Go to GCP Compute Engine Instances  of Google Cloud Platform.</li> <li>There, you will find the Virtual Machine that runs OpenVidu. Its name should be something like yourstackname-vm-ce.  Click on it.</li> <li>In the section of the Virtual Machine click on start button to start the Virtual Mache (and therefore OpenVidu).</li> </ol> <p></p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/gcp/admin/#change-the-instance-type","title":"Change the instance type","text":"<p>You can change the instance type of the OpenVidu Single Node instance to adapt it to your needs. To do this, follow these steps:</p> <ol> <li>Go to GCP Compute Engine Instances  of Google Cloud Platform.</li> <li>There, you will find the Virtual Machine that runs OpenVidu. Its name should be something like yourstackname-vm-ce. Click on it.</li> <li>Stop the instance if is not stopped. Wait for it to stop.</li> <li> <p>Click on \"Edit\", go down and change the Machine Type.</p> Change instance type <p></p> <p></p> </li> <li> <p>Select the new instance type and click on \"Save\".</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/gcp/admin/#administration-and-configuration","title":"Administration and configuration","text":"<p>Regarding the administration of your deployment, you can follow the instructions in section On Premises Single Node Administration.</p> <p>Regarding the configuration of your deployment, you can follow the instructions in section Changing Configuration. Additionally, the How to Guides offer multiple resources to assist with specific configuration changes.</p> <p>In addition to these, an Google Cloud Platform deployment provides the capability to manage global configurations via the Google Cloud Platform Console using Secrets Manager created during the deployment:</p> Changing configuration through Secrets Manager <ol> <li>Navigate to the GCP Secrets Manager  on Google Cloud Platform.</li> <li>Click on the desired secret you want to change and click on \"New Version\".      </li> <li>Enter the new secret value on \"Secret Value\" filed and click on \"Add new version\".      </li> <li>Go to the Instance resource of OpenVidu and click on Stop -&gt; Start to apply the changes to the OpenVidu Single Node deployment.</li> </ol> <p>Changes will be applied automatically.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/gcp/install/","title":"OpenVidu Single Node installation on Google Cloud Platform","text":"","tags":["Platform"]},{"location":"docs/self-hosting/single-node/gcp/install/#openvidu-single-node-community-installation-google-cloud-platform","title":"OpenVidu Single Node COMMUNITY installation: Google Cloud Platform","text":"<p>Warning</p> <p>Google Cloud Platform deployments are considered in Beta in version 3.4.0 of OpenVidu.</p> <p>This section contains the instructions of how to deploy a production-ready OpenVidu Single Node deployment in Google Cloud Platform. Deployed services are the same as the On Premises Single Node installation but they will be resources in Google Cloud Platform and you can automate the process in the Google Cloud Console.</p> <p>To deploy OpenVidu into Google Cloud Platform you just need to log into your Infrastructure Manager  in the GCP console. Then follow the next steps to fill the parameters of your choice.</p> Architecture overview <p>This is how the architecture of the deployment looks like:</p> <p></p> OpenVidu Single Node Google Cloud Platform Architecture <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/gcp/install/#deployment-details","title":"Deployment details","text":"<p>Info</p> <p>We recommend to create a new project to deploy OpenVidu there, avoiding possible conflicts.</p> <p>To deploy OpenVidu, first you need to create a new deployment in the top left button as you can see in the image.</p> <p></p> <p>Once you click the button you will see this window.</p> <p></p> <p>Fill Deployment ID with any name that you desire like openvidu-singlenode-deployment, next choose the Region that you prefer, leave Terraform version in the 1.5.7 and for Service Account you will need to create a new one with \"Owner\" permissions, in order to do that click on \"Service Account\" label and then into \"New Service Account\", choose your service account name click on \"Create and Continue\" and then select the \"Owner\" role, click on \"Continue\" and the in \"Done\".   </p> <p>For the Git repository put this link <code>https://github.com/OpenVidu/openvidu.git</code> that corresponds to our git repository where are allocated the terraform files to deploy openvidu. In the Git directory introduce the following path <code>openvidu-deployment/community/singlenode/gcp</code> and for the Git ref put <code>3.4.0</code> corresponding to the version then click on continue.   </p> New Service Account Steps <p></p> Step 1: Create Service Account <p></p> <p></p> Step 2: Service Account Details <p></p> <p></p> Step 3: Grant Permissions <p></p> <p></p> Step 4: Complete Setup <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/gcp/install/#input-values","title":"Input Values","text":"<p>In Google Cloud Platform there is no such thing like template with parameters, you will need to introduce by yourself in the console the parameters that are declared in our terraform files, so there is a detailed table of all the optional and non-optional parameters.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/gcp/install/#mandatory-parameters","title":"Mandatory Parameters","text":"Input Value Description projectId GCP project id where the resources will be created. stackName Stack name for OpenVidu deployment.","tags":["Platform"]},{"location":"docs/self-hosting/single-node/gcp/install/#optional-parameters","title":"Optional Parameters","text":"Input Value Default Value Description region \"europe-west1\" GCP region where resources will be created. zone \"europe-west1-b\" GCP zone that some resources will use. certificateType \"letsEncrypt\" Certificate type for OpenVidu deployment. Options:           <ul> <li>[selfsigned] Not recommended for production use. Just for testing purposes or development environments. You don't need a FQDN to use this option.</li> <li>[owncert] Valid for production environments. Use your own certificate. You need a FQDN to use this option.</li> <li>[letsencrypt] Valid for production environments. Can be used with or without a FQDN (if no FQDN is provided, a random sslip.io domain will be used).</li> </ul> publicIpAddress (none) Previously created Public IP address for the OpenVidu Deployment. Blank will generate a public IP. domainName (none) Domain name for the OpenVidu Deployment. ownPublicCertificate (none) If certificate type is 'owncert', this parameter will be used to specify the public certificate. ownPrivateCertificate (none) If certificate type is 'owncert', this parameter will be used to specify the private certificate. initialMeetAdminPassword (none) Initial password for the 'admin' user in OpenVidu Meet. If not provided, a random password will be generated. initialMeetApiKey (none) Initial API key for OpenVidu Meet. If not provided, no API key will be set and the user can set it later from Meet Console. instanceType \"e2-standard-8\" Specifies the GCE machine type for your OpenVidu instance. bucketName (none) Name of the S3 bucket to store data and recordings. If empty, a bucket will be created. additionalInstallFlags (none) Additional optional flags to pass to the OpenVidu installer (comma-separated, e.g., '--flag1=value, --flag2'). turnDomainName (none) (Optional) Domain name for the TURN server with TLS. Only needed if your users are behind restrictive firewalls. turnOwnPublicCertificate (none) (Optional) This setting is applicable if the certificate type is set to 'owncert' and the TurnDomainName is specified. turnOwnPrivateCertificate (none) (Optional) This setting is applicable if the certificate type is set to 'owncert' and the TurnDomainName is specified. <p>For more detail you can check the variables.tf  file to see more information about the inputs.   </p> <p>Warning</p> <p>It's important that you put the input variables with the same name as they appear in the table like in the next image.</p> <p></p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/gcp/install/#deploying-the-stack","title":"Deploying the stack","text":"<p>Whenever you are satisfied with your input values, just click on \"Continue\" and then in \"Create deployment\". Now it will validate the deployment and create all the resources. Wait about 5 to 10 minutes to let the instance install OpenVidu.</p> <p>Warning</p> <p>In case of failure, check the cloud build logs that appears on the top of the screen and redeploy with the changes that are causing the deployment to fail, if it keeps failing contact us.</p> <p></p> <p></p> <p>When everything is ready, you can check the secrets on the Secret Manager  or by connecting through SSH to the instance:</p> Check deployment outputs in Google Cloud Platform Secret ManagerCheck deployment outputs in the instance <ol> <li> <p>Go to the Secret Manager .</p> </li> <li> <p>Once you are in the Secret Manager you will see all the secrets by their name.</p> <p></p> <p></p> </li> <li> <p>Here click on the secret of your choice or whatever you need to check and click again in the last version of that secret.</p> <p></p> <p></p> </li> </ol> <p>SSH to the instance by gcloud command generated in the web console and navigate to the config folder <code>/opt/openvidu/config</code>. Files with the deployment outputs are:</p> <ul> <li><code>openvidu.env</code></li> <li><code>meet.env</code></li> </ul> <p>To find out the command go to Compute Engine Instances  and click on the arrow close to the SSH letters and then \"View gcloud command\". </p> <p></p> <p>To install gcloud in your shell follow the official instructions .</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/gcp/install/#configure-your-application-to-use-the-deployment","title":"Configure your application to use the deployment","text":"<p>You need your Google Cloud Platform secret outputs to configure your OpenVidu application. You can check these secrets by searching in the Secrets Manager with any of these two ways (Check deployment outputs in Google Cloud Platform Secret Manager) or (Check deployment outputs in the instance).</p> <p>Your authentication credentials and URL to point your applications would be:</p> <ul> <li>URL: The value in the Secret Manager of <code>OPENVIDU_URL</code>. In the instance in <code>openvidu.env</code> find <code>DOMAIN_NAME</code> and build it into a URL. The URL would be <code>https://your.domain.name/</code>. If you want the <code>LIVEKIT_URL</code> find the value in the Secret Manager of <code>LIVEKIT_URL</code> or build the URL with the <code>DOMAIN_NAME</code>as <code>wss://your.domain.name/</code>.</li> <li>API Key: The value in the Secret Manager of <code>LIVEKIT_API_KEY</code> or in the instance in <code>openvidu.env</code>.</li> <li>API Secret: The value in the Secret Manager of <code>LIVEKIT-API-SECRET</code> or in the instance in <code>openvidu.env</code>.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/gcp/install/#troubleshooting-initial-google-cloud-platform-deployment-creation","title":"Troubleshooting initial Google Cloud Platform deployment creation","text":"<p>If something goes wrong during the initial GCP deployment creation, your stack may reach some failed status for multiple reasons. It could be due to a misconfiguration in the parameters, a lack of permissions, or a problem with GCP services. When this happens, the following steps can help you troubleshoot the issue and identify what went wrong:</p> <ol> <li>Check if the instance or instances are running. If they are not, check the GCP cloud build logs for any error messages.</li> <li> <p>If the instance or instances are running, SSH into the instance and check the logs by running this command:</p> <ul> <li><code>journalctl -u google-startup-scripts | cat</code></li> </ul> <p>These logs will give you more information about the GCP deployment creation process.</p> </li> <li> <p>If everything seems fine, check the status and the logs of the installed OpenVidu services.</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/gcp/install/#configuration-and-administration","title":"Configuration and administration","text":"<p>When your Google Cloud Platform deployment reaches the <code>Active</code> state, it means that all the resources have been created. You will need to wait about 5 to 10 minutes to let the instance install OpenVidu as we mentioned before. When this time has elapsed, try connecting to the deployment URL. If it doesn't work, we recommend checking the previous section. Once finished you can check the Administration section to learn how to manage your deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/gcp/upgrade/","title":"Upgrade OpenVidu Single Node COMMUNITY - Google Cloud Platform","text":"","tags":["Platform"]},{"location":"docs/self-hosting/single-node/gcp/upgrade/#upgrade-openvidu-single-node-community-google-cloud-platform","title":"Upgrade OpenVidu Single Node COMMUNITY - Google Cloud Platform","text":"<p>In Google Cloud Platform, we recommend upgrading by redeploying OpenVidu Single Node Google Cloud Platform with the latest version.</p> <p>However, if you prefer to upgrade the OpenVidu Single Node without redeploying, you can follow the steps outlined in the Upgrade OpenVidu Single Node - On Premises section.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/on-premises/admin/","title":"OpenVidu Single Node administration on-premises","text":"","tags":["Platform"]},{"location":"docs/self-hosting/single-node/on-premises/admin/#openvidu-single-node-community-administration-on-premises","title":"OpenVidu Single Node COMMUNITY administration: On-premises","text":"<p>The OpenVidu installer offers an easy way to deploy OpenVidu Single Node COMMUNITY on-premises. However, once the deployment is complete, you may need to perform administrative tasks based on your specific requirements, such as changing passwords, specifying custom configurations, and starting or stopping services.</p> <p>This section provides details on configuration parameters and common administrative tasks for this deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/on-premises/admin/#starting-stopping-and-restarting-openvidu","title":"Starting, stopping, and restarting OpenVidu","text":"<p>You can start, stop, and restart the OpenVidu services using the following commands:</p> <p>Start OpenVidu</p> <pre><code>sudo systemctl start openvidu\n</code></pre> <p>Stop OpenVidu</p> <pre><code>sudo systemctl stop openvidu\n</code></pre> <p>Restart OpenVidu</p> <pre><code>sudo systemctl restart openvidu\n</code></pre>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/on-premises/admin/#checking-the-status-of-services","title":"Checking the status of services","text":"<p>You can check the status of the OpenVidu services using the following command:</p> <pre><code>cd /opt/openvidu/\ndocker compose ps\n</code></pre> <p>The services are operating correctly if you see an output similar to the following and there are no restarts from any of the services:</p> <pre><code>NAME         IMAGE                                        COMMAND                  SERVICE      CREATED          STATUS\nmeet         docker.io/openvidu/openvidu-meet             \"docker-entrypoint.s\u2026\"   meet         19 seconds ago   Up 16 seconds\ncaddy        docker.io/openvidu/openvidu-caddy            \"/bin/caddy run --co\u2026\"   caddy        19 seconds ago   Up 16 seconds\ndashboard    docker.io/openvidu/openvidu-dashboard        \"./openvidu-dashboard\"   dashboard    19 seconds ago   Up 16 seconds\negress       docker.io/livekit/egress                     \"/entrypoint.sh\"         egress       18 seconds ago   Up 14 seconds\ngrafana      docker.io/grafana/grafana                    \"/run.sh\"                grafana      18 seconds ago   Up 13 seconds\ningress      docker.io/livekit/ingress                    \"ingress\"                ingress      19 seconds ago   Up 14 seconds\nloki         docker.io/grafana/loki                       \"/usr/bin/loki -conf\u2026\"   loki         18 seconds ago   Up 14 seconds\nminio        docker.io/bitnami/minio                      \"/opt/bitnami/script\u2026\"   minio        18 seconds ago   Up 14 seconds\nmongo        docker.io/mongo                              \"docker-entrypoint.s\u2026\"   mongo        18 seconds ago   Up 15 seconds\nopenvidu     docker.io/openvidu/openvidu-server           \"/livekit-server --c\u2026\"   openvidu     19 seconds ago   Up 14 seconds\nprometheus   docker.io/prom/prometheus                    \"/bin/prometheus --c\u2026\"   prometheus   18 seconds ago   Up 14 seconds\npromtail     docker.io/grafana/promtail                   \"/usr/bin/promtail -\u2026\"   promtail     18 seconds ago   Up 14 seconds\nredis        docker.io/redis                              \"docker-entrypoint.s\u2026\"   redis        19 seconds ago   Up 15 seconds\n</code></pre>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/on-premises/admin/#checking-logs","title":"Checking logs","text":"<p>If any of the services are not working as expected, you can check the logs of the services using the following command:</p> <pre><code>cd /opt/openvidu/\ndocker compose logs &lt;service-name&gt;\n</code></pre> <p>Replace <code>&lt;service-name&gt;</code> with the name of the service you want to check. For example, to check the logs of the OpenVidu Server, use the following command:</p> <pre><code>cd /opt/openvidu/\ndocker compose logs openvidu\n</code></pre> <p>To check the logs of all services, use the following command:</p> <pre><code>cd /opt/openvidu/\ndocker compose logs\n</code></pre> <p>Or use journalctl:</p> <pre><code>journalctl -f -u openvidu\n</code></pre> <p>You can also review your logs using the Grafana dashboard provided with OpenVidu. To access it, go to https://&lt;your-domain.com&gt;/grafana and use the credentials located in <code>/opt/openvidu/.env</code> to log in. Once inside, navigate to the \"Home\" section, select \"Dashboard\", and then click on \"OpenVidu &gt; OpenVidu Logs\". All the logs will be displayed there.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/on-premises/admin/#changing-the-configuration","title":"Changing the configuration","text":"<p>You can check how to change the configuration in the Changing Configuration section. Also, there are multiple guides in the How to Guides section that can help you with specific configuration changes.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/on-premises/admin/#uninstalling-openvidu","title":"Uninstalling OpenVidu","text":"<p>To uninstall OpenVidu, just execute the following commands:</p> <pre><code>sudo su\nsystemctl stop openvidu\nrm -rf /opt/openvidu/\nrm /etc/systemd/system/openvidu.service\nrm /etc/sysctl.d/50-openvidu.conf\n</code></pre>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/on-premises/install/","title":"OpenVidu Single Node installation on-premises","text":"","tags":["Platform"]},{"location":"docs/self-hosting/single-node/on-premises/install/#openvidu-single-node-community-installation-on-premises","title":"OpenVidu Single Node COMMUNITY installation: On-premises","text":"<p>This section contains the instructions to deploy a production-ready OpenVidu Single Node COMMUNITY deployment on-premises. It is a deployment based on Docker and Docker Compose, which will automatically configure all the necessary services for OpenVidu to work properly.</p> Architecture overview <p>This is how the architecture of the deployment looks like:</p> <p></p> OpenVidu Single Node On Premises Architecture <p></p> <p>All services are deployed on a single machine, which includes:</p> <ul> <li>OpenVidu Server (LiveKit compatible).</li> <li>Ingress and Egress services.</li> <li>OpenVidu Dashboard, a web application interface to visualize your Rooms, Ingress, and Egress services.</li> <li>MinIO as an S3 storage service for recordings.</li> <li>Redis as a shared database for OpenVidu Server and Ingress/Egress services.</li> <li>MongoDB as a database for storing analytics and monitoring data.</li> <li>Caddy as a reverse proxy. It can be deployed with self-signed certificates, Let's Encrypt certificates, or custom certificates.</li> <li>OpenVidu Meet, an optional high-quality video calling service.</li> <li>Grafana, Mimir, Promtail, and Loki (Observability module) form an optional observability stack for monitoring, allowing you to keep track of logs and deployment statistics for OpenVidu.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/on-premises/install/#prerequisites","title":"Prerequisites","text":"<p>Before starting the installation process, make sure you have the following prerequisites:</p> <ul> <li>A machine with at least 4GB RAM and 4 CPU cores and Linux installed (Ubuntu recommended).</li> <li>Generous disk space (100GB recommended) if you are going to record your sessions.</li> <li>The machine must have a Public IP. An FQDN (Fully Qualified Domain Name) is optional. If not provided, an autogenerated domain using sslip.io will be used.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/on-premises/install/#port-rules","title":"Port rules","text":"<p>Ensure all these rules are configured in your firewall, security group, or any kind of network configuration that you have in your machine.</p> <p>Inbound port rules:</p> Protocol Ports Source Description TCP 80 0.0.0.0/0, ::/0 Redirect HTTP traffic to HTTPS and Let's Encrypt validation. TCP 443 0.0.0.0/0, ::/0 Allows access to the following: <ul><li>LiveKit API.</li><li>OpenVidu Dashboard.</li><li>OpenVidu Meet.</li><li>WHIP API.</li><li>TURN with TLS.</li><li>Custom layouts</li></ul> UDP 443 0.0.0.0/0, ::/0 STUN/TURN server over UDP. TCP 1935 0.0.0.0/0, ::/0 Needed if you want to ingest RTMP streams using Ingress service. TCP 7881 0.0.0.0/0, ::/0 Needed if you want to allow WebRTC over TCP. UDP 7885 0.0.0.0/0, ::/0 Needed if you want to ingest WebRTC using WHIP protocol. TCP 9000 0.0.0.0/0, ::/0 Needed if you want to expose MinIO publicly. UDP 50000 - 60000 0.0.0.0/0, ::/0 WebRTC Media traffic. <p>Outbound port rules:</p> <p>Typically, all outbound traffic is allowed.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/on-premises/install/#guided-installation","title":"Guided Installation","text":"<p>Before the installation, ensure that your machine meets the prerequisites and the port rules. Then, execute the following command on the machine where you want to deploy OpenVidu:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/community/singlenode/latest/install.sh)\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <p>A wizard will guide you through the installation process. You will be asked for the following information:</p> <ul> <li>Domain name (Optional): The domain name for your deployment. If left empty, an autogenerated domain using sslip.io (e.g., <code>10-20-30-40.sslip.io</code>) will be used based on your machine's public IP. For production environments, it's recommended to provide your own FQDN.</li> <li> <p>Select which certificate type to use:</p> <ul> <li>Self Signed Certificate: It will generate a self-signed certificate. It is not recommended for production environments, but it is useful for testing or development purposes.</li> <li>Let's Encrypt: It will automatically generate a certificate for your domain.</li> <li>ZeroSSL: It will automatically generate a certificate for your domain using ZeroSSL. An API Key is required and will be asked later in the wizard. Note: This option is only available when providing an FQDN (Fully Qualified Domain Name).</li> <li>Own Certificate: It will ask you for the certificate and key files. Just copy and paste the content of the files when the wizard asks for them. Note: This option is only available when providing an FQDN (Fully Qualified Domain Name).</li> </ul> <p>Note</p> <p>If you want to manage the certificate in your proxy own proxy server instead of relaying in the Caddy server deployed with OpenVidu, take a look to this How-to guide: How to deploy OpenVidu with an external proxy.</p> </li> <li> <p>(Optional) Turn domain name: The domain name for your TURN server with TLS. If no main domain is provided and this is also left empty, an autogenerated domain using sslip.io will be used. This is recommended if users who are going to connect to your OpenVidu deployment are behind restrictive firewalls.</p> </li> <li>Modules to enable: Select the modules you want to enable. You can enable the following modules:<ul> <li>OpenVidu Meet: A high-quality video calling service based on OpenVidu.</li> <li>Observability: Grafana stack, which includes logs and monitoring stats.</li> </ul> </li> </ul> <p>The rest of the parameters are secrets, usernames, and passwords. If empty, the wizard will generate random values for them.</p> <p>When the installation process finishes, you will see the following message:</p> <pre><code>&gt; - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - &lt;\n&gt;                                                                             &lt;\n&gt;  \ud83c\udf89 OpenVidu Community Installation Finished Successfully! \ud83c\udf89               &lt;\n&gt;                                                                             &lt;\n&gt; - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - &lt;\n</code></pre> <p>OpenVidu will be installed at <code>/opt/openvidu</code> and configured as a systemd service. You can start the service with the following command:</p> <pre><code>systemctl start openvidu\n</code></pre> <p>If everything goes well, all containers will be up and running without restarts, and you will be able to access any of the following services:</p> <ul> <li>OpenVidu Meet: https://openvidu.example.io/</li> <li>OpenVidu Dashboard: https://openvidu.example.io/dashboard</li> <li>MinIO: https://openvidu.example.io/minio-console</li> <li>Grafana: https://openvidu.example.io/grafana</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/on-premises/install/#configure-your-application-to-use-the-deployment","title":"Configure your application to use the deployment","text":"<p>To point your applications to your OpenVidu deployment, check the following files:</p> <ul> <li><code>/opt/openvidu/config/meet.env</code>: Contains the OpenVidu Meet parameters.</li> <li><code>/opt/openvidu/config/openvidu.env</code>: Contains all the credentials of services deployed with OpenVidu Platform.</li> </ul> <p>The most relevant parameters are:</p> <p>OpenVidu Meet:</p> <ul> <li><code>MEET_INITIAL_ADMIN_USER</code>: User to access OpenVidu Meet Console. It is always <code>admin</code>.</li> <li><code>MEET_INITIAL_ADMIN_PASSWORD</code>: Password to access OpenVidu Meet Console.</li> <li><code>MEET_INITIAL_API_KEY</code>: API key to use OpenVidu Meet Embedded and OpenVidu Meet REST API.</li> </ul> <p>Note</p> <p>The <code>MEET_INITIAL_ADMIN_USER</code>, <code>MEET_INITIAL_ADMIN_PASSWORD</code>, and <code>MEET_INITIAL_API_KEY</code> values are initial and cannot be changed from the <code>meet.env</code> file. They can only be changed from the Meet Console.</p> <p>OpenVidu Platform:</p> <ul> <li><code>LIVEKIT_URL</code>: The URL to use LiveKit SDKs, which can be <code>wss://yourdomain.example.io/</code> or <code>https://yourdomain.example.io/</code> depending on the client library you are using.</li> <li><code>LIVEKIT_API_KEY</code>: API Key for LiveKit SDKs.</li> <li><code>LIVEKIT_API_SECRET</code>: API Secret for LiveKit SDKs.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/on-premises/install/#non-interactive-installation","title":"Non-interactive installation","text":"<p>If you want to automate the installation process, you can generate a command with all the parameters needed to install OpenVidu by answering the wizard questions. You can do this by running the following command:</p> <pre><code>docker run --pull always --rm -it \\\n    openvidu/openvidu-installer:latest \\\n    --deployment-type=single_node\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <p>This is going to generate a command like this, but it may vary depending on the answers you provide. Here are examples of the command you can run depending on the certificate type and domain configuration:</p> Without Domain NameWith Domain Name Let's Encrypt certificatesSelf-signed certificates <p>Example using Let's Encrypt certificates with autogenerated sslip.io domain:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/community/singlenode/latest/install.sh) \\\n    --no-tty --install \\\n    --enabled-modules='observability,openviduMeet' \\\n    --livekit-api-key='xxxxx' \\\n    --livekit-api-secret='xxxxx' \\\n    --dashboard-admin-user='xxxxx' \\\n    --dashboard-admin-password='xxxxx' \\\n    --redis-password='xxxxx' \\\n    --minio-access-key='xxxxx' \\\n    --minio-secret-key='xxxxx' \\\n    --mongo-admin-user='xxxxx' \\\n    --mongo-admin-password='xxxxx' \\\n    --mongo-replica-set-key='xxxxx' \\\n    --grafana-admin-user='xxxxx' \\\n    --grafana-admin-password='xxxxx' \\\n    --meet-initial-admin-password='xxxxx' \\\n    --meet-initial-api-key='xxxxx' \\\n    --certificate-type='letsencrypt'\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <p>Example using self-signed certificates with autogenerated sslip.io domain:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/community/singlenode/latest/install.sh) \\\n    --no-tty --install \\\n    --enabled-modules='observability,openviduMeet' \\\n    --livekit-api-key='xxxxx' \\\n    --livekit-api-secret='xxxxx' \\\n    --dashboard-admin-user='xxxxx' \\\n    --dashboard-admin-password='xxxxx' \\\n    --redis-password='xxxxx' \\\n    --minio-access-key='xxxxx' \\\n    --minio-secret-key='xxxxx' \\\n    --mongo-admin-user='xxxxx' \\\n    --mongo-admin-password='xxxxx' \\\n    --mongo-replica-set-key='xxxxx' \\\n    --grafana-admin-user='xxxxx' \\\n    --grafana-admin-password='xxxxx' \\\n    --meet-initial-admin-password='xxxxx' \\\n    --meet-initial-api-key='xxxxx' \\\n    --certificate-type='selfsigned'\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> Let's Encrypt certificatesSelf-signed certificatesCustom certificates <p>Example using Let's Encrypt certificates with an FQDN (Fully Qualified Domain Name):</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/community/singlenode/latest/install.sh) \\\n    --no-tty --install \\\n    --domain-name='openvidu.example.io' \\\n    --enabled-modules='observability,openviduMeet' \\\n    --turn-domain-name='turn.example.io' \\\n    --livekit-api-key='xxxxx' \\\n    --livekit-api-secret='xxxxx' \\\n    --dashboard-admin-user='xxxxx' \\\n    --dashboard-admin-password='xxxxx' \\\n    --redis-password='xxxxx' \\\n    --minio-access-key='xxxxx' \\\n    --minio-secret-key='xxxxx' \\\n    --mongo-admin-user='xxxxx' \\\n    --mongo-admin-password='xxxxx' \\\n    --mongo-replica-set-key='xxxxx' \\\n    --grafana-admin-user='xxxxx' \\\n    --grafana-admin-password='xxxxx' \\\n    --meet-initial-admin-password='xxxxx' \\\n    --meet-initial-api-key='xxxxx' \\\n    --certificate-type='letsencrypt'\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <p>Example using self-signed certificates with an FQDN (Fully Qualified Domain Name):</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/community/singlenode/latest/install.sh) \\\n    --no-tty --install \\\n    --domain-name='openvidu.example.io' \\\n    --enabled-modules='observability,openviduMeet' \\\n    --turn-domain-name='turn.example.io' \\\n    --livekit-api-key='xxxxx' \\\n    --livekit-api-secret='xxxxx' \\\n    --dashboard-admin-user='xxxxx' \\\n    --dashboard-admin-password='xxxxx' \\\n    --redis-password='xxxxx' \\\n    --minio-access-key='xxxxx' \\\n    --minio-secret-key='xxxxx' \\\n    --mongo-admin-user='xxxxx' \\\n    --mongo-admin-password='xxxxx' \\\n    --mongo-replica-set-key='xxxxx' \\\n    --grafana-admin-user='xxxxx' \\\n    --grafana-admin-password='xxxxx' \\\n    --meet-initial-admin-password='xxxxx' \\\n    --meet-initial-api-key='xxxxx' \\\n    --certificate-type='selfsigned'\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <p>Example using custom certificates with an FQDN (Fully Qualified Domain Name):</p> <pre><code>CERT_PRIVATE_KEY=$(cat privkey.pem | base64 -w 0)\nCERT_PUBLIC_KEY=$(cat fullchain.pem | base64 -w 0)\n\n# Optional, only if you want to enable TURN with TLS\nCERT_TURN_PRIVATE_KEY=$(cat turn-privkey.pem | base64 -w 0)\nCERT_TURN_PUBLIC_KEY=$(cat turn-fullchain.pem | base64 -w 0)\n\nsh &lt;(curl -fsSL http://get.openvidu.io/community/singlenode/latest/install.sh) \\\n    --no-tty --install \\\n    --domain-name='openvidu.example.io' \\\n    --enabled-modules='observability,openviduMeet' \\\n    --turn-domain-name='turn.example.io' \\\n    --livekit-api-key='xxxxx' \\\n    --livekit-api-secret='xxxxx' \\\n    --dashboard-admin-user='xxxxx' \\\n    --dashboard-admin-password='xxxxx' \\\n    --redis-password='xxxxx' \\\n    --minio-access-key='xxxxx' \\\n    --minio-secret-key='xxxxx' \\\n    --mongo-admin-user='xxxxx' \\\n    --mongo-admin-password='xxxxx' \\\n    --mongo-replica-set-key='xxxxx' \\\n    --grafana-admin-user='xxxxx' \\\n    --grafana-admin-password='xxxxx' \\\n    --meet-initial-admin-password='xxxxx' \\\n    --meet-initial-api-key='xxxxx' \\\n    --certificate-type='owncert' \\\n    --owncert-private-key=\"$CERT_PRIVATE_KEY\" \\\n    --owncert-public-key=\"$CERT_PUBLIC_KEY\" \\\n    --turn-owncert-private-key=\"$CERT_TURN_PRIVATE_KEY\" \\\n    --turn-owncert-public-key=\"$CERT_TURN_PUBLIC_KEY\"\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <ul> <li>Note that you just need to pass <code>--owncert-private-key</code> and <code>--owncert-public-key</code> with the content of the private and public key files in base64 format. The installation script will decode them and save them in the proper files.</li> <li><code>--turn-owncert-private-key</code> and <code>--turn-owncert-public-key</code> are optional. You only need to pass them if you want to enable TURN with TLS.</li> </ul> <p>You can run that command in a CI/CD pipeline or in a script to automate the installation process.</p> <p>Some notes about the command:</p> <ul> <li>The argument <code>--domain-name</code> is optional. If not provided, an autogenerated domain using sslip.io will be used based on your machine's public IP.</li> <li>The argument <code>--turn-domain-name</code> is optional. You define it only if you want to enable TURN with TLS in case users are behind restrictive firewalls. If no main domain is provided and this is also left empty, an autogenerated domain using sslip.io will be used.</li> <li>When using autogenerated domains (no FQDN (Fully Qualified Domain Name) provided), only <code>selfsigned</code> and <code>letsencrypt</code> certificate types are available.</li> <li>In the argument <code>--enabled-modules</code>, you can enable the modules you want to deploy. You can enable <code>openviduMeet</code> OpenVidu Meet service and <code>observability</code> (Grafana stack).</li> <li>If no media appears in your conference, reinstall specifying the <code>--public-ip</code> parameter with your machine's public IP. OpenVidu usually auto-detects the public IP, but it can fail. This IP is used by clients to send and receive media.</li> </ul> <p>To start OpenVidu, remember to run:</p> <pre><code>systemctl start openvidu\n</code></pre>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/on-premises/install/#configuration-and-administration","title":"Configuration and administration","text":"<p>Once you have OpenVidu deployed, you can check the Administration section to learn how to manage your OpenVidu Single Node deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/on-premises/upgrade/","title":"Upgrade OpenVidu Single Node COMMUNITY - On Premises","text":"","tags":["Platform"]},{"location":"docs/self-hosting/single-node/on-premises/upgrade/#upgrade-openvidu-single-node-community-on-premises","title":"Upgrade OpenVidu Single Node COMMUNITY - On Premises","text":"<p>OpenVidu offers an updater that allows you to upgrade your OpenVidu deployment in an easy and automated way. The updater will take care of the whole process, from stopping the services to updating the configuration files.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/on-premises/upgrade/#upgrading-openvidu-single-node","title":"Upgrading OpenVidu Single Node","text":"<p>Upgrade OpenVidu Single Node is very simple. These are the steps you need to follow:</p> <ol> <li>SSH into your OpenVidu Single Node server.</li> <li> <p>Execute the following command:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/update/latest/update.sh)\n</code></pre> <p>Info</p> <p>If instead of upgrading to the latest version you want to upgrade to a specific version, you can execute the following command:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/update/&lt;VERSION&gt;/update.sh)\n</code></pre> <p>Where <code>&lt;VERSION&gt;</code> is the version you want to upgrade to.</p> </li> <li> <p>This will execute an update script which will guide you from the version you have installed to the latest one. The first thing you will see in the output is the following:</p> <pre><code>Stopping OpenVidu service...\nBacking up files...\n\n    - Backing up file '/opt/openvidu/config' to '/opt/openvidu/backups/&lt;DATE&gt;_&lt;VERSION&gt;/config'\n    ... More files ...\n\n--------------------\n\ud83d\udce6 Backup directory: /opt/openvidu/backups/&lt;DATE&gt;_&lt;VERSION&gt;/\n--------------------\n\n--------------------\n\ud83d\ude80 Updating OpenVidu from 3.x.x to 3.y.y\n--------------------\n\n? Do you want to update from 3.x.x to 3.y.y? \u203a\n\u2022 Yes\n  No\n</code></pre> </li> <li> <p>Answer <code>Yes</code> to the question and your OpenVidu Single Node will be upgraded to asked version. For each version the system will ask you to confirm the upgrade.</p> </li> <li>A <code>diff</code> will be shown with the changes made in the configuration files. You can review the changes and decide if you want to apply them or not. If you want to apply the changes, answer <code>Yes</code> to the question. If you want to discard the changes and stop the upgrading process, simply answer <code>No</code>.</li> <li>Once the upgrade is finished, it will ask you to pull the images of the services. Answer <code>Yes</code> if you want to do it.</li> <li>Start OpenVidu with the following command:</li> </ol> <pre><code>systemctl start openvidu &amp;&amp; journalctl -f -u openvidu\n</code></pre> <p>The <code>journalctl</code> command will show you the logs of the OpenVidu services. You can stop the logs by pressing <code>Ctrl + C</code>.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/on-premises/upgrade/#backups-and-rollback","title":"Backups and Rollback","text":"<p>When you finish the upgrade process, you will have a backup of the previous version in the <code>/opt/openvidu/backups</code> directory. To backup to a specific date and version, you can execute the following command:</p> <pre><code>cp -r /opt/openvidu/backups/&lt;DATE&gt;_&lt;VERSION&gt;/* /opt/openvidu\n</code></pre> <p>Where <code>&lt;DATE&gt;</code> and <code>&lt;VERSION&gt;</code> are the date and version of the backup you want to restore. For example:</p> <pre><code>cp -r /opt/openvidu/backups/2025-02-12-09-50-46_3.0.0/* /opt/openvidu\n</code></pre> <p>In the previous command, you have to replace the date and version with the one you want to restore.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node/on-premises/upgrade/#recommendations","title":"Recommendations","text":"<ul> <li>On any upgrade problem, a redeployment is always recommended for a clean installation.</li> <li>Keep your Docker and Docker Compose versions updated.</li> <li> <p>Remove non-used images and containers to free up disk space. For example, after the upgrade, when OpenVidu is running, you can remove the old images with the following command:</p> <pre><code>docker image prune -a\n</code></pre> <p>This command will remove all the images that are not being used by any container.</p> </li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/","title":"OpenVidu Single Node Pro","text":"","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/#openvidu-single-node-pro-installation","title":"OpenVidu Single Node PRO installation","text":"<p>OpenVidu Single Node PRO brings all the features of OpenVidu Single Node COMMUNITY plus 2x performance and advanced observability. It is aimed to users that want a single-node setup but still want OpenVidu PRO features.</p> <p>Info</p> <p>Scalability and fault tolerance require a multi-node setup. If you need them, consider using OpenVidu Elastic or OpenVidu High Availability.</p> <p>Install OpenVidu Single Node PRO in your preferred environment:</p> <ul> <li>On-premises installation: set up on your own servers.</li> <li>AWS installation: deploy to Amazon Web Services.</li> <li>Azure installation: deploy to Microsoft Azure.</li> <li>Google Cloud Platform installation: deploy to Google Cloud Platform.</li> </ul> <p>Once your deployment is complete, refer to the following sections for configuration and management:</p> <ul> <li>On-premises: configuration and administration</li> <li>AWS: configuration and administration</li> <li>Azure: configuration and administration</li> <li>Google Cloud Platform: configuration and administration</li> </ul> <p>If you want to upgrade your OpenVidu Single Node PRO installation, refer to this section:</p> <ul> <li>On-premises: upgrade OpenVidu Single Node PRO</li> <li>AWS: upgrade OpenVidu Single Node PRO</li> <li>Azure: upgrade OpenVidu Single Node PRO</li> <li>Google Cloud Platform: upgrade OpenVidu Single Node PRO</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/aws/admin/","title":"OpenVidu Single Node PRO administration on AWS","text":"","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/aws/admin/#openvidu-single-node-pro-administration-aws","title":"OpenVidu Single Node PRO administration: AWS","text":"<p>AWS deployment of OpenVidu Single Node is internally identical to the on-premises deployment, so you can follow the same instructions from the On Premises Single Node for administration and configuration. The only difference is that the deployment is automated with AWS CloudFormation.</p> <p>However, there are certain things worth mentioning:</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/aws/admin/#start-and-stop-openvidu-through-aws-console","title":"Start and stop OpenVidu through AWS Console","text":"<p>You can start and stop all services as explained in the On Premises Single Node section. But you can also start and stop the EC2 instance directly from the AWS Console. This will stop all services running in the instance and reduce AWS costs.</p> Stop OpenVidu Single NodeStart OpenVidu Single Node <ol> <li>Go to the EC2 Dashboard  of AWS.</li> <li>Right-click on the instance you want to start and select \"Stop instance\".</li> </ol> <p></p> <p></p> <ol> <li>Go to the EC2 Dashboard  of AWS.</li> <li>Right-click on the instance you want to start and select \"Start instance\".</li> </ol> <p></p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/aws/admin/#change-the-instance-type","title":"Change the instance type","text":"<p>You can change the instance type of the OpenVidu Single Node instance to adapt it to your needs. To do this, follow these steps:</p> <ol> <li>Stop the instance.</li> <li> <p>Right-click on the instance and select \"Instance Settings &gt; Change Instance Type\".</p> Change instance type <p></p> <p></p> </li> <li> <p>Select the new instance type and click on \"Apply\".</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/aws/admin/#administration-and-configuration","title":"Administration and configuration","text":"<p>For administration, you can follow the instructions from the On Premises Single Node Administration section.</p> <p>Regarding the configuration, in AWS it is managed similarly to an on-premises deployment. For detailed instructions, please refer to the Changing Configuration section. Additionally, the How to Guides offer multiple resources to assist with specific configuration changes.</p> <p>In addition to these, an AWS deployment provides the capability to manage global configurations via the AWS Console using AWS Secrets created during the deployment. To manage configurations this way, follow these steps:</p> Changing Configuration through AWS Secrets <ol> <li>Navigate to the CloudFormation Dashboard  on AWS.</li> <li>Select the CloudFormation Stack that you used to deploy OpenVidu Single Node.</li> <li>In the \"Outputs\" tab, click the Link at \"ServicesAndCredentials\". This will open the AWS Secrets Manager which contains all the configurations of the OpenVidu Single Node deployment.      </li> <li>Click on the \"Retrieve secret value\" button to get the JSON with all the information.      </li> <li>Modify the parameter you want to change and click on \"Save\".</li> <li>Go to the EC2 Console and click on \"Reboot instance\" to apply the changes to the Master Node.      </li> </ol> <p>Changes will be applied automatically.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/aws/install/","title":"OpenVidu Single Node installation on AWS","text":"","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/aws/install/#openvidu-single-node-pro-installation-aws","title":"OpenVidu Single Node PRO installation: AWS","text":"<p>This section contains the instructions to deploy a production-ready OpenVidu Single Node PRO deployment in AWS. Deployed services are the same as the On Premises Single Node installation but automate the process with AWS CloudFormation.</p> <p>First of all, import the template in the AWS CloudFormation console. You can click the following button...</p> <p> Deploy to AWS</p> <p>...or access your AWS CloudFormation console  and manually set this S3 URL in the <code>Specify template</code> section:</p> <pre><code>https://s3.eu-west-1.amazonaws.com/get.openvidu.io/pro/singlenode/latest/aws/cf-openvidu-singlenode.yaml\n</code></pre> <p>Info</p> <p>If you want to deploy a specific version of OpenVidu Single Node, replace <code>latest</code> with the version you want to deploy. For example, to deploy version <code>3.4.0</code>, use the following URL:</p> <pre><code>https://s3.eu-west-1.amazonaws.com/get.openvidu.io/pro/singlenode/3.4.0/aws/cf-openvidu-singlenode.yaml\n</code></pre> Architecture overview <p>This is how the architecture of the deployment looks like:</p> <p></p> OpenVidu Single Node AWS Architecture <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/aws/install/#cloudformation-parameters","title":"CloudFormation Parameters","text":"<p>Depending on your needs, you need to fill the following CloudFormation parameters:</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/aws/install/#domain-and-ssl-certificate-configuration","title":"Domain and SSL Certificate Configuration","text":"<p>There are three possible scenarios for this section:</p> Let's Encrypt Without Domain NameLet's Encrypt With Domain Name (recommended)Custom CertificatesSelf-Signed Certificate <p>If you don't have a Domain Name and want to quickly test OpenVidu on AWS, you can use this option, simply selecting the CertificateType as letsencrypt and keep the rest of parameters empty.</p> <p>It will deploy OpenVidu with a Let's Encrypt certificate generated using sslip.io based on the public IP created for the deployment.</p> <p></p> <p>For a production environment, it is highly recommended to use this option. It allows you to deploy OpenVidu on AWS with a valid Let's Encrypt certificate for your Fully Qualified Domain Name (FQDN).</p> <p>You need to previously create an Elastic IP and have a Domain Name pointing to that Elastic IP.</p> <p></p> <p>You can specify the DomainName with your FQDN and optionally the PublicElasticIP with the Elastic IP that the domain points to.</p> <p>Opt for this method if you possess your own certificate for an existing FQDN. It enables you to deploy OpenVidu on AWS using your certificates.</p> <p>You need to have a Fully Qualified Domain Name (FQDN) pointing to a previously created Elastic IP.</p> <p>Also, you need a temporary HTTP server hosting your private and public certificate under a specific URL. These URLs are needed for the instance to be able to download and install your certificates.</p> <p>The configured parameters would look like this:</p> <p></p> <p>You need to specify at OwnPublicCertificate and OwnPrivateCertificate the URLs where the public and private certificates are hosted, respectively. The DomainName and PublicElasticIP are mandatory parameters.</p> <p>Certificates need to be in PEM format and the URLs must be accessible from the instance.</p> <p>This option is useful for development and testing purposes. It allows you to deploy OpenVidu on AWS with an autogenerated self-signed certificate. This way, you can quickly set up a secure connection without the need to obtain a certificate from a trusted Certificate Authority (CA).</p> <p>However, this convenience comes with the caveat that users will need to manually accept the certificate in their web browsers. Please be aware that this configuration is solely for developmental and testing purposes and is not suitable for a production environment.</p> <p>These are the parameters needed in this section to use self-signed certificates:</p> <p></p> <p>You can optionally specify a DomainName. If no domain name is provided, sslip.io{:target=\"blank\"} will be used to generate a domain based on the public IP. Just select the CertificateType as _self-signed.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/aws/install/#openvidu-single-node-pro-configuration","title":"OpenVidu Single Node PRO configuration","text":"<p>In this section, you need to specify some properties needed for the OpenVidu Single Node PRO deployment.</p> OpenVidu Single Node PRO Configuration <p>Parameters of this section look like this:</p> <p></p> <p>Make sure to provide the OpenViduLicense parameter with the license key. If you don't have one, you can request one here.</p> <p>For the RTCEngine parameter, you can choose between Pion (the default engine used by LiveKit) and Mediasoup (with a boost in performance). Learn more about the differences here.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/aws/install/#openvidu-meet-credentials","title":"OpenVidu Meet Credentials","text":"<p>Configure the initial credentials for accessing OpenVidu Meet:</p> OpenVidu Meet credentials <p>Parameters in this section look like this:</p> <p></p> <ul> <li>InitialMeetAdminPassword: Initial password for the \"admin\" user in OpenVidu Meet. If not provided, a random password will be generated and stored in the AWS Secret Manager.</li> <li>InitialMeetApiKey: Initial API key for OpenVidu Meet. If not provided, no API key will be set and the user can configure it later from the Meet Console.</li> </ul> <p>Both parameters are optional. If you don't specify them, you can retrieve the generated credentials from the AWS Secret Manager after deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/aws/install/#ec2-instance-configuration","title":"EC2 Instance Configuration","text":"<p>You need to specify some properties for the EC2 instance that will be created.</p> EC2 Instance configuration <p>Parameters in this section look like this:</p> <p></p> <p>Simply select the type of instance you want to deploy at InstanceType, the SSH key you want to use to access the machine at KeyName, and the Amazon Image ID (AMI) to use at AmiId.</p> <p>By default, the parameter AmiId is configured to use the latest LTS Ubuntu AMI, so ideally you don\u2019t need to modify this.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/aws/install/#s3-bucket-for-application-data-and-recordings","title":"S3 bucket for application data and recordings","text":"<p>You can specify an S3 bucket to store the recordings and application data. If this parameter is not specified, a new S3 bucket will be created by the CloudFormation stack.</p> S3 bucket for application data and recordings <p>Parameters in this section look like this:</p> <p></p> <p>You can specify an existing S3 bucket or leave it empty to create a new one.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/aws/install/#optional-additional-flags","title":"(Optional) Additional flags","text":"<p>Additional optional flags to pass to the OpenVidu installer (comma-separated, e.g., <code>--flag1=value, --flag2</code>).</p> (Optional) Additional flags <p>Parameters in this section look like this:</p> <p></p> <p>For example, you can use <code>--experimental-turn-tls-with-main-domain</code> to use the same domain as the main one for the TURN server with TLS, instead of specifying a different one in the TURN server configuration with TLS section.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/aws/install/#optional-turn-server-configuration-with-tls","title":"(Optional) TURN server configuration with TLS","text":"<p>This section is optional. It is useful when your users are behind a restrictive firewall that blocks UDP traffic. This parameter will only work if you are using <code>letsencrypt</code> or <code>owncert</code> as the CertificateType parameter.</p> <p>Note that if you are not using any Domain Name in the Domain and SSL Certificate Configuration section, this section will be ignored and a generated domain based on the public IP and sslip.io will be used instead.</p> TURN server configuration with TLS <p>Parameters in this section look like this:</p> <p></p> <p>Set the TurnDomainName parameter to the domain name you intend to use for your TURN server. It should be pointing to the <code>PublicElasticIP</code> specified in the previous section.</p> <p>If you are using <code>letsencrypt</code> as the CertificateType parameter, you can leave the TurnOwnPublicCertificate and TurnOwnPrivateCertificate parameters empty. If you are using <code>owncert</code>, you need to specify the URLs where the public and private certificates are hosted.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/aws/install/#deploying-the-stack","title":"Deploying the stack","text":"<p>When you are ready with your CloudFormation parameters, just click on \"Next\", specify in \"Stack failure options\" the option \"Preserve successfully provisioned resources\" to be able to troubleshoot the deployment in case of error, click on \"Next\" again, and finally \"Submit\".</p> <p>When everything is ready, you will see the following links in the \"Outputs\" section of CloudFormation:</p> CloudFormation Outputs <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/aws/install/#configure-your-application-to-use-the-deployment","title":"Configure your application to use the deployment","text":"<p>The Output Key ServicesAndCredentials of the previous section points to an AWS Secret Manager secret that contains all URLs and credentials to access the services deployed. You can access the secret by clicking on the link in the Output Value column.</p> <p>Then, click on Retrieve secret value to get the JSON with all the information.</p> <p></p> <p></p> <p>To use your OpenVidu deployment, check the values of the JSON secret. All access credentials of all services are defined in this object. The most relevant ones are:</p> <p>OpenVidu Meet:</p> <ul> <li><code>OPENVIDU_URL</code>: The URL to access OpenVidu Meet, which is always <code>https://yourdomain.example.io/</code></li> <li><code>MEET_INITIAL_ADMIN_USER</code>: User to access OpenVidu Meet Console. It is always <code>admin</code>.</li> <li><code>MEET_INITIAL_ADMIN_PASSWORD</code>: Password to access OpenVidu Meet Console.</li> <li><code>MEET_INITIAL_API_KEY</code>: API key to use OpenVidu Meet Embedded and OpenVidu Meet REST API.</li> </ul> <p>Note</p> <p>The <code>MEET_INITIAL_ADMIN_USER</code>, <code>MEET_INITIAL_ADMIN_PASSWORD</code>, and <code>MEET_INITIAL_API_KEY</code> values are initial settings that cannot be changed from AWS Secret Manager. They can only be changed from the Meet Console.</p> <p>OpenVidu Platform:</p> <ul> <li><code>LIVEKIT_URL</code>: The URL to use LiveKit SDKs, which can be <code>wss://yourdomain.example.io/</code> or <code>https://yourdomain.example.io/</code> depending on the client library you are using.</li> <li><code>LIVEKIT_API_KEY</code>: API Key for LiveKit SDKs.</li> <li><code>LIVEKIT_API_SECRET</code>: API Secret for LiveKit SDKs.</li> </ul> <p>OpenVidu V2 Compatibility Credentials</p> <p>This section is only needed if you want to use OpenVidu v2 compatibility.</p> <ul> <li>URL: The URL to access OpenVidu, which is the value of <code>OPENVIDU_URL</code> (e.g., <code>https://yourdomain.example.io/</code>)</li> <li>Username: Basic auth user for OpenVidu v2 compatibility. It is always <code>OPENVIDUAPP</code>.</li> <li>Password: Basic auth password for OpenVidu v2 compatibility is the same as <code>LIVEKIT_API_SECRET</code>.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/aws/install/#troubleshooting-initial-cloudformation-stack-creation","title":"Troubleshooting Initial CloudFormation Stack Creation","text":"<p>If something goes wrong during the initial CloudFormation stack creation, your stack may reach the <code>CREATE_FAILED</code> status for multiple reasons. It could be due to a misconfiguration in the parameters, a lack of permissions, or a problem with the AWS services. When this happens, the following steps can help you troubleshoot the issue and identify what went wrong:</p> <ol> <li> <p>While deploying the stack, make sure at \"Stack failure options\" you have selected the option \"Preserve successfully provisioned resources\" to be able to troubleshoot the deployment in case of an error.</p> Disable Rollback on failure <p></p> <p></p> </li> <li> <p>Check if the EC2 instance or instances are running. If they are not, check the CloudFormation events for any error messages.</p> </li> <li> <p>If the EC2 instance or instances are running, SSH into the instance and check the logs of the following files:</p> <ul> <li><code>/var/log/cloud-init-output.log</code></li> <li><code>/var/log/cloud-init.log</code></li> </ul> <p>These logs will give you more information about the CloudFormation stack creation process.</p> </li> <li> <p>If everything seems fine, check the status and the logs of the installed OpenVidu services.</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/aws/install/#configuration-and-administration","title":"Configuration and administration","text":"<p>When your CloudFormation stack reaches the <code>CREATE_COMPLETE</code> status, your OpenVidu Single Node deployment is ready to use. You can check the Administration section to learn how to manage your deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/aws/upgrade/","title":"Upgrade OpenVidu Single Node PRO - AWS","text":"","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/aws/upgrade/#upgrade-openvidu-single-node-pro-aws","title":"Upgrade OpenVidu Single Node PRO - AWS","text":"<p>In AWS, we recommend upgrading by redeploying the OpenVidu Single Node CloudFormation with the latest version.</p> <p>However, if you prefer to upgrade the OpenVidu Single Node without redeploying, you can follow the steps outlined in the Upgrade OpenVidu Single Node - On Premises section.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/azure/admin/","title":"OpenVidu Single Node PRO administration on Azure","text":"","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/azure/admin/#openvidu-single-node-pro-administration-azure","title":"OpenVidu Single Node PRO administration: Azure","text":"<p>Azure OpenVidu Single Node deployments are internally identical to On Premises Single Node deployments, so you can follow the same instructions from On Premises Single Node documentation for administration and configuration. The only difference is that the deployment is automated with ARM Templates from Azure.</p> <p>However, there are certain things worth mentioning:</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/azure/admin/#start-and-stop-openvidu-through-azure-portal","title":"Start and stop OpenVidu through Azure Portal","text":"<p>You can start and stop all services as explained in the On Premises Single Node section. But you can also start and stop the Virtual Machine instance directly from Azure Portal. This will stop all services running in the instance and reduce Azure costs.</p> Stop OpenVidu Single NodeStart OpenVidu Single Node <ol> <li>Go to Azure Portal Dashboard  of Azure and enter into the resource group where you deployed OpenVidu Single Node.</li> <li>There, you will find the Virtual Machine that runs OpenVidu. Its name should be something like yourstackname-VM-CE. Click on it.</li> <li>In the section of the Virtual Machine click on stop button to stop the Virtual Mache (and therefore OpenVidu).</li> </ol> <p></p> <p></p> <ol> <li>Go to Azure Portal Dashboard  of Azure and enter into the resource group where you deployed OpenVidu Single Node.</li> <li>There, you will find the Virtual Machine that runs OpenVidu. Its name should be something like yourstackname-VM-CE.  Click on it.</li> <li>In the section of the Virtual Machine click on start button to start the Virtual Mache (and therefore OpenVidu).</li> </ol> <p></p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/azure/admin/#change-the-instance-type","title":"Change the instance type","text":"<p>You can change the instance type of the OpenVidu Single Node instance to adapt it to your needs. To do this, follow these steps:</p> <ol> <li>Go to Azure Portal Dashboard  of Azure and enter into the resource group where you deployed OpenVidu Single Node.</li> <li>There, you will find the Virtual Machine that runs OpenVidu. Its name should be something like yourstackname-VM-CE. Click on it.</li> <li> <p>In the left pannel click on \"Availability + scale\" -&gt; \"Size\".</p> Change instance type <p></p> <p></p> </li> <li> <p>Select the new instance type and click on \"Resize\".</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/azure/admin/#administration-and-configuration","title":"Administration and configuration","text":"<p>Regarding the administration of your deployment, you can follow the instructions in section On Premises Single Node Administration.</p> <p>Regarding the configuration of your deployment, you can follow the instructions in section Changing Configuration. Additionally, the How to Guides offer multiple resources to assist with specific configuration changes.</p> <p>In addition to these, an Azure deployment provides the capability to manage global configurations via the Azure portal using Key Vault Secrets created during the deployment:</p> Changing configuration through Key Vault secrets <ol> <li>Navigate to the Azure Portal Dashboard  on Azure.</li> <li>Select the Resource Group where you deployed your OpenVidu Single Node Stack.</li> <li>In the \"stackname-keyvault\" resource, click on \"Objects\" -&gt; \"Secrets\" on the left panel. This will show you all the secrets that are stored in the Key Vault of the OpenVidu deployment.      </li> <li>Click on the desired secret you want to change and click on \"New Version\".      </li> <li>Enter the new secret value on \"Secret Value\" filed and click on \"Create\".      </li> <li>Go to the Instance resource of OpenVidu and click on \"Restart\" to apply the changes to the OpenVidu Single Node deployment.      </li> </ol> <p>Changes will be applied automatically.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/azure/install/","title":"OpenVidu Single Node installation on Azure","text":"","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/azure/install/#openvidu-single-node-pro-installation-azure","title":"OpenVidu Single Node PRO installation: Azure","text":"<p>This section contains the instructions to deploy a production-ready OpenVidu Single Node PRO deployment in Azure. Deployed services are the same as the On Premises Single Node installation but automate the process with Template Spec of ARM.</p> <p>To use the Azure template you just need to click the button below (you will be redirected to Azure).</p> <p></p> Architecture overview <p>This is how the architecture of the deployment looks like:</p> <p></p> OpenVidu Single Node Azure Architecture <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/azure/install/#template-parameters","title":"Template Parameters","text":"<p>To deploy the template you need to fill the following parameters.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/azure/install/#resource-group-and-stack-name","title":"Resource Group and Stack Name","text":"<p>Select your Subscription and the Resource Group where you want to deploy OpenVidu.</p> <p></p> <p>Warning</p> <p>It is highly recommended to deploy OpenVidu in a brand new Azure Resource Group. Reusing an existing Resource Group can lead to conflicts. The only reason to reuse an existing Resource Group is to use the same IP and Azure Blob Storage Account as a previous OpenVidu deployment. The rest of resources are not reusable and should be eliminated before deploying OpenVidu in the same Resource Group.</p> <p>Select the Region and choose a descriptive Stack Name. It will be used as a prefix in the name of all the resources created by the template.</p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/azure/install/#domain-and-ssl-certificate-configuration","title":"Domain and SSL Certificate Configuration","text":"<p>There are three possible scenarios for this section:</p> Let's Encrypt Without Domain NameLet's Encrypt With Domain Name (recommended)Custom CertificatesSelf-Signed Certificate <p>If you don't have a Domain Name and want to quickly test OpenVidu on Azure, you can use this option, simply selecting the Certificate Type as letsencrypt and keep the rest of parameters empty.</p> <p>It will deploy OpenVidu with a Let's Encrypt certificate generated using sslip.io based on the public IP created for the deployment.</p> <p></p> <p>For a production-ready setup, this scenario is ideal when you have an FQDN (Fully Qualified Domain Name) and a Public IP at your disposal. It leverages the services of Let's Encrypt to automatically generate valid certificates.</p> <p>First, you need to have the FQDN pointing to the Public IP you are going to use.</p> <p>Then, you need to fill in the following parameters:</p> <p></p> <p></p> <p>As you can see, you need to specify the Public Ip Address with the Public IP that the domain points to, the Domain Name with your FQDN, and the Lets Encrypt Email with your email address for Let\u2019s Encrypt notifications. These parameters are mandatory.</p> <p>To deploy OpenVidu in Azure under your Fully Qualified Domain Name (FQDN) using already existing certificates, follow this method.</p> <p>You need to have your FQDN pointing to a previously created Public Ip.</p> <p>Also, you need a temporary HTTP server hosting your private and public certificate under a specific URL. These URLs are needed for the instance to be able to securely download and install your certificates.</p> <p>The configured parameters would look like this:</p> <p></p> <p></p> <p>You need to specify at Own Public Certificate and Own Private Certificate the URLs where the public and private certificates are hosted, respectively. The Domain Name, Public Ip Address are mandatory parameters.</p> <p>Certificates need to be in PEM format and the URLs must be accessible from the instance.</p> <p>This is the most straightforward option for deploying OpenVidu on Azure when you do not have a Fully Qualified Domain Name (FQDN). This method allows for the immediate use of OpenVidu with ARM Templates.</p> <p>However, this convenience comes with the caveat that users will need to manually accept the certificate in their web browsers. Please be aware that this configuration is solely for developmental and testing purposes and is not suitable for a real production environment.</p> <p>These are the parameters needed in this section to use self-signed certificates:</p> <p></p> <p></p> <p>You don\u2019t need to specify any parameters; just select the CertificateType as self-signed. The domain name used will be an Azure-generated one.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/azure/install/#openvidu-meet-credentials","title":"OpenVidu Meet Credentials","text":"<p>Configure the initial credentials for accessing OpenVidu Meet:</p> OpenVidu Meet credentials <p>Parameters in this section look like this:</p> <p></p> <ul> <li>InitialMeetAdminPassword: Initial password for the \"admin\" user in OpenVidu Meet. If not provided, a random password will be generated and stored in the Azure Key Vault.</li> <li>InitialMeetApiKey: Initial API key for OpenVidu Meet. If not provided, no API key will be set and the user can configure it later from the Meet Console.</li> </ul> <p>Both parameters are optional. If you don't specify them, you can retrieve the generated credentials from the Azure Key Vault after deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/azure/install/#openvidu-single-node-pro-configuration","title":"OpenVidu Single Node PRO configuration","text":"<p>In this section, you need to specify some properties needed for the OpenVidu Single Node PRO deployment.</p> OpenVidu Single Node PRO Configuration <p>Parameters of this section look like this:</p> <p></p> <p>Make sure to provide the OpenViduLicense parameter with the license key. If you don't have one, you can request one here.</p> <p>For the RTCEngine parameter, you can choose between Pion (the default engine used by LiveKit) and Mediasoup (with a boost in performance). Learn more about the differences here.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/azure/install/#azure-instance-configuration","title":"Azure Instance Configuration","text":"<p>Specify properties for the Azure instance that will host Openvidu.</p> Azure Instance configuration <p>Parameters in this section look like this:</p> <p></p> <p></p> <p>Simply select the type of instance you want to deploy at Type of Instance. Fill in the parameter Admin Username that will be set as admin username in the instance. Select the SSH key you've created previously in SSH public key source (or you can create a new one in the drop down) to allow you to SSH into the instance.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/azure/install/#storage-account","title":"Storage Account","text":"<p>You need to fill some parameters about the storage account that the deployment will use to save the recordings.</p> <p>Warning</p> <p>Recordings are not available in OpenVidu v2 Compatibility mode (v2compat) for OpenVidu Azure deployments.</p> Azure Storage Account configuration <p>Parameters in this section look like this:</p> <p></p> <p></p> <p>Storage Account Name: leave blank to create a new Storage Account for this deployment. You can specify an already existing Storage Account name  if you want (remember it must belong to the same resource group as your deployment).</p> <p>Container Name is the name that you desire for the container that of the storage account where the recordings will be saved. If you leave it blank it will create the container with name <code>openvidu-appdata</code>.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/azure/install/#optional-additional-flags","title":"(Optional) Additional flags","text":"<p>Additional optional flags to pass to the OpenVidu installer (comma-separated, e.g., <code>--flag1=value, --flag2</code>).</p> (Optional) Additional flags <p>Parameters in this section look like this:</p> <p></p> <p>For example, you can use <code>--experimental-turn-tls-with-main-domain</code> to use the same domain as the main one for the TURN server with TLS, instead of specifying a different one in the TURN server configuration with TLS section.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/azure/install/#optional-turn-server-configuration-with-tls","title":"(Optional) TURN server configuration with TLS","text":"<p>This section is optional. It is useful when your users are behind a restrictive firewall that blocks UDP traffic. This parameter will only work if you are using <code>letsencrypt</code> or <code>owncert</code> as the Certificate Type parameter.</p> TURN server configuration with TLS <p>Parameters in this section look like this:</p> <p></p> <p></p> <p>Set the Turn Domain Name parameter to the domain name you intend to use for your TURN server. It should be pointing to the <code>Public Ip Address</code> specified in the previous section.</p> <p>If you are using <code>letsencrypt</code> as the Certificate Type parameter, you can leave the Turn Own Public Certificate and Turn Own Private Certificate parameters empty. If you are using <code>owncert</code>, you need to specify the URLs where the public and private certificates are hosted.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/azure/install/#deploying-the-stack","title":"Deploying the stack","text":"<p>Whenever you are satisfied with your Template paremeters, just click on \"Next\" to trigger the validation process. If correct, click on \"Create\" to start the deployment process (which will take about 5 to 10 minutes).</p> <p>Warning</p> <p>In case of failure, it might be that some role failed to create. In this case redeploy in a new resource group and change the Stack Name. To remove a role in a resource group visit Remove Azure role assignments .</p> <p>When everything is ready, you can check the output secrets on the Key Vault or by connecting through SSH to the instance:</p> Check deployment outputs in Azure Key VaultCheck deployment outputs in the instance <ol> <li> <p>Go to the Key Vault created called yourstackname-keyvault in the Resource Group that you deployed. You can access it from the Azure Portal Dashboard .</p> </li> <li> <p>Once you are in the Key Vault on the left panel click on \"Objects\" \ud83e\udc52 \"Secrets\".</p> <p></p> <p></p> </li> <li> <p>Here click on the secret of your choice or whatever you need to check and click again in the current version of that secret</p> <p></p> <p></p> </li> <li> <p>Now you will see a lot of properties but the one you are searching for is located at the bottom and it will be revealed by clicking in \"Show Secret Value\".</p> <p></p> <p></p> </li> </ol> <p>SSH to the instance and navigate to the config folder <code>/opt/openvidu/config</code>. Files with the deployment outputs are:</p> <ul> <li><code>openvidu.env</code></li> <li><code>meet.env</code></li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/azure/install/#configure-your-application-to-use-the-deployment","title":"Configure your application to use the deployment","text":"<p>You need your Azure deployment outputs to configure your OpenVidu application. If you have permissions to access the Key Vault you will be able to check there all the outputs (Check deployment outputs in Azure Key Vault). If you don't have permissions to access the Key Vault you can still check the outputs directly in the instance through SSH (Check deployment outputs in the instance).</p> <p>Your authentication credentials and URL to point your applications would be:</p> <p>OpenVidu Meet:</p> <ul> <li><code>OPENVIDU-URL</code>: The URL to access OpenVidu Meet, which is always <code>https://yourdomain.example.io/</code></li> <li><code>MEET-INITIAL-ADMIN-USER</code>: User to access OpenVidu Meet Console. It is always <code>admin</code>.</li> <li><code>MEET-INITIAL-ADMIN-PASSWORD</code>: Password to access OpenVidu Meet Console.</li> <li><code>MEET-INITIAL-API-KEY</code>: API key to use OpenVidu Meet Embedded and OpenVidu Meet REST API.</li> </ul> <p>Note</p> <p>The <code>MEET-INITIAL-ADMIN-USER</code>, <code>MEET-INITIAL-ADMIN-PASSWORD</code>, and <code>MEET-INITIAL-API-KEY</code> values are initial settings that cannot be changed from Azure Key Vault. They can only be changed from the Meet Console.</p> <p>OpenVidu Platform:</p> <ul> <li><code>LIVEKIT-URL</code>: The URL to use LiveKit SDKs, which can be <code>wss://yourdomain.example.io/</code> or <code>https://yourdomain.example.io/</code> depending on the client library you are using.</li> <li><code>LIVEKIT-API-KEY</code>: API Key for LiveKit SDKs.</li> <li><code>LIVEKIT-API-SECRET</code>: API Secret for LiveKit SDKs.</li> </ul> <p>OpenVidu V2 Compatibility Credentials</p> <p>This section is only needed if you want to use OpenVidu v2 compatibility.</p> <ul> <li>URL: The URL to access OpenVidu, which is the value of <code>OPENVIDU-URL</code> (e.g., <code>https://yourdomain.example.io/</code>)</li> <li>Username: Basic auth user for OpenVidu v2 compatibility. It is always <code>OPENVIDUAPP</code>.</li> <li>Password: Basic auth password for OpenVidu v2 compatibility is the same as <code>LIVEKIT-API-SECRET</code>.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/azure/install/#troubleshooting-initial-azure-stack-creation","title":"Troubleshooting initial Azure stack creation","text":"<p>If something goes wrong during the initial Azure stack creation, your stack may reach some failed status for multiple reasons. It could be due to a misconfiguration in the parameters, a lack of permissions, or a problem with Azure services. When this happens, the following steps can help you troubleshoot the issue and identify what went wrong:</p> <ol> <li>Check if the instance or instances are running. If they are not, check the Azure deployment events for any error messages.</li> <li> <p>If the instance or instances are running, SSH into the instance and check the logs of the following files:</p> <ul> <li><code>/var/log/cloud-init-output.log</code></li> <li><code>/var/log/cloud-init.log</code></li> </ul> <p>These logs will give you more information about the Azure stack creation process.</p> </li> <li> <p>If everything seems fine, check the status and the logs of the installed OpenVidu services.</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/azure/install/#configuration-and-administration","title":"Configuration and administration","text":"<p>When your Azure stack reaches the <code>Succeeded</code> status, it means that all the resources have been created. You will need to wait about 5 to 10 minutes to let the instance install OpenVidu as we mentioned before. When this time has elapsed, try connecting to the deployment URL. If it doesn't work, we recommend checking the previous section. Once finished you can check the Administration section to learn how to manage your deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/azure/upgrade/","title":"Upgrade OpenVidu Single Node PRO - Azure","text":"","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/azure/upgrade/#upgrade-openvidu-single-node-pro-azure","title":"Upgrade OpenVidu Single Node PRO - Azure","text":"<p>In Azure, we recommend upgrading by redeploying OpenVidu Single Node Azure with the latest version.</p> <p>However, if you prefer to upgrade the OpenVidu Single Node without redeploying, you can follow the steps outlined in the Upgrade OpenVidu Single Node - On Premises section.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/gcp/admin/","title":"OpenVidu Single Node administration on Google Cloud Platform","text":"","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/gcp/admin/#openvidu-single-node-pro-administration-google-cloud-platform","title":"OpenVidu Single Node PRO administration: Google Cloud Platform","text":"<p>Google Cloud Platform OpenVidu Single Node deployments are internally identical to On Premises Single Node deployments, so you can follow the same instructions from On Premises Single Node documentation for administration and configuration. The only difference is that the deployment is automated with terraform from Google Cloud Platform.</p> <p>However, there are certain things worth mentioning:</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/gcp/admin/#start-and-stop-openvidu-through-google-cloud-platform-console","title":"Start and stop OpenVidu through Google Cloud Platform Console","text":"<p>You can start and stop all services as explained in the On Premises Single Node section. But you can also start and stop the Virtual Machine instance directly from Google Cloud Platform Console. This will stop all services running in the instance and reduce Google Cloud Platform costs.</p> Stop OpenVidu Single NodeStart OpenVidu Single Node <ol> <li>Go to GCP Compute Engine Instances  of Google Cloud Platform.</li> <li>There, you will find the Virtual Machine that runs OpenVidu. Its name should be something like yourstackname-vm-ce. Click on it.</li> <li>In the section of the Virtual Machine click on stop button to stop the Virtual Mache (and therefore OpenVidu).</li> </ol> <p></p> <p></p> <ol> <li>Go to GCP Compute Engine Instances  of Google Cloud Platform.</li> <li>There, you will find the Virtual Machine that runs OpenVidu. Its name should be something like yourstackname-vm-ce.  Click on it.</li> <li>In the section of the Virtual Machine click on start button to start the Virtual Mache (and therefore OpenVidu).</li> </ol> <p></p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/gcp/admin/#change-the-instance-type","title":"Change the instance type","text":"<p>You can change the instance type of the OpenVidu Single Node instance to adapt it to your needs. To do this, follow these steps:</p> <ol> <li>Go to GCP Compute Engine Instances  of Google Cloud Platform.</li> <li>There, you will find the Virtual Machine that runs OpenVidu. Its name should be something like yourstackname-vm-ce. Click on it.</li> <li>Stop the instance if is not stopped. Wait for it to stop.</li> <li> <p>Click on \"Edit\", go down and change the Machine Type.</p> Change instance type <p></p> <p></p> </li> <li> <p>Select the new instance type and click on \"Save\".</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/gcp/admin/#administration-and-configuration","title":"Administration and configuration","text":"<p>Regarding the administration of your deployment, you can follow the instructions in section On Premises Single Node Administration.</p> <p>Regarding the configuration of your deployment, you can follow the instructions in section Changing Configuration. Additionally, the How to Guides offer multiple resources to assist with specific configuration changes.</p> <p>In addition to these, an Google Cloud Platform deployment provides the capability to manage global configurations via the Google Cloud Platform Console using Secrets Manager created during the deployment:</p> Changing configuration through Secrets Manager <ol> <li>Navigate to the GCP Secrets Manager  on Google Cloud Platform.</li> <li>Click on the desired secret you want to change and click on \"New Version\".      </li> <li>Enter the new secret value on \"Secret Value\" filed and click on \"Add new version\".      </li> <li>Go to the Instance resource of OpenVidu and click on Stop -&gt; Start to apply the changes to the OpenVidu Single Node deployment.</li> </ol> <p>Changes will be applied automatically.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/gcp/install/","title":"OpenVidu Single Node installation on Google Cloud Platform","text":"","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/gcp/install/#openvidu-single-node-pro-administration-google-cloud-platform","title":"OpenVidu Single Node PRO administration: Google Cloud Platform","text":"<p>Warning</p> <p>Google Cloud Platform deployments are considered in Beta in version 3.4.0 of OpenVidu.</p> <p>This section contains the instructions of how to deploy a production-ready OpenVidu Single Node PRO deployment in Google Cloud Platform. Deployed services are the same as the On Premises Single Node installation but they will be resources in Google Cloud Platform and you can automate the process in the Google Cloud Console.</p> <p>To deploy OpenVidu into Google Cloud Platform you just need to log into your Infrastructure Manager  in the GCP console. Then follow the next steps to fill the parameters of your choice.</p> Architecture overview <p>This is how the architecture of the deployment looks like:</p> <p></p> OpenVidu Single Node Google Cloud Platform Architecture <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/gcp/install/#deployment-details","title":"Deployment details","text":"<p>Info</p> <p>We recommend to create a new project to deploy OpenVidu there, avoiding possible conflicts.</p> <p>To deploy OpenVidu, first you need to create a new deployment in the top left button as you can see in the image.</p> <p></p> <p>Once you click the button you will see this window.</p> <p></p> <p>Fill Deployment ID with any name that you desire like openvidu-singlenode-deployment, next choose the Region that you prefer, leave Terraform version in the 1.5.7 and for Service Account you will need to create a new one with \"Owner\" permissions, in order to do that click on \"Service Account\" label and then into \"New Service Account\", choose your service account name click on \"Create and Continue\" and then select the \"Owner\" role, click on \"Continue\" and the in \"Done\".   </p> <p>For the Git repository put this link <code>https://github.com/OpenVidu/openvidu.git</code> that corresponds to our git repository where are allocated the terraform files to deploy openvidu. In the Git directory introduce the following path <code>openvidu-deployment/pro/singlenode/gcp</code> and for the Git ref put <code>3.4.0</code> corresponding to the version then click on continue.   </p> New Service Account Steps <p></p> Step 1: Create Service Account <p></p> <p></p> Step 2: Service Account Details <p></p> <p></p> Step 3: Grant Permissions <p></p> <p></p> Step 4: Complete Setup <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/gcp/install/#input-values","title":"Input Values","text":"<p>In Google Cloud Platform there is no such thing like template with parameters, you will need to introduce by yourself in the console the parameters that are declared in our terraform files, so there is a detailed table of all the optional and non-optional parameters.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/gcp/install/#mandatory-parameters","title":"Mandatory Parameters","text":"Input Value Description projectId GCP project id where the resources will be created. stackName Stack name for OpenVidu deployment. openviduLicense Visit https://openvidu.io/account","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/gcp/install/#optional-parameters","title":"Optional Parameters","text":"Input Value Default Value Description region \"europe-west1\" GCP region where resources will be created. zone \"europe-west1-b\" GCP zone that some resources will use. certificateType \"letsEncrypt\" Certificate type for OpenVidu deployment. Options:           <ul> <li>[selfsigned] Not recommended for production use. Just for testing purposes or development environments. You don't need a FQDN to use this option.</li> <li>[owncert] Valid for production environments. Use your own certificate. You need a FQDN to use this option.</li> <li>[letsencrypt] Valid for production environments. Can be used with or without a FQDN (if no FQDN is provided, a random sslip.io domain will be used).</li> </ul> publicIpAddress (none) Previously created Public IP address for the OpenVidu Deployment. Blank will generate a public IP. domainName (none) Domain name for the OpenVidu Deployment. ownPublicCertificate (none) If certificate type is 'owncert', this parameter will be used to specify the public certificate. ownPrivateCertificate (none) If certificate type is 'owncert', this parameter will be used to specify the private certificate. initialMeetAdminPassword (none) Initial password for the 'admin' user in OpenVidu Meet. If not provided, a random password will be generated. initialMeetApiKey (none) Initial API key for OpenVidu Meet. If not provided, no API key will be set and the user can set it later from Meet Console. RTCEngine \"pion\" RTCEngine media engine to use. Allowed values are 'pion' and 'mediasoup'. instanceType \"e2-standard-8\" Specifies the GCE machine type for your OpenVidu instance. bucketName (none) Name of the S3 bucket to store data and recordings. If empty, a bucket will be created. additionalInstallFlags (none) Additional optional flags to pass to the OpenVidu installer (comma-separated, e.g., '--flag1=value, --flag2'). turnDomainName (none) (Optional) Domain name for the TURN server with TLS. Only needed if your users are behind restrictive firewalls. turnOwnPublicCertificate (none) (Optional) This setting is applicable if the certificate type is set to 'owncert' and the TurnDomainName is specified. turnOwnPrivateCertificate (none) (Optional) This setting is applicable if the certificate type is set to 'owncert' and the TurnDomainName is specified. <p>For more detail you can check the variables.tf  file to see more information about the inputs.   </p> <p>Warning</p> <p>It's important that you put the input variables with the same name as they appear in the table like in the next image.</p> <p></p> <p></p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/gcp/install/#deploying-the-stack","title":"Deploying the stack","text":"<p>Whenever you are satisfied with your input values, just click on \"Continue\" and then in \"Create deployment\". Now it will validate the deployment and create all the resources. Wait about 5 to 10 minutes to let the instance install OpenVidu.</p> <p>Warning</p> <p>In case of failure, check the cloud build logs that appears on the top of the screen and redeploy with the changes that are causing the deployment to fail, if it keeps failing contact us.</p> <p></p> <p></p> <p>When everything is ready, you can check the secrets on the Secret Manager  or by connecting through SSH to the instance:</p> Check deployment outputs in Google Cloud Platform Secret ManagerCheck deployment outputs in the instance <ol> <li> <p>Go to the Secret Manager .</p> </li> <li> <p>Once you are in the Secret Manager you will see all the secrets by their name.</p> <p></p> <p></p> </li> <li> <p>Here click on the secret of your choice or whatever you need to check and click again in the last version of that secret.</p> <p></p> <p></p> </li> </ol> <p>SSH to the instance by gcloud command generated in the web console and navigate to the config folder <code>/opt/openvidu/config</code>. Files with the deployment outputs are:</p> <ul> <li><code>openvidu.env</code></li> <li><code>meet.env</code></li> </ul> <p>To find out the command go to Compute Engine Instances  and click on the arrow close to the SSH letters and then \"View gcloud command\". </p> <p></p> <p>To install gcloud in your shell follow the official instructions .</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/gcp/install/#configure-your-application-to-use-the-deployment","title":"Configure your application to use the deployment","text":"<p>You need your Google Cloud Platform secret outputs to configure your OpenVidu application. You can check these secrets by searching in the Secrets Manager with any of these two ways (Check deployment outputs in Google Cloud Platform Secret Manager) or (Check deployment outputs in the instance).</p> <p>Your authentication credentials and URL to point your applications would be:</p> <ul> <li>URL: The value in the Secret Manager of <code>OPENVIDU_URL</code>. In the instance in <code>openvidu.env</code> find <code>DOMAIN_NAME</code> and build it into a URL. The URL would be <code>https://your.domain.name/</code>. If you want the <code>LIVEKIT_URL</code> find the value in the Secret Manager of <code>LIVEKIT_URL</code> or build the URL with the <code>DOMAIN_NAME</code>as <code>wss://your.domain.name/</code>.</li> <li>API Key: The value in the Secret Manager of <code>LIVEKIT_API_KEY</code> or in the instance in <code>openvidu.env</code>.</li> <li>API Secret: The value in the Secret Manager of <code>LIVEKIT-API-SECRET</code> or in the instance in <code>openvidu.env</code>.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/gcp/install/#troubleshooting-initial-google-cloud-platform-deployment-creation","title":"Troubleshooting initial Google Cloud Platform deployment creation","text":"<p>If something goes wrong during the initial GCP deployment creation, your stack may reach some failed status for multiple reasons. It could be due to a misconfiguration in the parameters, a lack of permissions, or a problem with GCP services. When this happens, the following steps can help you troubleshoot the issue and identify what went wrong:</p> <ol> <li>Check if the instance or instances are running. If they are not, check the GCP cloud build logs for any error messages.</li> <li> <p>If the instance or instances are running, SSH into the instance and check the logs by running this command:</p> <ul> <li><code>journalctl -u google-startup-scripts | cat</code></li> </ul> <p>These logs will give you more information about the GCP deployment creation process.</p> </li> <li> <p>If everything seems fine, check the status and the logs of the installed OpenVidu services.</p> </li> </ol>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/gcp/install/#configuration-and-administration","title":"Configuration and administration","text":"<p>When your Google Cloud Platform deployment reaches the <code>Active</code> state, it means that all the resources have been created. You will need to wait about 5 to 10 minutes to let the instance install OpenVidu as we mentioned before. When this time has elapsed, try connecting to the deployment URL. If it doesn't work, we recommend checking the previous section. Once finished you can check the Administration section to learn how to manage your deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/gcp/upgrade/","title":"Upgrade OpenVidu Single Node PRO - Google Cloud Platform","text":"","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/gcp/upgrade/#openvidu-single-node-pro-administration-google-cloud-platform","title":"OpenVidu Single Node PRO administration: Google Cloud Platform","text":"<p>In Google Cloud Platform, we recommend upgrading by redeploying OpenVidu Single Node Google Cloud Platform with the latest version.</p> <p>However, if you prefer to upgrade the OpenVidu Single Node without redeploying, you can follow the steps outlined in the Upgrade OpenVidu Single Node - On Premises section.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/on-premises/admin/","title":"OpenVidu Single Node administration on-premises","text":"","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/on-premises/admin/#openvidu-single-node-pro-administration-on-premises","title":"OpenVidu Single Node PRO administration: On-premises","text":"<p>The OpenVidu installer offers an easy way to deploy OpenVidu Single Node PRO on-premises. However, once the deployment is complete, you may need to perform administrative tasks based on your specific requirements, such as changing passwords, specifying custom configurations, and starting or stopping services.</p> <p>This section provides details on configuration parameters and common administrative tasks for this deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/on-premises/admin/#starting-stopping-and-restarting-openvidu","title":"Starting, stopping, and restarting OpenVidu","text":"<p>You can start, stop, and restart the OpenVidu services using the following commands:</p> <p>Start OpenVidu</p> <pre><code>sudo systemctl start openvidu\n</code></pre> <p>Stop OpenVidu</p> <pre><code>sudo systemctl stop openvidu\n</code></pre> <p>Restart OpenVidu</p> <pre><code>sudo systemctl restart openvidu\n</code></pre>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/on-premises/admin/#checking-the-status-of-services","title":"Checking the status of services","text":"<p>You can check the status of the OpenVidu services using the following command:</p> <pre><code>cd /opt/openvidu/\ndocker compose ps\n</code></pre> <p>The services are operating correctly if you see an output similar to the following and there are no restarts from any of the services:</p> <pre><code>NAME                       IMAGE                                              COMMAND                   SERVICE                    CREATED          STATUS\napp                        docker.io/openvidu/openvidu-call:main              \"docker-entrypoint.s\u2026\"    app                        18 seconds ago   Up 7 seconds\ncaddy                      docker.io/openvidu/openvidu-pro-caddy:main         \"/bin/caddy run --co\u2026\"    caddy                      18 seconds ago   Up 8 seconds\ndashboard                  docker.io/openvidu/openvidu-pro-dashboard:main     \"./openvidu-dashboard\"    dashboard                  18 seconds ago   Up 8 seconds\negress                     docker.io/livekit/egress:v1.9.0                    \"/entrypoint.sh\"          egress                     18 seconds ago   Up 5 seconds\ngrafana                    docker.io/grafana/grafana:11.5.1                   \"/bin/sh -c '\\n  if !\u2026\"   grafana                    17 seconds ago   Up 4 seconds\ningress                    docker.io/openvidu/ingress:main                    \"ingress\"                 ingress                    18 seconds ago   Up 6 seconds\nloki                       docker.io/grafana/loki:3.3.2                       \"/bin/sh -c '\\n  if !\u2026\"   loki                       18 seconds ago   Up 6 seconds\nminio                      docker.io/bitnami/minio:2025.2.7-debian-12-r0      \"/bin/sh -c '\\n  . /c\u2026\"   minio                      18 seconds ago   Up 8 seconds\nmongo                      docker.io/mongo:8.0.4                              \"/bin/sh -c '\\n  . /c\u2026\"   mongo                      18 seconds ago   Up 15 seconds\nopenvidu                   docker.io/openvidu/openvidu-server-pro:main        \"/livekit-server --c\u2026\"    openvidu                   18 seconds ago   Up 5 seconds\nopenvidu-v2compatibility   docker.io/openvidu/openvidu-v2compatibility:main   \"/bin/entrypoint.sh\"      openvidu-v2compatibility   18 seconds ago   Up 6 seconds\noperator                   docker.io/openvidu/openvidu-operator:main          \"/bin/operator\"           operator                   18 seconds ago   Up 5 seconds\nprometheus                 docker.io/prom/prometheus:v3.1.0                   \"/bin/sh -c '\\n  if !\u2026\"   prometheus                 17 seconds ago   Up 5 seconds\npromtail                   docker.io/grafana/promtail:3.3.2                   \"/bin/sh -c '\\n  if !\u2026\"   promtail                   18 seconds ago   Up 5 seconds\nredis                      docker.io/redis:7.4.2-alpine                       \"/bin/sh -c '\\n  . /c\u2026\"   redis                      18 seconds ago   Up 6 seconds\n</code></pre>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/on-premises/admin/#checking-logs","title":"Checking logs","text":"<p>If any of the services are not working as expected, you can check the logs of the services using the following command:</p> <pre><code>cd /opt/openvidu/\ndocker compose logs &lt;service-name&gt;\n</code></pre> <p>Replace <code>&lt;service-name&gt;</code> with the name of the service you want to check. For example, to check the logs of the OpenVidu Server, use the following command:</p> <pre><code>cd /opt/openvidu/\ndocker compose logs openvidu\n</code></pre> <p>To check the logs of all services, use the following command:</p> <pre><code>cd /opt/openvidu/\ndocker compose logs\n</code></pre> <p>Or use journalctl:</p> <pre><code>journalctl -f -u openvidu\n</code></pre> <p>You can also review your logs using the Grafana dashboard provided with OpenVidu. To access it, go to https://&lt;your-domain.com&gt;/grafana and use the credentials located in <code>/opt/openvidu/.env</code> to log in. Once inside, navigate to the \"Home\" section, select \"Dashboard\", and then click on \"OpenVidu &gt; OpenVidu Logs\". All the logs will be displayed there.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/on-premises/admin/#changing-the-configuration","title":"Changing the configuration","text":"<p>You can check how to change the configuration in the Changing Configuration section. Also, there are multiple guides in the How to Guides section that can help you with specific configuration changes.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/on-premises/admin/#uninstalling-openvidu","title":"Uninstalling OpenVidu","text":"<p>To uninstall OpenVidu, just execute the following commands:</p> <pre><code>sudo su\nsystemctl stop openvidu\nrm -rf /opt/openvidu/\nrm /etc/systemd/system/openvidu.service\nrm /etc/sysctl.d/50-openvidu.conf\n</code></pre>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/on-premises/install/","title":"OpenVidu Single Node PRO installation on-premises","text":"","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/on-premises/install/#openvidu-single-node-pro-installation-on-premises","title":"OpenVidu Single Node PRO installation: On-premises","text":"<p>This section contains the instructions to deploy a production-ready OpenVidu Single Node PRO deployment on-premises. It is a deployment based on Docker and Docker Compose, which will automatically configure all the necessary services for OpenVidu to work properly.</p> Architecture overview <p>This is how the architecture of the deployment looks like:</p> <p></p> OpenVidu Single Node On Premises Architecture <p></p> <p>All services are deployed on a single machine, which includes:</p> <ul> <li>OpenVidu Server (LiveKit compatible).</li> <li>Ingress and Egress services.</li> <li>OpenVidu Dashboard, a web application interface to visualize your Rooms, Ingress, and Egress services.</li> <li>MinIO as an S3 storage service for recordings.</li> <li>Redis as a shared database for OpenVidu Server and Ingress/Egress services.</li> <li>MongoDB as a database for storing analytics and monitoring data.</li> <li>Caddy as a reverse proxy. It can be deployed with self-signed certificates, Let's Encrypt certificates, or custom certificates.</li> <li>OpenVidu Meet, an optional high-quality video calling service.</li> <li>OpenVidu V2 Compatibility (v2compatibility module) is an optional service that provides an API designed to maintain compatibility for applications developed with OpenVidu version 2.</li> <li>Grafana, Mimir, Promtail, and Loki (Observability module) form an optional observability stack for monitoring, allowing you to keep track of logs and deployment statistics for OpenVidu.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/on-premises/install/#prerequisites","title":"Prerequisites","text":"<p>Before starting the installation process, make sure you have the following prerequisites:</p> <ul> <li>A machine with at least 4GB RAM and 4 CPU cores and Linux installed (Ubuntu recommended).</li> <li>Generous disk space (100GB recommended) if you are going to record your sessions.</li> <li>The machine must have a Public IP. An FQDN (Fully Qualified Domain Name) is optional. If not provided, an autogenerated domain using sslip.io will be used.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/on-premises/install/#port-rules","title":"Port rules","text":"<p>Ensure all these rules are configured in your firewall, security group, or any kind of network configuration that you have in your machine.</p> <p>Inbound port rules:</p> Protocol Ports Source Description TCP 80 0.0.0.0/0, ::/0 Redirect HTTP traffic to HTTPS and Let's Encrypt validation. TCP 443 0.0.0.0/0, ::/0 Allows access to the following: <ul><li>LiveKit API.</li><li>OpenVidu Dashboard.</li><li>OpenVidu Meet.</li><li>WHIP API.</li><li>TURN with TLS.</li><li>Custom layouts</li></ul> UDP 443 0.0.0.0/0, ::/0 STUN/TURN server over UDP. TCP 1935 0.0.0.0/0, ::/0 Needed if you want to ingest RTMP streams using Ingress service. TCP 9000 0.0.0.0/0, ::/0 Needed if you want to expose MinIO publicly. TCP 7881 0.0.0.0/0, ::/0 Needed for WebRTC media traffic over TCP with Pion. UDP 7885 0.0.0.0/0, ::/0 Needed if you want to ingest WebRTC using WHIP. UDP 50000-60000 0.0.0.0/0, ::/0 Needed for WebRTC media traffic over UDP. TCP 50000-60000 0.0.0.0/0, ::/0 Needed for WebRTC media traffic over TCP with Mediasoup. <p>Outbound port rules:</p> <p>Typically, all outbound traffic is allowed.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/on-premises/install/#guided-installation","title":"Guided Installation","text":"<p>Before the installation, ensure that your machine meets the prerequisites and the port rules. Then, execute the following command on the machine where you want to deploy OpenVidu:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/pro/singlenode/latest/install.sh)\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <p>A wizard will guide you through the installation process. You will be asked for the following information:</p> <ul> <li>Write your OpenVidu PRO License: Write your OpenVidu PRO License.</li> <li>Domain name (Optional): The domain name for your deployment. If left empty, an autogenerated domain using sslip.io (e.g., <code>10-20-30-40.sslip.io</code>) will be used based on your machine's public IP. For production environments, it's recommended to provide your own FQDN.</li> <li> <p>Select which certificate type to use:</p> <ul> <li>Self Signed Certificate: It will generate a self-signed certificate. It is not recommended for production environments, but it is useful for testing or development purposes.</li> <li>Let's Encrypt: It will automatically generate a certificate for your domain.</li> <li>ZeroSSL: It will automatically generate a certificate for your domain using ZeroSSL. An API Key is required and will be asked later in the wizard. Note: This option is only available when providing an FQDN (Fully Qualified Domain Name).</li> <li>Own Certificate: It will ask you for the certificate and key files. Just copy and paste the content of the files when the wizard asks for them. Note: This option is only available when providing an FQDN (Fully Qualified Domain Name).</li> </ul> <p>Note</p> <p>If you want to manage the certificate in your proxy own proxy server instead of relaying in the Caddy server deployed with OpenVidu, take a look to this How-to guide: How to deploy OpenVidu with an external proxy.</p> </li> <li> <p>(Optional) Turn domain name: The domain name for your TURN server with TLS. If no main domain is provided and this is also left empty, an autogenerated domain using sslip.io will be used. This is recommended if users who are going to connect to your OpenVidu deployment are behind restrictive firewalls.</p> </li> <li>Select which RTC engine to use: Select the WebRTC engine you want to use. You can choose between Pion (the default engine used by LiveKit) and Mediasoup (with a boost in performance). Learn more about the differences here.</li> <li>Modules to enable: Select the modules you want to enable. You can enable the following modules:<ul> <li>OpenVidu Meet: A high-quality video calling service based on OpenVidu.</li> <li>Observability: Grafana stack, which includes logs and monitoring stats.</li> <li>OpenVidu V2 Compatibility: Compatibility API for applications developed with OpenVidu v2.</li> </ul> </li> </ul> <p>The rest of the parameters are secrets, usernames, and passwords. If empty, the wizard will generate random values for them.</p> <p>When the installation process finishes, you will see the following message:</p> <pre><code>&gt; - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - &lt;\n&gt;                                                                             &lt;\n&gt;  \ud83c\udf89 OpenVidu Single Node PRO Installation Finished Successfully! \ud83c\udf89         &lt;\n&gt;                                                                             &lt;\n&gt; - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - &lt;\n</code></pre> <p>OpenVidu will be installed at <code>/opt/openvidu</code> and configured as a systemd service. You can start the service with the following command:</p> <pre><code>systemctl start openvidu\n</code></pre> <p>If everything goes well, all containers will be up and running without restarts, and you will be able to access any of the following services:</p> <ul> <li>OpenVidu Meet: https://openvidu.example.io/</li> <li>OpenVidu Dashboard: https://openvidu.example.io/dashboard</li> <li>MinIO: https://openvidu.example.io/minio-console</li> <li>Grafana: https://openvidu.example.io/grafana</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/on-premises/install/#configure-your-application-to-use-the-deployment","title":"Configure your application to use the deployment","text":"<p>To point your applications to your OpenVidu deployment, check the following files:</p> <ul> <li><code>/opt/openvidu/config/meet.env</code>: Contains the OpenVidu Meet parameters.</li> <li><code>/opt/openvidu/config/openvidu.env</code>: Contains all the credentials of services deployed with OpenVidu Platform.</li> </ul> <p>The most relevant parameters are:</p> <p>OpenVidu Meet:</p> <ul> <li><code>MEET_INITIAL_ADMIN_USER</code>: User to access OpenVidu Meet Console. It is always <code>admin</code>.</li> <li><code>MEET_INITIAL_ADMIN_PASSWORD</code>: Password to access OpenVidu Meet Console.</li> <li><code>MEET_INITIAL_API_KEY</code>: API key to use OpenVidu Meet Embedded and OpenVidu Meet REST API.</li> </ul> <p>Note</p> <p>The <code>MEET_INITIAL_ADMIN_USER</code>, <code>MEET_INITIAL_ADMIN_PASSWORD</code>, and <code>MEET_INITIAL_API_KEY</code> values are initial and cannot be changed from the <code>meet.env</code> file. They can only be changed from the Meet Console.</p> <p>OpenVidu Platform:</p> <ul> <li><code>LIVEKIT_URL</code>: The URL to use LiveKit SDKs, which can be <code>wss://yourdomain.example.io/</code> or <code>https://yourdomain.example.io/</code> depending on the client library you are using.</li> <li><code>LIVEKIT_API_KEY</code>: API Key for LiveKit SDKs.</li> <li><code>LIVEKIT_API_SECRET</code>: API Secret for LiveKit SDKs.</li> </ul> <p>OpenVidu V2 Compatibility Credentials</p> <p>This section is only needed if you want to use OpenVidu v2 compatibility.</p> <ul> <li>URL: The URL to access OpenVidu, which is formed by the <code>DOMAIN_NAME</code> as <code>https://yourdomain.example.io/</code></li> <li>Username: Basic auth user for OpenVidu v2 compatibility. It is always <code>OPENVIDUAPP</code>.</li> <li>Password: Basic auth password for OpenVidu v2 compatibility is the same as <code>LIVEKIT_API_SECRET</code>.</li> </ul>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/on-premises/install/#non-interactive-installation","title":"Non-interactive installation","text":"<p>If you want to automate the installation process, you can generate a command with all the parameters needed to install OpenVidu by answering the wizard questions. You can do this by running the following command:</p> <pre><code>docker run --pull always --rm -it \\\n    openvidu/openvidu-installer:latest \\\n    --deployment-type=single_node_pro\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <p>This is going to generate a command like this, but it may vary depending on the answers you provide. Here are three examples of the command you can run depending on the certificate type you choose:</p> Without Domain NameWith Domain Name Let's Encrypt certificatesSelf-signed certificates <p>Example using Let's Encrypt certificates with autogenerated sslip.io domain:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/pro/singlenode/latest/install.sh) \\\n    --no-tty --install \\\n    --openvidu-pro-license='xxxxx' \\\n    --enabled-modules='observability,v2compatibility,openviduMeet' \\\n    --rtc-engine='pion' \\\n    --livekit-api-key='xxxxx' \\\n    --livekit-api-secret='xxxxx' \\\n    --dashboard-admin-user='xxxxx' \\\n    --dashboard-admin-password='xxxxx' \\\n    --redis-password='xxxxx' \\\n    --minio-access-key='xxxxx' \\\n    --minio-secret-key='xxxxx' \\\n    --mongo-admin-user='xxxxx' \\\n    --mongo-admin-password='xxxxx' \\\n    --mongo-replica-set-key='xxxxx' \\\n    --grafana-admin-user='xxxxx' \\\n    --grafana-admin-password='xxxxx' \\\n    --meet-initial-admin-password='xxxxx' \\\n    --meet-initial-api-key='xxxxx' \\\n    --certificate-type='letsencrypt'\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <ul> <li><code>--openvidu-pro-license</code> is mandatory. You can get a 15-day free trial license key by creating an OpenVidu account.</li> <li>Depending on the RTC engine, the argument <code>--rtc-engine</code> can be <code>pion</code> or <code>mediasoup</code>.</li> </ul> <p>Example using self-signed certificates with autogenerated sslip.io domain:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/pro/singlenode/latest/install.sh) \\\n    --no-tty --install \\\n    --openvidu-pro-license='xxxxx' \\\n    --enabled-modules='observability,v2compatibility,openviduMeet' \\\n    --rtc-engine='pion' \\\n    --livekit-api-key='xxxxx' \\\n    --livekit-api-secret='xxxxx' \\\n    --dashboard-admin-user='xxxxx' \\\n    --dashboard-admin-password='xxxxx' \\\n    --redis-password='xxxxx' \\\n    --minio-access-key='xxxxx' \\\n    --minio-secret-key='xxxxx' \\\n    --mongo-admin-user='xxxxx' \\\n    --mongo-admin-password='xxxxx' \\\n    --mongo-replica-set-key='xxxxx' \\\n    --grafana-admin-user='xxxxx' \\\n    --grafana-admin-password='xxxxx' \\\n    --meet-initial-admin-password='xxxxx' \\\n    --meet-initial-api-key='xxxxx' \\\n    --certificate-type='selfsigned'\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <ul> <li><code>--openvidu-pro-license</code> is mandatory. You can get a 15-day free trial license key by creating an OpenVidu account.</li> <li>Depending on the RTC engine, the argument <code>--rtc-engine</code> can be <code>pion</code> or <code>mediasoup</code>.</li> </ul> Let's Encrypt certificatesSelf-signed certificatesCustom certificates <p>Example using Let's Encrypt certificates:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/pro/singlenode/latest/install.sh) \\\n    --no-tty --install \\\n    --openvidu-pro-license='xxxxx' \\\n    --domain-name='openvidu.example.io' \\\n    --enabled-modules='observability,v2compatibility,openviduMeet' \\\n    --turn-domain-name='turn.example.io' \\\n    --rtc-engine='pion' \\\n    --livekit-api-key='xxxxx' \\\n    --livekit-api-secret='xxxxx' \\\n    --dashboard-admin-user='xxxxx' \\\n    --dashboard-admin-password='xxxxx' \\\n    --redis-password='xxxxx' \\\n    --minio-access-key='xxxxx' \\\n    --minio-secret-key='xxxxx' \\\n    --mongo-admin-user='xxxxx' \\\n    --mongo-admin-password='xxxxx' \\\n    --mongo-replica-set-key='xxxxx' \\\n    --grafana-admin-user='xxxxx' \\\n    --grafana-admin-password='xxxxx' \\\n    --meet-initial-admin-password='xxxxx' \\\n    --meet-initial-api-key='xxxxx' \\\n    --certificate-type='letsencrypt'\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <ul> <li><code>--openvidu-pro-license</code> is mandatory. You can get a 15-day free trial license key by creating an OpenVidu account.</li> <li>Depending on the RTC engine, the argument <code>--rtc-engine</code> can be <code>pion</code> or <code>mediasoup</code>.</li> </ul> <p>Example using self-signed certificates:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/pro/singlenode/latest/install.sh) \\\n    --no-tty --install \\\n    --openvidu-pro-license='xxxxx' \\\n    --domain-name='openvidu.example.io' \\\n    --enabled-modules='observability,v2compatibility,openviduMeet' \\\n    --turn-domain-name='turn.example.io' \\\n    --rtc-engine='pion' \\\n    --livekit-api-key='xxxxx' \\\n    --livekit-api-secret='xxxxx' \\\n    --dashboard-admin-user='xxxxx' \\\n    --dashboard-admin-password='xxxxx' \\\n    --redis-password='xxxxx' \\\n    --minio-access-key='xxxxx' \\\n    --minio-secret-key='xxxxx' \\\n    --mongo-admin-user='xxxxx' \\\n    --mongo-admin-password='xxxxx' \\\n    --mongo-replica-set-key='xxxxx' \\\n    --grafana-admin-user='xxxxx' \\\n    --grafana-admin-password='xxxxx' \\\n    --meet-initial-admin-password='xxxxx' \\\n    --meet-initial-api-key='xxxxx' \\\n    --certificate-type='selfsigned'\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <ul> <li><code>--openvidu-pro-license</code> is mandatory. You can get a 15-day free trial license key by creating an OpenVidu account.</li> <li>Depending on the RTC engine, the argument <code>--rtc-engine</code> can be <code>pion</code> or <code>mediasoup</code>.</li> </ul> <p>Example using custom certificates:</p> <pre><code>CERT_PRIVATE_KEY=$(cat privkey.pem | base64 -w 0)\nCERT_PUBLIC_KEY=$(cat fullchain.pem | base64 -w 0)\n\n# Optional, only if you want to enable TURN with TLS\nCERT_TURN_PRIVATE_KEY=$(cat turn-privkey.pem | base64 -w 0)\nCERT_TURN_PUBLIC_KEY=$(cat turn-fullchain.pem | base64 -w 0)\n\nsh &lt;(curl -fsSL http://get.openvidu.io/pro/singlenode/latest/install.sh) \\\n    --no-tty --install \\\n    --openvidu-pro-license='xxxxx' \\\n    --domain-name='openvidu.example.io' \\\n    --enabled-modules='observability,v2compatibility,openviduMeet' \\\n    --turn-domain-name='turn.example.io' \\\n    --rtc-engine='pion' \\\n    --livekit-api-key='xxxxx' \\\n    --livekit-api-secret='xxxxx' \\\n    --dashboard-admin-user='xxxxx' \\\n    --dashboard-admin-password='xxxxx' \\\n    --redis-password='xxxxx' \\\n    --minio-access-key='xxxxx' \\\n    --minio-secret-key='xxxxx' \\\n    --mongo-admin-user='xxxxx' \\\n    --mongo-admin-password='xxxxx' \\\n    --mongo-replica-set-key='xxxxx' \\\n    --grafana-admin-user='xxxxx' \\\n    --grafana-admin-password='xxxxx' \\\n    --meet-initial-admin-password='xxxxx' \\\n    --meet-initial-api-key='xxxxx' \\\n    --certificate-type='owncert' \\\n    --owncert-private-key=\"$CERT_PRIVATE_KEY\" \\\n    --owncert-public-key=\"$CERT_PUBLIC_KEY\" \\\n    --turn-owncert-private-key=\"$CERT_TURN_PRIVATE_KEY\" \\\n    --turn-owncert-public-key=\"$CERT_TURN_PUBLIC_KEY\"\n</code></pre> <p>Note</p> <p>In case you want to deploy a specific version, just replace <code>latest</code> with the desired version. For example: <code>3.4.0</code>.</p> <ul> <li>Note that you just need to pass <code>--owncert-private-key</code> and <code>--owncert-public-key</code> with the content of the private and public key files in base64 format. The installation script will decode them and save them in the proper files.</li> <li><code>--openvidu-pro-license</code> is mandatory. You can get a 15-day free trial license key by creating an OpenVidu account.</li> <li>Depending on the RTC engine, the argument <code>--rtc-engine</code> can be <code>pion</code> or <code>mediasoup</code>.</li> <li><code>--turn-owncert-private-key</code> and <code>--turn-owncert-public-key</code> are optional. You only need to pass them if you want to enable TURN with TLS.</li> </ul> <p>You can run that command in a CI/CD pipeline or in a script to automate the installation process.</p> <p>Some notes about the command:</p> <ul> <li>The argument <code>--domain-name</code> is optional. If not provided, an autogenerated domain using sslip.io will be used based on your machine's public IP.</li> <li>The argument <code>--turn-domain-name</code> is optional. You define it only if you want to enable TURN with TLS in case users are behind restrictive firewalls. If no main domain is provided and this is also left empty, an autogenerated domain using sslip.io will be used.</li> <li>When using autogenerated domains (no FQDN (Fully Qualified Domain Name) provided), only <code>selfsigned</code> and <code>letsencrypt</code> certificate types are available.</li> <li>At the argument <code>--enabled-modules</code>, you can enable the modules you want to deploy. You can enable <code>openviduMeet</code> OpenVidu Meet service, <code>observability</code> (Grafana stack) and <code>v2compatibility</code> (OpenVidu v2 compatibility API).</li> <li>If no media appears in your conference, reinstall specifying the <code>--public-ip</code> parameter with your machine's public IP. OpenVidu usually auto-detects the public IP, but it can fail. This IP is used by clients to send and receive media.</li> </ul> <p>To start OpenVidu, remember to run:</p> <pre><code>systemctl start openvidu\n</code></pre>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/on-premises/install/#configuration-and-administration","title":"Configuration and administration","text":"<p>Once you have OpenVidu deployed, you can check the Administration section to learn how to manage your OpenVidu Single Node deployment.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/on-premises/upgrade/","title":"Upgrade OpenVidu Single Node","text":"","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/on-premises/upgrade/#upgrade-openvidu-single-node-pro-on-premises","title":"Upgrade OpenVidu Single Node PRO - On Premises","text":"<p>OpenVidu offers an updater that allows you to upgrade your OpenVidu deployment in an easy and automated way. The updater will take care of the whole process, from stopping the services to updating the configuration files.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/on-premises/upgrade/#upgrading-openvidu-single-node","title":"Upgrading OpenVidu Single Node","text":"<p>Upgrade OpenVidu Single Node is very simple. These are the steps you need to follow:</p> <ol> <li>SSH into your OpenVidu Single Node server.</li> <li> <p>Execute the following command:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/update/latest/update.sh)\n</code></pre> <p>Info</p> <p>If instead of upgrading to the latest version you want to upgrade to a specific version, you can execute the following command:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/update/&lt;VERSION&gt;/update.sh)\n</code></pre> <p>Where <code>&lt;VERSION&gt;</code> is the version you want to upgrade to.</p> </li> <li> <p>This will execute an update script which will guide you from the version you have installed to the latest one. The first thing you will see in the output is the following:</p> <pre><code>Stopping OpenVidu service...\nBacking up files...\n\n    - Backing up file '/opt/openvidu/config' to '/opt/openvidu/backups/&lt;DATE&gt;_&lt;VERSION&gt;/config'\n    ... More files ...\n\n--------------------\n\ud83d\udce6 Backup directory: /opt/openvidu/backups/&lt;DATE&gt;_&lt;VERSION&gt;/\n--------------------\n\n--------------------\n\ud83d\ude80 Updating OpenVidu from 3.x.x to 3.y.y\n--------------------\n\n? Do you want to update from 3.x.x to 3.y.y? \u203a\n\u2022 Yes\n  No\n</code></pre> </li> <li> <p>Answer <code>Yes</code> to the question and your OpenVidu Single Node will be upgraded to asked version. For each version the system will ask you to confirm the upgrade.</p> </li> <li>A <code>diff</code> will be shown with the changes made in the configuration files. You can review the changes and decide if you want to apply them or not. If you want to apply the changes, answer <code>Yes</code> to the question. If you want to discard the changes and stop the upgrading process, simply answer <code>No</code>.</li> <li>Once the upgrade is finished, it will ask you to pull the images of the services. Answer <code>Yes</code> if you want to do it.</li> <li>Start OpenVidu with the following command:</li> </ol> <pre><code>systemctl start openvidu &amp;&amp; journalctl -f -u openvidu\n</code></pre> <p>The <code>journalctl</code> command will show you the logs of the OpenVidu services. You can stop the logs by pressing <code>Ctrl + C</code>.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/on-premises/upgrade/#backups-and-rollback","title":"Backups and Rollback","text":"<p>When you finish the upgrade process, you will have a backup of the previous version in the <code>/opt/openvidu/backups</code> directory. To backup to a specific date and version, you can execute the following command:</p> <pre><code>cp -r /opt/openvidu/backups/&lt;DATE&gt;_&lt;VERSION&gt;/* /opt/openvidu\n</code></pre> <p>Where <code>&lt;DATE&gt;</code> and <code>&lt;VERSION&gt;</code> are the date and version of the backup you want to restore. For example:</p> <pre><code>cp -r /opt/openvidu/backups/2025-02-12-09-50-46_3.0.0/* /opt/openvidu\n</code></pre> <p>In the previous command, you have to replace the date and version with the one you want to restore.</p>","tags":["Platform"]},{"location":"docs/self-hosting/single-node-pro/on-premises/upgrade/#recommendations","title":"Recommendations","text":"<ul> <li>On any upgrade problem, a redeployment is always recommended for a clean installation.</li> <li>Keep your Docker and Docker Compose versions updated.</li> <li> <p>Remove non-used images and containers to free up disk space. For example, after the upgrade, when OpenVidu is running, you can remove the old images with the following command:</p> <pre><code>docker image prune -a\n</code></pre> <p>This command will remove all the images that are not being used by any container.</p> </li> </ul>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/","title":"Advanced Features Tutorials","text":"","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/#advanced-features-tutorials","title":"Advanced Features Tutorials","text":"<p>Explore more advanced features of LiveKit! For now, we have implemented a basic recording tutorial and an advanced one, but our tutorials for streaming and ingesting are coming soon.</p> <p> Recording Basic S3</p> <p> Recording Advanced S3</p> <p> Recording Basic Azure</p> <p> Recording Advanced Azure</p>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-azure/","title":"Advanced Recording Tutorial Azure","text":"","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-azure/#advanced-recording-tutorial-azure","title":"Advanced Recording Tutorial Azure","text":"<p>Source code </p> <p>This tutorial improves the basic recording tutorial by doing the following:</p> <ul> <li>Complete recording metadata: Listen to webhook events and save all necessary metadata in a separate file.</li> <li>Real time recording status notification: Implement a custom notification system to inform participants about the recording status by listening to webhook events and updating room metadata.</li> <li>Recording deletion notification: Implement a custom notification system that alerts all participants of a recording's deletion by sending data messages.</li> <li>Direct access to recording files: Add an additional method to allow access to recording files directly from the Azure Container by creating a presigned URL.</li> </ul> <p>For OpenVidu deployments in Azure, all recordings are stored in an Azure Blob Storage container.</p>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-azure/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-azure/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu in Azure <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Deploy a Storage Account in Azure and add a container with the name that you want.</p> </li> <li> <p>Change in the egress.yaml the S3 configuration for the Azure configuration you will find commented and fill the configuration with your credentials</p> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <ol> <li> <p>Deploy OpenVidu Single Node in Azure following these instructions to deploy in Azure.</p> <p>CPUs to be able to record</p> <p>Make sure you deploy with at least 4 CPUs in the Virtual Machine of Azure.</p> </li> <li> <p>Point the tutorial to your Azure deployment:</p> <ul> <li>Modify file <code>.env</code>  to update the LiveKit and Azure configuration to the values of your Azure deployment. You can get the values of <code>LIVEKIT_URL</code>, <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code> from the Check deployment outputs in Azure Key Vault section. You can get the values of <code>AZURE_ACCOUNT_NAME</code>, <code>AZURE_ACCOUNT_KEY</code> and <code>AZURE_CONTAINER_NAME</code> from the <code>openvidu.env</code> file of your deployment (see Azure SSH Outputs).</li> <li>Modify file <code>app.js</code> to update the value of <code>LIVEKIT_URL</code> to <code>wss://your.azure.deployment.domain</code></li> </ul> </li> </ol> <p>Warning</p> <p>If you are using self-signed certificate you will need to accept the certificate in the browser before using the tutorial.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-azure/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-azure/#3-run-the-application","title":"3. Run the application","text":"<p>To run this application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the application directory</li> </ol> <pre><code>cd openvidu-livekit-tutorials/advanced-features/openvidu-recording-advanced-node-azure\n</code></pre> <ol> <li>Install dependencies</li> </ol> <pre><code>npm install\n</code></pre> <ol> <li>Run the application</li> </ol> <pre><code>npm start\n</code></pre> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:6080</code>. You should see a screen like this:</p> <p></p> <p></p> <p>Accessing your application from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:6443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Limitation: Playing recordings with the <code>Azure</code> strategy from other devices in your local network is not possible due to MinIO not being exposed. To play recordings from other devices, you need to change the environment variable <code>RECORDING_PLAYBACK_STRATEGY</code> to <code>PROXY</code>.</p>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-azure/#enhancements","title":"Enhancements","text":"","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-azure/#refactoring-backend","title":"Refactoring backend","text":"<p>The backend has been refactored to prevent code duplication and improve readability. The main changes are:</p> <ul> <li> <p>Endpoints have been moved to the <code>controllers</code> folder, creating a controller for each set of related endpoints:</p> <ul> <li><code>RoomController</code> for the room creation endpoint.</li> <li><code>RecordingController</code> for the recording endpoints.</li> <li><code>WebhookController</code> for the webhook endpoint.</li> </ul> </li> <li> <p>The <code>index.js</code> file now simply sets the route for each controller:</p> index.js<pre><code>app.use(\"/token\", roomController);\napp.use(\"/recordings\", recordingController);\napp.use(\"/livekit/webhook\", webhookController);\n</code></pre> </li> <li> <p>The configuration of environment variables and constants has been moved to the <code>config.js</code> file:</p> config.js<pre><code>export const SERVER_PORT = process.env.SERVER_PORT || 6080;\nexport const APP_NAME = \"openvidu-recording-advanced-node\";\n\n// LiveKit configuration\nexport const LIVEKIT_URL = process.env.LIVEKIT_URL || \"http://localhost:7880\";\nexport const LIVEKIT_API_KEY = process.env.LIVEKIT_API_KEY || \"devkey\";\nexport const LIVEKIT_API_SECRET = process.env.LIVEKIT_API_SECRET || \"secret\";\n\n// Azure Blob Storage configuration\nexport const AZURE_ACCOUNT_NAME = process.env.AZURE_ACCOUNT_NAME || \"your_account_name\";\nexport const AZURE_ACCOUNT_KEY = process.env.AZURE_ACCOUNT_KEY || \"your_account_key\";\nexport const AZURE_CONTAINER_NAME = process.env.AZURE_CONTAINER_NAME || \"openvidu-appdata\";\nexport const AZURE_ENDPOINT = process.env.AZURE_ENDPOINT || `https://${AZURE_ACCOUNT_NAME}.blob.core.windows.net`;\n\nexport const RECORDINGS_PATH = process.env.RECORDINGS_PATH ?? \"recordings/\";\nexport const RECORDINGS_METADATA_PATH = \".metadata/\";\nexport const RECORDING_PLAYBACK_STRATEGY = process.env.RECORDING_PLAYBACK_STRATEGY || \"Azure\"; // PROXY or Azure\nexport const RECORDING_FILE_PORTION_SIZE = 5 * 1024 * 1024; // 5MB\n</code></pre> </li> <li> <p>Operations of the <code>EgressClient</code> and functions related to recording management have been moved to the <code>RecordingService</code> class within the <code>services</code> folder.</p> </li> </ul> <p>After refactoring and implementing the improvements, the backend of the application has the following structure:</p> <pre><code>src\n\u251c\u2500\u2500 controllers\n\u2502   \u251c\u2500\u2500 recording.controller.js\n\u2502   \u251c\u2500\u2500 room.controller.js\n\u2502   \u2514\u2500\u2500 webhook.controller.js\n\u251c\u2500\u2500 services\n\u2502   \u251c\u2500\u2500 recording.service.js\n\u2502   \u251c\u2500\u2500 room.service.js\n\u2502   \u2514\u2500\u2500 azure.blobstorage.service.js\n\u251c\u2500\u2500 config.js\n\u251c\u2500\u2500 index.js\n</code></pre> <p>Where <code>room.service.js</code> defines the <code>RoomService</code> class, that contains the logic to manage rooms using the <code>RoomServiceClient</code>.</p>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-azure/#adding-room-metadata","title":"Adding room metadata","text":"<p>In order to store the recording status in the room metadata, we have to create the room explicitly the first time a user joins it, setting the metadata field with an object that contains the recording status. This object also contains the app name, which is used to identify webhook events related to the application. This is done in the <code>POST /token</code> endpoint:</p> room.controller.js<pre><code>roomController.post(\"/\", async (req, res) =&gt; {\n    const roomName = req.body.roomName;\n    const participantName = req.body.participantName;\n\n    if (!roomName || !participantName) {\n        res.status(400).json({ errorMessage: \"roomName and participantName are required\" });\n        return;\n    }\n\n    const at = new AccessToken(LIVEKIT_API_KEY, LIVEKIT_API_SECRET, {\n        identity: participantName\n    });\n    at.addGrant({ room: roomName, roomJoin: true, roomRecord: true });\n    const token = await at.toJwt();\n\n    try {\n        // Create room if it doesn't exist\n        const exists = await roomService.exists(roomName); // (1)!\n\n        if (!exists) {\n            await roomService.createRoom(roomName); // (2)!\n        }\n\n        res.json({ token });\n    } catch (error) {\n        console.error(\"Error creating room.\", error);\n        res.status(500).json({ errorMessage: \"Error creating room\" });\n    }\n});\n</code></pre> <ol> <li>Check if the room exists.</li> <li>Create the room if it doesn't exist.</li> </ol> <p>After generating the access token with the required permissions, this endpoint does the following:</p> <ol> <li> <p>Checks if the room exists by calling the <code>exists</code> method of the <code>RoomService</code> with the <code>roomName</code> as a parameter. This method returns a boolean indicating whether the room obtained from the <code>getRoom</code> method is not <code>null</code>. This other method lists all active rooms that match the <code>roomName</code> by calling the <code>listRooms</code> method of the <code>RoomServiceClient</code> with an array containing the <code>roomName</code> as a parameter, and returns the first element of the list if it exists:</p> room.service.js<pre><code>async getRoom(roomName) {\n    const rooms = await this.roomClient.listRooms([roomName]); // (1)!\n    return rooms.length &gt; 0 ? rooms[0] : null; // (2)!\n}\n\nasync exists(roomName) {\n    const room = await this.getRoom(roomName);\n    return room !== null;\n}\n</code></pre> <ol> <li>List all active rooms that match the <code>roomName</code> by calling the <code>listRooms</code> method of the <code>RoomServiceClient</code> with an array containing the <code>roomName</code> as a parameter.</li> <li>Return the first element of the list if it exists.</li> </ol> </li> <li> <p>Creates the room if it doesn't exist by calling the <code>createRoom</code> method of the <code>RoomService</code> with the <code>roomName</code> as a parameter. This method creates a room with the <code>roomName</code> and sets the metadata field with an object that contains the app name (defined in the <code>config.js</code> file) and the recording status initialized to <code>STOPPED</code>. To achieve this, the method calls the <code>createRoom</code> method of the <code>RoomServiceClient</code> with an object indicating the room name and metadata:</p> room.service.js<pre><code>async createRoom(roomName) {\n    const roomOptions = {\n        name: roomName,\n        metadata: JSON.stringify({\n            createdBy: APP_NAME, // (1)!\n            recordingStatus: \"STOPPED\" // (2)!\n        })\n    };\n    return this.roomClient.createRoom(roomOptions); // (3)!\n}\n</code></pre> <ol> <li>Set the app name.</li> <li>Set the recording status to <code>STOPPED</code>.</li> <li>Create the room with the <code>roomOptions</code> object by calling the <code>createRoom</code> method of the <code>RoomServiceClient</code>.</li> </ol> </li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-azure/#handling-webhook-events","title":"Handling webhook events","text":"<p>In previous tutorials, we listened to all webhook events and printed them in the console without doing anything else. In this tutorial, we have to first check if the webhook is related to the application and then act accordingly depending on the event type. This is done in the <code>POST /livekit/webhook</code> endpoint:</p> webhook.controller.js<pre><code>webhookController.post(\"/\", async (req, res) =&gt; {\n    try {\n        const webhookEvent = await webhookReceiver.receive(req.body, req.get(\"Authorization\"));\n        const isWebhookRelatedToMe = await checkWebhookRelatedToMe(webhookEvent); // (1)!\n\n        if (isWebhookRelatedToMe) {\n            console.log(webhookEvent);\n            const { event: eventType, egressInfo } = webhookEvent; // (2)!\n\n            switch (eventType) {\n                case \"egress_started\": // (3)!\n                case \"egress_updated\":\n                    await notifyRecordingStatusUpdate(egressInfo);\n                    break;\n                case \"egress_ended\": // (4)!\n                    await handleEgressEnded(egressInfo);\n                    break;\n            }\n        }\n    } catch (error) {\n        console.error(\"Error validating webhook event.\", error);\n    }\n\n    res.status(200).send();\n});\n</code></pre> <ol> <li>Check if the webhook is related to the application.</li> <li>Destructure the event type and egress info from the webhook event.</li> <li>If the event type is <code>egress_started</code> or <code>egress_updated</code>, notify the recording status update.</li> <li>If the event type is <code>egress_ended</code>, handle the egress ended.</li> </ol> <p>After receiving the webhook event, this endpoint does the following:</p> <ol> <li> <p>Checks if the webhook is related to the application by calling the <code>checkWebhookRelatedToMe</code> function with the webhook event as a parameter. This function returns a boolean indicating whether the app name obtained from the metadata field of the room related to the webhook event is equal to the app name defined in the <code>config.js</code> file:</p> webhook.controller.js<pre><code>const checkWebhookRelatedToMe = async (webhookEvent) =&gt; {\n    const { room, egressInfo, ingressInfo } = webhookEvent; // (1)!\n    let roomInfo = room;\n    // (2)!\n    if (!room || !room.metadata) {\n        const roomName = room?.name ?? egressInfo?.roomName ?? ingressInfo?.roomName; // (3)!\n        roomInfo = await roomService.getRoom(roomName); // (4)!\n\n        if (!roomInfo) {\n            return false;\n        }\n    }\n\n    const metadata = roomInfo.metadata ? JSON.parse(roomInfo.metadata) : null; // (5)!\n    return metadata?.createdBy === APP_NAME; // (6)!\n};\n</code></pre> <ol> <li>Destructure the room, egress info, and ingress info from the webhook event.</li> <li>Check if the room and metadata fields exist.</li> <li>If the room or metadata fields don't exist, get the room name from the room, egress info, or ingress info.</li> <li>Get the room info by calling the <code>getRoom</code> method of the <code>RoomService</code> with the <code>roomName</code> as a parameter.</li> <li>Parse the metadata field of the room info.</li> <li>Return whether the app name is equal to the app name defined in the <code>config.js</code> file.</li> </ol> </li> <li> <p>Destructures the event type and egress info from the webhook event.</p> </li> <li> <p>If the event type is <code>egress_started</code> or <code>egress_updated</code>, calls the <code>notifyRecordingStatusUpdate</code> function with the egress info as a parameter. This function notifies all participants in the room related to the egress info about the recording status update. See the Notifying recording status update section for more information.</p> </li> <li> <p>If the event type is <code>egress_ended</code>, calls the <code>handleEgressEnded</code> function with the egress info as a parameter. This function saves the recording metadata in a separate file (see the Saving recording metadata section) and notifies all participants in the room related to the egress info that the recording has been stopped:</p> webhook.controller.js<pre><code>const handleEgressEnded = async (egressInfo) =&gt; {\n    try {\n        await recordingService.saveRecordingMetadata(egressInfo); // (1)!\n    } catch (error) {\n        console.error(\"Error saving recording metadata.\", error);\n    }\n\n    await notifyRecordingStatusUpdate(egressInfo); // (2)!\n};\n</code></pre> <ol> <li>Save the recording metadata.</li> <li>Notify all participants in the room that the recording has been stopped.</li> </ol> </li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-azure/#notifying-recording-status-update","title":"Notifying recording status update","text":"<p>When the recording status changes, all participants in the room have to be notified. This is done by updating the metadata field of the room with the new recording status, which will trigger the <code>RoomEvent.RoomMetadataChanged</code> event in the client side. This is implemented in the <code>notifyRecordingStatusUpdate</code> function:</p> webhook.controller.js<pre><code>const notifyRecordingStatusUpdate = async (egressInfo) =&gt; {\n    const roomName = egressInfo.roomName; // (1)!\n    const recordingStatus = recordingService.getRecordingStatus(egressInfo.status); // (2)!\n\n    try {\n        await roomService.updateRoomMetadata(roomName, recordingStatus); // (3)!\n    } catch (error) {\n        console.error(\"Error updating room metadata.\", error);\n    }\n};\n</code></pre> <ol> <li>Get the room name from the egress info.</li> <li>Get the recording status from the egress info status.</li> <li>Update the room metadata with the new recording status.</li> </ol> <p>After getting the room name from the egress info, this function does the following:</p> <ol> <li> <p>Gets the recording status by calling the <code>getRecordingStatus</code> method of the <code>RecordingService</code> with the egress info status as a parameter. This method returns the recording status based on the egress info status:</p> recording.service.js<pre><code>getRecordingStatus(egressStatus) {\n    switch (egressStatus) {\n        case EgressStatus.EGRESS_STARTING:\n            return \"STARTING\";\n        case EgressStatus.EGRESS_ACTIVE:\n            return \"STARTED\";\n        case EgressStatus.EGRESS_ENDING:\n            return \"STOPPING\";\n        case EgressStatus.EGRESS_COMPLETE:\n            return \"STOPPED\";\n        default:\n            return \"FAILED\";\n    }\n}\n</code></pre> <p>We distinguish between the following recording statuses:</p> <ul> <li><code>STARTING</code>: The recording is starting.</li> <li><code>STARTED</code>: The recording is active.</li> <li><code>STOPPING</code>: The recording is stopping.</li> <li><code>STOPPED</code>: The recording has stopped.</li> <li><code>FAILED</code>: The recording has failed.</li> </ul> </li> <li> <p>Updates the room metadata with the new recording status by calling the <code>updateRoomMetadata</code> method of the <code>RoomService</code> with the <code>roomName</code> and <code>recordingStatus</code> as parameters. This method updates the metadata field of the room with an object that contains the app name and the new recording status by calling the <code>updateRoomMetadata</code> method of the <code>RoomServiceClient</code> with the <code>roomName</code> and a stringified object as parameters:</p> room.service.js<pre><code>async updateRoomMetadata(roomName, recordingStatus) {\n    const metadata = {\n        createdBy: APP_NAME,\n        recordingStatus // (1)!\n    };\n    return this.roomClient.updateRoomMetadata(roomName, JSON.stringify(metadata)); // (2)!\n}\n</code></pre> <ol> <li>Update the recording status.</li> <li>Update the room metadata with the new metadata by calling the <code>updateRoomMetadata</code> method of the <code>RoomServiceClient</code> with the <code>roomName</code> and a stringified object as parameters.</li> </ol> </li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-azure/#saving-recording-metadata","title":"Saving recording metadata","text":"<p>When the recording ends, the metadata related to the recording has to be saved in a separate file. This is done in the <code>saveRecordingMetadata</code> function:</p> recording.service.js<pre><code>async saveRecordingMetadata(egressInfo) {\n    const recordingInfo = this.convertToRecordingInfo(egressInfo);\n    const key = this.getMetadataKey(recordingInfo.name);\n    await azureBlobService.uploadObject(key, recordingInfo);\n}\n</code></pre> <ol> <li>Convert the egress info to a recording info object.</li> <li>Get the metadata key from the recording info name.</li> <li>Upload the recording metadata to the Azure Container.</li> </ol> <p>This method does the following:</p> <ol> <li> <p>Converts the egress info to a recording info object by calling the <code>convertToRecordingInfo</code> method:</p> recording.service.js<pre><code>convertToRecordingInfo(egressInfo) {\n    const file = egressInfo.fileResults[0];\n    return {\n        id: egressInfo.egressId,\n        name: file.filename.split(\"/\").pop(),\n        roomName: egressInfo.roomName,\n        roomId: egressInfo.roomId,\n        startedAt: Number(egressInfo.startedAt) / 1_000_000,\n        duration: Number(file.duration) / 1_000_000_000,\n        size: Number(file.size)\n    };\n}\n</code></pre> <p>Getting recording metadata</p> <p>In this tutorial, we can access detailed information about the recording directly from the metadata file stored in the Azure Container, without needing to make additional requests. This is made possible by saving all the necessary data retrieved from the egress info object. Compared to the basic recording tutorial, we are now storing additional details such as the recording name, duration and size.</p> </li> <li> <p>Gets the metadata key from the recordings path and the recordings metadata path, both defined in the <code>config.js</code> file, and the recording name replacing the <code>.mp4</code> extension with <code>.json</code>:</p> recording.service.js<pre><code>getMetadataKey(recordingName) {\n    return RECORDINGS_PATH + RECORDINGS_METADATA_PATH + recordingName.replace(\".mp4\", \".json\");\n}\n</code></pre> </li> <li> <p>Uploads the recording metadata to the Azure Container by calling the <code>uploadObject</code> method of the <code>AzureBlobService</code> with the <code>key</code> and <code>recordingInfo</code> as parameters. This method uploads an object to the Azure Container with the key and the stringified object as parameters:</p> azure.blobstorage.service.js<pre><code>async uploadObject(key, body) {\n    const blockBlobClient = this.containerClient.getBlockBlobClient(key);\n    const data = JSON.stringify(body);\n    await blockBlobClient.upload(data, Buffer.byteLength(data));\n}\n</code></pre> </li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-azure/#notifying-recording-deletion","title":"Notifying recording deletion","text":"<p>When a recording is deleted, all participants in the room have to be notified. This is done by sending a data message to all participants in the room. To achieve this, the <code>DELETE /recordings/:recordingName</code> endpoint has been modified as follows:</p> recording.controller.js<pre><code>recordingController.delete(\"/:recordingName\", async (req, res) =&gt; {\n    const { recordingName } = req.params;\n    const exists = await recordingService.existsRecording(recordingName);\n\n    if (!exists) {\n        res.status(404).json({ errorMessage: \"Recording not found\" });\n        return;\n    }\n\n    try {\n        const { roomName } = await recordingService.getRecordingMetadata(recordingName); // (1)!\n        await recordingService.deleteRecording(recordingName);\n\n        // Notify to all participants that the recording was deleted\n        const existsRoom = await roomService.exists(roomName); // (2)!\n\n        if (existsRoom) {\n            await roomService.sendDataToRoom(roomName, { recordingName }); // (3)!\n        }\n\n        res.json({ message: \"Recording deleted\" });\n    } catch (error) {\n        console.error(\"Error deleting recording.\", error);\n        res.status(500).json({ errorMessage: \"Error deleting recording\" });\n    }\n});\n</code></pre> <ol> <li>Get the room name from the recording metadata.</li> <li>Check if the room exists.</li> <li>Send a data message to the room indicating that the recording was deleted.</li> </ol> <p>Before deleting the recording, we get the room name from the recording metadata. After deleting the recording, we check if the room exists and, if it does, send a data message to the room indicating that the recording was deleted. This is done by calling the <code>sendDataToRoom</code> method of the <code>RoomService</code> with the <code>roomName</code> and an object containing the <code>recordingName</code> as parameters:</p> room.service.js<pre><code>async sendDataToRoom(roomName, rawData) {\n    const data = encoder.encode(JSON.stringify(rawData)); // (1)!\n    const options = {\n        topic: \"RECORDING_DELETED\", // (2)!\n        destinationSids: [] // (3)!\n    };\n\n    try {\n        await this.roomClient.sendData(roomName, data, DataPacket_Kind.RELIABLE, options); // (4)!\n    } catch (error) {\n        console.error(\"Error sending data to room\", error);\n    }\n}\n</code></pre> <ol> <li>Encodes the raw data.</li> <li>Sets the topic to <code>RECORDING_DELETED</code>.</li> <li>Sets the destination SIDs to an empty array (all participants in the room).</li> <li>Sends the data message to the room by calling the <code>sendData</code> method of the <code>RoomServiceClient</code> with the <code>roomName</code>, <code>data</code>, <code>DataPacket_Kind.RELIABLE</code> and <code>options</code> as parameters.</li> </ol> <p>This method does the following:</p> <ol> <li>Encodes the raw data by calling the <code>encode</code> method of the <code>TextEncoder</code> with the stringified raw data as a parameter.</li> <li>Sets the topic of the data message to <code>RECORDING_DELETED</code>.</li> <li>Sets the destination SIDs to an empty array, which means that the message will be sent to all participants in the room.</li> <li>Sends the data message to the room by calling the <code>sendData</code> method of the <code>RoomServiceClient</code> with the <code>roomName</code>, <code>data</code>, <code>DataPacket_Kind.RELIABLE</code> and <code>options</code> as parameters. The <code>DataPacket_Kind.RELIABLE</code> parameter indicates that the message will be sent reliably.</li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-azure/#accessing-recording-files-directly-from-the-azure-container","title":"Accessing recording files directly from the Azure Container","text":"<p>In this tutorial, we have added an additional method to allow access to recording files directly from the Azure Container by creating a presigned URL. To accomplish this, we have created a new endpoint (<code>GET /recordings/:recordingName/url</code>) to get the recording URL depending on the playback strategy defined in the environment variable <code>RECORDING_PLAYBACK_STRATEGY</code>, whose value can be <code>PROXY</code> or <code>AZURE</code>:</p> recording.controller.js<pre><code>recordingController.get(\"/:recordingName/url\", async (req, res) =&gt; {\n    const { recordingName } = req.params;\n    const exists = await recordingService.existsRecording(recordingName); // (1)!\n\n    if (!exists) {\n        res.status(404).json({ errorMessage: \"Recording not found\" });\n        return;\n    }\n\n    // If the recording playback strategy is \"PROXY\", return the endpoint URL\n    if (RECORDING_PLAYBACK_STRATEGY === \"PROXY\") {\n        res.json({ recordingUrl: `/recordings/${recordingName}` }); // (2)!\n        return;\n    }\n\n    try {\n        // If the recording playback strategy is \"AZURE\", return a signed URL to access the recording directly from Azure\n        const recordingUrl = await recordingService.getRecordingUrl(recordingName); // (3)!\n        res.json({ recordingUrl });\n    } catch (error) {\n        console.error(\"Error getting recording URL.\", error);\n        res.status(500).json({ errorMessage: \"Error getting recording URL\" });\n    }\n});\n</code></pre> <ol> <li>Check if the recording exists.</li> <li>Return the <code>GET /recordings/:recordingName</code> endpoint URL if the playback strategy is <code>PROXY</code>.</li> <li>Create a presigned URL to access the recording directly from the Azure Container if the playback strategy is <code>Azure</code>.</li> </ol> <p>This endpoint does the following:</p> <ol> <li>Extracts the <code>recordingName</code> parameter from the request.</li> <li>Checks if the recording exists. If it does not exist, it returns a <code>404</code> error.</li> <li>If the playback strategy is <code>PROXY</code>, it returns the <code>GET /recordings/:recordingName</code> endpoint URL to get the recording file from the backend.</li> <li> <p>If the playback strategy is <code>AZURE</code>, it creates a presigned URL to access the recording directly from the Azure Container by calling the <code>getRecordingUrl</code> method of the <code>RecordingService</code> with the <code>recordingName</code> as a parameter. This method simply calls the <code>getObjectUrl</code> method of the <code>AzureBlobService</code> with the key of the recording as a parameter:</p> azure.blobstorage.service.js<pre><code>async getObjectUrl(key) {\n    if (!AZURE_ACCOUNT_NAME || !AZURE_ACCOUNT_KEY) {\n        throw new Error(\"Credenciales de cuenta de Azure no est\u00e1n definidas para generar SAS\");\n    }\n    const blobClient = this.containerClient.getBlobClient(key);\n    const expiresOn = new Date(new Date().valueOf() + 24 * 60 * 60 * 1000); // 24 horas\n    const sasPermissions = BlobSASPermissions.parse(\"r\");\n    const sasToken = generateBlobSASQueryParameters(\n        {\n            containerName: AZURE_CONTAINER_NAME,\n            blobName: key,\n            expiresOn,\n            permissions: sasPermissions,\n            protocol: SASProtocol.Https\n        },\n        new StorageSharedKeyCredential(AZURE_ACCOUNT_NAME, AZURE_ACCOUNT_KEY)\n    ).toString();\n\n    return `${blobClient.url}?${sasToken}`;\n}\n</code></pre> <p>This method creates a presigned URL to access the object in the Azure Container by getting the url of the blob client and generating a SAS token, indicating the <code>CONTAINER_NAME</code>, <code>key</code> and the expiration time in seconds as parameters. In this case, the expiration time is set to 24 hours.</p> <p>Presigned URLs</p> <p>Presigned URLs are URLs that provide access to an Azure object for a limited time. This is useful when you want to share an object with someone for a limited time without providing them with your AWS credentials.</p> <p>Compared to the proxy strategy, accessing recording files directly from the Azure Container via presigned URLs is more efficient, as it reduces server load. However, it presents a security risk, as the URL, once generated, can be used by anyone until it expires.</p> </li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-azure/#handling-new-room-events-in-the-client-side","title":"Handling new room events in the client side","text":"<p>In the client side, we have to handle the new room events related to the recording status and the recording deletion. This is done by listening to the <code>RoomEvent.RoomMetadataChanged</code> and <code>RoomEvent.DataReceived</code> events in the <code>joinRoom</code> method:</p> app.js<pre><code>async function joinRoom() {\n    // ...\n    // When recording status changes...\n    room.on(LivekitClient.RoomEvent.RoomMetadataChanged, async (metadata) =&gt; {\n        const { recordingStatus } = JSON.parse(metadata);\n        await updateRecordingInfo(recordingStatus);\n    });\n\n    // When a message is received...\n    room.on(LivekitClient.RoomEvent.DataReceived, async (payload, _participant, _kind, topic) =&gt; {\n        // If the message is a recording deletion notification, remove the recording from the list\n        if (topic === \"RECORDING_DELETED\") {\n            const { recordingName } = JSON.parse(new TextDecoder().decode(payload));\n            deleteRecordingContainer(recordingName);\n        }\n    });\n    // ...\n}\n</code></pre> <p>When a new <code>RoomEvent.RoomMetadataChanged</code> event is received, we parse the metadata to get the recording status and update the recording info accordingly. The <code>updateRecordingInfo</code> function has been updated to handle the new recording statuses.</p> <p>In addition to handling this event, we need to update the recording info in the UI the first time a user joins the room. Once the user has joined, we retrieve the current room metadata and update the UI accordingly. Recordings will be listed unless the recording status is <code>STOPPED</code> or <code>FAILED</code>, to prevent listing recordings twice:</p> app.js<pre><code>async function joinRoom() {\n    // ...\n    // Update recording info\n    const { recordingStatus } = JSON.parse(room.metadata);\n    await updateRecordingInfo(recordingStatus);\n\n    if (recordingStatus !== \"STOPPED\" &amp;&amp; recordingStatus !== \"FAILED\") {\n        const roomId = await room.getSid();\n        await listRecordings(room.name, roomId);\n    }\n    // ...\n}\n</code></pre> <p>When a new <code>RoomEvent.DataReceived</code> event is received, we check if the topic of the message is <code>RECORDING_DELETED</code>. If it is, we decode the payload using a <code>TextDecoder</code> and parse the message to get the recording name. Then, we remove the recording from the list by calling the <code>deleteRecordingContainer</code> function.</p>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-s3/","title":"Advanced Recording Tutorial S3","text":"","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-s3/#advanced-recording-tutorial-s3","title":"Advanced Recording Tutorial S3","text":"<p>Source code </p> <p>This tutorial improves the basic recording tutorial by doing the following:</p> <ul> <li>Complete recording metadata: Listen to webhook events and save all necessary metadata in a separate file.</li> <li>Real time recording status notification: Implement a custom notification system to inform participants about the recording status by listening to webhook events and updating room metadata.</li> <li>Recording deletion notification: Implement a custom notification system that alerts all participants of a recording's deletion by sending data messages.</li> <li>Direct access to recording files: Add an additional method to allow access to recording files directly from the S3 bucket by creating a presigned URL.</li> </ul> <p>Recordings are always persisted in some kind of storage system. This type of storage depends on your OpenVidu deployment:</p> <ul> <li>When running OpenVidu locally or On-Premises, recordings are stored in a local S3 Minio bucket.</li> <li>When running OpenVidu in AWS, recordings are stored in an AWS S3 bucket.</li> <li>When running OpenVidu in Azure, recordings are stored in an Azure Blob Storage container. If this is your case, follow the Recording Advanced Azure tutorial instead.</li> </ul>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-s3/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-s3/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <ol> <li> <p>Deploy OpenVidu Single Node in AWS following these instructions to deploy in AWS.</p> <p>CPUs to be able to record</p> <p>Make sure you deploy with at least 4 CPUs in the Virtual Machine of AWS.</p> </li> <li> <p>Point the tutorial to your AWS deployment:</p> <ul> <li>Modify file <code>.env</code>  to update the LiveKit and AWS configuration to the values of your AWS deployment. You can get the values of <code>LIVEKIT_URL</code>, <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code> from the Configure your application to use the deployment section. You can get the values of <code>S3_ENDPOINT</code>, <code>AWS_REGION</code> and <code>S3_BUCKET</code> from the <code>openvidu.env</code> file of your deployment by making ssh to the instance. For the <code>S3_ACCESS_KEY</code> and <code>S3_SECRET_KEY</code> you will need to create an access key in the IAM section of AWS to be able to use them in the tutorial (check Manage access keys for IAM users).   </li> <li>Modify file <code>app.js</code> to update the value of <code>LIVEKIT_URL</code> with your <code>LIVEKIT_URL</code>.</li> </ul> </li> </ol> <p>Warning</p> <p>If you are using self-signed certificate you will need to add this line in the first line after the imports on the <code>index.js</code> <code>process.env.NODE_TLS_REJECT_UNAUTHORIZED = \"0\"; // Disable TLS verification for local testing</code></p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-s3/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-s3/#3-run-the-application","title":"3. Run the application","text":"<p>To run this application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the application directory</li> </ol> <pre><code>cd openvidu-livekit-tutorials/advanced-features/openvidu-recording-advanced-node\n</code></pre> <ol> <li>Install dependencies</li> </ol> <pre><code>npm install\n</code></pre> <ol> <li>Run the application</li> </ol> <pre><code>npm start\n</code></pre> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:6080</code>. You should see a screen like this:</p> <p></p> <p></p> <p>Accessing your application from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:6443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Limitation: Playing recordings with the <code>S3</code> strategy from other devices in your local network is not possible due to MinIO not being exposed. To play recordings from other devices, you need to change the environment variable <code>RECORDING_PLAYBACK_STRATEGY</code> to <code>PROXY</code>.</p>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-s3/#enhancements","title":"Enhancements","text":"","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-s3/#refactoring-backend","title":"Refactoring backend","text":"<p>The backend has been refactored to prevent code duplication and improve readability. The main changes are:</p> <ul> <li> <p>Endpoints have been moved to the <code>controllers</code> folder, creating a controller for each set of related endpoints:</p> <ul> <li><code>RoomController</code> for the room creation endpoint.</li> <li><code>RecordingController</code> for the recording endpoints.</li> <li><code>WebhookController</code> for the webhook endpoint.</li> </ul> </li> <li> <p>The <code>index.js</code> file now simply sets the route for each controller:</p> index.js<pre><code>app.use(\"/token\", roomController);\napp.use(\"/recordings\", recordingController);\napp.use(\"/livekit/webhook\", webhookController);\n</code></pre> </li> <li> <p>The configuration of environment variables and constants has been moved to the <code>config.js</code> file:</p> config.js<pre><code>export const SERVER_PORT = process.env.SERVER_PORT || 6080;\nexport const APP_NAME = \"openvidu-recording-advanced-node\";\n\n// LiveKit configuration\nexport const LIVEKIT_URL = process.env.LIVEKIT_URL || \"http://localhost:7880\";\nexport const LIVEKIT_API_KEY = process.env.LIVEKIT_API_KEY || \"devkey\";\nexport const LIVEKIT_API_SECRET = process.env.LIVEKIT_API_SECRET || \"secret\";\n\n// S3 configuration\nexport const S3_ENDPOINT = process.env.S3_ENDPOINT || \"http://localhost:9000\";\nexport const S3_ACCESS_KEY = process.env.S3_ACCESS_KEY || \"minioadmin\";\nexport const S3_SECRET_KEY = process.env.S3_SECRET_KEY || \"minioadmin\";\nexport const AWS_REGION = process.env.AWS_REGION || \"us-east-1\";\nexport const S3_BUCKET = process.env.S3_BUCKET || \"openvidu\";\n\nexport const RECORDINGS_PATH = process.env.RECORDINGS_PATH ?? \"recordings/\";\nexport const RECORDINGS_METADATA_PATH = \".metadata/\";\nexport const RECORDING_PLAYBACK_STRATEGY = process.env.RECORDING_PLAYBACK_STRATEGY || \"S3\"; // PROXY or S3\nexport const RECORDING_FILE_PORTION_SIZE = 5 * 1024 * 1024; // 5MB\n</code></pre> </li> <li> <p>Operations of the <code>EgressClient</code> and functions related to recording management have been moved to the <code>RecordingService</code> class within the <code>services</code> folder.</p> </li> </ul> <p>After refactoring and implementing the improvements, the backend of the application has the following structure:</p> <pre><code>src\n\u251c\u2500\u2500 controllers\n\u2502   \u251c\u2500\u2500 recording.controller.js\n\u2502   \u251c\u2500\u2500 room.controller.js\n\u2502   \u2514\u2500\u2500 webhook.controller.js\n\u251c\u2500\u2500 services\n\u2502   \u251c\u2500\u2500 recording.service.js\n\u2502   \u251c\u2500\u2500 room.service.js\n\u2502   \u2514\u2500\u2500 s3.service.js\n\u251c\u2500\u2500 config.js\n\u251c\u2500\u2500 index.js\n</code></pre> <p>Where <code>room.service.js</code> defines the <code>RoomService</code> class, that contains the logic to manage rooms using the <code>RoomServiceClient</code>.</p>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-s3/#adding-room-metadata","title":"Adding room metadata","text":"<p>In order to store the recording status in the room metadata, we have to create the room explicitly the first time a user joins it, setting the metadata field with an object that contains the recording status. This object also contains the app name, which is used to identify webhook events related to the application. This is done in the <code>POST /token</code> endpoint:</p> room.controller.js<pre><code>roomController.post(\"/\", async (req, res) =&gt; {\n    const roomName = req.body.roomName;\n    const participantName = req.body.participantName;\n\n    if (!roomName || !participantName) {\n        res.status(400).json({ errorMessage: \"roomName and participantName are required\" });\n        return;\n    }\n\n    const at = new AccessToken(LIVEKIT_API_KEY, LIVEKIT_API_SECRET, {\n        identity: participantName\n    });\n    at.addGrant({ room: roomName, roomJoin: true, roomRecord: true });\n    const token = await at.toJwt();\n\n    try {\n        // Create room if it doesn't exist\n        const exists = await roomService.exists(roomName); // (1)!\n\n        if (!exists) {\n            await roomService.createRoom(roomName); // (2)!\n        }\n\n        res.json({ token });\n    } catch (error) {\n        console.error(\"Error creating room.\", error);\n        res.status(500).json({ errorMessage: \"Error creating room\" });\n    }\n});\n</code></pre> <ol> <li>Check if the room exists.</li> <li>Create the room if it doesn't exist.</li> </ol> <p>After generating the access token with the required permissions, this endpoint does the following:</p> <ol> <li> <p>Checks if the room exists by calling the <code>exists</code> method of the <code>RoomService</code> with the <code>roomName</code> as a parameter. This method returns a boolean indicating whether the room obtained from the <code>getRoom</code> method is not <code>null</code>. This other method lists all active rooms that match the <code>roomName</code> by calling the <code>listRooms</code> method of the <code>RoomServiceClient</code> with an array containing the <code>roomName</code> as a parameter, and returns the first element of the list if it exists:</p> room.service.js<pre><code>async getRoom(roomName) {\n    const rooms = await this.roomClient.listRooms([roomName]); // (1)!\n    return rooms.length &gt; 0 ? rooms[0] : null; // (2)!\n}\n\nasync exists(roomName) {\n    const room = await this.getRoom(roomName);\n    return room !== null;\n}\n</code></pre> <ol> <li>List all active rooms that match the <code>roomName</code> by calling the <code>listRooms</code> method of the <code>RoomServiceClient</code> with an array containing the <code>roomName</code> as a parameter.</li> <li>Return the first element of the list if it exists.</li> </ol> </li> <li> <p>Creates the room if it doesn't exist by calling the <code>createRoom</code> method of the <code>RoomService</code> with the <code>roomName</code> as a parameter. This method creates a room with the <code>roomName</code> and sets the metadata field with an object that contains the app name (defined in the <code>config.js</code> file) and the recording status initialized to <code>STOPPED</code>. To achieve this, the method calls the <code>createRoom</code> method of the <code>RoomServiceClient</code> with an object indicating the room name and metadata:</p> room.service.js<pre><code>async createRoom(roomName) {\n    const roomOptions = {\n        name: roomName,\n        metadata: JSON.stringify({\n            createdBy: APP_NAME, // (1)!\n            recordingStatus: \"STOPPED\" // (2)!\n        })\n    };\n    return this.roomClient.createRoom(roomOptions); // (3)!\n}\n</code></pre> <ol> <li>Set the app name.</li> <li>Set the recording status to <code>STOPPED</code>.</li> <li>Create the room with the <code>roomOptions</code> object by calling the <code>createRoom</code> method of the <code>RoomServiceClient</code>.</li> </ol> </li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-s3/#handling-webhook-events","title":"Handling webhook events","text":"<p>In previous tutorials, we listened to all webhook events and printed them in the console without doing anything else. In this tutorial, we have to first check if the webhook is related to the application and then act accordingly depending on the event type. This is done in the <code>POST /livekit/webhook</code> endpoint:</p> webhook.controller.js<pre><code>webhookController.post(\"/\", async (req, res) =&gt; {\n    try {\n        const webhookEvent = await webhookReceiver.receive(req.body, req.get(\"Authorization\"));\n        const isWebhookRelatedToMe = await checkWebhookRelatedToMe(webhookEvent); // (1)!\n\n        if (isWebhookRelatedToMe) {\n            console.log(webhookEvent);\n            const { event: eventType, egressInfo } = webhookEvent; // (2)!\n\n            switch (eventType) {\n                case \"egress_started\": // (3)!\n                case \"egress_updated\":\n                    await notifyRecordingStatusUpdate(egressInfo);\n                    break;\n                case \"egress_ended\": // (4)!\n                    await handleEgressEnded(egressInfo);\n                    break;\n            }\n        }\n    } catch (error) {\n        console.error(\"Error validating webhook event.\", error);\n    }\n\n    res.status(200).send();\n});\n</code></pre> <ol> <li>Check if the webhook is related to the application.</li> <li>Destructure the event type and egress info from the webhook event.</li> <li>If the event type is <code>egress_started</code> or <code>egress_updated</code>, notify the recording status update.</li> <li>If the event type is <code>egress_ended</code>, handle the egress ended.</li> </ol> <p>After receiving the webhook event, this endpoint does the following:</p> <ol> <li> <p>Checks if the webhook is related to the application by calling the <code>checkWebhookRelatedToMe</code> function with the webhook event as a parameter. This function returns a boolean indicating whether the app name obtained from the metadata field of the room related to the webhook event is equal to the app name defined in the <code>config.js</code> file:</p> webhook.controller.js<pre><code>const checkWebhookRelatedToMe = async (webhookEvent) =&gt; {\n    const { room, egressInfo, ingressInfo } = webhookEvent; // (1)!\n    let roomInfo = room;\n    // (2)!\n    if (!room || !room.metadata) {\n        const roomName = room?.name ?? egressInfo?.roomName ?? ingressInfo?.roomName; // (3)!\n        roomInfo = await roomService.getRoom(roomName); // (4)!\n\n        if (!roomInfo) {\n            return false;\n        }\n    }\n\n    const metadata = roomInfo.metadata ? JSON.parse(roomInfo.metadata) : null; // (5)!\n    return metadata?.createdBy === APP_NAME; // (6)!\n};\n</code></pre> <ol> <li>Destructure the room, egress info, and ingress info from the webhook event.</li> <li>Check if the room and metadata fields exist.</li> <li>If the room or metadata fields don't exist, get the room name from the room, egress info, or ingress info.</li> <li>Get the room info by calling the <code>getRoom</code> method of the <code>RoomService</code> with the <code>roomName</code> as a parameter.</li> <li>Parse the metadata field of the room info.</li> <li>Return whether the app name is equal to the app name defined in the <code>config.js</code> file.</li> </ol> </li> <li> <p>Destructures the event type and egress info from the webhook event.</p> </li> <li> <p>If the event type is <code>egress_started</code> or <code>egress_updated</code>, calls the <code>notifyRecordingStatusUpdate</code> function with the egress info as a parameter. This function notifies all participants in the room related to the egress info about the recording status update. See the Notifying recording status update section for more information.</p> </li> <li> <p>If the event type is <code>egress_ended</code>, calls the <code>handleEgressEnded</code> function with the egress info as a parameter. This function saves the recording metadata in a separate file (see the Saving recording metadata section) and notifies all participants in the room related to the egress info that the recording has been stopped:</p> webhook.controller.js<pre><code>const handleEgressEnded = async (egressInfo) =&gt; {\n    try {\n        await recordingService.saveRecordingMetadata(egressInfo); // (1)!\n    } catch (error) {\n        console.error(\"Error saving recording metadata.\", error);\n    }\n\n    await notifyRecordingStatusUpdate(egressInfo); // (2)!\n};\n</code></pre> <ol> <li>Save the recording metadata.</li> <li>Notify all participants in the room that the recording has been stopped.</li> </ol> </li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-s3/#notifying-recording-status-update","title":"Notifying recording status update","text":"<p>When the recording status changes, all participants in the room have to be notified. This is done by updating the metadata field of the room with the new recording status, which will trigger the <code>RoomEvent.RoomMetadataChanged</code> event in the client side. This is implemented in the <code>notifyRecordingStatusUpdate</code> function:</p> webhook.controller.js<pre><code>const notifyRecordingStatusUpdate = async (egressInfo) =&gt; {\n    const roomName = egressInfo.roomName; // (1)!\n    const recordingStatus = recordingService.getRecordingStatus(egressInfo.status); // (2)!\n\n    try {\n        await roomService.updateRoomMetadata(roomName, recordingStatus); // (3)!\n    } catch (error) {\n        console.error(\"Error updating room metadata.\", error);\n    }\n};\n</code></pre> <ol> <li>Get the room name from the egress info.</li> <li>Get the recording status from the egress info status.</li> <li>Update the room metadata with the new recording status.</li> </ol> <p>After getting the room name from the egress info, this function does the following:</p> <ol> <li> <p>Gets the recording status by calling the <code>getRecordingStatus</code> method of the <code>RecordingService</code> with the egress info status as a parameter. This method returns the recording status based on the egress info status:</p> recording.service.js<pre><code>getRecordingStatus(egressStatus) {\n    switch (egressStatus) {\n        case EgressStatus.EGRESS_STARTING:\n            return \"STARTING\";\n        case EgressStatus.EGRESS_ACTIVE:\n            return \"STARTED\";\n        case EgressStatus.EGRESS_ENDING:\n            return \"STOPPING\";\n        case EgressStatus.EGRESS_COMPLETE:\n            return \"STOPPED\";\n        default:\n            return \"FAILED\";\n    }\n}\n</code></pre> <p>We distinguish between the following recording statuses:</p> <ul> <li><code>STARTING</code>: The recording is starting.</li> <li><code>STARTED</code>: The recording is active.</li> <li><code>STOPPING</code>: The recording is stopping.</li> <li><code>STOPPED</code>: The recording has stopped.</li> <li><code>FAILED</code>: The recording has failed.</li> </ul> </li> <li> <p>Updates the room metadata with the new recording status by calling the <code>updateRoomMetadata</code> method of the <code>RoomService</code> with the <code>roomName</code> and <code>recordingStatus</code> as parameters. This method updates the metadata field of the room with an object that contains the app name and the new recording status by calling the <code>updateRoomMetadata</code> method of the <code>RoomServiceClient</code> with the <code>roomName</code> and a stringified object as parameters:</p> room.service.js<pre><code>async updateRoomMetadata(roomName, recordingStatus) {\n    const metadata = {\n        createdBy: APP_NAME,\n        recordingStatus // (1)!\n    };\n    return this.roomClient.updateRoomMetadata(roomName, JSON.stringify(metadata)); // (2)!\n}\n</code></pre> <ol> <li>Update the recording status.</li> <li>Update the room metadata with the new metadata by calling the <code>updateRoomMetadata</code> method of the <code>RoomServiceClient</code> with the <code>roomName</code> and a stringified object as parameters.</li> </ol> </li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-s3/#saving-recording-metadata","title":"Saving recording metadata","text":"<p>When the recording ends, the metadata related to the recording has to be saved in a separate file. This is done in the <code>saveRecordingMetadata</code> function:</p> recording.service.js<pre><code>async saveRecordingMetadata(egressInfo) {\n    const recordingInfo = this.convertToRecordingInfo(egressInfo); // (1)!\n    const key = this.getMetadataKey(recordingInfo.name); // (2)!\n    await s3Service.uploadObject(key, recordingInfo); // (3)!\n}\n</code></pre> <ol> <li>Convert the egress info to a recording info object.</li> <li>Get the metadata key from the recording info name.</li> <li>Upload the recording metadata to the S3 bucket.</li> </ol> <p>This method does the following:</p> <ol> <li> <p>Converts the egress info to a recording info object by calling the <code>convertToRecordingInfo</code> method:</p> recording.service.js<pre><code>convertToRecordingInfo(egressInfo) {\n    const file = egressInfo.fileResults[0];\n    return {\n        id: egressInfo.egressId,\n        name: file.filename.split(\"/\").pop(),\n        roomName: egressInfo.roomName,\n        roomId: egressInfo.roomId,\n        startedAt: Number(egressInfo.startedAt) / 1_000_000,\n        duration: Number(file.duration) / 1_000_000_000,\n        size: Number(file.size)\n    };\n}\n</code></pre> <p>Getting recording metadata</p> <p>In this tutorial, we can access detailed information about the recording directly from the metadata file stored in the S3 bucket, without needing to make additional requests. This is made possible by saving all the necessary data retrieved from the egress info object. Compared to the basic recording tutorial, we are now storing additional details such as the recording name, duration and size.</p> </li> <li> <p>Gets the metadata key from the recordings path and the recordings metadata path, both defined in the <code>config.js</code> file, and the recording name replacing the <code>.mp4</code> extension with <code>.json</code>:</p> recording.service.js<pre><code>getMetadataKey(recordingName) {\n    return RECORDINGS_PATH + RECORDINGS_METADATA_PATH + recordingName.replace(\".mp4\", \".json\");\n}\n</code></pre> </li> <li> <p>Uploads the recording metadata to the S3 bucket by calling the <code>uploadObject</code> method of the <code>S3Service</code> with the <code>key</code> and <code>recordingInfo</code> as parameters. This method uploads an object to the S3 bucket by sending a <code>PutObjectCommand</code> with the key and the stringified object as parameters:</p> s3.service.js<pre><code>async uploadObject(key, body) {\n    const params = {\n        Bucket: S3_BUCKET,\n        Key: key,\n        Body: JSON.stringify(body)\n    };\n    const command = new PutObjectCommand(params);\n    return this.run(command);\n}\n</code></pre> </li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-s3/#notifying-recording-deletion","title":"Notifying recording deletion","text":"<p>When a recording is deleted, all participants in the room have to be notified. This is done by sending a data message to all participants in the room. To achieve this, the <code>DELETE /recordings/:recordingName</code> endpoint has been modified as follows:</p> recording.controller.js<pre><code>recordingController.delete(\"/:recordingName\", async (req, res) =&gt; {\n    const { recordingName } = req.params;\n    const exists = await recordingService.existsRecording(recordingName);\n\n    if (!exists) {\n        res.status(404).json({ errorMessage: \"Recording not found\" });\n        return;\n    }\n\n    try {\n        const { roomName } = await recordingService.getRecordingMetadata(recordingName); // (1)!\n        await recordingService.deleteRecording(recordingName);\n\n        // Notify to all participants that the recording was deleted\n        const existsRoom = await roomService.exists(roomName); // (2)!\n\n        if (existsRoom) {\n            await roomService.sendDataToRoom(roomName, { recordingName }); // (3)!\n        }\n\n        res.json({ message: \"Recording deleted\" });\n    } catch (error) {\n        console.error(\"Error deleting recording.\", error);\n        res.status(500).json({ errorMessage: \"Error deleting recording\" });\n    }\n});\n</code></pre> <ol> <li>Get the room name from the recording metadata.</li> <li>Check if the room exists.</li> <li>Send a data message to the room indicating that the recording was deleted.</li> </ol> <p>Before deleting the recording, we get the room name from the recording metadata. After deleting the recording, we check if the room exists and, if it does, send a data message to the room indicating that the recording was deleted. This is done by calling the <code>sendDataToRoom</code> method of the <code>RoomService</code> with the <code>roomName</code> and an object containing the <code>recordingName</code> as parameters:</p> room.service.js<pre><code>async sendDataToRoom(roomName, rawData) {\n    const data = encoder.encode(JSON.stringify(rawData)); // (1)!\n    const options = {\n        topic: \"RECORDING_DELETED\", // (2)!\n        destinationSids: [] // (3)!\n    };\n\n    try {\n        await this.roomClient.sendData(roomName, data, DataPacket_Kind.RELIABLE, options); // (4)!\n    } catch (error) {\n        console.error(\"Error sending data to room\", error);\n    }\n}\n</code></pre> <ol> <li>Encodes the raw data.</li> <li>Sets the topic to <code>RECORDING_DELETED</code>.</li> <li>Sets the destination SIDs to an empty array (all participants in the room).</li> <li>Sends the data message to the room by calling the <code>sendData</code> method of the <code>RoomServiceClient</code> with the <code>roomName</code>, <code>data</code>, <code>DataPacket_Kind.RELIABLE</code> and <code>options</code> as parameters.</li> </ol> <p>This method does the following:</p> <ol> <li>Encodes the raw data by calling the <code>encode</code> method of the <code>TextEncoder</code> with the stringified raw data as a parameter.</li> <li>Sets the topic of the data message to <code>RECORDING_DELETED</code>.</li> <li>Sets the destination SIDs to an empty array, which means that the message will be sent to all participants in the room.</li> <li>Sends the data message to the room by calling the <code>sendData</code> method of the <code>RoomServiceClient</code> with the <code>roomName</code>, <code>data</code>, <code>DataPacket_Kind.RELIABLE</code> and <code>options</code> as parameters. The <code>DataPacket_Kind.RELIABLE</code> parameter indicates that the message will be sent reliably.</li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-s3/#accessing-recording-files-directly-from-the-s3-bucket","title":"Accessing recording files directly from the S3 bucket","text":"<p>In this tutorial, we have added an additional method to allow access to recording files directly from the S3 bucket by creating a presigned URL. To accomplish this, we have created a new endpoint (<code>GET /recordings/:recordingName/url</code>) to get the recording URL depending on the playback strategy defined in the environment variable <code>RECORDING_PLAYBACK_STRATEGY</code>, whose value can be <code>PROXY</code> or <code>S3</code>:</p> recording.controller.js<pre><code>recordingController.get(\"/:recordingName/url\", async (req, res) =&gt; {\n    const { recordingName } = req.params;\n    const exists = await recordingService.existsRecording(recordingName); // (1)!\n\n    if (!exists) {\n        res.status(404).json({ errorMessage: \"Recording not found\" });\n        return;\n    }\n\n    // If the recording playback strategy is \"PROXY\", return the endpoint URL\n    if (RECORDING_PLAYBACK_STRATEGY === \"PROXY\") {\n        res.json({ recordingUrl: `/recordings/${recordingName}` }); // (2)!\n        return;\n    }\n\n    try {\n        // If the recording playback strategy is \"S3\", return a signed URL to access the recording directly from S3\n        const recordingUrl = await recordingService.getRecordingUrl(recordingName); // (3)!\n        res.json({ recordingUrl });\n    } catch (error) {\n        console.error(\"Error getting recording URL.\", error);\n        res.status(500).json({ errorMessage: \"Error getting recording URL\" });\n    }\n});\n</code></pre> <ol> <li>Check if the recording exists.</li> <li>Return the <code>GET /recordings/:recordingName</code> endpoint URL if the playback strategy is <code>PROXY</code>.</li> <li>Create a presigned URL to access the recording directly from the S3 bucket if the playback strategy is <code>S3</code>.</li> </ol> <p>This endpoint does the following:</p> <ol> <li>Extracts the <code>recordingName</code> parameter from the request.</li> <li>Checks if the recording exists. If it does not exist, it returns a <code>404</code> error.</li> <li>If the playback strategy is <code>PROXY</code>, it returns the <code>GET /recordings/:recordingName</code> endpoint URL to get the recording file from the backend.</li> <li> <p>If the playback strategy is <code>S3</code>, it creates a presigned URL to access the recording directly from the S3 bucket by calling the <code>getRecordingUrl</code> method of the <code>RecordingService</code> with the <code>recordingName</code> as a parameter. This method simply calls the <code>getObjectUrl</code> method of the <code>S3Service</code> with the key of the recording as a parameter:</p> s3.service.js<pre><code>async getObjectUrl(key) {\n    const params = {\n        Bucket: S3_BUCKET,\n        Key: key\n    };\n    const command = new GetObjectCommand(params);\n    return getSignedUrl(this.s3Client, command, { expiresIn: 86400 }); // 24 hours\n}\n</code></pre> <p>This method creates a presigned URL to access the object in the S3 bucket by calling the <code>getSignedUrl</code> function from the @aws-sdk/s3-request-presigner  package, indicating the <code>S3Client</code>, <code>GetObjectCommand</code> and the expiration time in seconds as parameters. In this case, the expiration time is set to 24 hours.</p> <p>Presigned URLs</p> <p>Presigned URLs are URLs that provide access to an S3 object for a limited time. This is useful when you want to share an object with someone for a limited time without providing them with your AWS credentials.</p> <p>Compared to the proxy strategy, accessing recording files directly from the S3 bucket via presigned URLs is more efficient, as it reduces server load. However, it presents a security risk, as the URL, once generated, can be used by anyone until it expires.</p> </li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-advanced-s3/#handling-new-room-events-in-the-client-side","title":"Handling new room events in the client side","text":"<p>In the client side, we have to handle the new room events related to the recording status and the recording deletion. This is done by listening to the <code>RoomEvent.RoomMetadataChanged</code> and <code>RoomEvent.DataReceived</code> events in the <code>joinRoom</code> method:</p> app.js<pre><code>async function joinRoom() {\n    // ...\n    // When recording status changes...\n    room.on(LivekitClient.RoomEvent.RoomMetadataChanged, async (metadata) =&gt; {\n        const { recordingStatus } = JSON.parse(metadata);\n        await updateRecordingInfo(recordingStatus);\n    });\n\n    // When a message is received...\n    room.on(LivekitClient.RoomEvent.DataReceived, async (payload, _participant, _kind, topic) =&gt; {\n        // If the message is a recording deletion notification, remove the recording from the list\n        if (topic === \"RECORDING_DELETED\") {\n            const { recordingName } = JSON.parse(new TextDecoder().decode(payload));\n            deleteRecordingContainer(recordingName);\n        }\n    });\n    // ...\n}\n</code></pre> <p>When a new <code>RoomEvent.RoomMetadataChanged</code> event is received, we parse the metadata to get the recording status and update the recording info accordingly. The <code>updateRecordingInfo</code> function has been updated to handle the new recording statuses.</p> <p>In addition to handling this event, we need to update the recording info in the UI the first time a user joins the room. Once the user has joined, we retrieve the current room metadata and update the UI accordingly. Recordings will be listed unless the recording status is <code>STOPPED</code> or <code>FAILED</code>, to prevent listing recordings twice:</p> app.js<pre><code>async function joinRoom() {\n    // ...\n    // Update recording info\n    const { recordingStatus } = JSON.parse(room.metadata);\n    await updateRecordingInfo(recordingStatus);\n\n    if (recordingStatus !== \"STOPPED\" &amp;&amp; recordingStatus !== \"FAILED\") {\n        const roomId = await room.getSid();\n        await listRecordings(room.name, roomId);\n    }\n    // ...\n}\n</code></pre> <p>When a new <code>RoomEvent.DataReceived</code> event is received, we check if the topic of the message is <code>RECORDING_DELETED</code>. If it is, we decode the payload using a <code>TextDecoder</code> and parse the message to get the recording name. Then, we remove the recording from the list by calling the <code>deleteRecordingContainer</code> function.</p>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-azure/","title":"Basic Recording Tutorial Azure","text":"","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-azure/#basic-recording-tutorial-azure","title":"Basic Recording Tutorial Azure","text":"<p>Source code </p> <p>This tutorial is a simple video-call application, built upon Node.js server and JavaScript client tutorials, and extends them by adding recording capabilities:</p> <ul> <li>Start and stop recording a room.</li> <li>List all recordings in a room.</li> <li>Play a recording.</li> <li>Delete a recording.</li> <li>List all available recordings.</li> </ul> <p>For OpenVidu deployments in Azure, all recordings are stored in an Azure Blob Storage container.</p>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-azure/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-azure/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu in Azure <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Deploy a Storage Account in Azure and add a container with the name that you want.</p> </li> <li> <p>Change in the egress.yaml the S3 configuration for the Azure configuration you will find commented and fill the configuration with your credentials</p> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <ol> <li> <p>Deploy OpenVidu Single Node in Azure following these instructions to deploy in Azure.</p> <p>CPUs to be able to record</p> <p>Make sure you deploy with at least 4 CPUs in the Virtual Machine of Azure.</p> </li> <li> <p>Point the tutorial to your Azure deployment:</p> <ul> <li>Modify file <code>.env</code>  to update the LiveKit and Azure configuration to the values of your Azure deployment. You can get the values of <code>LIVEKIT_URL</code>, <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code> from the Check deployment outputs in Azure Key Vault section. You can get the values of <code>AZURE_ACCOUNT_NAME</code>, <code>AZURE_ACCOUNT_KEY</code> and <code>AZURE_CONTAINER_NAME</code> from the <code>openvidu.env</code> file of your deployment (see Azure SSH Outputs).</li> <li>Modify file <code>app.js</code> to update the value of <code>LIVEKIT_URL</code> to <code>wss://your.azure.deployment.domain</code></li> </ul> </li> </ol> <p>Warning</p> <p>If you are using self-signed certificate you will need to accept the certificate in the browser before using the tutorial.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-azure/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-azure/#3-run-the-application","title":"3. Run the application","text":"<p>To run this application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the application directory</li> </ol> <pre><code>cd openvidu-livekit-tutorials/advanced-features/openvidu-recording-basic-node-azure\n</code></pre> <ol> <li>Install dependencies</li> </ol> <pre><code>npm install\n</code></pre> <ol> <li>Run the application</li> </ol> <pre><code>npm start\n</code></pre> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:6080</code>. You should see a screen like this:</p> <p></p> <p></p> <p>Accessing your application from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:6443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-azure/#understanding-the-code","title":"Understanding the code","text":"<p>This application consists of two essential backend files under the <code>src</code> directory:</p> <ul> <li><code>index.js</code>: This file holds the server application and defines the REST API endpoints.</li> <li><code>azure.blobstorage.service.js</code>: This file encapsulates the operations to interact with the Azure Blob Storage container.</li> </ul> <p>And the following essential frontend files under the <code>public</code> directory:</p> <ul> <li><code>index.html</code>: This is the client application's main HTML file.</li> <li><code>app.js</code>: This is the main JavaScript file that interacts with the server application and handles the client application's logic and functionality.</li> <li><code>style.css</code>: This file contains the client application's styling.</li> <li><code>recordings.html</code>: This file defines the HTML for the general recording page.</li> </ul>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-azure/#backend","title":"Backend","text":"<p>The server application extends the Node.js server tutorial by adding the following REST API endpoints:</p> <ul> <li><code>POST /recordings/start</code>: Starts the recording of a room.</li> <li><code>POST /recordings/stop</code>: Stops the recording of a room.</li> <li><code>GET /recordings</code>: Lists all recordings stored in the Azure Container. This endpoint also allows filtering recordings by room ID.</li> <li><code>GET /recordings/:recordingName</code>: Retrieves a recording from the Azure Container and returns it as a stream.</li> <li><code>DELETE /recordings/:recordingName</code>: This endpoint deletes a recording from the Azure Container.</li> </ul> <p>Before we dive into the code of each endpoint, let's first see the changes introduced in the <code>index.js</code> file:</p> index.js<pre><code>// Configuration\nconst SERVER_PORT = process.env.SERVER_PORT || 6080;\nconst LIVEKIT_API_KEY = process.env.LIVEKIT_API_KEY || \"devkey\";\nconst LIVEKIT_API_SECRET = process.env.LIVEKIT_API_SECRET || \"secret\";\nconst LIVEKIT_URL = process.env.LIVEKIT_URL || \"http://localhost:7880\"; // (1)!\nconst RECORDING_FILE_PORTION_SIZE = 5 * 1024 * 1024; // (2)!\n\nconst app = express();\n\napp.use(cors());\napp.use(express.json());\napp.use(express.raw({ type: \"application/webhook+json\" }));\n\n// Set the static files location\nconst __filename = fileURLToPath(import.meta.url);\nconst __dirname = path.dirname(__filename);\napp.use(express.static(path.join(__dirname, \"../public\"))); // (3)!\n</code></pre> <ol> <li>The URL of the LiveKit server.</li> <li>The portion size of the recording that will be sent to the client in each request. This value is set to <code>5 MB</code>.</li> <li>Set the <code>public</code> directory as the static files location.</li> </ol> <p>There are two new environment variables:</p> <ul> <li><code>LIVEKIT_URL</code>: The URL of the LiveKit server.</li> <li><code>RECORDING_FILE_PORTION_SIZE</code>: The portion size of the recording that will be sent to the client in each request.</li> </ul> <p>Besides, the <code>index.js</code> file configures the server to serve static files from the <code>public</code> directory.</p> <p>It also initializes the <code>EgressClient</code>, which will help interacting with Egress API  to manage recordings, and the <code>AzureBlobStorageService</code>, which will help interacting with the Blob Container:</p> index.js<pre><code>const egressClient = new EgressClient(\n  LIVEKIT_URL,\n  LIVEKIT_API_KEY,\n  LIVEKIT_API_SECRET\n);\nconst azureBlobService = new AzureBlobService();\n</code></pre> <p>The <code>POST /token</code> endpoint has been modified to add the <code>roomRecord</code> permission to the access token, so that participants can start recording a room:</p> index.js<pre><code>app.post(\"/token\", async (req, res) =&gt; {\n  const roomName = req.body.roomName;\n  const participantName = req.body.participantName;\n\n  if (!roomName || !participantName) {\n    return res\n      .status(400)\n      .json({ errorMessage: \"roomName and participantName are required\" });\n  }\n\n  const at = new AccessToken(LIVEKIT_API_KEY, LIVEKIT_API_SECRET, {\n    identity: participantName,\n  });\n  at.addGrant({ roomJoin: true, room: roomName, roomRecord: true }); // (1)!\n  const token = await at.toJwt();\n\n  return res.json({ token });\n});\n</code></pre> <ol> <li>Add the <code>roomRecord</code> permission to the access token.</li> </ol> <p>Now let's explore the code for each recording feature:</p>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-azure/#start-recording","title":"Start recording","text":"<p>The <code>POST /recordings/start</code> endpoint starts the recording of a room. It receives the name of the room to record as parameter and returns the recording metadata:</p> index.js<pre><code>app.post(\"/recordings/start\", async (req, res) =&gt; {\n  const { roomName } = req.body;\n\n  if (!roomName) {\n    return res.status(400).json({ errorMessage: \"roomName is required\" });\n  }\n\n  const activeRecording = await getActiveRecordingByRoom(roomName); // (1)!\n\n  // Check if there is already an active recording for this room\n  if (activeRecording) {\n    return res\n      .status(409)\n      .json({ errorMessage: \"Recording already started for this room\" }); // (2)!\n  }\n\n  // Use the EncodedFileOutput to save the recording to an MP4 file\n  // The room name, time and room ID in the file path help to organize the recordings\n  const fileOutput = new EncodedFileOutput({\n    // (3)!\n    fileType: EncodedFileType.MP4, // (4)!\n    filepath: `RoomComposite-{room_name}-{time}-{room_id}`, // (5)!\n    disableManifest: true,\n  });\n\n  try {\n    // Start a RoomCompositeEgress to record all participants in the room\n    const egressInfo = await egressClient.startRoomCompositeEgress(roomName, {\n      // (6)!\n      file: fileOutput,\n    });\n    const recording = {\n      name: egressInfo.fileResults[0].filename.split(\"/\").pop(), // (7)!\n      startedAt: Number(egressInfo.startedAt) / 1_000_000,\n    };\n    res.json({ message: \"Recording started\", recording }); // (8)!\n  } catch (error) {\n    console.error(\"Error starting recording.\", error);\n    res.status(500).json({ errorMessage: \"Error starting recording\" });\n  }\n});\n</code></pre> <ol> <li>The <code>getActiveRecordingByRoom</code> function retrieves the active recording for a room.</li> <li>If there is already an active recording for the room, the server returns a <code>409 Conflict</code> status code.</li> <li>Use the <code>EncodedFileOutput</code> class to export the recording to an external file.</li> <li>Define the file type as <code>MP4</code>.</li> <li>Define the file path where the recording will be stored. The <code>{room_name}</code>, <code>{time}</code> and <code>{room_id}</code> templates will be replaced by the actual room name, timestamp and room ID, respectively. Check out all available filename templates .</li> <li>Start a <code>RoomCompositeEgress</code> to record all participants in the room by calling the <code>startRoomCompositeEgress</code> method of the <code>EgressClient</code> with the <code>roomName</code> and <code>fileOutput</code> as parameters.</li> <li>Extract the recording name from the <code>fileResults</code> array.</li> <li>Return the recording metadata to the client.</li> </ol> <p>This endpoint does the following:</p> <ol> <li>Obtains the <code>roomName</code> parameter from the request body. If it is not available, it returns a <code>400</code> error.</li> <li> <p>Check if there is already an active recording for the room. If there is, it returns a <code>409</code> error to prevent starting a new recording. To accomplish this, we use the <code>getActiveRecordingByRoom</code> function, which lists all active egresses for a specified room by calling the <code>listEgress</code> method of the <code>EgressClient</code> with the <code>roomName</code> and <code>active</code> parameters, and then returns the egress ID of the first active egress found:</p> index.js<pre><code>const getActiveRecordingByRoom = async (roomName) =&gt; {\n  try {\n    // List all active egresses for the room\n    const egresses = await egressClient.listEgress({\n      roomName,\n      active: true,\n    });\n    return egresses.length &gt; 0 ? egresses[0].egressId : null;\n  } catch (error) {\n    console.error(\"Error listing egresses.\", error);\n    return null;\n  }\n};\n</code></pre> </li> <li> <p>Initializes an <code>EncodedFileOutput</code> object to export the recording to an external file. It sets the file type as <code>MP4</code> and defines the file path where the recording will be stored. The <code>{room_name}</code>, <code>{time}</code> and <code>{room_id}</code> templates will be replaced by the actual room name, timestamp and room ID, respectively. Check out all available filename templates .</p> </li> <li>Starts a <code>RoomCompositeEgress</code> to record all participants in the room by calling the <code>startRoomCompositeEgress</code> method of the <code>EgressClient</code> with <code>roomName</code> and <code>fileOutput</code> as parameters.</li> <li>Extracts the recording name from the <code>fileResults</code> array.</li> <li>Returns the recording metadata to the client.</li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-azure/#stop-recording","title":"Stop recording","text":"<p>The <code>POST /recordings/stop</code> endpoint stops the recording of a room. It receives the room name of the room to stop recording as a parameter and returns the updated recording metadata:</p> index.js<pre><code>app.post(\"/recordings/stop\", async (req, res) =&gt; {\n  const { roomName } = req.body;\n\n  if (!roomName) {\n    return res.status(400).json({ errorMessage: \"roomName is required\" });\n  }\n\n  const activeRecording = await getActiveRecordingByRoom(roomName); // (1)!\n\n  // Check if there is an active recording for this room\n  if (!activeRecording) {\n    return res\n      .status(409)\n      .json({ errorMessage: \"Recording not started for this room\" }); // (2)!\n  }\n\n  try {\n    // Stop the egress to finish the recording\n    const egressInfo = await egressClient.stopEgress(activeRecording); // (3)!\n    const file = egressInfo.fileResults[0];\n    const recording = {\n      name: file.filename.split(\"/\").pop(),\n    };\n    return res.json({ message: \"Recording stopped\", recording }); // (4)!\n  } catch (error) {\n    console.error(\"Error stopping recording.\", error);\n    return res.status(500).json({ errorMessage: \"Error stopping recording\" });\n  }\n});\n</code></pre> <ol> <li>The <code>getActiveRecordingByRoom</code> function retrieves the active recording for a room.</li> <li>If there is no active recording for the room, the server returns a <code>409 Conflict</code> status code.</li> <li>Stop the egress to finish the recording by calling the <code>stopEgress</code> method of the <code>EgressClient</code> with the egress ID (<code>activeRecording</code>) as a parameter.</li> <li>Return the updated recording metadata to the client.</li> </ol> <p>This endpoint does the following:</p> <ol> <li>Obtains the <code>roomName</code> parameter from the request body. If it is not available, it returns a <code>400</code> error.</li> <li>Retrieves all active egresses for the room. If there is no active egress for the room, it returns a <code>409</code> error to prevent stopping a non-existent recording.</li> <li>Extracts the <code>egressId</code> from the active egress.</li> <li>Stops the egress to finish the recording by calling the <code>stopEgress</code> method of the <code>EgressClient</code> with the egress ID (<code>activeRecording</code>) as a parameter.</li> <li>Returns the updated recording metadata to the client.</li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-azure/#list-recordings","title":"List recordings","text":"<p>The <code>GET /recordings</code> endpoint lists all recordings stored in the Azure Container. This endpoint also allows filtering recordings by room name or room ID:</p> index.js<pre><code>app.get(\"/recordings\", async (req, res) =&gt; {\n  const roomId = req.query.roomId?.toString(); // (1)!\n  try {\n    const azureResponse = await azureBlobService.listObjects(); // (2)!\n    let recordings = [];\n    if (azureResponse.length &gt; 0) {\n      recordings = azureResponse.map((obj) =&gt; ({\n        // (3)!\n        name: obj.name,\n      }));\n    }\n    // Filter recordings by room ID\n    recordings = recordings.filter((recording) =&gt; // (4)!\n      roomId ? recording.name.includes(roomId) : true\n    ); \n    return res.json({ recordings }); // (5)!\n  } catch (error) {\n    console.error(\"Error listing recordings.\", error);\n    return res.status(500).json({ errorMessage: \"Error listing recordings\" });\n  }\n});\n</code></pre> <ol> <li>Obtain the <code>roomId</code> query parameter for later filtering, if available.</li> <li>List all Egress video files in the Azure Container.</li> <li>Map all of the recording names from the Azure response.</li> <li>Filter the recordings by room ID, if available.</li> <li>Return the list of recordings to the client.</li> </ol> <p>This endpoint does the following:</p> <ol> <li>Obtains the <code>roomId</code> query parameter for later filtering, if available.</li> <li>Lists all Egress video files in the Azure Container. To accomplish this, we use the <code>listObjects</code> method of the <code>AzureBlobService</code> with the <code>RECORDINGS_PATH</code> parameter.</li> <li>Extracts the recording names from the Azure response.</li> <li>Filters the recordings by room ID, if available. The room ID is part of the recording name, so we can filter with a quick check.</li> <li>Returns the list of recordings to the client.</li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-azure/#get-recording","title":"Get recording","text":"<p>The <code>GET /recordings/:recordingName</code> endpoint retrieves a specific portion of a recording from the Azure Container and returns it as a stream. The server sends the recording file in portions of <code>5 MB</code> each time the client requests a range of the recording file. This is done to prevent loading the entire recording file into memory and to allow the client to play the recording while it is being downloaded and seek to a specific time:</p> index.js<pre><code>app.get(\"/recordings/:recordingName\", async (req, res) =&gt; {\n  const { recordingName } = req.params;\n  const { range } = req.headers;\n  const exists = await azureBlobService.exists(recordingName); // (1)!\n\n  if (!exists) {\n    return res.status(404).json({ errorMessage: \"Recording not found\" });\n  }\n\n  try {\n    // Get the recording file from azure\n    const { stream, size, start, end } = await getRecordingStream(\n      // (2)!\n      recordingName,\n      range\n    );\n\n    // Set response headers\n    res.status(206); // (3)!\n    res.setHeader(\"Cache-Control\", \"no-cache\"); // (4)!\n    res.setHeader(\"Content-Type\", \"video/mp4\"); // (5)!\n    res.setHeader(\"Accept-Ranges\", \"bytes\"); // (6)!\n    res.setHeader(\"Content-Range\", `bytes ${start}-${end}/${size}`); // (7)!\n    res.setHeader(\"Content-Length\", end - start + 1); // (8)!\n\n    // Pipe the recording file to the response\n    stream.pipe(res).on(\"finish\", () =&gt; res.end()); // (9)!\n  } catch (error) {\n    console.error(\"Error getting recording.\", error);\n    return res.status(500).json({ errorMessage: \"Error getting recording\" });\n  }\n});\n</code></pre> <ol> <li>Check if the recording exists in the Azure Container.</li> <li>Get the recording file from the Azure Container.</li> <li>Set the response status code to <code>206 Partial Content</code>.</li> <li>Set the <code>Cache-Control</code> header as <code>no-cache</code>.</li> <li>Set the <code>Content-Type</code> header as <code>video/mp4</code>.</li> <li>Set the <code>Accept-Ranges</code> header as <code>bytes</code>.</li> <li>Set the <code>Content-Range</code> header with the start and end of the recording file and its size.</li> <li>Set the <code>Content-Length</code> header as the size of the recording file portion.</li> <li>Pipe the recording file to the response.</li> </ol> <p>This endpoint does the following:</p> <ol> <li>Extracts the <code>recordingName</code> parameter from the request.</li> <li>Checks if the recording exists in the Azure Container by calling the <code>exists</code> method of the <code>AzureBlobService</code> with the <code>recordingName</code> as a parameter. If the recording does not exist, it returns a <code>404</code> error.</li> <li> <p>Gets the requested range of the recording file by calling the <code>getRecordingStream</code> function:</p> index.js<pre><code>const getRecordingStream = async (recordingName, range) =&gt; {\n  const size = await azureBlobService.getObjectSize(recordingName);\n\n  // Get the requested range\n  const parts = range?.replace(/bytes=/, \"\").split(\"-\"); // (1)!\n  const start = range ? parseInt(parts[0], 10) : 0; // (2)!\n  const endRange = parts[1]\n    ? parseInt(parts[1], 10)\n    : start + RECORDING_FILE_PORTION_SIZE; // (3)!\n  const end = Math.min(endRange, size - 1); // (4)!\n\n  const stream = await azureBlobService.getObject(recordingName, { start, end }); // (5)!\n  return { stream, size, start, end };\n};\n</code></pre> <ol> <li>Get the size of the recording file.</li> <li>Get the start of the requested range.</li> <li>Get the end of the requested range or set it to the start plus the established portion size.</li> <li>Get the minimum between the end of the requested range and the size of the recording file minus one.</li> <li>Get the recording file from the Azure Container with the requested range.</li> </ol> <p>This function does the following:</p> <ol> <li>Gets the size of the recording file by calling the <code>getObjectSize</code> method of the <code>AzureBlobService</code> with the <code>recordingName</code> as a parameter.</li> <li>Extracts the start of the requested range from the <code>range</code> header.</li> <li>Extracts the end of the requested range from the <code>range</code> header. If the end is not provided, it sets the end to the start plus the established portion size.</li> <li>Gets the minimum between the end of the requested range and the size of the recording file minus one. This is done to prevent requesting a range that exceeds the recording file size.</li> <li>Gets the recording file from the Azure Container with the requested range by calling the <code>getObject</code> method of the <code>AzureBlobService</code> with the <code>recordingName</code> and <code>range</code> as parameters.</li> </ol> </li> <li> <p>Sets the response headers:</p> <ul> <li><code>Cache-Control</code>: <code>no-cache</code>.</li> <li><code>Content-Type</code>: <code>video/mp4</code>.</li> <li><code>Accept-Ranges</code>: <code>bytes</code>.</li> <li><code>Content-Range</code>: The start and end of the recording file and its size.</li> <li><code>Content-Length</code>: The size of the recording file portion.</li> </ul> </li> <li> <p>Pipes the recording file to the response.</p> </li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-azure/#delete-recording","title":"Delete recording","text":"<p>The <code>DELETE /recordings/:recordingName</code> endpoint deletes a recording from the Azure Container:</p> index.js<pre><code>app.delete(\"/recordings/:recordingName\", async (req, res) =&gt; {\n  const { recordingName } = req.params;\n  const exists = await azureBlobService.exists(recordingName); // (1)!\n\n  if (!exists) {\n    return res.status(404).json({ errorMessage: \"Recording not found\" });\n  }\n\n  try {\n    // Delete the recording file from Azure\n    await Promise.all([azureBlobService.deleteObject(recordingName)]); // (2)!\n    res.json({ message: \"Recording deleted\" });\n  } catch (error) {\n    console.error(\"Error deleting recording.\", error);\n    res.status(500).json({ errorMessage: \"Error deleting recording\" });\n  }\n});\n</code></pre> <ol> <li>Check if the recording exists in the Azure Container.</li> <li>Delete the recording file from the Azure Container.</li> </ol> <p>This endpoint does the following:</p> <ol> <li>Extracts the <code>recordingName</code> parameter from the request.</li> <li>Checks if the recording exists in the Azure Container by calling the <code>exists</code> method of the <code>AzureBlobService</code> with the <code>recordingName</code> as a parameter. If the recording does not exist, it returns a <code>404</code> error.</li> <li>Deletes the recording file from the Azure Container by calling the <code>deleteObject</code> method of the <code>AzureBlobService</code> with the object's <code>recordingName</code> as a parameter.</li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-azure/#azure-blob-storage-service","title":"Azure Blob Storage Service","text":"<p>Finally, let's take a look at the <code>azure.blobstorage.service.js</code> file, which encapsulates the operations to interact with the Azure Container:</p> azure.blobstorage.service.js<pre><code>// Azure configuration\nconst AZURE_ACCOUNT_NAME = process.env.AZURE_ACCOUNT_NAME || \"devstoreaccount\"; // (1)!\nconst AZURE_ACCOUNT_KEY =\n    process.env.AZURE_ACCOUNT_KEY || \"nokey\"; // (2)!\nconst AZURE_CONTAINER_NAME =\n    process.env.AZURE_CONTAINER_NAME || \"openvidu-appdata\"; // (3)!\n\nconst AZURE_ENDPOINT =\n    process.env.AZURE_ENDPOINT ||\n    `https://${AZURE_ACCOUNT_NAME}.blob.core.windows.net`; // (4)!\n\nexport class AzureBlobService {\n    static instance;\n\n    constructor() {\n        if (AzureBlobService.instance) {\n            return AzureBlobService.instance;\n        }\n        // (5)!\n        const sharedKeyCredential = new StorageSharedKeyCredential(\n            AZURE_ACCOUNT_NAME,\n            AZURE_ACCOUNT_KEY\n        );\n\n        this.blobServiceClient = new BlobServiceClient(\n            AZURE_ENDPOINT,\n            sharedKeyCredential\n        );\n\n        this.containerClient = this.blobServiceClient.getContainerClient(\n            AZURE_CONTAINER_NAME\n        );\n\n        AzureBlobService.instance = this;\n        return this;\n    }\n\n    async exists(key) { // (6)!\n        const blobClient = this.containerClient.getBlobClient(key);\n        return await blobClient.exists();\n    }\n\n    async getObjectSize(key) { // (8)!\n        const props = await this.headObject(key);\n        return props.contentLength;\n    }\n\n    async headObject(key) { // (7)!\n        const blobClient = this.containerClient.getBlobClient(key);\n        const props = await blobClient.getProperties();\n        return props;\n    }\n\n    async getObject(key, range) { // (9)!\n        const blobClient = this.containerClient.getBlobClient(key);\n        const downloadOptions = range\n            ? {\n                rangeGetContentMD5: false,\n                range: {\n                    offset: range.start,\n                    count: range.end - range.start + 1,\n                },\n            }\n            : {};\n\n        const response = await blobClient.download(\n            downloadOptions.range?.offset ?? 0,\n            downloadOptions.range?.count\n        );\n\n        return response.readableStreamBody;\n    }\n\n    async listObjects() { // (10)!\n        const result = [];\n        for await (const blob of this.containerClient.listBlobsFlat()) {\n            result.push(blob);\n        }\n        return result;\n    }\n\n    async deleteObject(key) { // (11)!\n        const blobClient = this.containerClient.getBlobClient(key);\n        return await blobClient.deleteIfExists();\n    }\n}\n</code></pre> <ol> <li>The Storage Account Name of Azure.</li> <li>The access key of Azure Blob Storage.</li> <li>The name of Azure Container.</li> <li>The URL of Azure endpoint.</li> <li>Initialize the <code>Clients</code> with the provided configuration.</li> <li>Check if an object exists in the Azure Container.</li> <li>Retrieve the metadata of an object in the Azure Container.</li> <li>Retrieve the size of an object in the Azure Container.</li> <li>Retrieve a specified range of bytes from an object in the Azure Container.</li> <li>List objects in the Azure Container that match a regex pattern.</li> <li>Delete an object from the Azure Container.</li> </ol> <p>This file loads environment variables for the Azure configuration:</p> <ul> <li><code>AZURE_ACCOUNT_NAME</code>: The name of the Azure Storage Account.</li> <li><code>AZURE_ACCOUNT_KEY</code>: The access key of Azure Blob Storage.</li> <li><code>AZURE_CONTAINER_NAME</code>: The name of the Azure Container.</li> <li><code>AZURE_ENDPOINT</code>: The URL of Azure endpoint.</li> </ul> <p>Then, it defines the <code>AzureBlobService</code> class as a singleton, which initializes the <code>Clients</code> with the provided configuration. The class encapsulates the following methods to interact with the Azure Container:</p> <ul> <li><code>exists</code>: Checks if an object exists in the Azure Container.</li> <li><code>getObjectSize</code>: Retrieves the size of an object in the Azure Container.</li> <li><code>headObject</code>: Retrieves the metadata of an object in the Azure Container.</li> <li><code>getObject</code>: Retrieves an object from the Azure Container.</li> <li><code>listObjects</code>: Lists objects in the Azure Container that match a regex pattern.</li> <li><code>deleteObject</code>: Deletes an object from the Azure Container.</li> </ul>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-azure/#frontend","title":"Frontend","text":"<p>The client application extends the JavaScript client tutorial by adding recording features, introducing new buttons to facilitate actions such as starting and stopping recording a room, as well as listing, playing and deleting recordings. When these newly introduced buttons are interacted with, the client triggers requests to the REST API endpoints of the server application.</p> <p>In order to update the user interface of all participants in the room according to the recording status, the client application subscribes to the <code>RoomEvent.RecordingStatusChanged</code> event, which is triggered when the room changes from being recorded to not being recorded, and vice versa. When this event is triggered, the <code>updateRecordingInfo</code> function is called to update the recording information of the room displayed on the screen. This function is also called when a participant joins the room, using the current value of the <code>room.recording</code> property at that moment. This is done in the <code>joinRoom</code> function of the <code>app.js</code> file:</p> <p>Limitations of the <code>RoomEvent.RecordingStatusChanged</code> event</p> <p>By using the <code>RoomEvent.RecordingStatusChanged</code> event, we can only detect when the recording has started or stopped, but not other states like <code>starting</code>, <code>stopping</code> or <code>failed</code>. Additionally, when the recording stops, the event is not triggered until the recorder participant leaves the room, causing a delay of 20 seconds approximately between the stop and when participants are notified.</p> <p>To overcome these limitations, you can follow the steps described in the advanced recording tutorial, where we implement a custom notification system. This system informs participants about the recording status by listening to webhook events and updating room metadata.</p> app.js<pre><code>async function joinRoom() {\n  // Disable 'Join' button\n  document.getElementById(\"join-button\").disabled = true;\n  document.getElementById(\"join-button\").innerText = \"Joining...\";\n\n  // Initialize a new Room object\n  room = new LivekitClient.Room();\n\n  // Specify the actions when events take place in the room\n  // On every new Track received...\n  room.on(\n    LivekitClient.RoomEvent.TrackSubscribed,\n    (track, _publication, participant) =&gt; {\n      addTrack(track, participant.identity);\n    }\n  );\n\n  // On every new Track destroyed...\n  room.on(\n    LivekitClient.RoomEvent.TrackUnsubscribed,\n    (track, _publication, participant) =&gt; {\n      track.detach();\n      document.getElementById(track.sid)?.remove();\n\n      if (track.kind === \"video\") {\n        removeVideoContainer(participant.identity);\n      }\n    }\n  );\n\n  // When recording status changes...\n  room.on(\n    LivekitClient.RoomEvent.RecordingStatusChanged,\n    async (isRecording) =&gt; {\n      await updateRecordingInfo(isRecording);\n    }\n  );\n\n  try {\n    // Get the room name and participant name from the form\n    const roomName = document.getElementById(\"room-name\").value;\n    const userName = document.getElementById(\"participant-name\").value;\n\n    // Get a token from your application server with the room name and participant name\n    const token = await getToken(roomName, userName);\n\n    // Connect to the room with the LiveKit URL and the token\n    await room.connect(LIVEKIT_URL, token);\n\n    // Hide the 'Join room' page and show the 'Room' page\n    document.getElementById(\"room-title\").innerText = roomName;\n    document.getElementById(\"join\").hidden = true;\n    document.getElementById(\"room\").hidden = false;\n\n    // Publish your camera and microphone\n    await room.localParticipant.enableCameraAndMicrophone();\n    const localVideoTrack = this.room.localParticipant.videoTrackPublications\n      .values()\n      .next().value.track;\n    addTrack(localVideoTrack, userName, true);\n\n    // Update recording info\n    await updateRecordingInfo(room.isRecording);\n  } catch (error) {\n    console.log(\"There was an error connecting to the room:\", error.message);\n    await leaveRoom();\n  }\n}\n</code></pre> <p>The <code>updateRecordingInfo</code> function updates the recording information of the room by changing the recording button's text and color according to the recording status. It also shows or hides the alert message that informs the user that the room is being recorded. Finally, it updates the recording list by calling the <code>listRecordings</code> function.</p> <p>This function retrieves all recordings available for the room from the backend and displays their relevant information by invoking the <code>showRecordingList</code> function:</p> app.js<pre><code>function showRecordingList(recordings) {\n  const recordingsList = document.getElementById(\"recording-list\");\n\n  if (recordings.length === 0) {\n    recordingsList.innerHTML = \"&lt;span&gt;There are no recordings available&lt;/span&gt;\";\n  } else {\n    recordingsList.innerHTML = \"\";\n  }\n\n  recordings.forEach((recording) =&gt; {\n    const recordingName = recording.name;\n\n    const recordingContainer = document.createElement(\"div\");\n    recordingContainer.className = \"recording-container\";\n    recordingContainer.id = recordingName;\n\n    recordingContainer.innerHTML = `\n            &lt;i class=\"fa-solid fa-file-video\"&gt;&lt;/i&gt;\n            &lt;div class=\"recording-info\"&gt;\n                &lt;p class=\"recording-name\"&gt;${recordingName}&lt;/p&gt;\n            &lt;/div&gt;\n            &lt;div class=\"recording-actions\"&gt;\n                &lt;button title=\"Play\" class=\"icon-button\" onclick=\"displayRecording('${recordingName}')\"&gt;\n                    &lt;i class=\"fa-solid fa-play\"&gt;&lt;/i&gt;\n                &lt;/button&gt;\n                &lt;button title=\"Delete\" class=\"icon-button delete-button\" onclick=\"deleteRecording('${recordingName}')\"&gt;\n                    &lt;i class=\"fa-solid fa-trash\"&gt;&lt;/i&gt;\n                &lt;/button&gt;\n            &lt;/div&gt;\n        `;\n\n    recordingsList.append(recordingContainer);\n  });\n}\n</code></pre> <p>The <code>showRecordingList</code> function creates a new <code>div</code> element for each recording available in the room and appends it to the <code>recording-list</code> container. Each <code>div</code> element contains the recording name, as well as buttons to play and delete the recording.</p> <p>Recording deletion</p> <p>When a recording is deleted, it is removed from the recording list, but only for the user who initiated the deletion. Other users will continue to see the recording in their list until it is refreshed.</p> <p>In the advanced recording tutorial, we show how to implement a custom notification system that alerts all participants of a recording's deletion by sending data messages.</p> <p>When the user clicks the play button, the <code>displayRecording</code> function is called to play the recording. This function opens a dialog window with an embedded video element and sets the source of the video to the get recording endpoint of the server application:</p> app.js<pre><code>function displayRecording(recordingName) {\n  const recordingVideoDialog = document.getElementById(\n    \"recording-video-dialog\"\n  );\n  recordingVideoDialog.showModal();\n  const recordingVideo = document.getElementById(\"recording-video\");\n  recordingVideo.src = `/recordings/${recordingName}`;\n}\n</code></pre> index.html<pre><code>&lt;dialog id=\"recording-video-dialog\"&gt;\n    &lt;video id=\"recording-video\" autoplay controls&gt;&lt;/video&gt;\n    &lt;button class=\"btn btn-secondary\" id=\"close-recording-video-dialog\" onclick=\"closeRecording()\"&gt;\n        Close\n    &lt;/button&gt;\n&lt;/dialog&gt;\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-azure/#general-recording-page","title":"General recording page","text":"<p>The <code>recordings.html</code> file defines the HTML for the general recording page. This page lists all available recordings from all rooms and allows the user to filter them by room name. It also provides buttons to play and delete each recording.</p> <p></p> <p></p>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-s3/","title":"Basic Recording Tutorial S3","text":"","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-s3/#basic-recording-tutorial-s3","title":"Basic Recording Tutorial S3","text":"<p>Source code </p> <p>This tutorial is a simple video-call application, built upon Node.js server and JavaScript client tutorials, and extends them by adding recording capabilities:</p> <ul> <li>Start and stop recording a room.</li> <li>List all recordings in a room.</li> <li>Play a recording.</li> <li>Delete a recording.</li> <li>List all available recordings.</li> </ul> <p>Recordings are always persisted in some kind of storage system. This type of storage depends on your OpenVidu deployment:</p> <ul> <li>When running OpenVidu locally or On-Premises, recordings are stored in a local S3 Minio bucket.</li> <li>When running OpenVidu in AWS, recordings are stored in an AWS S3 bucket.</li> <li>When running OpenVidu in Azure, recordings are stored in an Azure Blob Storage container. If this is your case, follow the Recording Basic Azure tutorial instead.</li> </ul>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-s3/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-s3/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <ol> <li> <p>Deploy OpenVidu Single Node in AWS following these instructions to deploy in AWS.</p> <p>CPUs to be able to record</p> <p>Make sure you deploy with at least 4 CPUs in the Virtual Machine of AWS.</p> </li> <li> <p>Point the tutorial to your AWS deployment:</p> <ul> <li>Modify file <code>.env</code>  to update the LiveKit and AWS configuration to the values of your AWS deployment. You can get the values of <code>LIVEKIT_URL</code>, <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code> from the Configure your application to use the deployment section. You can get the values of <code>S3_ENDPOINT</code>, <code>AWS_REGION</code> and <code>S3_BUCKET</code> from the <code>openvidu.env</code> file of your deployment by making ssh to the instance. For the <code>S3_ACCESS_KEY</code> and <code>S3_SECRET_KEY</code> you will need to create an access key in the IAM section of AWS to be able to use them in the tutorial (check Manage access keys for IAM users).   </li> <li>Modify file <code>app.js</code> to update the value of <code>LIVEKIT_URL</code> with your <code>LIVEKIT_URL</code>.</li> </ul> </li> </ol> <p>Warning</p> <p>If you are using self-signed certificate you will need to add this line in the first line after the imports on the <code>index.js</code> <code>process.env.NODE_TLS_REJECT_UNAUTHORIZED = \"0\"; // Disable TLS verification for local testing</code></p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-s3/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-s3/#3-run-the-application","title":"3. Run the application","text":"<p>To run this application, you need Node.js  (\u2265 18) installed on your device.</p> <ol> <li>Navigate into the application directory</li> </ol> <pre><code>cd openvidu-livekit-tutorials/advanced-features/openvidu-recording-basic-node\n</code></pre> <ol> <li>Install dependencies</li> </ol> <pre><code>npm install\n</code></pre> <ol> <li>Run the application</li> </ol> <pre><code>npm start\n</code></pre> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:6080</code>. You should see a screen like this:</p> <p></p> <p></p> <p>Accessing your application from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:6443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-s3/#understanding-the-code","title":"Understanding the code","text":"<p>This application consists of two essential backend files under the <code>src</code> directory:</p> <ul> <li><code>index.js</code>: This file holds the server application and defines the REST API endpoints.</li> <li><code>s3.service.js</code>: This file encapsulates the operations to interact with the S3 bucket.</li> </ul> <p>And the following essential frontend files under the <code>public</code> directory:</p> <ul> <li><code>index.html</code>: This is the client application's main HTML file.</li> <li><code>app.js</code>: This is the main JavaScript file that interacts with the server application and handles the client application's logic and functionality.</li> <li><code>style.css</code>: This file contains the client application's styling.</li> <li><code>recordings.html</code>: This file defines the HTML for the general recording page.</li> </ul>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-s3/#backend","title":"Backend","text":"<p>The server application extends the Node.js server tutorial by adding the following REST API endpoints:</p> <ul> <li><code>POST /recordings/start</code>: Starts the recording of a room.</li> <li><code>POST /recordings/stop</code>: Stops the recording of a room.</li> <li><code>GET /recordings</code>: Lists all recordings stored in the S3 bucket. This endpoint also allows filtering recordings by room ID.</li> <li><code>GET /recordings/:recordingName</code>: Retrieves a recording from the S3 bucket and returns it as a stream.</li> <li><code>DELETE /recordings/:recordingName</code>: This endpoint deletes a recording from the S3 bucket.</li> </ul> <p>Before we dive into the code of each endpoint, let's first see the changes introduced in the <code>index.js</code> file:</p> index.js<pre><code>// Configuration\nconst SERVER_PORT = process.env.SERVER_PORT || 6080;\nconst LIVEKIT_API_KEY = process.env.LIVEKIT_API_KEY || \"devkey\";\nconst LIVEKIT_API_SECRET = process.env.LIVEKIT_API_SECRET || \"secret\";\nconst LIVEKIT_URL = process.env.LIVEKIT_URL || \"http://localhost:7880\"; // (1)!\nconst RECORDINGS_PATH = process.env.RECORDINGS_PATH ?? \"recordings/\"; // (2)!\nconst RECORDING_FILE_PORTION_SIZE = 5 * 1024 * 1024; // (3)!\n\nconst app = express();\n\napp.use(cors());\napp.use(express.json());\napp.use(express.raw({ type: \"application/webhook+json\" }));\n\n// Set the static files location\nconst __filename = fileURLToPath(import.meta.url);\nconst __dirname = path.dirname(__filename);\napp.use(express.static(path.join(__dirname, \"../public\"))); // (4)!\n</code></pre> <ol> <li>The URL of the LiveKit server.</li> <li>The path where recordings will be stored in the S3 bucket.</li> <li>The portion size of the recording that will be sent to the client in each request. This value is set to <code>5 MB</code>.</li> <li>Set the <code>public</code> directory as the static files location.</li> </ol> <p>There are three new environment variables:</p> <ul> <li><code>LIVEKIT_URL</code>: The URL of the LiveKit server.</li> <li><code>RECORDINGS_PATH</code>: The path where recordings will be stored in the S3 bucket.</li> <li><code>RECORDING_FILE_PORTION_SIZE</code>: The portion size of the recording that will be sent to the client in each request.</li> </ul> <p>Besides, the <code>index.js</code> file configures the server to serve static files from the <code>public</code> directory.</p> <p>It also initializes the <code>EgressClient</code>, which will help interacting with Egress API  to manage recordings, and the <code>S3Service</code>, which will help interacting with the S3 bucket:</p> index.js<pre><code>const egressClient = new EgressClient(\n  LIVEKIT_URL,\n  LIVEKIT_API_KEY,\n  LIVEKIT_API_SECRET\n);\nconst s3Service = new S3Service();\n</code></pre> <p>The <code>POST /token</code> endpoint has been modified to add the <code>roomRecord</code> permission to the access token, so that participants can start recording a room:</p> index.js<pre><code>app.post(\"/token\", async (req, res) =&gt; {\n  const roomName = req.body.roomName;\n  const participantName = req.body.participantName;\n\n  if (!roomName || !participantName) {\n    return res\n      .status(400)\n      .json({ errorMessage: \"roomName and participantName are required\" });\n  }\n\n  const at = new AccessToken(LIVEKIT_API_KEY, LIVEKIT_API_SECRET, {\n    identity: participantName,\n  });\n  at.addGrant({ roomJoin: true, room: roomName, roomRecord: true }); // (1)!\n  const token = await at.toJwt();\n\n  return res.json({ token });\n});\n</code></pre> <ol> <li>Add the <code>roomRecord</code> permission to the access token.</li> </ol> <p>Now let's explore the code for each recording feature:</p>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-s3/#start-recording","title":"Start recording","text":"<p>The <code>POST /recordings/start</code> endpoint starts the recording of a room. It receives the name of the room to record as parameter and returns the recording metadata:</p> index.js<pre><code>app.post(\"/recordings/start\", async (req, res) =&gt; {\n  const { roomName } = req.body;\n\n  if (!roomName) {\n    return res.status(400).json({ errorMessage: \"roomName is required\" });\n  }\n\n  const activeRecording = await getActiveRecordingByRoom(roomName); // (1)!\n\n  // Check if there is already an active recording for this room\n  if (activeRecording) {\n    return res\n      .status(409)\n      .json({ errorMessage: \"Recording already started for this room\" }); // (2)!\n  }\n\n  // Use the EncodedFileOutput to save the recording to an MP4 file\n  // The room name, time and room ID in the file path help to organize the recordings\n  const fileOutput = new EncodedFileOutput({\n    // (3)!\n    fileType: EncodedFileType.MP4, // (4)!\n    filepath: `${RECORDINGS_PATH}/{room_name}-{time}-{room_id}`, // (5)!\n    disableManifest: true,\n  });\n\n  try {\n    // Start a RoomCompositeEgress to record all participants in the room\n    const egressInfo = await egressClient.startRoomCompositeEgress(roomName, {\n      // (6)!\n      file: fileOutput,\n    });\n    const recording = {\n      name: egressInfo.fileResults[0].filename.split(\"/\").pop(), // (7)!\n      startedAt: Number(egressInfo.startedAt) / 1_000_000,\n    };\n    res.json({ message: \"Recording started\", recording }); // (8)!\n  } catch (error) {\n    console.error(\"Error starting recording.\", error);\n    res.status(500).json({ errorMessage: \"Error starting recording\" });\n  }\n});\n</code></pre> <ol> <li>The <code>getActiveRecordingByRoom</code> function retrieves the active recording for a room.</li> <li>If there is already an active recording for the room, the server returns a <code>409 Conflict</code> status code.</li> <li>Use the <code>EncodedFileOutput</code> class to export the recording to an external file.</li> <li>Define the file type as <code>MP4</code>.</li> <li>Define the file path where the recording will be stored. The <code>{room_name}</code>, <code>{time}</code> and <code>{room_id}</code> templates will be replaced by the actual room name, timestamp and room ID, respectively. Check out all available filename templates .</li> <li>Start a <code>RoomCompositeEgress</code> to record all participants in the room by calling the <code>startRoomCompositeEgress</code> method of the <code>EgressClient</code> with the <code>roomName</code> and <code>fileOutput</code> as parameters.</li> <li>Extract the recording name from the <code>fileResults</code> array.</li> <li>Return the recording metadata to the client.</li> </ol> <p>This endpoint does the following:</p> <ol> <li>Obtains the <code>roomName</code> parameter from the request body. If it is not available, it returns a <code>400</code> error.</li> <li> <p>Check if there is already an active recording for the room. If there is, it returns a <code>409</code> error to prevent starting a new recording. To accomplish this, we use the <code>getActiveRecordingByRoom</code> function, which lists all active egresses for a specified room by calling the <code>listEgress</code> method of the <code>EgressClient</code> with the <code>roomName</code> and <code>active</code> parameters, and then returns the egress ID of the first active egress found:</p> index.js<pre><code>const getActiveRecordingByRoom = async (roomName) =&gt; {\n  try {\n    // List all active egresses for the room\n    const egresses = await egressClient.listEgress({\n      roomName,\n      active: true,\n    });\n    return egresses.length &gt; 0 ? egresses[0].egressId : null;\n  } catch (error) {\n    console.error(\"Error listing egresses.\", error);\n    return null;\n  }\n};\n</code></pre> </li> <li> <p>Initializes an <code>EncodedFileOutput</code> object to export the recording to an external file. It sets the file type as <code>MP4</code> and defines the file path where the recording will be stored. The <code>{room_name}</code>, <code>{time}</code> and <code>{room_id}</code> templates will be replaced by the actual room name, timestamp and room ID, respectively. Check out all available filename templates .</p> </li> <li>Starts a <code>RoomCompositeEgress</code> to record all participants in the room by calling the <code>startRoomCompositeEgress</code> method of the <code>EgressClient</code> with <code>roomName</code> and <code>fileOutput</code> as parameters.</li> <li>Extracts the recording name from the <code>fileResults</code> array.</li> <li>Returns the recording metadata to the client.</li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-s3/#stop-recording","title":"Stop recording","text":"<p>The <code>POST /recordings/stop</code> endpoint stops the recording of a room. It receives the room name of the room to stop recording as a parameter and returns the updated recording metadata:</p> index.js<pre><code>app.post(\"/recordings/stop\", async (req, res) =&gt; {\n  const { roomName } = req.body;\n\n  if (!roomName) {\n    return res.status(400).json({ errorMessage: \"roomName is required\" });\n  }\n\n  const activeRecording = await getActiveRecordingByRoom(roomName); // (1)!\n\n  // Check if there is an active recording for this room\n  if (!activeRecording) {\n    return res\n      .status(409)\n      .json({ errorMessage: \"Recording not started for this room\" }); // (2)!\n  }\n\n  try {\n    // Stop the egress to finish the recording\n    const egressInfo = await egressClient.stopEgress(activeRecording); // (3)!\n    const file = egressInfo.fileResults[0];\n    const recording = {\n      name: file.filename.split(\"/\").pop(),\n    };\n    return res.json({ message: \"Recording stopped\", recording }); // (4)!\n  } catch (error) {\n    console.error(\"Error stopping recording.\", error);\n    return res.status(500).json({ errorMessage: \"Error stopping recording\" });\n  }\n});\n</code></pre> <ol> <li>The <code>getActiveRecordingByRoom</code> function retrieves the active recording for a room.</li> <li>If there is no active recording for the room, the server returns a <code>409 Conflict</code> status code.</li> <li>Stop the egress to finish the recording by calling the <code>stopEgress</code> method of the <code>EgressClient</code> with the egress ID (<code>activeRecording</code>) as a parameter.</li> <li>Return the updated recording metadata to the client.</li> </ol> <p>This endpoint does the following:</p> <ol> <li>Obtains the <code>roomName</code> parameter from the request body. If it is not available, it returns a <code>400</code> error.</li> <li>Retrieves all active egresses for the room. If there is no active egress for the room, it returns a <code>409</code> error to prevent stopping a non-existent recording.</li> <li>Extracts the <code>egressId</code> from the active egress.</li> <li>Stops the egress to finish the recording by calling the <code>stopEgress</code> method of the <code>EgressClient</code> with the egress ID (<code>activeRecording</code>) as a parameter.</li> <li>Returns the updated recording metadata to the client.</li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-s3/#list-recordings","title":"List recordings","text":"<p>The <code>GET /recordings</code> endpoint lists all recordings stored in the S3 bucket. This endpoint also allows filtering recordings by room name or room ID:</p> index.js<pre><code>app.get(\"/recordings\", async (req, res) =&gt; {\n  const roomId = req.query.roomId?.toString(); // (1)!\n  try {\n    const awsResponse = await s3Service.listObjects(RECORDINGS_PATH); // (2)!\n    let recordings = [];\n    if (awsResponse.Contents) {\n      recordings = awsResponse.Contents.map((recording) =&gt; {\n        // (3)!\n        return {\n          name: recording.Key.split(\"/\").pop(),\n        };\n      });\n    }\n    // Filter recordings by room ID\n    recordings = recordings.filter(\n      (\n        recording // (4)!\n      ) =&gt; (roomId ? recording.name.includes(roomId) : true)\n    );\n    return res.json({ recordings }); // (5)!\n  } catch (error) {\n    console.error(\"Error listing recordings.\", error);\n    return res.status(500).json({ errorMessage: \"Error listing recordings\" });\n  }\n});\n</code></pre> <ol> <li>Obtain the <code>roomId</code> query parameter for later filtering, if available.</li> <li>List all Egress video files in the S3 bucket.</li> <li>Map all of the recording names from the S3 response.</li> <li>Filter the recordings by room ID, if available.</li> <li>Return the list of recordings to the client.</li> </ol> <p>This endpoint does the following:</p> <ol> <li>Obtains the <code>roomId</code> query parameter for later filtering, if available.</li> <li>Lists all Egress video files in the S3 bucket. To accomplish this, we use the <code>listObjects</code> method of the <code>S3Service</code> with the <code>RECORDINGS_PATH</code> parameter.</li> <li>Extracts the recording names from the S3 response.</li> <li>Filters the recordings by room ID, if available. The room ID is part of the recording name, so we can filter with a quick check.</li> <li>Returns the list of recordings to the client.</li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-s3/#get-recording","title":"Get recording","text":"<p>The <code>GET /recordings/:recordingName</code> endpoint retrieves a specific portion of a recording from the S3 bucket and returns it as a stream. The server sends the recording file in portions of <code>5 MB</code> each time the client requests a range of the recording file. This is done to prevent loading the entire recording file into memory and to allow the client to play the recording while it is being downloaded and seek to a specific time:</p> index.js<pre><code>app.get(\"/recordings/:recordingName\", async (req, res) =&gt; {\n  const { recordingName } = req.params;\n  const { range } = req.headers;\n  const key = RECORDINGS_PATH + recordingName;\n  const exists = await s3Service.exists(key); // (1)!\n\n  if (!exists) {\n    return res.status(404).json({ errorMessage: \"Recording not found\" });\n  }\n\n  try {\n    // Get the recording file from S3\n    const { stream, size, start, end } = await getRecordingStream(\n      // (2)!\n      recordingName,\n      range\n    );\n\n    // Set response headers\n    res.status(206); // (3)!\n    res.setHeader(\"Cache-Control\", \"no-cache\"); // (4)!\n    res.setHeader(\"Content-Type\", \"video/mp4\"); // (5)!\n    res.setHeader(\"Accept-Ranges\", \"bytes\"); // (6)!\n    res.setHeader(\"Content-Range\", `bytes ${start}-${end}/${size}`); // (7)!\n    res.setHeader(\"Content-Length\", end - start + 1); // (8)!\n\n    // Pipe the recording file to the response\n    stream.pipe(res).on(\"finish\", () =&gt; res.end()); // (9)!\n  } catch (error) {\n    console.error(\"Error getting recording.\", error);\n    return res.status(500).json({ errorMessage: \"Error getting recording\" });\n  }\n});\n</code></pre> <ol> <li>Check if the recording exists in the S3 bucket.</li> <li>Get the recording file from the S3 bucket.</li> <li>Set the response status code to <code>206 Partial Content</code>.</li> <li>Set the <code>Cache-Control</code> header as <code>no-cache</code>.</li> <li>Set the <code>Content-Type</code> header as <code>video/mp4</code>.</li> <li>Set the <code>Accept-Ranges</code> header as <code>bytes</code>.</li> <li>Set the <code>Content-Range</code> header with the start and end of the recording file and its size.</li> <li>Set the <code>Content-Length</code> header as the size of the recording file portion.</li> <li>Pipe the recording file to the response.</li> </ol> <p>This endpoint does the following:</p> <ol> <li>Extracts the <code>recordingName</code> parameter from the request.</li> <li>Checks if the recording exists in the S3 bucket by calling the <code>exists</code> method of the <code>S3Service</code> with the <code>key</code> as a parameter. If the recording does not exist, it returns a <code>404</code> error.</li> <li> <p>Gets the requested range of the recording file by calling the <code>getRecordingStream</code> function:</p> index.js<pre><code>const getRecordingStream = async (recordingName, range) =&gt; {\n  const key = RECORDINGS_PATH + recordingName;\n  const size = await s3Service.getObjectSize(key);\n\n  // Get the requested range\n  const parts = range?.replace(/bytes=/, \"\").split(\"-\"); // (1)!\n  const start = range ? parseInt(parts[0], 10) : 0; // (2)!\n  const endRange = parts[1]\n    ? parseInt(parts[1], 10)\n    : start + RECORDING_FILE_PORTION_SIZE; // (3)!\n  const end = Math.min(endRange, size - 1); // (4)!\n\n  const stream = await s3Service.getObject(key, { start, end }); // (5)!\n  return { stream, size, start, end };\n};\n</code></pre> <ol> <li>Get the size of the recording file.</li> <li>Get the start of the requested range.</li> <li>Get the end of the requested range or set it to the start plus the established portion size.</li> <li>Get the minimum between the end of the requested range and the size of the recording file minus one.</li> <li>Get the recording file from the S3 bucket with the requested range.</li> </ol> <p>This function does the following:</p> <ol> <li>Gets the size of the recording file by calling the <code>getObjectSize</code> method of the <code>S3Service</code> with the <code>key</code> as a parameter.</li> <li>Extracts the start of the requested range from the <code>range</code> header.</li> <li>Extracts the end of the requested range from the <code>range</code> header. If the end is not provided, it sets the end to the start plus the established portion size.</li> <li>Gets the minimum between the end of the requested range and the size of the recording file minus one. This is done to prevent requesting a range that exceeds the recording file size.</li> <li>Gets the recording file from the S3 bucket with the requested range by calling the <code>getObject</code> method of the <code>S3Service</code> with the <code>key</code> and <code>range</code> as parameters.</li> </ol> </li> <li> <p>Sets the response headers:</p> <ul> <li><code>Cache-Control</code>: <code>no-cache</code>.</li> <li><code>Content-Type</code>: <code>video/mp4</code>.</li> <li><code>Accept-Ranges</code>: <code>bytes</code>.</li> <li><code>Content-Range</code>: The start and end of the recording file and its size.</li> <li><code>Content-Length</code>: The size of the recording file portion.</li> </ul> </li> <li> <p>Pipes the recording file to the response.</p> </li> </ol> <p>Direct access to S3 bucket</p> <p>With this approach, the backend acts as a proxy between the client and S3, which may result in increased server resource usage. To avoid this, it is more efficient to provide the client with a presigned URL, allowing direct access to the recording files from the S3 bucket. In the advanced recording tutorial, we show how to implement this method, along with a discussion of its advantages and disadvantages.</p>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-s3/#delete-recording","title":"Delete recording","text":"<p>The <code>DELETE /recordings/:recordingName</code> endpoint deletes a recording from the S3 bucket:</p> index.js<pre><code>app.delete(\"/recordings/:recordingName\", async (req, res) =&gt; {\n  const { recordingName } = req.params;\n  const key = RECORDINGS_PATH + recordingName;\n  const exists = await s3Service.exists(key); // (1)!\n\n  if (!exists) {\n    return res.status(404).json({ errorMessage: \"Recording not found\" });\n  }\n\n  try {\n    // Delete the recording file from S3\n    await Promise.all([s3Service.deleteObject(key)]); // (2)!\n    res.json({ message: \"Recording deleted\" });\n  } catch (error) {\n    console.error(\"Error deleting recording.\", error);\n    res.status(500).json({ errorMessage: \"Error deleting recording\" });\n  }\n});\n</code></pre> <ol> <li>Check if the recording exists in the S3 bucket.</li> <li>Delete the recording file from the S3 bucket.</li> </ol> <p>This endpoint does the following:</p> <ol> <li>Extracts the <code>recordingName</code> parameter from the request.</li> <li>Checks if the recording exists in the S3 bucket by calling the <code>exists</code> method of the <code>S3Service</code> with the <code>key</code> as a parameter. If the recording does not exist, it returns a <code>404</code> error.</li> <li>Deletes the recording file from the S3 bucket by calling the <code>deleteObject</code> method of the <code>S3Service</code> with the object's <code>key</code> as a parameter.</li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-s3/#s3-service","title":"S3 service","text":"<p>Finally, let's take a look at the <code>s3.service.js</code> file, which encapsulates the operations to interact with the S3 bucket:</p> s3.service.js<pre><code>// S3 configuration\nconst S3_ENDPOINT = process.env.S3_ENDPOINT || \"http://localhost:9000\"; // (1)!\nconst S3_ACCESS_KEY = process.env.S3_ACCESS_KEY || \"minioadmin\"; // (2)!\nconst S3_SECRET_KEY = process.env.S3_SECRET_KEY || \"minioadmin\"; // (3)!\nconst AWS_REGION = process.env.AWS_REGION || \"us-east-1\"; // (4)!\nconst S3_BUCKET = process.env.S3_BUCKET || \"openvidu\"; // (5)!\n\nexport class S3Service {\n  static instance;\n\n  constructor() {\n    if (S3Service.instance) {\n      return S3Service.instance;\n    }\n\n    this.s3Client = new S3Client({ // (6)!\n      endpoint: S3_ENDPOINT,\n      credentials: {\n        accessKeyId: S3_ACCESS_KEY,\n        secretAccessKey: S3_SECRET_KEY,\n      },\n      region: AWS_REGION,\n      forcePathStyle: true,\n    });\n\n    S3Service.instance = this;\n    return this;\n  }\n\n  async exists(key) { // (7)!\n    try {\n      await this.headObject(key);\n      return true;\n    } catch (error) {\n      return false;\n    }\n  }\n\n  async headObject(key) { // (8)!\n    const params = {\n      Bucket: S3_BUCKET,\n      Key: key,\n    };\n    const command = new HeadObjectCommand(params);\n    return this.run(command);\n  }\n\n  async getObjectSize(key) { // (9)!\n    const { ContentLength: size } = await this.headObject(key);\n    return size;\n  }\n\n  async getObject(key, range) { // (10)!\n    const params = {\n      Bucket: S3_BUCKET,\n      Key: key,\n      Range: range ? `bytes=${range.start}-${range.end}` : undefined,\n    };\n    const command = new GetObjectCommand(params);\n    const { Body: body } = await this.run(command);\n    return body;\n  }\n\n  async listObjects(prefix) { // (11)!\n    const params = {\n      Bucket: S3_BUCKET,\n      Prefix: prefix,\n    };\n    const command = new ListObjectsV2Command(params);\n    return await this.run(command);\n  }\n\n  async deleteObject(key) { // (12)!\n    const params = {\n      Bucket: S3_BUCKET,\n      Key: key,\n    };\n    const command = new DeleteObjectCommand(params);\n    return this.run(command);\n  }\n\n  async run(command) { // (13)!\n    return this.s3Client.send(command);\n  }\n}\n</code></pre> <ol> <li>The URL of the S3 server.</li> <li>The access key of the S3 server.</li> <li>The secret key of the S3 server.</li> <li>The AWS region of the S3 server.</li> <li>The name of the S3 bucket.</li> <li>Initialize the <code>S3Client</code> with the provided configuration.</li> <li>Check if an object exists in the S3 bucket.</li> <li>Retrieve the metadata of an object in the S3 bucket.</li> <li>Retrieve the size of an object in the S3 bucket.</li> <li>Retrieve a specified range of bytes from an object in the S3 bucket.</li> <li>List objects in the S3 bucket that match a regex pattern.</li> <li>Delete an object from the S3 bucket.</li> <li>Execute an S3 command.</li> </ol> <p>This file loads environment variables for the S3 configuration:</p> <ul> <li><code>S3_ENDPOINT</code>: The URL of the S3 server.</li> <li><code>S3_ACCESS_KEY</code>: The access key of the S3 server.</li> <li><code>S3_SECRET_KEY</code>: The secret key of the S3 server.</li> <li><code>AWS_REGION</code>: The AWS region of the S3 server.</li> <li><code>S3_BUCKET</code>: The name of the S3 bucket.</li> </ul> <p>Then, it defines the <code>S3Service</code> class as a singleton, which initializes the <code>S3Client</code> with the provided configuration. The class encapsulates the following methods to interact with the S3 bucket:</p> <ul> <li><code>exists</code>: Checks if an object exists in the S3 bucket.</li> <li><code>headObject</code>: Retrieves the metadata of an object in the S3 bucket.</li> <li><code>getObjectSize</code>: Retrieves the size of an object in the S3 bucket.</li> <li><code>getObject</code>: Retrieves an object from the S3 bucket.</li> <li><code>listObjects</code>: Lists objects in the S3 bucket that match a regex pattern.</li> <li><code>deleteObject</code>: Deletes an object from the S3 bucket.</li> <li><code>run</code>: Executes an S3 command.</li> </ul>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-s3/#frontend","title":"Frontend","text":"<p>The client application extends the JavaScript client tutorial by adding recording features, introducing new buttons to facilitate actions such as starting and stopping recording a room, as well as listing, playing and deleting recordings. When these newly introduced buttons are interacted with, the client triggers requests to the REST API endpoints of the server application.</p> <p>In order to update the user interface of all participants in the room according to the recording status, the client application subscribes to the <code>RoomEvent.RecordingStatusChanged</code> event, which is triggered when the room changes from being recorded to not being recorded, and vice versa. When this event is triggered, the <code>updateRecordingInfo</code> function is called to update the recording information of the room displayed on the screen. This function is also called when a participant joins the room, using the current value of the <code>room.recording</code> property at that moment. This is done in the <code>joinRoom</code> function of the <code>app.js</code> file:</p> <p>Limitations of the <code>RoomEvent.RecordingStatusChanged</code> event</p> <p>By using the <code>RoomEvent.RecordingStatusChanged</code> event, we can only detect when the recording has started or stopped, but not other states like <code>starting</code>, <code>stopping</code> or <code>failed</code>. Additionally, when the recording stops, the event is not triggered until the recorder participant leaves the room, causing a delay of 20 seconds approximately between the stop and when participants are notified.</p> <p>To overcome these limitations, you can follow the steps described in the advanced recording tutorial, where we implement a custom notification system. This system informs participants about the recording status by listening to webhook events and updating room metadata.</p> app.js<pre><code>async function joinRoom() {\n  // Disable 'Join' button\n  document.getElementById(\"join-button\").disabled = true;\n  document.getElementById(\"join-button\").innerText = \"Joining...\";\n\n  // Initialize a new Room object\n  room = new LivekitClient.Room();\n\n  // Specify the actions when events take place in the room\n  // On every new Track received...\n  room.on(\n    LivekitClient.RoomEvent.TrackSubscribed,\n    (track, _publication, participant) =&gt; {\n      addTrack(track, participant.identity);\n    }\n  );\n\n  // On every new Track destroyed...\n  room.on(\n    LivekitClient.RoomEvent.TrackUnsubscribed,\n    (track, _publication, participant) =&gt; {\n      track.detach();\n      document.getElementById(track.sid)?.remove();\n\n      if (track.kind === \"video\") {\n        removeVideoContainer(participant.identity);\n      }\n    }\n  );\n\n  // When recording status changes...\n  room.on(\n    LivekitClient.RoomEvent.RecordingStatusChanged,\n    async (isRecording) =&gt; {\n      await updateRecordingInfo(isRecording);\n    }\n  );\n\n  try {\n    // Get the room name and participant name from the form\n    const roomName = document.getElementById(\"room-name\").value;\n    const userName = document.getElementById(\"participant-name\").value;\n\n    // Get a token from your application server with the room name and participant name\n    const token = await getToken(roomName, userName);\n\n    // Connect to the room with the LiveKit URL and the token\n    await room.connect(LIVEKIT_URL, token);\n\n    // Hide the 'Join room' page and show the 'Room' page\n    document.getElementById(\"room-title\").innerText = roomName;\n    document.getElementById(\"join\").hidden = true;\n    document.getElementById(\"room\").hidden = false;\n\n    // Publish your camera and microphone\n    await room.localParticipant.enableCameraAndMicrophone();\n    const localVideoTrack = this.room.localParticipant.videoTrackPublications\n      .values()\n      .next().value.track;\n    addTrack(localVideoTrack, userName, true);\n\n    // Update recording info\n    await updateRecordingInfo(room.isRecording);\n  } catch (error) {\n    console.log(\"There was an error connecting to the room:\", error.message);\n    await leaveRoom();\n  }\n}\n</code></pre> <p>The <code>updateRecordingInfo</code> function updates the recording information of the room by changing the recording button's text and color according to the recording status. It also shows or hides the alert message that informs the user that the room is being recorded. Finally, it updates the recording list by calling the <code>listRecordings</code> function.</p> <p>This function retrieves all recordings available for the room from the backend and displays their relevant information by invoking the <code>showRecordingList</code> function:</p> app.js<pre><code>function showRecordingList(recordings) {\n  const recordingsList = document.getElementById(\"recording-list\");\n\n  if (recordings.length === 0) {\n    recordingsList.innerHTML = \"&lt;span&gt;There are no recordings available&lt;/span&gt;\";\n  } else {\n    recordingsList.innerHTML = \"\";\n  }\n\n  recordings.forEach((recording) =&gt; {\n    const recordingName = recording.name;\n\n    const recordingContainer = document.createElement(\"div\");\n    recordingContainer.className = \"recording-container\";\n    recordingContainer.id = recordingName;\n\n    recordingContainer.innerHTML = `\n            &lt;i class=\"fa-solid fa-file-video\"&gt;&lt;/i&gt;\n            &lt;div class=\"recording-info\"&gt;\n                &lt;p class=\"recording-name\"&gt;${recordingName}&lt;/p&gt;\n            &lt;/div&gt;\n            &lt;div class=\"recording-actions\"&gt;\n                &lt;button title=\"Play\" class=\"icon-button\" onclick=\"displayRecording('${recordingName}')\"&gt;\n                    &lt;i class=\"fa-solid fa-play\"&gt;&lt;/i&gt;\n                &lt;/button&gt;\n                &lt;button title=\"Delete\" class=\"icon-button delete-button\" onclick=\"deleteRecording('${recordingName}')\"&gt;\n                    &lt;i class=\"fa-solid fa-trash\"&gt;&lt;/i&gt;\n                &lt;/button&gt;\n            &lt;/div&gt;\n        `;\n\n    recordingsList.append(recordingContainer);\n  });\n}\n</code></pre> <p>The <code>showRecordingList</code> function creates a new <code>div</code> element for each recording available in the room and appends it to the <code>recording-list</code> container. Each <code>div</code> element contains the recording name, as well as buttons to play and delete the recording.</p> <p>Recording deletion</p> <p>When a recording is deleted, it is removed from the recording list, but only for the user who initiated the deletion. Other users will continue to see the recording in their list until it is refreshed.</p> <p>In the advanced recording tutorial, we show how to implement a custom notification system that alerts all participants of a recording's deletion by sending data messages.</p> <p>When the user clicks the play button, the <code>displayRecording</code> function is called to play the recording. This function opens a dialog window with an embedded video element and sets the source of the video to the get recording endpoint of the server application:</p> app.js<pre><code>function displayRecording(recordingName) {\n  const recordingVideoDialog = document.getElementById(\n    \"recording-video-dialog\"\n  );\n  recordingVideoDialog.showModal();\n  const recordingVideo = document.getElementById(\"recording-video\");\n  recordingVideo.src = `/recordings/${recordingName}`;\n}\n</code></pre> index.html<pre><code>&lt;dialog id=\"recording-video-dialog\"&gt;\n    &lt;video id=\"recording-video\" autoplay controls&gt;&lt;/video&gt;\n    &lt;button class=\"btn btn-secondary\" id=\"close-recording-video-dialog\" onclick=\"closeRecording()\"&gt;\n        Close\n    &lt;/button&gt;\n&lt;/dialog&gt;\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/advanced-features/recording-basic-s3/#general-recording-page","title":"General recording page","text":"<p>The <code>recordings.html</code> file defines the HTML for the general recording page. This page lists all available recordings from all rooms and allows the user to filter them by room name. It also provides buttons to play and delete each recording.</p> <p></p> <p></p>","tags":["Platform"]},{"location":"docs/tutorials/ai-services/","title":"AI Services Tutorials","text":"","tags":["Platform"]},{"location":"docs/tutorials/ai-services/#ai-services-tutorials","title":"AI Services Tutorials","text":"<p>Explore these tutorials to learn how to integrate AI services in your OpenVidu applications:</p> <p> Live Captions</p>","tags":["Platform"]},{"location":"docs/tutorials/ai-services/openvidu-live-captions/","title":"OpenVidu Live Captions tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/ai-services/openvidu-live-captions/#live-captions-tutorial","title":"Live Captions tutorial","text":"<p>Source code </p> <p>This tutorial is a simple variation of the JavaScript client tutorial, adding live captions thanks to the use of OpenVidu Live Captions service.</p>","tags":["Platform"]},{"location":"docs/tutorials/ai-services/openvidu-live-captions/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/ai-services/openvidu-live-captions/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Enable the Speech Processing agent</p> <p>Modify file <code>openvidu-local-deployment/community/agent-speech-processing.yaml</code>  to enable the Speech Processing agent. At least you need to set the following properties:</p> <pre><code>enabled: true\n\nlive_captions:\n\n    processing: automatic\n\n    provider: YOUR_SPEECH_PROVIDER\n\n    # Followed by your provider specific configuration\n</code></pre> <p>Info</p> <p>Visit Supported AI providers for more information about the available providers and their specific configuration. Many of them provide a free tier, so you can quickly test them without any cost!</p> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Enable the Live Captions service</p> <p>Once your deployment is up and running, enable the Live Captions service following the official instructions.</p>","tags":["Platform"]},{"location":"docs/tutorials/ai-services/openvidu-live-captions/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/ai-services/openvidu-live-captions/#3-run-a-server-application","title":"3. Run a server application","text":"Node.js Go Ruby Java Python Rust PHP .NET <p>To run this server application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/node\n</code></pre></li> <li>Install dependencies <pre><code>npm install\n</code></pre></li> <li>Run the application <pre><code>npm start\n</code></pre></li> </ol> <p>For more information, check the Node.js tutorial.</p> <p>To run this server application, you need Go  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/go\n</code></pre></li> <li>Run the application <pre><code>go run main.go\n</code></pre></li> </ol> <p>For more information, check the Go tutorial.</p> <p>To run this server application, you need Ruby  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/ruby\n</code></pre></li> <li>Install dependencies <pre><code>bundle install\n</code></pre></li> <li>Run the application <pre><code>ruby app.rb\n</code></pre></li> </ol> <p>For more information, check the Ruby tutorial.</p> <p>To run this server application, you need Java  and Maven  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/java\n</code></pre></li> <li>Run the application <pre><code>mvn spring-boot:run\n</code></pre></li> </ol> <p>For more information, check the Java tutorial.</p> <p>To run this server application, you need Python 3  installed on your device.</p> <ol> <li> <p>Navigate into the server directory</p> <pre><code>cd openvidu-livekit-tutorials/application-server/python\n</code></pre> </li> <li> <p>Create a python virtual environment</p> <pre><code>python -m venv venv\n</code></pre> </li> <li> <p>Activate the virtual environment</p>  Windows macOS Linux <pre><code>.\\venv\\Scripts\\activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> </li> <li> <p>Install dependencies</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the application</p> <pre><code>python app.py\n</code></pre> </li> </ol> <p>For more information, check the Python tutorial.</p> <p>To run this server application, you need Rust  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/rust\n</code></pre></li> <li>Run the application <pre><code>cargo run\n</code></pre></li> </ol> <p>For more information, check the Rust tutorial.</p> <p>To run this server application, you need PHP  and Composer  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/php\n</code></pre></li> <li>Install dependencies <pre><code>composer install\n</code></pre></li> <li>Run the application <pre><code>composer start\n</code></pre></li> </ol> <p>Warning</p> <p>LiveKit PHP SDK requires library BCMath . This is available out-of-the-box in PHP for Windows, but a manual installation might be necessary in other OS. Run <code>sudo apt install php-bcmath</code> or <code>sudo yum install php-bcmath</code></p> <p>For more information, check the PHP tutorial.</p> <p>To run this server application, you need .NET  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/dotnet\n</code></pre></li> <li>Run the application <pre><code>dotnet run\n</code></pre></li> </ol> <p>Warning</p> <p>This .NET server application needs the <code>LIVEKIT_API_SECRET</code> env variable to be at least 32 characters long. Make sure to update it here  and in your OpenVidu Server.</p> <p>For more information, check the .NET tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/ai-services/openvidu-live-captions/#4-run-the-client-application","title":"4. Run the client application","text":"<p>To run the client application tutorial, you need an HTTP web server installed on your development computer. A great option is http-server . You can install it via NPM:</p> <pre><code>npm install -g http-server\n</code></pre> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/ai-services/openvidu-live-captions\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>http-server -p 5080 ./src\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p> <p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p>","tags":["Platform"]},{"location":"docs/tutorials/ai-services/openvidu-live-captions/#understanding-the-code","title":"Understanding the code","text":"<p>You can first take a look at the JavaScript client tutorial, as this application shares the same codebase. The only thing added by this tutorial is a new handler for the <code>Room</code>  object to receive transcription messages and display them as live captions in the HTML:</p> app.js<pre><code>room.registerTextStreamHandler(\"lk.transcription\", async (reader, participantInfo) =&gt; { // (1)!\n    const message = await reader.readAll(); // (2)!\n    const isFinal = reader.info.attributes[\"lk.transcription_final\"] === \"true\"; // (3)!\n    const trackId = reader.info.attributes[\"lk.transcribed_track_id\"]; // (4)!\n\n    if (isFinal) {\n      const speaker = participantInfo.identity == room.localParticipant.identity // (5)!\n          ? \"You\" : participantInfo.identity;\n      const timestamp = new Date().toLocaleTimeString();\n      const captionsTextarea = document.getElementById(\"captions\"); // (6)!\n      captionsTextarea.value += `[${timestamp}] ${speaker}: ${message}\\n`;\n      captionsTextarea.scrollTop = captionsTextarea.scrollHeight;\n    }\n  }\n);\n</code></pre> <ol> <li>Use method Room.registerTextStreamHandler  to register a handler on topic <code>lk.transcription</code>. Transcription messages will arrive to this handler.</li> <li>Await each transcription message.</li> <li>Read attribute <code>lk.transcription_final</code> to determine if the transcription message is a final or an interim one. See Final vs Interim transcriptions.</li> <li>You can also read attribute <code>lk.transcribed_track_id</code> to know which specific audio track has been transcribed.</li> <li>Read property <code>participantInfo.identity</code> to get the identity of the participant that originated the transcription event.</li> <li>Build your live caption message as desired and append it to the HTML.</li> </ol> <p>Using method Room.registerTextStreamHandler  we subscribe to topic <code>lk.transcription</code>. All transcription messages will arrive to this handler.</p> <p>You can get the identity of the participant that originated the transcription event from the <code>participantInfo</code> object passed to the handler.</p> <p>Apart from the message itself (which you get by awaiting method <code>reader.readAll()</code>) there are two main attributes in the transcription message (which you can access via <code>reader.info.attributes</code>):</p> <ul> <li><code>lk.transcription_final</code>: Indicates whether the transcription message is final or interim. See Final vs Interim transcriptions for more details.</li> <li><code>lk.transcribed_track_id</code>: The ID of the audio track that has been transcribed. This is useful to know which specific participant's audio track has been transcribed, if necessary.</li> </ul> <p>Once you have all the information about the transcription message, you can build your live caption text as desired and display it in the HTML (in this case, using a simple <code>&lt;textarea&gt;</code> element).</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/","title":"Angular Components Tutorials","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/#angular-components-tutorials","title":"Angular Components Tutorials","text":"Angular Components <p>In the following tutorials you can learn how to use each one of the available Angular Components to build your application UI tailored to your needs:</p> <ul> <li>Custom UI: learn how to customize the UI, changing colors, shapes and add your branding logo.</li> <li>Custom toolbar: learn how to replace the default toolbar with your own.</li> <li>Toolbar buttons: learn how to add custom buttons to the toolbar.</li> <li>Toolbar panel buttons: learn how to add custom panel buttons to the toolbar.</li> <li>Custom layout: learn how to replace the default layout with your own.</li> <li>Custom stream: learn how to replace the default stream with your own.</li> <li>Custom panels: learn how to replace the default panels with your own.</li> <li>Additional panel: learn how to add a new extra panel besides the default ones.</li> <li>Custom chat panel: learn how to replace the default chat panel with your own.</li> <li>Custom activities panel: learn how to replace the default activities panel with your own.</li> <li>Custom participants panel: learn how to replace the default participants panel with your own.</li> <li>Custom participant panel item: learn how to replace the default participants panel item with your own.</li> <li>Custom participant panel item element: learn how to replace the default participant panel item element with your own.</li> <li>Toggle hand: learn how to add extra features to the videoconference.</li> <li>Admin dashboard: learn how to add an admin dashboard to the videoconference.</li> </ul>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-additional-panels/","title":"Additional panels using Angular Components","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-additional-panels/#additional-panels-using-angular-components","title":"Additional panels using Angular Components","text":"<p>Source code </p> <p>The openvidu-additional-panels tutorial demonstrates how to add new panels to the videoconference, providing a more tailored user experience.</p> <p>Adding new videoconference panels is made simple with the AdditionalPanelsDirective, which offers a straightforward way to replace and adapt the PanelComponent to your needs.</p> <p> </p> OpenVidu Components - Additional Panel <p>This tutorial combines the use of the ToolbarAdditionalPanelButtonsDirective and the AdditionalPanelsDirective to add new buttons to the toolbar and new panels to the videoconference. If you want to learn how to add new buttons to the toolbar, you can check the openvidu-toolbar-panel-buttons tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-additional-panels/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-additional-panels/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-additional-panels/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\ngit clone https://github.com/OpenVidu/openvidu-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-additional-panels/#3-run-a-server-application","title":"3. Run a server application","text":"Node.js Go Ruby Java Python Rust PHP .NET <p>To run this server application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/node\n</code></pre></li> <li>Install dependencies <pre><code>npm install\n</code></pre></li> <li>Run the application <pre><code>npm start\n</code></pre></li> </ol> <p>For more information, check the Node.js tutorial.</p> <p>To run this server application, you need Go  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/go\n</code></pre></li> <li>Run the application <pre><code>go run main.go\n</code></pre></li> </ol> <p>For more information, check the Go tutorial.</p> <p>To run this server application, you need Ruby  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/ruby\n</code></pre></li> <li>Install dependencies <pre><code>bundle install\n</code></pre></li> <li>Run the application <pre><code>ruby app.rb\n</code></pre></li> </ol> <p>For more information, check the Ruby tutorial.</p> <p>To run this server application, you need Java  and Maven  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/java\n</code></pre></li> <li>Run the application <pre><code>mvn spring-boot:run\n</code></pre></li> </ol> <p>For more information, check the Java tutorial.</p> <p>To run this server application, you need Python 3  installed on your device.</p> <ol> <li> <p>Navigate into the server directory</p> <pre><code>cd openvidu-livekit-tutorials/application-server/python\n</code></pre> </li> <li> <p>Create a python virtual environment</p> <pre><code>python -m venv venv\n</code></pre> </li> <li> <p>Activate the virtual environment</p>  Windows macOS Linux <pre><code>.\\venv\\Scripts\\activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> </li> <li> <p>Install dependencies</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the application</p> <pre><code>python app.py\n</code></pre> </li> </ol> <p>For more information, check the Python tutorial.</p> <p>To run this server application, you need Rust  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/rust\n</code></pre></li> <li>Run the application <pre><code>cargo run\n</code></pre></li> </ol> <p>For more information, check the Rust tutorial.</p> <p>To run this server application, you need PHP  and Composer  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/php\n</code></pre></li> <li>Install dependencies <pre><code>composer install\n</code></pre></li> <li>Run the application <pre><code>composer start\n</code></pre></li> </ol> <p>Warning</p> <p>LiveKit PHP SDK requires library BCMath . This is available out-of-the-box in PHP for Windows, but a manual installation might be necessary in other OS. Run <code>sudo apt install php-bcmath</code> or <code>sudo yum install php-bcmath</code></p> <p>For more information, check the PHP tutorial.</p> <p>To run this server application, you need .NET  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/dotnet\n</code></pre></li> <li>Run the application <pre><code>dotnet run\n</code></pre></li> </ol> <p>Warning</p> <p>This .NET server application needs the <code>LIVEKIT_API_SECRET</code> env variable to be at least 32 characters long. Make sure to update it here  and in your OpenVidu Server.</p> <p>For more information, check the .NET tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-additional-panels/#4-run-the-openvidu-additional-panels-tutorial","title":"4. Run the openvidu-additional-panels tutorial","text":"<p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>  cd openvidu-tutorials/openvidu-components/openvidu-additional-panels\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>  npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>  npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>.</p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-additional-panels/#understanding-the-code","title":"Understanding the code","text":"<p>This tutorial is an Angular project generated with Angular CLI tool. Therefore, you will see many configuration files and other components that are not the primary focus of this tutorial. We will concentrate on the following files in the <code>src</code> directory:</p> <ul> <li><code>main.ts</code>: This file defines the root application component. It imports the <code>OpenViduComponentsModule</code>, where we configure the OpenVidu Components Angular library.</li> <li><code>app/app.component.ts</code>: This file defines the AppComponent, the primary and sole component of the application. It is responsible for requesting the OpenVidu token and passing it to the videoconference component, facilitating the connection to the OpenVidu Room.</li> <li><code>styles.scss</code>: This file defines the global styles of the application. Here, you can customize the UI of the OpenVidu Components Angular library.</li> </ul> <p>To use OpenVidu Components Angular in your application, you need to install the library and import the <code>OpenViduComponentsModule</code> in your Angular module. Let's see how to do this:</p> <ol> <li> <p>Create an Angular Project (version 17 or higher)</p> <p>To begin, you will need to create a new Angular project if you haven't already. Ensure you have Node.js and the Angular CLI installed. Then, run the following command to create a new Angular project:</p> <pre><code>ng new your-project-name\n</code></pre> <p>Replace <code>your-project-name</code> with the desired name for your project.</p> </li> <li> <p>Add Angular Material to your project</p> <p>OpenVidu Components Angular needs Angular Material, which provides a range of UI components. To add Angular Material to your project, navigate to your project directory and run:</p> <pre><code>ng add @angular/material\n</code></pre> </li> <li> <p>Install OpenVidu Components Angular</p> <p>With your Angular project set up, it's time to add videoconferencing capabilities with OpenVidu Components Angular. Install the library using npm:</p> <pre><code>npm install openvidu-components-angular\n</code></pre> </li> <li> <p>Import and use OpenVidu Components Angular</p> <p>To use OpenVidu Components Angular in your application, you need to:</p> <ol> <li>Import the <code>OpenViduComponentsModule</code> in your Angular application.</li> <li>Configure the module with the <code>OpenViduComponentsConfig</code> object.</li> <li>Add the component to your template file.</li> <li>Assign the OpenVidu token and LiveKit URL to the component.</li> <li>Customize the appearance of the components using CSS variables.</li> </ol> </li> </ol> main.tsapp.component.tsstyles.scss <p>In your <code>main.ts</code> application file, import the it and configure it as follows:</p> <pre><code>// Other imports ...\n\nimport { OpenViduComponentsModule, OpenViduComponentsConfig } from 'openvidu-components-angular';\n\nconst config: OpenViduComponentsConfig = {\n    production: true,\n};\n\nbootstrapApplication(AppComponent, {\n    providers: [\n        importProvidersFrom(\n            OpenViduComponentsModule.forRoot(config)\n            // Other imports ...\n        ),\n        provideAnimations(),\n    ],\n}).catch((err) =&gt; console.error(err));\n</code></pre> <p>Use the <code>ov-videoconference</code> component to create a videoconference. This component requires a token to connect to the OpenVidu Room. The <code>AppComponent</code> class is responsible for requesting the token and passing it to the <code>ov-videoconference</code> component.</p> <pre><code>import { OpenViduComponentsModule } from 'openvidu-components-angular';\n\n@Component({\n  selector: 'app-root',\n  template:`\n    &lt;!-- OpenVidu Video Conference Component --&gt;\n    &lt;ov-videoconference\n      [token]=\"token\"\n      [livekitUrl]=\"LIVEKIT_URL\"\n      (onTokenRequested)=\"onTokenRequested($event)\"\n    &gt;\n      &lt;!-- Additional Toolbar Buttons --&gt;\n      &lt;div *ovToolbarAdditionalPanelButtons style=\"text-align: center;\"&gt;\n        &lt;button mat-icon-button (click)=\"toggleMyPanel('my-panel1')\"&gt;\n          &lt;mat-icon&gt;360&lt;/mat-icon&gt;\n        &lt;/button&gt;\n        &lt;button mat-icon-button (click)=\"toggleMyPanel('my-panel2')\"&gt;\n          &lt;mat-icon&gt;star&lt;/mat-icon&gt;\n        &lt;/button&gt;\n      &lt;/div&gt;\n\n      &lt;!-- Additional Panels --&gt;\n      &lt;div *ovAdditionalPanels id=\"my-panels\"&gt;\n        @if (showExternalPanel) {\n        &lt;div id=\"my-panel1\"&gt;\n          &lt;h2&gt;NEW PANEL 1&lt;/h2&gt;\n          &lt;p&gt;This is my new additional panel&lt;/p&gt;\n        &lt;/div&gt;\n        } @if (showExternalPanel2) {\n        &lt;div id=\"my-panel2\"&gt;\n          &lt;h2&gt;NEW PANEL 2&lt;/h2&gt;\n          &lt;p&gt;This is another new panel&lt;/p&gt;\n        &lt;/div&gt;\n        }\n      &lt;/div&gt;\n    &lt;/ov-videoconference&gt;\n  `,\n  styles: [''],\n  standalone: true,\n  imports: [OpenViduComponentsModule, MatIconButton, MatIcon],\n})\nexport class AppComponent {\n  // For local development, leave these variables empty\n  // For production, configure them with correct URLs depending on your deployment\n\n  APPLICATION_SERVER_URL = '';  // (1)!\n  LIVEKIT_URL = ''; // (2)!\n\n  // The name of the room to join.\n  roomName = 'openvidu-additional-panels';  // (3)!\n\n  // The token used to join the room.\n  token!: string; // (4)!\n\n  // Flags to control the visibility of external panels\n  showExternalPanel: boolean = false; // (5)!\n  showExternalPanel2: boolean = false; // (6)!\n\n  constructor(private httpClient: HttpClient) {\n    this.configureUrls();\n  }\n\n  private configureUrls() {\n    // If APPLICATION_SERVER_URL is not configured, use default value from local development\n    if (!this.APPLICATION_SERVER_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.APPLICATION_SERVER_URL = 'http://localhost:6080/';\n      } else {\n        this.APPLICATION_SERVER_URL =\n          'https://' + window.location.hostname + ':6443/';\n      }\n    }\n\n    // If LIVEKIT_URL is not configured, use default value from local development\n    if (!this.LIVEKIT_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.LIVEKIT_URL = 'ws://localhost:7880/';\n      } else {\n        this.LIVEKIT_URL = 'wss://' + window.location.hostname + ':7443/';\n      }\n    }\n  }\n\n  ngOnInit() {\n    this.subscribeToPanelToggling(); // (7)!\n  }\n\n  // Requests a token to join the room with the given participant name.\n  async onTokenRequested(participantName: string) { // (8)!\n    const { token } = await this.getToken(this.roomName, participantName);\n    this.token = token;\n  }\n\n  // Subscribe to panel toggling events\n  subscribeToPanelToggling() {\n    this.panelService.panelStatusObs.subscribe((ev: PanelStatusInfo) =&gt; { // (9)!\n      this.showExternalPanel = ev.isOpened &amp;&amp; ev.panelType === 'my-panel1';\n      this.showExternalPanel2 = ev.isOpened &amp;&amp; ev.panelType === 'my-panel2';\n    });\n  }\n\n  // Toggle the visibility of external panels\n  toggleMyPanel(type: string) { // (10)!\n    this.panelService.togglePanel(type);\n  }\n\n  // Retrieves a token to join the room with the given name and participant name.\n  getToken(roomName: string, participantName: string): Promise&lt;any&gt; { // (11)!\n    // Requesting token to the server application\n  }\n}\n</code></pre> <ol> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect.</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>showExternalPanel</code>: Flag to control the visibility of the first external panel.</li> <li><code>showExternalPanel2</code>: Flag to control the visibility of the second external panel.</li> <li><code>subscribeToPanelToggling</code> method that subscribes to panel toggling events.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>panelService.panelStatusObs</code> observable that listens to panel toggling events.</li> <li><code>toggleMyPanel</code> method that toggles the visibility of external panels.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ol> <p>The <code>app.component.ts</code> file declares the following properties and methods:</p> <ul> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect.</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>showExternalPanel</code>: Flag to control the visibility of the first external panel.</li> <li><code>showExternalPanel2</code>: Flag to control the visibility of the second external panel.</li> <li><code>subscribeToPanelToggling</code> method that subscribes to panel toggling events.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>panelService.panelStatusObs</code> observable that listens to panel toggling events.</li> <li><code>toggleMyPanel</code> method that toggles the visibility of external panels.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ul> <p>Configure the URLs</p> <p>When running OpenVidu locally, leave <code>APPLICATION_SERVER_URL</code> and <code>LIVEKIT_URL</code> variables empty. The function <code>configureUrls()</code> will automatically configure them with default values. However, for other deployment type, you should configure these variables with the correct URLs depending on your deployment.</p> <p>The OpenVidu Components Angular library provides a set of CSS variables that you can use to customize the appearance of the components. You can define these variables in your application's global styles file (e.g. <code>styles.scss</code>).</p> <pre><code>:root {\n    /* Basic colors */\n    --ov-background-color: #303030; // Background color\n    --ov-surface-color: #ffffff; // Surfaces colors (panels, dialogs)\n\n    /* Text colors */\n    --ov-text-primary-color: #ffffff; // Text color over primary background\n    --ov-text-surface-color: #1d1d1d; // Text color over surface background\n\n    /* Action colors */\n    --ov-primary-action-color: #273235; // Primary color for buttons, etc.\n    --ov-secondary-action-color: #f1f1f1; // Secondary color for buttons, etc.\n    --ov-accent-action-color: #0089ab; // Color for highlighted elements\n\n    /* Status colors */\n    --ov-error-color: #eb5144; // Error color\n    --ov-warn-color: #ffba53; // Warning color\n\n    /* Radius */\n    --ov-toolbar-buttons-radius: 50%; // Radius for toolbar buttons\n    --ov-leave-button-radius: 10px; // Radius for leave button\n    --ov-video-radius: 5px; // Radius for videos\n    --ov-surface-radius: 5px; // Radius for surfaces\n}\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-additional-panels/#adding-new-panels","title":"Adding new panels","text":"<p>The <code>*ovPanel</code> directive is used to replace the default videoconference panels with a custom ones. In the <code>app.component.ts</code> file, you can see the following code snippet:</p> <pre><code>@Component({\n    selector: 'app-root',\n    template: `\n        &lt;!-- OpenVidu Video Conference Component --&gt;\n        &lt;ov-videoconference\n            [token]=\"token\"\n            [livekitUrl]=\"LIVEKIT_URL\"\n            [toolbarDisplayRoomName]=\"false\"\n            (onTokenRequested)=\"onTokenRequested($event)\"\n        &gt;\n            &lt;!-- Additional Toolbar Buttons --&gt;\n            &lt;div *ovToolbarAdditionalPanelButtons style=\"text-align: center;\"&gt;\n                &lt;button mat-icon-button (click)=\"toggleMyPanel('my-panel1')\"&gt;\n                    &lt;mat-icon&gt;360&lt;/mat-icon&gt;\n                &lt;/button&gt;\n                &lt;button mat-icon-button (click)=\"toggleMyPanel('my-panel2')\"&gt;\n                    &lt;mat-icon&gt;star&lt;/mat-icon&gt;\n                &lt;/button&gt;\n            &lt;/div&gt;\n\n            &lt;!-- Additional Panels --&gt;\n            &lt;div *ovAdditionalPanels id=\"my-panels\"&gt;\n                @if (showExternalPanel) {\n                &lt;div id=\"my-panel1\"&gt;\n                    &lt;h2&gt;NEW PANEL 1&lt;/h2&gt;\n                    &lt;p&gt;This is my new additional panel&lt;/p&gt;\n                &lt;/div&gt;\n                } @if (showExternalPanel2) {\n                &lt;div id=\"my-panel2\"&gt;\n                    &lt;h2&gt;NEW PANEL 2&lt;/h2&gt;\n                    &lt;p&gt;This is another new panel&lt;/p&gt;\n                &lt;/div&gt;\n                }\n            &lt;/div&gt;\n        &lt;/ov-videoconference&gt;\n    `,\n    styles: [''],\n    standalone: true,\n    imports: [OpenViduComponentsModule, MatIconButton, MatIcon],\n})\nexport class AppComponent {\n    // ...\n}\n</code></pre> <p>In this code snippet, the <code>*ovToolbarAdditionalPanelButtons</code> directive is used to add new buttons to the toolbar and the <code>*ovAdditionalPanels</code> directive is used to add new panels to the videoconference.</p> <p>When the user clicks on the buttons, the <code>toggleMyPanel</code> method is called to toggle the visibility of the new panels. These new panels are handled by the <code>showExternalPanel</code> and <code>showExternalPanel2</code> flags.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-admin-dashboard/","title":"Create admin dashboard using Angular Components","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-admin-dashboard/#create-admin-dashboard-using-angular-components","title":"Create admin dashboard using Angular Components","text":"<p>Source code </p> <p>The openvidu-admin-dashboard tutorial demonstrates how to create an admin dashboard to manage the recordings of a videoconference using the OpenVidu Components Angular library.</p> <p> </p> OpenVidu Components - Admin Login <p> </p> OpenVidu Components - Admin Dashboard","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-admin-dashboard/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-admin-dashboard/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-admin-dashboard/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\ngit clone https://github.com/OpenVidu/openvidu-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-admin-dashboard/#3-run-a-server-application","title":"3. Run a server application","text":"Node.js Go Ruby Java Python Rust PHP .NET <p>To run this server application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/node\n</code></pre></li> <li>Install dependencies <pre><code>npm install\n</code></pre></li> <li>Run the application <pre><code>npm start\n</code></pre></li> </ol> <p>For more information, check the Node.js tutorial.</p> <p>To run this server application, you need Go  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/go\n</code></pre></li> <li>Run the application <pre><code>go run main.go\n</code></pre></li> </ol> <p>For more information, check the Go tutorial.</p> <p>To run this server application, you need Ruby  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/ruby\n</code></pre></li> <li>Install dependencies <pre><code>bundle install\n</code></pre></li> <li>Run the application <pre><code>ruby app.rb\n</code></pre></li> </ol> <p>For more information, check the Ruby tutorial.</p> <p>To run this server application, you need Java  and Maven  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/java\n</code></pre></li> <li>Run the application <pre><code>mvn spring-boot:run\n</code></pre></li> </ol> <p>For more information, check the Java tutorial.</p> <p>To run this server application, you need Python 3  installed on your device.</p> <ol> <li> <p>Navigate into the server directory</p> <pre><code>cd openvidu-livekit-tutorials/application-server/python\n</code></pre> </li> <li> <p>Create a python virtual environment</p> <pre><code>python -m venv venv\n</code></pre> </li> <li> <p>Activate the virtual environment</p>  Windows macOS Linux <pre><code>.\\venv\\Scripts\\activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> </li> <li> <p>Install dependencies</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the application</p> <pre><code>python app.py\n</code></pre> </li> </ol> <p>For more information, check the Python tutorial.</p> <p>To run this server application, you need Rust  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/rust\n</code></pre></li> <li>Run the application <pre><code>cargo run\n</code></pre></li> </ol> <p>For more information, check the Rust tutorial.</p> <p>To run this server application, you need PHP  and Composer  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/php\n</code></pre></li> <li>Install dependencies <pre><code>composer install\n</code></pre></li> <li>Run the application <pre><code>composer start\n</code></pre></li> </ol> <p>Warning</p> <p>LiveKit PHP SDK requires library BCMath . This is available out-of-the-box in PHP for Windows, but a manual installation might be necessary in other OS. Run <code>sudo apt install php-bcmath</code> or <code>sudo yum install php-bcmath</code></p> <p>For more information, check the PHP tutorial.</p> <p>To run this server application, you need .NET  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/dotnet\n</code></pre></li> <li>Run the application <pre><code>dotnet run\n</code></pre></li> </ol> <p>Warning</p> <p>This .NET server application needs the <code>LIVEKIT_API_SECRET</code> env variable to be at least 32 characters long. Make sure to update it here  and in your OpenVidu Server.</p> <p>For more information, check the .NET tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-admin-dashboard/#4-run-the-openvidu-admin-dashboard-tutorial","title":"4. Run the openvidu-admin-dashboard tutorial","text":"<p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>  cd openvidu-tutorials/openvidu-components/openvidu-admin-dashboard\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>  npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>  npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>.</p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-admin-dashboard/#understanding-the-code","title":"Understanding the code","text":"<p>This tutorial is an Angular project generated with Angular CLI tool. Therefore, you will see many configuration files and other components that are not the primary focus of this tutorial. We will concentrate on the following files in the <code>src</code> directory:</p> <ul> <li><code>main.ts</code>: This file defines the root application component. It imports the <code>OpenViduComponentsModule</code>, where we configure the OpenVidu Components Angular library.</li> <li><code>app/app.component.ts</code>: This file defines the AppComponent, the primary and sole component of the application. It is responsible for requesting the OpenVidu token and passing it to the videoconference component, facilitating the connection to the OpenVidu Room.</li> <li><code>styles.scss</code>: This file defines the global styles of the application. Here, you can customize the UI of the OpenVidu Components Angular library.</li> </ul> <p>To use OpenVidu Components Angular in your application, you need to install the library and import the <code>OpenViduComponentsModule</code> in your Angular module. Let's see how to do this:</p> <ol> <li> <p>Create an Angular Project (version 17 or higher)</p> <p>To begin, you will need to create a new Angular project if you haven't already. Ensure you have Node.js and the Angular CLI installed. Then, run the following command to create a new Angular project:</p> <pre><code>ng new your-project-name\n</code></pre> <p>Replace <code>your-project-name</code> with the desired name for your project.</p> </li> <li> <p>Add Angular Material to your project</p> <p>OpenVidu Components Angular needs Angular Material, which provides a range of UI components. To add Angular Material to your project, navigate to your project directory and run:</p> <pre><code>ng add @angular/material\n</code></pre> </li> <li> <p>Install OpenVidu Components Angular</p> <p>With your Angular project set up, it's time to add videoconferencing capabilities with OpenVidu Components Angular. Install the library using npm:</p> <pre><code>npm install openvidu-components-angular\n</code></pre> </li> <li> <p>Import and use OpenVidu Components Angular</p> <p>To use OpenVidu Components Angular in your application, you need to:</p> <ol> <li>Import the <code>OpenViduComponentsModule</code> in your Angular application.</li> <li>Configure the module with the <code>OpenViduComponentsConfig</code> object.</li> <li>Add the component to your template file.</li> <li>Assign the OpenVidu token and LiveKit URL to the component.</li> <li>Customize the appearance of the components using CSS variables.</li> </ol> </li> </ol> main.tsapp.component.tsstyles.scss <p>In your <code>main.ts</code> application file, import the it and configure it as follows:</p> <pre><code>// Other imports ...\n\nimport { OpenViduComponentsModule, OpenViduComponentsConfig } from 'openvidu-components-angular';\n\nconst config: OpenViduComponentsConfig = {\n    production: true,\n};\n\nbootstrapApplication(AppComponent, {\n    providers: [\n        importProvidersFrom(\n            OpenViduComponentsModule.forRoot(config)\n            // Other imports ...\n        ),\n        provideAnimations(),\n    ],\n}).catch((err) =&gt; console.error(err));\n</code></pre> <p>Use the <code>ov-admin-login</code> component to create a login form and the <code>ov-admin-dashboard</code> component to create the admin dashboard.</p> <pre><code>import { OpenViduComponentsModule } from 'openvidu-components-angular';\n\n@Component({\n  selector: 'app-root',\n  template:`\n    @if (logged) {\n    &lt;ov-admin-dashboard\n      [recordingsList]=\"recordings()\"\n      (onLogoutRequested)=\"onLogoutRequested()\"\n      (onRefreshRecordingsRequested)=\"onRefreshRecordingsRequested()\"\n      (onLoadMoreRecordingsRequested)=\"onLoadMoreRecordingsRequested()\"\n      (onRecordingDeleteRequested)=\"onRecordingDeleteRequested($event)\"\n    &gt;&lt;/ov-admin-dashboard&gt;\n    } @else {\n    &lt;ov-admin-login (onLoginRequested)=\"onLoginRequested($event)\"&gt;\n    &lt;/ov-admin-login&gt;\n    }\n  `,\n  styles: [''],\n  standalone: true,\n  imports: [OpenViduComponentsModule],\n})\nexport class AppComponent {\n\n  roomName = 'openvidu-admin-dashboard'; // (1)!\n\n  logged: boolean = false; // (2)!\n\n  // Recordings list to show in the dashboard\n  // This is a dummy list, you should replace it with your own list from the server\n  recordings: WritableSignal&lt;RecordingInfo[]&gt; = signal([ // (3)!\n    {\n      id: 'recording1',\n      roomName: this.roomName,\n      roomId: 'roomId1',\n      outputMode: RecordingOutputMode.COMPOSED,\n      status: RecordingStatus.READY,\n      filename: 'sampleRecording.mp4',\n      startedAt: new Date().getTime(),\n      endedAt: new Date().getTime(),\n      duration: 0,\n      size: 100,\n      location: 'http://localhost:8080/recordings/recording1',\n    }\n  ]);\n\n  constructor() {}\n\n  onLoginRequested(credentials: { username: string; password: string }) { // (4)!\n    console.log(`Login button clicked ${credentials}`);\n    /**\n     * WARNING! This code is developed for didactic purposes only.\n     * The authentication process should be done in the server side.\n     **/\n    this.logged = true;\n  }\n\n  onLogoutRequested() { // (5)!\n    console.log('Logout button clicked');\n    /**\n     * WARNING! This code is developed for didactic purposes only.\n     * The authentication process should be done in the server side.\n     **/\n    this.logged = false;\n  }\n\n  onRefreshRecordingsRequested() { // (6)!\n    console.log('Refresh recording clicked');\n    /**\n     * WARNING! This code is developed for didactic purposes only.\n     * The authentication process should be done in the server side.\n     **/\n    // Getting the recordings from the server\n    this.recordings.update(() =&gt; [\n      {\n        id: 'recording1',\n        roomName: this.title,\n        roomId: 'roomId1',\n        outputMode: RecordingOutputMode.COMPOSED,\n        status: RecordingStatus.READY,\n        filename: 'sampleRecording1.mp4',\n        startedAt: new Date().getTime(),\n        endedAt: new Date().getTime(),\n        duration: 0,\n        size: 100,\n        location: 'http://localhost:8080/recordings/recording1',\n      },\n    ]);\n  }\n\n  onLoadMoreRecordingsRequested() { // (7)!\n    console.log('Load more recordings clicked');\n  }\n\n  onRecordingDeleteRequested(recording: RecordingDeleteRequestedEvent) { // (8)!\n    console.log(`Delete recording clicked ${recording.recordingId}`);\n    /**\n     * WARNING! This code is developed for didactic purposes only.\n     * The authentication process should be done in the server side.\n     **/\n    // Deleting the recording from the server\n    this.recordings.update((recordings) =&gt;\n      recordings.filter((rec) =&gt; rec.id !== recording.recordingId)\n    );\n\n    console.log(this.recordings());\n  }\n}\n</code></pre> <ol> <li><code>roomName</code>: OpenVidu Room name.</li> <li><code>logged</code>: Boolean that indicates if the user is logged in.</li> <li><code>recordings</code>: Dummy list of recordings to show in the dashboard. You should replace it with your own list from the server from the server.</li> <li><code>onLoginRequested</code> method that fires when the login button is clicked.</li> <li><code>onLogoutRequested</code> method that fires when the logout button is clicked.</li> <li><code>onRefreshRecordingsRequested</code> method that fires when the refresh recordings button is clicked.</li> <li><code>onLoadMoreRecordingsRequested</code> method that fires when the load more recordings button is clicked.</li> <li><code>onRecordingDeleteRequested</code> method that fires when the delete recording button is clicked.</li> </ol> <p>The <code>app.component.ts</code> file declares the following properties and methods:</p> <ul> <li><code>roomName</code>: OpenVidu Room name.</li> <li><code>logged</code>: Boolean that indicates if the user is logged in.</li> <li><code>recordings</code>: Dummy list of recordings to show in the dashboard. You should replace it with your own list from the server from the server.</li> <li><code>onLoginRequested</code> method that fires when the login button is clicked.</li> <li><code>onLogoutRequested</code> method that fires when the logout button is clicked.</li> <li><code>onRefreshRecordingsRequested</code> method that fires when the refresh recordings button is clicked.</li> <li><code>onLoadMoreRecordingsRequested</code> method that fires when the load more recordings button is clicked.</li> <li><code>onRecordingDeleteRequested</code> method that fires when the delete recording button is clicked.</li> </ul> <p>Configure the URLs</p> <p>When running OpenVidu locally, leave <code>APPLICATION_SERVER_URL</code> and <code>LIVEKIT_URL</code> variables empty. The function <code>configureUrls()</code> will automatically configure them with default values. However, for other deployment type, you should configure these variables with the correct URLs depending on your deployment.</p> <p>The OpenVidu Components Angular library provides a set of CSS variables that you can use to customize the appearance of the components. You can define these variables in your application's global styles file (e.g. <code>styles.scss</code>).</p> <pre><code>:root {\n    /* Basic colors */\n    --ov-background-color: #303030; // Background color\n    --ov-surface-color: #ffffff; // Surfaces colors (panels, dialogs)\n\n    /* Text colors */\n    --ov-text-primary-color: #ffffff; // Text color over primary background\n    --ov-text-surface-color: #1d1d1d; // Text color over surface background\n\n    /* Action colors */\n    --ov-primary-action-color: #273235; // Primary color for buttons, etc.\n    --ov-secondary-action-color: #f1f1f1; // Secondary color for buttons, etc.\n    --ov-accent-action-color: #0089ab; // Color for highlighted elements\n\n    /* Status colors */\n    --ov-error-color: #eb5144; // Error color\n    --ov-warn-color: #ffba53; // Warning color\n\n    /* Radius */\n    --ov-toolbar-buttons-radius: 50%; // Radius for toolbar buttons\n    --ov-leave-button-radius: 10px; // Radius for leave button\n    --ov-video-radius: 5px; // Radius for videos\n    --ov-surface-radius: 5px; // Radius for surfaces\n}\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-activities-panel/","title":"Custom activities panel using Angular Components","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-activities-panel/#custom-activities-panel-using-angular-components","title":"Custom activities panel using Angular Components","text":"<p>Source code </p> <p>The openvidu-custom-activities-panel tutorial demonstrates how to customize the activities panel, providing a more tailored user experience.</p> <p>Replacing the default activities panel is made simple with the ActivitiesPanelDirective, which offers a straightforward way to replace and adapt the ActivitiesPanelComponent to your needs.</p> <p> </p> OpenVidu Components - Custom Activities Panel","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-activities-panel/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-activities-panel/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-activities-panel/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\ngit clone https://github.com/OpenVidu/openvidu-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-activities-panel/#3-run-a-server-application","title":"3. Run a server application","text":"Node.js Go Ruby Java Python Rust PHP .NET <p>To run this server application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/node\n</code></pre></li> <li>Install dependencies <pre><code>npm install\n</code></pre></li> <li>Run the application <pre><code>npm start\n</code></pre></li> </ol> <p>For more information, check the Node.js tutorial.</p> <p>To run this server application, you need Go  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/go\n</code></pre></li> <li>Run the application <pre><code>go run main.go\n</code></pre></li> </ol> <p>For more information, check the Go tutorial.</p> <p>To run this server application, you need Ruby  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/ruby\n</code></pre></li> <li>Install dependencies <pre><code>bundle install\n</code></pre></li> <li>Run the application <pre><code>ruby app.rb\n</code></pre></li> </ol> <p>For more information, check the Ruby tutorial.</p> <p>To run this server application, you need Java  and Maven  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/java\n</code></pre></li> <li>Run the application <pre><code>mvn spring-boot:run\n</code></pre></li> </ol> <p>For more information, check the Java tutorial.</p> <p>To run this server application, you need Python 3  installed on your device.</p> <ol> <li> <p>Navigate into the server directory</p> <pre><code>cd openvidu-livekit-tutorials/application-server/python\n</code></pre> </li> <li> <p>Create a python virtual environment</p> <pre><code>python -m venv venv\n</code></pre> </li> <li> <p>Activate the virtual environment</p>  Windows macOS Linux <pre><code>.\\venv\\Scripts\\activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> </li> <li> <p>Install dependencies</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the application</p> <pre><code>python app.py\n</code></pre> </li> </ol> <p>For more information, check the Python tutorial.</p> <p>To run this server application, you need Rust  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/rust\n</code></pre></li> <li>Run the application <pre><code>cargo run\n</code></pre></li> </ol> <p>For more information, check the Rust tutorial.</p> <p>To run this server application, you need PHP  and Composer  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/php\n</code></pre></li> <li>Install dependencies <pre><code>composer install\n</code></pre></li> <li>Run the application <pre><code>composer start\n</code></pre></li> </ol> <p>Warning</p> <p>LiveKit PHP SDK requires library BCMath . This is available out-of-the-box in PHP for Windows, but a manual installation might be necessary in other OS. Run <code>sudo apt install php-bcmath</code> or <code>sudo yum install php-bcmath</code></p> <p>For more information, check the PHP tutorial.</p> <p>To run this server application, you need .NET  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/dotnet\n</code></pre></li> <li>Run the application <pre><code>dotnet run\n</code></pre></li> </ol> <p>Warning</p> <p>This .NET server application needs the <code>LIVEKIT_API_SECRET</code> env variable to be at least 32 characters long. Make sure to update it here  and in your OpenVidu Server.</p> <p>For more information, check the .NET tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-activities-panel/#4-run-the-openvidu-custom-activities-panel-tutorial","title":"4. Run the openvidu-custom-activities-panel tutorial","text":"<p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>  cd openvidu-tutorials/openvidu-components/openvidu-custom-activities-panel\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>  npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>  npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>.</p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-activities-panel/#understanding-the-code","title":"Understanding the code","text":"<p>This tutorial is an Angular project generated with Angular CLI tool. Therefore, you will see many configuration files and other components that are not the primary focus of this tutorial. We will concentrate on the following files in the <code>src</code> directory:</p> <ul> <li><code>main.ts</code>: This file defines the root application component. It imports the <code>OpenViduComponentsModule</code>, where we configure the OpenVidu Components Angular library.</li> <li><code>app/app.component.ts</code>: This file defines the AppComponent, the primary and sole component of the application. It is responsible for requesting the OpenVidu token and passing it to the videoconference component, facilitating the connection to the OpenVidu Room.</li> <li><code>styles.scss</code>: This file defines the global styles of the application. Here, you can customize the UI of the OpenVidu Components Angular library.</li> </ul> <p>To use OpenVidu Components Angular in your application, you need to install the library and import the <code>OpenViduComponentsModule</code> in your Angular module. Let's see how to do this:</p> <ol> <li> <p>Create an Angular Project (version 17 or higher)</p> <p>To begin, you will need to create a new Angular project if you haven't already. Ensure you have Node.js and the Angular CLI installed. Then, run the following command to create a new Angular project:</p> <pre><code>ng new your-project-name\n</code></pre> <p>Replace <code>your-project-name</code> with the desired name for your project.</p> </li> <li> <p>Add Angular Material to your project</p> <p>OpenVidu Components Angular needs Angular Material, which provides a range of UI components. To add Angular Material to your project, navigate to your project directory and run:</p> <pre><code>ng add @angular/material\n</code></pre> </li> <li> <p>Install OpenVidu Components Angular</p> <p>With your Angular project set up, it's time to add videoconferencing capabilities with OpenVidu Components Angular. Install the library using npm:</p> <pre><code>npm install openvidu-components-angular\n</code></pre> </li> <li> <p>Import and use OpenVidu Components Angular</p> <p>To use OpenVidu Components Angular in your application, you need to:</p> <ol> <li>Import the <code>OpenViduComponentsModule</code> in your Angular application.</li> <li>Configure the module with the <code>OpenViduComponentsConfig</code> object.</li> <li>Add the component to your template file.</li> <li>Assign the OpenVidu token and LiveKit URL to the component.</li> <li>Customize the appearance of the components using CSS variables.</li> </ol> </li> </ol> main.tsapp.component.tsstyles.scss <p>In your <code>main.ts</code> application file, import the it and configure it as follows:</p> <pre><code>// Other imports ...\n\nimport { OpenViduComponentsModule, OpenViduComponentsConfig } from 'openvidu-components-angular';\n\nconst config: OpenViduComponentsConfig = {\n    production: true,\n};\n\nbootstrapApplication(AppComponent, {\n    providers: [\n        importProvidersFrom(\n            OpenViduComponentsModule.forRoot(config)\n            // Other imports ...\n        ),\n        provideAnimations(),\n    ],\n}).catch((err) =&gt; console.error(err));\n</code></pre> <p>Use the <code>ov-videoconference</code> component to create a videoconference. This component requires a token to connect to the OpenVidu Room. The <code>AppComponent</code> class is responsible for requesting the token and passing it to the <code>ov-videoconference</code> component.</p> <pre><code>import { OpenViduComponentsModule } from 'openvidu-components-angular';\n\n@Component({\n  selector: 'app-root',\n  template:`\n    &lt;!-- OpenVidu Video Conference Component --&gt;\n    &lt;ov-videoconference\n        [token]=\"token\"\n        [livekitUrl]=\"LIVEKIT_URL\"\n        (onTokenRequested)=\"onTokenRequested($event)\"\n    &gt;\n        &lt;!-- Custom activities panel --&gt;\n        &lt;div *ovActivitiesPanel id=\"my-panel\"&gt;\n            &lt;h3&gt;ACTIVITIES&lt;/h3&gt;\n            &lt;div&gt;CUSTOM ACTIVITIES&lt;/div&gt;\n        &lt;/div&gt;\n    &lt;/ov-videoconference&gt;\n  `,\n  styles: [''],\n  standalone: true,\n  imports: [OpenViduComponentsModule],\n})\nexport class AppComponent {\n  // For local development, leave these variables empty\n  // For production, configure them with correct URLs depending on your deployment\n\n  APPLICATION_SERVER_URL = '';  // (1)!\n  LIVEKIT_URL = ''; // (2)!\n\n  // The name of the room to join.\n  roomName = 'openvidu-custom-activities-panel';  // (3)!\n\n  // The token used to join the room.\n  token!: string; // (4)!\n\n  constructor(private httpClient: HttpClient) {\n    this.configureUrls();\n  }\n\n  private configureUrls() {\n    // If APPLICATION_SERVER_URL is not configured, use default value from local development\n    if (!this.APPLICATION_SERVER_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.APPLICATION_SERVER_URL = 'http://localhost:6080/';\n      } else {\n        this.APPLICATION_SERVER_URL =\n          'https://' + window.location.hostname + ':6443/';\n      }\n    }\n\n    // If LIVEKIT_URL is not configured, use default value from local development\n    if (!this.LIVEKIT_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.LIVEKIT_URL = 'ws://localhost:7880/';\n      } else {\n        this.LIVEKIT_URL = 'wss://' + window.location.hostname + ':7443/';\n      }\n    }\n  }\n\n  // Requests a token to join the room with the given participant name.\n  async onTokenRequested(participantName: string) { // (5)!\n    const { token } = await this.getToken(this.roomName, participantName);\n    this.token = token;\n  }\n\n  // Retrieves a token to join the room with the given name and participant name.\n  getToken(roomName: string, participantName: string): Promise&lt;any&gt; { // (6)!\n    // Requesting token to the server application\n  }\n}\n</code></pre> <ol> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect.</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ol> <p>The <code>app.component.ts</code> file declares the following properties and methods:</p> <ul> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect.</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ul> <p>Configure the URLs</p> <p>When running OpenVidu locally, leave <code>APPLICATION_SERVER_URL</code> and <code>LIVEKIT_URL</code> variables empty. The function <code>configureUrls()</code> will automatically configure them with default values. However, for other deployment type, you should configure these variables with the correct URLs depending on your deployment.</p> <p>The OpenVidu Components Angular library provides a set of CSS variables that you can use to customize the appearance of the components. You can define these variables in your application's global styles file (e.g. <code>styles.scss</code>).</p> <pre><code>:root {\n    /* Basic colors */\n    --ov-background-color: #303030; // Background color\n    --ov-surface-color: #ffffff; // Surfaces colors (panels, dialogs)\n\n    /* Text colors */\n    --ov-text-primary-color: #ffffff; // Text color over primary background\n    --ov-text-surface-color: #1d1d1d; // Text color over surface background\n\n    /* Action colors */\n    --ov-primary-action-color: #273235; // Primary color for buttons, etc.\n    --ov-secondary-action-color: #f1f1f1; // Secondary color for buttons, etc.\n    --ov-accent-action-color: #0089ab; // Color for highlighted elements\n\n    /* Status colors */\n    --ov-error-color: #eb5144; // Error color\n    --ov-warn-color: #ffba53; // Warning color\n\n    /* Radius */\n    --ov-toolbar-buttons-radius: 50%; // Radius for toolbar buttons\n    --ov-leave-button-radius: 10px; // Radius for leave button\n    --ov-video-radius: 5px; // Radius for videos\n    --ov-surface-radius: 5px; // Radius for surfaces\n}\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-activities-panel/#customizing-chat-panel","title":"Customizing chat panel","text":"<p>This tutorial uses the <code>*ovActivitiesPanel</code> directive with the aim of replacing the default activities panel with a custom one.</p> <p>In the <code>app.component.ts</code> file, you can see the following code snippet:</p> <pre><code>@Component({\n    selector: 'app-root',\n    template: `\n        &lt;!-- OpenVidu Video Conference Component --&gt;\n        &lt;ov-videoconference\n            [token]=\"token\"\n            [livekitUrl]=\"LIVEKIT_URL\"\n            (onTokenRequested)=\"onTokenRequested($event)\"\n        &gt;\n            &lt;!-- Custom activities panel --&gt;\n            &lt;div *ovActivitiesPanel id=\"my-panel\"&gt;\n                &lt;h3&gt;ACTIVITIES&lt;/h3&gt;\n                &lt;div&gt;CUSTOM ACTIVITIES&lt;/div&gt;\n            &lt;/div&gt;\n        &lt;/ov-videoconference&gt;\n    `,\n    styles: [''],\n    standalone: true,\n    imports: [OpenViduComponentsModule],\n})\nexport class AppComponent {\n    // ...\n}\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-chat-panel/","title":"Custom chat panel using Angular Components","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-chat-panel/#custom-chat-panel-using-angular-components","title":"Custom chat panel using Angular Components","text":"<p>Source code </p> <p>The openvidu-custom-chat-panel tutorial demonstrates how to customize the chat panel, providing a more tailored user experience.</p> <p>Replacing the default chat panel is made simple with the ChatPanelDirective, which offers a straightforward way to replace and adapt the ChatPanelComponent to your needs.</p> <p> </p> OpenVidu Components - Custom Chat Panel","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-chat-panel/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-chat-panel/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-chat-panel/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\ngit clone https://github.com/OpenVidu/openvidu-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-chat-panel/#3-run-a-server-application","title":"3. Run a server application","text":"Node.js Go Ruby Java Python Rust PHP .NET <p>To run this server application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/node\n</code></pre></li> <li>Install dependencies <pre><code>npm install\n</code></pre></li> <li>Run the application <pre><code>npm start\n</code></pre></li> </ol> <p>For more information, check the Node.js tutorial.</p> <p>To run this server application, you need Go  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/go\n</code></pre></li> <li>Run the application <pre><code>go run main.go\n</code></pre></li> </ol> <p>For more information, check the Go tutorial.</p> <p>To run this server application, you need Ruby  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/ruby\n</code></pre></li> <li>Install dependencies <pre><code>bundle install\n</code></pre></li> <li>Run the application <pre><code>ruby app.rb\n</code></pre></li> </ol> <p>For more information, check the Ruby tutorial.</p> <p>To run this server application, you need Java  and Maven  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/java\n</code></pre></li> <li>Run the application <pre><code>mvn spring-boot:run\n</code></pre></li> </ol> <p>For more information, check the Java tutorial.</p> <p>To run this server application, you need Python 3  installed on your device.</p> <ol> <li> <p>Navigate into the server directory</p> <pre><code>cd openvidu-livekit-tutorials/application-server/python\n</code></pre> </li> <li> <p>Create a python virtual environment</p> <pre><code>python -m venv venv\n</code></pre> </li> <li> <p>Activate the virtual environment</p>  Windows macOS Linux <pre><code>.\\venv\\Scripts\\activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> </li> <li> <p>Install dependencies</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the application</p> <pre><code>python app.py\n</code></pre> </li> </ol> <p>For more information, check the Python tutorial.</p> <p>To run this server application, you need Rust  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/rust\n</code></pre></li> <li>Run the application <pre><code>cargo run\n</code></pre></li> </ol> <p>For more information, check the Rust tutorial.</p> <p>To run this server application, you need PHP  and Composer  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/php\n</code></pre></li> <li>Install dependencies <pre><code>composer install\n</code></pre></li> <li>Run the application <pre><code>composer start\n</code></pre></li> </ol> <p>Warning</p> <p>LiveKit PHP SDK requires library BCMath . This is available out-of-the-box in PHP for Windows, but a manual installation might be necessary in other OS. Run <code>sudo apt install php-bcmath</code> or <code>sudo yum install php-bcmath</code></p> <p>For more information, check the PHP tutorial.</p> <p>To run this server application, you need .NET  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/dotnet\n</code></pre></li> <li>Run the application <pre><code>dotnet run\n</code></pre></li> </ol> <p>Warning</p> <p>This .NET server application needs the <code>LIVEKIT_API_SECRET</code> env variable to be at least 32 characters long. Make sure to update it here  and in your OpenVidu Server.</p> <p>For more information, check the .NET tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-chat-panel/#4-run-the-openvidu-custom-chat-panel-tutorial","title":"4. Run the openvidu-custom-chat-panel tutorial","text":"<p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>  cd openvidu-tutorials/openvidu-components/openvidu-custom-chat-panel\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>  npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>  npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>.</p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-chat-panel/#understanding-the-code","title":"Understanding the code","text":"<p>This tutorial is an Angular project generated with Angular CLI tool. Therefore, you will see many configuration files and other components that are not the primary focus of this tutorial. We will concentrate on the following files in the <code>src</code> directory:</p> <ul> <li><code>main.ts</code>: This file defines the root application component. It imports the <code>OpenViduComponentsModule</code>, where we configure the OpenVidu Components Angular library.</li> <li><code>app/app.component.ts</code>: This file defines the AppComponent, the primary and sole component of the application. It is responsible for requesting the OpenVidu token and passing it to the videoconference component, facilitating the connection to the OpenVidu Room.</li> <li><code>styles.scss</code>: This file defines the global styles of the application. Here, you can customize the UI of the OpenVidu Components Angular library.</li> </ul> <p>To use OpenVidu Components Angular in your application, you need to install the library and import the <code>OpenViduComponentsModule</code> in your Angular module. Let's see how to do this:</p> <ol> <li> <p>Create an Angular Project (version 17 or higher)</p> <p>To begin, you will need to create a new Angular project if you haven't already. Ensure you have Node.js and the Angular CLI installed. Then, run the following command to create a new Angular project:</p> <pre><code>ng new your-project-name\n</code></pre> <p>Replace <code>your-project-name</code> with the desired name for your project.</p> </li> <li> <p>Add Angular Material to your project</p> <p>OpenVidu Components Angular needs Angular Material, which provides a range of UI components. To add Angular Material to your project, navigate to your project directory and run:</p> <pre><code>ng add @angular/material\n</code></pre> </li> <li> <p>Install OpenVidu Components Angular</p> <p>With your Angular project set up, it's time to add videoconferencing capabilities with OpenVidu Components Angular. Install the library using npm:</p> <pre><code>npm install openvidu-components-angular\n</code></pre> </li> <li> <p>Import and use OpenVidu Components Angular</p> <p>To use OpenVidu Components Angular in your application, you need to:</p> <ol> <li>Import the <code>OpenViduComponentsModule</code> in your Angular application.</li> <li>Configure the module with the <code>OpenViduComponentsConfig</code> object.</li> <li>Add the component to your template file.</li> <li>Assign the OpenVidu token and LiveKit URL to the component.</li> <li>Customize the appearance of the components using CSS variables.</li> </ol> </li> </ol> main.tsapp.component.tsstyles.scss <p>In your <code>main.ts</code> application file, import the it and configure it as follows:</p> <pre><code>// Other imports ...\n\nimport { OpenViduComponentsModule, OpenViduComponentsConfig } from 'openvidu-components-angular';\n\nconst config: OpenViduComponentsConfig = {\n    production: true,\n};\n\nbootstrapApplication(AppComponent, {\n    providers: [\n        importProvidersFrom(\n            OpenViduComponentsModule.forRoot(config)\n            // Other imports ...\n        ),\n        provideAnimations(),\n    ],\n}).catch((err) =&gt; console.error(err));\n</code></pre> <p>Use the <code>ov-videoconference</code> component to create a videoconference. This component requires a token to connect to the OpenVidu Room. The <code>AppComponent</code> class is responsible for requesting the token and passing it to the <code>ov-videoconference</code> component.</p> <pre><code>import {\n  DataPacket_Kind,\n  DataPublishOptions,\n  DataTopic,\n  ParticipantService,\n  RemoteParticipant,\n  Room,\n  RoomEvent,\n  OpenViduComponentsModule,\n} from 'openvidu-components-angular';\n\n@Component({\n  selector: 'app-root',\n  template:`\n    &lt;!-- OpenVidu Video Conference Component --&gt;\n    &lt;ov-videoconference\n      [token]=\"token\"\n      [livekitUrl]=\"LIVEKIT_URL\"\n      [toolbarDisplayRoomName]=\"false\"\n      (onTokenRequested)=\"onTokenRequested($event)\"\n      (onRoomCreated)=\"onRoomCreated($event)\"\n    &gt;\n      &lt;!-- Chat Panel --&gt;\n      &lt;div *ovChatPanel id=\"my-panel\"&gt;\n        &lt;h3&gt;Chat&lt;/h3&gt;\n        &lt;div&gt;\n          &lt;ul&gt;\n            @for (msg of messages; track msg) {\n            &lt;li&gt;{{ msg }}&lt;/li&gt;\n            }\n          &lt;/ul&gt;\n        &lt;/div&gt;\n        &lt;input value=\"Hello\" #input /&gt;\n        &lt;button (click)=\"send(input.value)\"&gt;Send&lt;/button&gt;\n      &lt;/div&gt;\n    &lt;/ov-videoconference&gt;\n  `,\n  styles: [''],\n  standalone: true,\n  imports: [OpenViduComponentsModule],\n})\nexport class AppComponent {\n  // For local development, leave these variables empty\n  // For production, configure them with correct URLs depending on your deployment\n\n  APPLICATION_SERVER_URL = '';  // (1)!\n  LIVEKIT_URL = ''; // (2)!\n\n  // The name of the room to join.\n  roomName = 'openvidu-custom-chat-panel';  // (3)!\n\n  // The token used to join the room.\n  token!: string; // (4)!\n\n  messages: string[] = []; // (5)!\n\n  constructor(private httpClient: HttpClient, private participantService: ParticipantService) {\n    this.configureUrls();\n  }\n\n  private configureUrls() {\n    // If APPLICATION_SERVER_URL is not configured, use default value from local development\n    if (!this.APPLICATION_SERVER_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.APPLICATION_SERVER_URL = 'http://localhost:6080/';\n      } else {\n        this.APPLICATION_SERVER_URL =\n          'https://' + window.location.hostname + ':6443/';\n      }\n    }\n\n    // If LIVEKIT_URL is not configured, use default value from local development\n    if (!this.LIVEKIT_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.LIVEKIT_URL = 'ws://localhost:7880/';\n      } else {\n        this.LIVEKIT_URL = 'wss://' + window.location.hostname + ':7443/';\n      }\n    }\n  }\n\n  // Requests a token to join the room with the given participant name.\n  async onTokenRequested(participantName: string) { // (6)!\n    const { token } = await this.getToken(this.roomName, participantName);\n    this.token = token;\n  }\n\n  /**\n   * Handles the creation of a new room and sets up an event listener for receiving data.\n   *\n   * @param room - The Room object that was created.\n   */\n  onRoomCreated(room: Room) { // (7)!\n    // Set up an event listener for the RoomEvent.DataReceived event.\n    room.on(RoomEvent.DataReceived, ( // (8)!\n      payload: Uint8Array,\n      participant?: RemoteParticipant,\n      _?: DataPacket_Kind,\n      topic?: string\n    ) =&gt; {\n      // Check if the received data topic is related to chat messages.\n      if (topic === DataTopic.CHAT) {\n        // Decode the payload from Uint8Array to a string and parse it as JSON.\n        const { message } = JSON.parse(new TextDecoder().decode(payload));\n\n        // Get the participant's name or default to 'Unknown' if not available.\n        const participantName = participant?.name || 'Unknown';\n\n        // Add the received message to the messages array.\n        this.messages.push(message);\n\n        // Log the received message and the participant's name to the console.\n        console.log(`Message received from ${participantName}:`, message);\n      }\n    });\n  }\n\n  // Function to send a chat message\n  async send(message: string): Promise&lt;void&gt; { // (9)!\n    const strData = JSON.stringify({ message });\n    const data: Uint8Array = new TextEncoder().encode(strData);\n    const options: DataPublishOptions = { topic: DataTopic.CHAT };\n    await this.participantService.publishData(data, options);\n    this.messages.push(message);\n  }\n\n  // Retrieves a token to join the room with the given name and participant name.\n  getToken(roomName: string, participantName: string): Promise&lt;any&gt; { // (10)!\n    // Requesting token to the server application\n  }\n}\n</code></pre> <ol> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect.</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>messages</code> array that stores the chat messages.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>onRoomCreated</code> method that handles the creation of a new room and sets up an event listener for receiving data.</li> <li>Event listener for the RoomEvent.DataReceived event that listens to chat messages.</li> <li><code>send</code> method that sends a chat message.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ol> <p>The <code>app.component.ts</code> file declares the following properties and methods:</p> <ul> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect.</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>messages</code> array that stores the chat messages.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>onRoomCreated</code> method that handles the creation of a new room and sets up an event listener for receiving data.</li> <li>Event listener for the RoomEvent.DataReceived event that listens to chat messages.</li> <li><code>send</code> method that sends a chat message.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ul> <p>Configure the URLs</p> <p>When running OpenVidu locally, leave <code>APPLICATION_SERVER_URL</code> and <code>LIVEKIT_URL</code> variables empty. The function <code>configureUrls()</code> will automatically configure them with default values. However, for other deployment type, you should configure these variables with the correct URLs depending on your deployment.</p> <p>The OpenVidu Components Angular library provides a set of CSS variables that you can use to customize the appearance of the components. You can define these variables in your application's global styles file (e.g. <code>styles.scss</code>).</p> <pre><code>:root {\n    /* Basic colors */\n    --ov-background-color: #303030; // Background color\n    --ov-surface-color: #ffffff; // Surfaces colors (panels, dialogs)\n\n    /* Text colors */\n    --ov-text-primary-color: #ffffff; // Text color over primary background\n    --ov-text-surface-color: #1d1d1d; // Text color over surface background\n\n    /* Action colors */\n    --ov-primary-action-color: #273235; // Primary color for buttons, etc.\n    --ov-secondary-action-color: #f1f1f1; // Secondary color for buttons, etc.\n    --ov-accent-action-color: #0089ab; // Color for highlighted elements\n\n    /* Status colors */\n    --ov-error-color: #eb5144; // Error color\n    --ov-warn-color: #ffba53; // Warning color\n\n    /* Radius */\n    --ov-toolbar-buttons-radius: 50%; // Radius for toolbar buttons\n    --ov-leave-button-radius: 10px; // Radius for leave button\n    --ov-video-radius: 5px; // Radius for videos\n    --ov-surface-radius: 5px; // Radius for surfaces\n}\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-chat-panel/#customizing-chat-panel","title":"Customizing chat panel","text":"<p>This tutorial uses the <code>*ovChatPanel</code> directive with the aim of replacing the default chat panel with a custom one.</p> <p>In the <code>app.component.ts</code> file, you can see the following code snippet:</p> <pre><code>@Component({\n    selector: 'app-root',\n    template: `\n        &lt;!-- OpenVidu Video Conference Component --&gt;\n        &lt;ov-videoconference\n            [token]=\"token\"\n            [livekitUrl]=\"LIVEKIT_URL\"\n            (onTokenRequested)=\"onTokenRequested($event)\"\n            (onRoomCreated)=\"onRoomCreated($event)\"\n        &gt;\n            &lt;!-- Chat Panel --&gt;\n            &lt;div *ovChatPanel id=\"my-panel\"&gt;\n                &lt;h3&gt;Chat&lt;/h3&gt;\n                &lt;div&gt;\n                    &lt;ul&gt;\n                        @for (msg of messages; track msg) {\n                        &lt;li&gt;{{ msg }}&lt;/li&gt;\n                        }\n                    &lt;/ul&gt;\n                &lt;/div&gt;\n                &lt;input value=\"Hello\" #input /&gt;\n                &lt;button (click)=\"send(input.value)\"&gt;Send&lt;/button&gt;\n            &lt;/div&gt;\n        &lt;/ov-videoconference&gt;\n    `,\n    styles: [''],\n    standalone: true,\n    imports: [OpenViduComponentsModule],\n})\nexport class AppComponent {\n    // ...\n}\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-layout/","title":"Custom layout using Angular Components","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-layout/#custom-layout-using-angular-components","title":"Custom layout using Angular Components","text":"<p>Source code </p> <p>The openvidu-custom-layout tutorial demonstrates how to replace the default layout of the OpenVidu Components Angular library with a custom layout.</p> <p>Replacing the default layout is made simple with the LayoutDirective, which offers a straightforward way to customize the LayoutComponent.</p> <p> </p> OpenVidu Components - Custom Layout","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-layout/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-layout/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-layout/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\ngit clone https://github.com/OpenVidu/openvidu-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-layout/#3-run-a-server-application","title":"3. Run a server application","text":"Node.js Go Ruby Java Python Rust PHP .NET <p>To run this server application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/node\n</code></pre></li> <li>Install dependencies <pre><code>npm install\n</code></pre></li> <li>Run the application <pre><code>npm start\n</code></pre></li> </ol> <p>For more information, check the Node.js tutorial.</p> <p>To run this server application, you need Go  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/go\n</code></pre></li> <li>Run the application <pre><code>go run main.go\n</code></pre></li> </ol> <p>For more information, check the Go tutorial.</p> <p>To run this server application, you need Ruby  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/ruby\n</code></pre></li> <li>Install dependencies <pre><code>bundle install\n</code></pre></li> <li>Run the application <pre><code>ruby app.rb\n</code></pre></li> </ol> <p>For more information, check the Ruby tutorial.</p> <p>To run this server application, you need Java  and Maven  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/java\n</code></pre></li> <li>Run the application <pre><code>mvn spring-boot:run\n</code></pre></li> </ol> <p>For more information, check the Java tutorial.</p> <p>To run this server application, you need Python 3  installed on your device.</p> <ol> <li> <p>Navigate into the server directory</p> <pre><code>cd openvidu-livekit-tutorials/application-server/python\n</code></pre> </li> <li> <p>Create a python virtual environment</p> <pre><code>python -m venv venv\n</code></pre> </li> <li> <p>Activate the virtual environment</p>  Windows macOS Linux <pre><code>.\\venv\\Scripts\\activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> </li> <li> <p>Install dependencies</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the application</p> <pre><code>python app.py\n</code></pre> </li> </ol> <p>For more information, check the Python tutorial.</p> <p>To run this server application, you need Rust  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/rust\n</code></pre></li> <li>Run the application <pre><code>cargo run\n</code></pre></li> </ol> <p>For more information, check the Rust tutorial.</p> <p>To run this server application, you need PHP  and Composer  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/php\n</code></pre></li> <li>Install dependencies <pre><code>composer install\n</code></pre></li> <li>Run the application <pre><code>composer start\n</code></pre></li> </ol> <p>Warning</p> <p>LiveKit PHP SDK requires library BCMath . This is available out-of-the-box in PHP for Windows, but a manual installation might be necessary in other OS. Run <code>sudo apt install php-bcmath</code> or <code>sudo yum install php-bcmath</code></p> <p>For more information, check the PHP tutorial.</p> <p>To run this server application, you need .NET  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/dotnet\n</code></pre></li> <li>Run the application <pre><code>dotnet run\n</code></pre></li> </ol> <p>Warning</p> <p>This .NET server application needs the <code>LIVEKIT_API_SECRET</code> env variable to be at least 32 characters long. Make sure to update it here  and in your OpenVidu Server.</p> <p>For more information, check the .NET tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-layout/#4-run-the-openvidu-custom-layout-tutorial","title":"4. Run the openvidu-custom-layout tutorial","text":"<p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>  cd openvidu-tutorials/openvidu-components/openvidu-custom-layout\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>  npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>  npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>.</p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-layout/#understanding-the-code","title":"Understanding the code","text":"<p>This tutorial is an Angular project generated with Angular CLI tool. Therefore, you will see many configuration files and other components that are not the primary focus of this tutorial. We will concentrate on the following files in the <code>src</code> directory:</p> <ul> <li><code>main.ts</code>: This file defines the root application component. It imports the <code>OpenViduComponentsModule</code>, where we configure the OpenVidu Components Angular library.</li> <li><code>app/app.component.ts</code>: This file defines the AppComponent, the primary and sole component of the application. It is responsible for requesting the OpenVidu token and passing it to the videoconference component, facilitating the connection to the OpenVidu Room.</li> <li><code>styles.scss</code>: This file defines the global styles of the application. Here, you can customize the UI of the OpenVidu Components Angular library.</li> </ul> <p>To use OpenVidu Components Angular in your application, you need to install the library and import the <code>OpenViduComponentsModule</code> in your Angular module. Let's see how to do this:</p> <ol> <li> <p>Create an Angular Project (version 17 or higher)</p> <p>To begin, you will need to create a new Angular project if you haven't already. Ensure you have Node.js and the Angular CLI installed. Then, run the following command to create a new Angular project:</p> <pre><code>ng new your-project-name\n</code></pre> <p>Replace <code>your-project-name</code> with the desired name for your project.</p> </li> <li> <p>Add Angular Material to your project</p> <p>OpenVidu Components Angular needs Angular Material, which provides a range of UI components. To add Angular Material to your project, navigate to your project directory and run:</p> <pre><code>ng add @angular/material\n</code></pre> </li> <li> <p>Install OpenVidu Components Angular</p> <p>With your Angular project set up, it's time to add videoconferencing capabilities with OpenVidu Components Angular. Install the library using npm:</p> <pre><code>npm install openvidu-components-angular\n</code></pre> </li> <li> <p>Import and use OpenVidu Components Angular</p> <p>To use OpenVidu Components Angular in your application, you need to:</p> <ol> <li>Import the <code>OpenViduComponentsModule</code> in your Angular application.</li> <li>Configure the module with the <code>OpenViduComponentsConfig</code> object.</li> <li>Add the component to your template file.</li> <li>Assign the OpenVidu token and LiveKit URL to the component.</li> <li>Customize the appearance of the components using CSS variables.</li> </ol> </li> </ol> main.tsapp.component.tsstyles.scss <p>In your <code>main.ts</code> application file, import the it and configure it as follows:</p> <pre><code>// Other imports ...\n\nimport { OpenViduComponentsModule, OpenViduComponentsConfig } from 'openvidu-components-angular';\n\nconst config: OpenViduComponentsConfig = {\n    production: true,\n};\n\nbootstrapApplication(AppComponent, {\n    providers: [\n        importProvidersFrom(\n            OpenViduComponentsModule.forRoot(config)\n            // Other imports ...\n        ),\n        provideAnimations(),\n    ],\n}).catch((err) =&gt; console.error(err));\n</code></pre> <p>Use the <code>ov-videoconference</code> component to create a videoconference. This component requires a token to connect to the OpenVidu Room. The <code>AppComponent</code> class is responsible for requesting the token and passing it to the <code>ov-videoconference</code> component.</p> <pre><code>import { OpenViduComponentsModule, ParticipantModel, ParticipantService } from 'openvidu-components-angular';\n\n@Component({\n  selector: 'app-root',\n  template:`\n      &lt;!-- OpenVidu Video Conference Component --&gt;\n      &lt;ov-videoconference\n        [token]=\"token\"\n        [livekitUrl]=\"LIVEKIT_URL\"\n        (onTokenRequested)=\"onTokenRequested($event)\"\n      &gt;\n        &lt;!-- Custom Layout for Video Streams --&gt;\n        &lt;div *ovLayout&gt;\n          &lt;div class=\"container\"&gt;\n            &lt;!-- Local Participant's Tracks --&gt;\n            @for (track of localParticipant.tracks; track track) {\n            &lt;div\n              class=\"item\"\n              [ngClass]=\"{\n                hidden:\n                  track.isAudioTrack &amp;&amp; !track.participant.onlyHasAudioTracks\n              }\"\n            &gt;\n              &lt;ov-stream [track]=\"track\"&gt;&lt;/ov-stream&gt;\n            &lt;/div&gt;\n            }\n\n            &lt;!-- Remote Participants' Tracks --&gt;\n            @for (track of remoteParticipants | tracks; track track) {\n            &lt;div\n              class=\"item\"\n              [ngClass]=\"{\n                hidden:\n                  track.isAudioTrack &amp;&amp; !track.participant.onlyHasAudioTracks\n              }\"\n            &gt;\n              &lt;ov-stream [track]=\"track\"&gt;&lt;/ov-stream&gt;\n            &lt;/div&gt;\n            }\n          &lt;/div&gt;\n        &lt;/div&gt;\n      &lt;/ov-videoconference&gt;\n  `,\n  styles: `\n    /* css styles */\n  `,\n  standalone: true,\n    imports: [OpenViduComponentsModule, NgClass],\n})\nexport class AppComponent implements OnInit, OnDestroy {\n  // For local development, leave these variables empty\n  // For production, configure them with correct URLs depending on your deployment\n\n  APPLICATION_SERVER_URL = '';  // (1)!\n  LIVEKIT_URL = ''; // (2)!\n\n  // The name of the room to join.\n  roomName = 'openvidu-custom-layout';  // (3)!\n\n  // The token used to join the room.\n  token!: string; // (4)!\n\n  // Participant-related properties\n  localParticipant!: ParticipantModel; // (5)!\n  remoteParticipants!: ParticipantModel[]; // (6)!\n  localParticipantSubs!: Subscription; // (7)!\n  remoteParticipantsSubs!: Subscription; // (8)!\n\n  constructor(private httpClient: HttpClient,   private participantService: ParticipantService) {\n    this.configureUrls();\n  }\n\n  private configureUrls() {\n    // If APPLICATION_SERVER_URL is not configured, use default value from local development\n    if (!this.APPLICATION_SERVER_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.APPLICATION_SERVER_URL = 'http://localhost:6080/';\n      } else {\n        this.APPLICATION_SERVER_URL =\n          'https://' + window.location.hostname + ':6443/';\n      }\n    }\n\n    // If LIVEKIT_URL is not configured, use default value from local development\n    if (!this.LIVEKIT_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.LIVEKIT_URL = 'ws://localhost:7880/';\n      } else {\n        this.LIVEKIT_URL = 'wss://' + window.location.hostname + ':7443/';\n      }\n    }\n  }\n\n  ngOnInit() {\n    // Subscribe to participants' updates\n    this.subscribeToParticipants();\n  }\n\n  ngOnDestroy() {\n    // Unsubscribe from participant updates to prevent memory leaks\n    this.localParticipantSubs?.unsubscribe();\n    this.remoteParticipantsSubs?.unsubscribe();\n  }\n\n  // Requests a token to join the room with the given participant name.\n  async onTokenRequested(participantName: string) { // (9)!\n    const { token } = await this.getToken(this.roomName, participantName);\n    this.token = token;\n  }\n\n  // Subscribe to updates for local and remote participants\n  private subscribeToParticipants() { // (10)!\n    this.localParticipantSubs = this.participantService.localParticipant$.subscribe((p) =&gt; {\n      if (p) this.localParticipant = p;\n    });\n\n    this.remoteParticipantsSubs = this.participantService.remoteParticipants$.subscribe((participants) =&gt; {\n      this.remoteParticipants = participants;\n    });\n  }\n\n  // Retrieves a token to join the room with the given name and participant name.\n  getToken(roomName: string, participantName: string): Promise&lt;any&gt; { // (11)!\n    // Requesting token to the server application\n  }\n}\n</code></pre> <ol> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect.</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>localParticipant</code>: Local participant model.</li> <li><code>remoteParticipants</code>: Remote participants model.</li> <li><code>localParticipantSubs</code>: Subscription to the local participant updates.</li> <li><code>remoteParticipantsSubs</code>: Subscription to the remote participants updates.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>subscribeToParticipants</code> method that subscribes to updates for local and remote participants.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ol> <p>The <code>app.component.ts</code> file declares the following properties and methods:</p> <ul> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect.</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>localParticipant</code>: Local participant model.</li> <li><code>remoteParticipants</code>: Remote participants model.</li> <li><code>localParticipantSubs</code>: Subscription to the local participant updates.</li> <li><code>remoteParticipantsSubs</code>: Subscription to the remote participants updates.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>subscribeToParticipants</code> method that subscribes to updates for local and remote participants.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ul> <p>Configure the URLs</p> <p>When running OpenVidu locally, leave <code>APPLICATION_SERVER_URL</code> and <code>LIVEKIT_URL</code> variables empty. The function <code>configureUrls()</code> will automatically configure them with default values. However, for other deployment type, you should configure these variables with the correct URLs depending on your deployment.</p> <p>The OpenVidu Components Angular library provides a set of CSS variables that you can use to customize the appearance of the components. You can define these variables in your application's global styles file (e.g. <code>styles.scss</code>).</p> <pre><code>:root {\n    /* Basic colors */\n    --ov-background-color: #303030; // Background color\n    --ov-surface-color: #ffffff; // Surfaces colors (panels, dialogs)\n\n    /* Text colors */\n    --ov-text-primary-color: #ffffff; // Text color over primary background\n    --ov-text-surface-color: #1d1d1d; // Text color over surface background\n\n    /* Action colors */\n    --ov-primary-action-color: #273235; // Primary color for buttons, etc.\n    --ov-secondary-action-color: #f1f1f1; // Secondary color for buttons, etc.\n    --ov-accent-action-color: #0089ab; // Color for highlighted elements\n\n    /* Status colors */\n    --ov-error-color: #eb5144; // Error color\n    --ov-warn-color: #ffba53; // Warning color\n\n    /* Radius */\n    --ov-toolbar-buttons-radius: 50%; // Radius for toolbar buttons\n    --ov-leave-button-radius: 10px; // Radius for leave button\n    --ov-video-radius: 5px; // Radius for videos\n    --ov-surface-radius: 5px; // Radius for surfaces\n}\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-layout/#adding-custom-buttons-to-the-toolbar","title":"Adding custom buttons to the toolbar","text":"<p>OpenVidu Components Angular provides a directive called <code>*ovLayout</code> that allows you to customize the default layout of the videoconference. In this tutorial, we are creating a very basic layout just for demonstration purposes.</p> <pre><code>@Component({\n    selector: 'app-root',\n    template: `\n        &lt;!-- OpenVidu Video Conference Component --&gt;\n        &lt;ov-videoconference\n            [token]=\"token\"\n            [livekitUrl]=\"LIVEKIT_URL\"\n            (onTokenRequested)=\"onTokenRequested($event)\"\n        &gt;\n            &lt;!-- Custom Layout for Video Streams --&gt;\n            &lt;div *ovLayout&gt;\n                &lt;div class=\"container\"&gt;\n                    &lt;!-- Local Participant's Tracks --&gt;\n                    @for (track of localParticipant.tracks; track track) {\n                    &lt;div\n                        class=\"item\"\n                        [ngClass]=\"{\n                            hidden:\n                                track.isAudioTrack &amp;&amp; !track.participant.onlyHasAudioTracks\n                        }\"\n                    &gt;\n                        &lt;ov-stream [track]=\"track\"&gt;&lt;/ov-stream&gt;\n                    &lt;/div&gt;\n                    }\n\n                    &lt;!-- Remote Participants' Tracks --&gt;\n                    @for (track of remoteParticipants | tracks; track track) {\n                    &lt;div\n                        class=\"item\"\n                        [ngClass]=\"{\n                            hidden:\n                                track.isAudioTrack &amp;&amp; !track.participant.onlyHasAudioTracks\n                        }\"\n                    &gt;\n                        &lt;ov-stream [track]=\"track\"&gt;&lt;/ov-stream&gt;\n                    &lt;/div&gt;\n                    }\n                &lt;/div&gt;\n            &lt;/div&gt;\n        &lt;/ov-videoconference&gt;\n    `,\n    styles: [''],\n    standalone: true,\n    imports: [OpenViduComponentsModule, MatIconButton, MatIcon],\n})\nexport class AppComponent implements OnInit, OnDestroy {\n    // ...\n}\n</code></pre> <p>In this code snippet, the <code>*ovLayout</code> directive is used to customize the layout of the videoconference. The layout is divided into two sections: one for the local participant's tracks and another for the remote participants' tracks.</p> <p>The repeater directive <code>@for</code> is used to iterate over the tracks of the local participant and the remote participants and display them in the layout using the <code>ov-stream</code> component.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-panels/","title":"Custom panels using Angular Components","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-panels/#custom-panels-using-angular-components","title":"Custom panels using Angular Components","text":"<p>Source code </p> <p>The openvidu-custom-panels tutorial demonstrates how to replace the default panels with a custom ones, providing a more tailored user experience.</p> <p>Customizing the videoconference panels is made simple with the PanelDirective, which offers a straightforward way to replace and adapt the PanelComponent to your needs.</p> <p> </p> OpenVidu Components - Custom Panels","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-panels/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-panels/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-panels/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\ngit clone https://github.com/OpenVidu/openvidu-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-panels/#3-run-a-server-application","title":"3. Run a server application","text":"Node.js Go Ruby Java Python Rust PHP .NET <p>To run this server application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/node\n</code></pre></li> <li>Install dependencies <pre><code>npm install\n</code></pre></li> <li>Run the application <pre><code>npm start\n</code></pre></li> </ol> <p>For more information, check the Node.js tutorial.</p> <p>To run this server application, you need Go  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/go\n</code></pre></li> <li>Run the application <pre><code>go run main.go\n</code></pre></li> </ol> <p>For more information, check the Go tutorial.</p> <p>To run this server application, you need Ruby  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/ruby\n</code></pre></li> <li>Install dependencies <pre><code>bundle install\n</code></pre></li> <li>Run the application <pre><code>ruby app.rb\n</code></pre></li> </ol> <p>For more information, check the Ruby tutorial.</p> <p>To run this server application, you need Java  and Maven  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/java\n</code></pre></li> <li>Run the application <pre><code>mvn spring-boot:run\n</code></pre></li> </ol> <p>For more information, check the Java tutorial.</p> <p>To run this server application, you need Python 3  installed on your device.</p> <ol> <li> <p>Navigate into the server directory</p> <pre><code>cd openvidu-livekit-tutorials/application-server/python\n</code></pre> </li> <li> <p>Create a python virtual environment</p> <pre><code>python -m venv venv\n</code></pre> </li> <li> <p>Activate the virtual environment</p>  Windows macOS Linux <pre><code>.\\venv\\Scripts\\activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> </li> <li> <p>Install dependencies</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the application</p> <pre><code>python app.py\n</code></pre> </li> </ol> <p>For more information, check the Python tutorial.</p> <p>To run this server application, you need Rust  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/rust\n</code></pre></li> <li>Run the application <pre><code>cargo run\n</code></pre></li> </ol> <p>For more information, check the Rust tutorial.</p> <p>To run this server application, you need PHP  and Composer  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/php\n</code></pre></li> <li>Install dependencies <pre><code>composer install\n</code></pre></li> <li>Run the application <pre><code>composer start\n</code></pre></li> </ol> <p>Warning</p> <p>LiveKit PHP SDK requires library BCMath . This is available out-of-the-box in PHP for Windows, but a manual installation might be necessary in other OS. Run <code>sudo apt install php-bcmath</code> or <code>sudo yum install php-bcmath</code></p> <p>For more information, check the PHP tutorial.</p> <p>To run this server application, you need .NET  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/dotnet\n</code></pre></li> <li>Run the application <pre><code>dotnet run\n</code></pre></li> </ol> <p>Warning</p> <p>This .NET server application needs the <code>LIVEKIT_API_SECRET</code> env variable to be at least 32 characters long. Make sure to update it here  and in your OpenVidu Server.</p> <p>For more information, check the .NET tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-panels/#4-run-the-openvidu-custom-panels-tutorial","title":"4. Run the openvidu-custom-panels tutorial","text":"<p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>  cd openvidu-tutorials/openvidu-components/openvidu-custom-panels\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>  npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>  npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>.</p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-panels/#understanding-the-code","title":"Understanding the code","text":"<p>This tutorial is an Angular project generated with Angular CLI tool. Therefore, you will see many configuration files and other components that are not the primary focus of this tutorial. We will concentrate on the following files in the <code>src</code> directory:</p> <ul> <li><code>main.ts</code>: This file defines the root application component. It imports the <code>OpenViduComponentsModule</code>, where we configure the OpenVidu Components Angular library.</li> <li><code>app/app.component.ts</code>: This file defines the AppComponent, the primary and sole component of the application. It is responsible for requesting the OpenVidu token and passing it to the videoconference component, facilitating the connection to the OpenVidu Room.</li> <li><code>styles.scss</code>: This file defines the global styles of the application. Here, you can customize the UI of the OpenVidu Components Angular library.</li> </ul> <p>To use OpenVidu Components Angular in your application, you need to install the library and import the <code>OpenViduComponentsModule</code> in your Angular module. Let's see how to do this:</p> <ol> <li> <p>Create an Angular Project (version 17 or higher)</p> <p>To begin, you will need to create a new Angular project if you haven't already. Ensure you have Node.js and the Angular CLI installed. Then, run the following command to create a new Angular project:</p> <pre><code>ng new your-project-name\n</code></pre> <p>Replace <code>your-project-name</code> with the desired name for your project.</p> </li> <li> <p>Add Angular Material to your project</p> <p>OpenVidu Components Angular needs Angular Material, which provides a range of UI components. To add Angular Material to your project, navigate to your project directory and run:</p> <pre><code>ng add @angular/material\n</code></pre> </li> <li> <p>Install OpenVidu Components Angular</p> <p>With your Angular project set up, it's time to add videoconferencing capabilities with OpenVidu Components Angular. Install the library using npm:</p> <pre><code>npm install openvidu-components-angular\n</code></pre> </li> <li> <p>Import and use OpenVidu Components Angular</p> <p>To use OpenVidu Components Angular in your application, you need to:</p> <ol> <li>Import the <code>OpenViduComponentsModule</code> in your Angular application.</li> <li>Configure the module with the <code>OpenViduComponentsConfig</code> object.</li> <li>Add the component to your template file.</li> <li>Assign the OpenVidu token and LiveKit URL to the component.</li> <li>Customize the appearance of the components using CSS variables.</li> </ol> </li> </ol> main.tsapp.component.tsstyles.scss <p>In your <code>main.ts</code> application file, import the it and configure it as follows:</p> <pre><code>// Other imports ...\n\nimport { OpenViduComponentsModule, OpenViduComponentsConfig } from 'openvidu-components-angular';\n\nconst config: OpenViduComponentsConfig = {\n    production: true,\n};\n\nbootstrapApplication(AppComponent, {\n    providers: [\n        importProvidersFrom(\n            OpenViduComponentsModule.forRoot(config)\n            // Other imports ...\n        ),\n        provideAnimations(),\n    ],\n}).catch((err) =&gt; console.error(err));\n</code></pre> <p>Use the <code>ov-videoconference</code> component to create a videoconference. This component requires a token to connect to the OpenVidu Room. The <code>AppComponent</code> class is responsible for requesting the token and passing it to the <code>ov-videoconference</code> component.</p> <pre><code>import { OpenViduComponentsModule } from 'openvidu-components-angular';\n\n@Component({\n  selector: 'app-root',\n  template:`\n      &lt;!-- OpenVidu Video Conference Component --&gt;\n      &lt;ov-videoconference\n        [token]=\"token\"\n        [livekitUrl]=\"LIVEKIT_URL\"\n        (onTokenRequested)=\"onTokenRequested($event)\"\n      &gt;\n        &lt;!-- Custom Panels --&gt;\n        &lt;ov-panel *ovPanel&gt;\n          &lt;!-- Custom Chat Panel --&gt;\n          &lt;div *ovChatPanel id=\"my-chat-panel\"&gt;This is my custom chat panel&lt;/div&gt;\n\n          &lt;!-- Custom Participants Panel --&gt;\n          &lt;div *ovParticipantsPanel id=\"my-participants-panel\"&gt;\n            This is my custom participants panel\n          &lt;/div&gt;\n\n          &lt;!-- Custom Activities Panel --&gt;\n          &lt;div *ovActivitiesPanel id=\"my-activities-panel\"&gt;\n            This is my custom activities panel\n          &lt;/div&gt;\n        &lt;/ov-panel&gt;\n      &lt;/ov-videoconference&gt;\n  `,\n  styles: [''],\n  standalone: true,\n  imports: [OpenViduComponentsModule],\n})\nexport class AppComponent {\n  // For local development, leave these variables empty\n  // For production, configure them with correct URLs depending on your deployment\n\n  APPLICATION_SERVER_URL = '';  // (1)!\n  LIVEKIT_URL = ''; // (2)!\n\n  // The name of the room to join.\n  roomName = 'openvidu-custom-panels';  // (3)!\n\n  // The token used to join the room.\n  token!: string; // (4)!\n\n  constructor(private httpClient: HttpClient) {\n    this.configureUrls();\n  }\n\n  private configureUrls() {\n    // If APPLICATION_SERVER_URL is not configured, use default value from local development\n    if (!this.APPLICATION_SERVER_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.APPLICATION_SERVER_URL = 'http://localhost:6080/';\n      } else {\n        this.APPLICATION_SERVER_URL =\n          'https://' + window.location.hostname + ':6443/';\n      }\n    }\n\n    // If LIVEKIT_URL is not configured, use default value from local development\n    if (!this.LIVEKIT_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.LIVEKIT_URL = 'ws://localhost:7880/';\n      } else {\n        this.LIVEKIT_URL = 'wss://' + window.location.hostname + ':7443/';\n      }\n    }\n  }\n\n  // Requests a token to join the room with the given participant name.\n  async onTokenRequested(participantName: string) { // (5)!\n    const { token } = await this.getToken(this.roomName, participantName);\n    this.token = token;\n  }\n\n  // Retrieves a token to join the room with the given name and participant name.\n  getToken(roomName: string, participantName: string): Promise&lt;any&gt; { // (6)!\n    // Requesting token to the server application\n  }\n}\n</code></pre> <ol> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect.</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ol> <p>The <code>app.component.ts</code> file declares the following properties and methods:</p> <ul> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect.</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ul> <p>Configure the URLs</p> <p>When running OpenVidu locally, leave <code>APPLICATION_SERVER_URL</code> and <code>LIVEKIT_URL</code> variables empty. The function <code>configureUrls()</code> will automatically configure them with default values. However, for other deployment type, you should configure these variables with the correct URLs depending on your deployment.</p> <p>The OpenVidu Components Angular library provides a set of CSS variables that you can use to customize the appearance of the components. You can define these variables in your application's global styles file (e.g. <code>styles.scss</code>).</p> <pre><code>:root {\n    /* Basic colors */\n    --ov-background-color: #303030; // Background color\n    --ov-surface-color: #ffffff; // Surfaces colors (panels, dialogs)\n\n    /* Text colors */\n    --ov-text-primary-color: #ffffff; // Text color over primary background\n    --ov-text-surface-color: #1d1d1d; // Text color over surface background\n\n    /* Action colors */\n    --ov-primary-action-color: #273235; // Primary color for buttons, etc.\n    --ov-secondary-action-color: #f1f1f1; // Secondary color for buttons, etc.\n    --ov-accent-action-color: #0089ab; // Color for highlighted elements\n\n    /* Status colors */\n    --ov-error-color: #eb5144; // Error color\n    --ov-warn-color: #ffba53; // Warning color\n\n    /* Radius */\n    --ov-toolbar-buttons-radius: 50%; // Radius for toolbar buttons\n    --ov-leave-button-radius: 10px; // Radius for leave button\n    --ov-video-radius: 5px; // Radius for videos\n    --ov-surface-radius: 5px; // Radius for surfaces\n}\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-panels/#customizing-the-panels","title":"Customizing the panels","text":"<p>The <code>*ovPanel</code> directive is used to replace the default videoconference panels with a custom ones. In the <code>app.component.ts</code> file, you can see the following code snippet:</p> <pre><code>@Component({\n    selector: 'app-root',\n    template: `\n        &lt;!-- OpenVidu Video Conference Component --&gt;\n        &lt;ov-videoconference\n            [token]=\"token\"\n            [livekitUrl]=\"LIVEKIT_URL\"\n            (onTokenRequested)=\"onTokenRequested($event)\"\n        &gt;\n            &lt;!-- Custom Panels --&gt;\n            &lt;ov-panel *ovPanel&gt;\n                &lt;!-- Custom Chat Panel --&gt;\n                &lt;div *ovChatPanel id=\"my-chat-panel\"&gt;This is my custom chat panel&lt;/div&gt;\n\n                &lt;!-- Custom Participants Panel --&gt;\n                &lt;div *ovParticipantsPanel id=\"my-participants-panel\"&gt;\n                    This is my custom participants panel\n                &lt;/div&gt;\n\n                &lt;!-- Custom Activities Panel --&gt;\n                &lt;div *ovActivitiesPanel id=\"my-activities-panel\"&gt;\n                    This is my custom activities panel\n                &lt;/div&gt;\n            &lt;/ov-panel&gt;\n        &lt;/ov-videoconference&gt;\n    `,\n    styles: [''],\n    standalone: true,\n    imports: [OpenViduComponentsModule],\n})\nexport class AppComponent {\n    // ...\n}\n</code></pre> <p>In this code snippet, the <code>*ovPanel</code> directive is used to replace the default videoconference panels with custom ones. The <code>*ovChatPanel</code>, <code>*ovParticipantsPanel</code>, and <code>*ovActivitiesPanel</code> directives are used to replace the default chat, participants, and activities panels with custom ones.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-participant-panel-item-element/","title":"Custom participants panel item element using Angular Components","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-participant-panel-item-element/#custom-participants-panel-item-element-using-angular-components","title":"Custom participants panel item element using Angular Components","text":"<p>Source code </p> <p>The openvidu-custom-participant-panel-item-element tutorial demonstrates how to replace the default participant item element inside of the participants panel with a custom one, providing a more tailored user experience.</p> <p>Replacing the default participant item element is made simple with the ParticipantsPanelItemElementsDirective, which offers a straightforward way to replace and adapt the ParticipantsPanelItemComponent to your needs.</p> <p> </p> OpenVidu Components - Custom Participants Panel Item Element","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-participant-panel-item-element/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-participant-panel-item-element/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-participant-panel-item-element/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\ngit clone https://github.com/OpenVidu/openvidu-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-participant-panel-item-element/#3-run-a-server-application","title":"3. Run a server application","text":"Node.js Go Ruby Java Python Rust PHP .NET <p>To run this server application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/node\n</code></pre></li> <li>Install dependencies <pre><code>npm install\n</code></pre></li> <li>Run the application <pre><code>npm start\n</code></pre></li> </ol> <p>For more information, check the Node.js tutorial.</p> <p>To run this server application, you need Go  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/go\n</code></pre></li> <li>Run the application <pre><code>go run main.go\n</code></pre></li> </ol> <p>For more information, check the Go tutorial.</p> <p>To run this server application, you need Ruby  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/ruby\n</code></pre></li> <li>Install dependencies <pre><code>bundle install\n</code></pre></li> <li>Run the application <pre><code>ruby app.rb\n</code></pre></li> </ol> <p>For more information, check the Ruby tutorial.</p> <p>To run this server application, you need Java  and Maven  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/java\n</code></pre></li> <li>Run the application <pre><code>mvn spring-boot:run\n</code></pre></li> </ol> <p>For more information, check the Java tutorial.</p> <p>To run this server application, you need Python 3  installed on your device.</p> <ol> <li> <p>Navigate into the server directory</p> <pre><code>cd openvidu-livekit-tutorials/application-server/python\n</code></pre> </li> <li> <p>Create a python virtual environment</p> <pre><code>python -m venv venv\n</code></pre> </li> <li> <p>Activate the virtual environment</p>  Windows macOS Linux <pre><code>.\\venv\\Scripts\\activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> </li> <li> <p>Install dependencies</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the application</p> <pre><code>python app.py\n</code></pre> </li> </ol> <p>For more information, check the Python tutorial.</p> <p>To run this server application, you need Rust  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/rust\n</code></pre></li> <li>Run the application <pre><code>cargo run\n</code></pre></li> </ol> <p>For more information, check the Rust tutorial.</p> <p>To run this server application, you need PHP  and Composer  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/php\n</code></pre></li> <li>Install dependencies <pre><code>composer install\n</code></pre></li> <li>Run the application <pre><code>composer start\n</code></pre></li> </ol> <p>Warning</p> <p>LiveKit PHP SDK requires library BCMath . This is available out-of-the-box in PHP for Windows, but a manual installation might be necessary in other OS. Run <code>sudo apt install php-bcmath</code> or <code>sudo yum install php-bcmath</code></p> <p>For more information, check the PHP tutorial.</p> <p>To run this server application, you need .NET  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/dotnet\n</code></pre></li> <li>Run the application <pre><code>dotnet run\n</code></pre></li> </ol> <p>Warning</p> <p>This .NET server application needs the <code>LIVEKIT_API_SECRET</code> env variable to be at least 32 characters long. Make sure to update it here  and in your OpenVidu Server.</p> <p>For more information, check the .NET tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-participant-panel-item-element/#4-run-the-openvidu-custom-participant-panel-item-element-tutorial","title":"4. Run the openvidu-custom-participant-panel-item-element tutorial","text":"<p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>  cd openvidu-tutorials/openvidu-components/openvidu-custom-participant-panel-item-element\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>  npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>  npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>.</p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-participant-panel-item-element/#understanding-the-code","title":"Understanding the code","text":"<p>This tutorial is an Angular project generated with Angular CLI tool. Therefore, you will see many configuration files and other components that are not the primary focus of this tutorial. We will concentrate on the following files in the <code>src</code> directory:</p> <ul> <li><code>main.ts</code>: This file defines the root application component. It imports the <code>OpenViduComponentsModule</code>, where we configure the OpenVidu Components Angular library.</li> <li><code>app/app.component.ts</code>: This file defines the AppComponent, the primary and sole component of the application. It is responsible for requesting the OpenVidu token and passing it to the videoconference component, facilitating the connection to the OpenVidu Room.</li> <li><code>styles.scss</code>: This file defines the global styles of the application. Here, you can customize the UI of the OpenVidu Components Angular library.</li> </ul> <p>To use OpenVidu Components Angular in your application, you need to install the library and import the <code>OpenViduComponentsModule</code> in your Angular module. Let's see how to do this:</p> <ol> <li> <p>Create an Angular Project (version 17 or higher)</p> <p>To begin, you will need to create a new Angular project if you haven't already. Ensure you have Node.js and the Angular CLI installed. Then, run the following command to create a new Angular project:</p> <pre><code>ng new your-project-name\n</code></pre> <p>Replace <code>your-project-name</code> with the desired name for your project.</p> </li> <li> <p>Add Angular Material to your project</p> <p>OpenVidu Components Angular needs Angular Material, which provides a range of UI components. To add Angular Material to your project, navigate to your project directory and run:</p> <pre><code>ng add @angular/material\n</code></pre> </li> <li> <p>Install OpenVidu Components Angular</p> <p>With your Angular project set up, it's time to add videoconferencing capabilities with OpenVidu Components Angular. Install the library using npm:</p> <pre><code>npm install openvidu-components-angular\n</code></pre> </li> <li> <p>Import and use OpenVidu Components Angular</p> <p>To use OpenVidu Components Angular in your application, you need to:</p> <ol> <li>Import the <code>OpenViduComponentsModule</code> in your Angular application.</li> <li>Configure the module with the <code>OpenViduComponentsConfig</code> object.</li> <li>Add the component to your template file.</li> <li>Assign the OpenVidu token and LiveKit URL to the component.</li> <li>Customize the appearance of the components using CSS variables.</li> </ol> </li> </ol> main.tsapp.component.tsstyles.scss <p>In your <code>main.ts</code> application file, import the it and configure it as follows:</p> <pre><code>// Other imports ...\n\nimport { OpenViduComponentsModule, OpenViduComponentsConfig } from 'openvidu-components-angular';\n\nconst config: OpenViduComponentsConfig = {\n    production: true,\n};\n\nbootstrapApplication(AppComponent, {\n    providers: [\n        importProvidersFrom(\n            OpenViduComponentsModule.forRoot(config)\n            // Other imports ...\n        ),\n        provideAnimations(),\n    ],\n}).catch((err) =&gt; console.error(err));\n</code></pre> <p>Use the <code>ov-videoconference</code> component to create a videoconference. This component requires a token to connect to the OpenVidu Room. The <code>AppComponent</code> class is responsible for requesting the token and passing it to the <code>ov-videoconference</code> component.</p> <pre><code>import {\n  ParticipantModel,\n    ParticipantService,\n  OpenViduComponentsModule\n} from 'openvidu-components-angular';\n\n@Component({\n  selector: 'app-root',\n  template:`\n    &lt;!-- OpenVidu Video Conference Component --&gt;\n    &lt;ov-videoconference\n      [token]=\"token\"\n      [livekitUrl]=\"LIVEKIT_URL\"\n      (onTokenRequested)=\"onTokenRequested($event)\"\n    &gt;\n      &lt;!-- Participant Panel Item Elements --&gt;\n      &lt;div *ovParticipantPanelItemElements=\"let participant\"&gt;\n        &lt;!-- Leave Button for Local Participant --&gt;\n        @if (participant.isLocal) {\n        &lt;button (click)=\"leaveSession()\"&gt;Leave&lt;/button&gt;\n        }\n      &lt;/div&gt;\n    &lt;/ov-videoconference&gt;\n  `,\n  styles: [''],\n  standalone: true,\n  imports: [OpenViduComponentsModule],\n})\nexport class AppComponent {\n  // For local development, leave these variables empty\n  // For production, configure them with correct URLs depending on your deployment\n\n  APPLICATION_SERVER_URL = '';  // (1)!\n  LIVEKIT_URL = ''; // (2)!\n\n  // The name of the room to join.\n  roomName = 'openvidu-custom-participant-panel-item-element';  // (3)!\n\n  // The token used to join the room.\n  token!: string; // (4)!\n\n  constructor(private httpClient: HttpClient) {\n    this.configureUrls();\n  }\n\n  private configureUrls() {\n    // If APPLICATION_SERVER_URL is not configured, use default value from local development\n    if (!this.APPLICATION_SERVER_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.APPLICATION_SERVER_URL = 'http://localhost:6080/';\n      } else {\n        this.APPLICATION_SERVER_URL =\n          'https://' + window.location.hostname + ':6443/';\n      }\n    }\n\n    // If LIVEKIT_URL is not configured, use default value from local development\n    if (!this.LIVEKIT_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.LIVEKIT_URL = 'ws://localhost:7880/';\n      } else {\n        this.LIVEKIT_URL = 'wss://' + window.location.hostname + ':7443/';\n      }\n    }\n  }\n\n  // Requests a token to join the room with the given participant name.\n  async onTokenRequested(participantName: string) { // (5)!\n    const { token } = await this.getToken(this.roomName, participantName);\n    this.token = token;\n  }\n\n  // Function to leave the session\n  async leaveSession() { // (6)!\n    await this.openviduService.disconnectRoom();\n  }\n\n  // Retrieves a token to join the room with the given name and participant name.\n  getToken(roomName: string, participantName: string): Promise&lt;any&gt; { // (7)!\n    // Requesting token to the server application\n  }\n}\n</code></pre> <ol> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect.</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>leaveSession</code> method that disconnects the client from the OpenVidu Room.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ol> <p>The <code>app.component.ts</code> file declares the following properties and methods:</p> <ul> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect.</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>leaveSession</code> method that disconnects the client from the OpenVidu Room.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ul> <p>Configure the URLs</p> <p>When running OpenVidu locally, leave <code>APPLICATION_SERVER_URL</code> and <code>LIVEKIT_URL</code> variables empty. The function <code>configureUrls()</code> will automatically configure them with default values. However, for other deployment type, you should configure these variables with the correct URLs depending on your deployment.</p> <p>The OpenVidu Components Angular library provides a set of CSS variables that you can use to customize the appearance of the components. You can define these variables in your application's global styles file (e.g. <code>styles.scss</code>).</p> <pre><code>:root {\n    /* Basic colors */\n    --ov-background-color: #303030; // Background color\n    --ov-surface-color: #ffffff; // Surfaces colors (panels, dialogs)\n\n    /* Text colors */\n    --ov-text-primary-color: #ffffff; // Text color over primary background\n    --ov-text-surface-color: #1d1d1d; // Text color over surface background\n\n    /* Action colors */\n    --ov-primary-action-color: #273235; // Primary color for buttons, etc.\n    --ov-secondary-action-color: #f1f1f1; // Secondary color for buttons, etc.\n    --ov-accent-action-color: #0089ab; // Color for highlighted elements\n\n    /* Status colors */\n    --ov-error-color: #eb5144; // Error color\n    --ov-warn-color: #ffba53; // Warning color\n\n    /* Radius */\n    --ov-toolbar-buttons-radius: 50%; // Radius for toolbar buttons\n    --ov-leave-button-radius: 10px; // Radius for leave button\n    --ov-video-radius: 5px; // Radius for videos\n    --ov-surface-radius: 5px; // Radius for surfaces\n}\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-participant-panel-item-element/#customizing-participant-item-element","title":"Customizing participant item element","text":"<p>This tutorial uses the <code>*ovParticipantPanelItem</code> directive with the aim of replacing the default participant item, inside of the participants panel, with a custom one.</p> <p>In the <code>app.component.ts</code> file, you can see the following code snippet:</p> <pre><code>@Component({\n    selector: 'app-root',\n    template: `\n        &lt;!-- OpenVidu Video Conference Component --&gt;\n        &lt;ov-videoconference\n            [token]=\"token\"\n            [livekitUrl]=\"LIVEKIT_URL\"\n            (onTokenRequested)=\"onTokenRequested($event)\"\n        &gt;\n            &lt;!-- Participant Panel Item Elements --&gt;\n            &lt;div *ovParticipantPanelItemElements=\"let participant\"&gt;\n                &lt;!-- Leave Button for Local Participant --&gt;\n                @if (participant.isLocal) {\n                &lt;button (click)=\"leaveSession()\"&gt;Leave&lt;/button&gt;\n                }\n            &lt;/div&gt;\n        &lt;/ov-videoconference&gt;\n    `,\n    styles: [''],\n    standalone: true,\n    imports: [OpenViduComponentsModule],\n})\nexport class AppComponent {\n    // ...\n}\n</code></pre> <p>In this code snippet, the <code>*ovParticipantPanelItemElements</code> directive is used to replace the default participant item element, inside of the participants panel, with a custom one.</p> <p>The <code>*ovParticipantPanelItemElements</code> directive provides a way to access the participant object and customize the participant item component to your needs.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-participant-panel-item/","title":"Custom participants panel item using Angular Components","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-participant-panel-item/#custom-participants-panel-item-using-angular-components","title":"Custom participants panel item using Angular Components","text":"<p>Source code </p> <p>The openvidu-custom-participant-panel-item tutorial demonstrates how to replace the default participant item inside of the participants panel with a custom one, providing a more tailored user experience.</p> <p>Replacing the default participant item is made simple with the ParticipantsPanelItemDirective, which offers a straightforward way to replace and adapt the ParticipantsPanelItemComponent to your needs.</p> <p> </p> OpenVidu Components - Custom Participants Panel Item","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-participant-panel-item/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-participant-panel-item/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-participant-panel-item/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\ngit clone https://github.com/OpenVidu/openvidu-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-participant-panel-item/#3-run-a-server-application","title":"3. Run a server application","text":"Node.js Go Ruby Java Python Rust PHP .NET <p>To run this server application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/node\n</code></pre></li> <li>Install dependencies <pre><code>npm install\n</code></pre></li> <li>Run the application <pre><code>npm start\n</code></pre></li> </ol> <p>For more information, check the Node.js tutorial.</p> <p>To run this server application, you need Go  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/go\n</code></pre></li> <li>Run the application <pre><code>go run main.go\n</code></pre></li> </ol> <p>For more information, check the Go tutorial.</p> <p>To run this server application, you need Ruby  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/ruby\n</code></pre></li> <li>Install dependencies <pre><code>bundle install\n</code></pre></li> <li>Run the application <pre><code>ruby app.rb\n</code></pre></li> </ol> <p>For more information, check the Ruby tutorial.</p> <p>To run this server application, you need Java  and Maven  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/java\n</code></pre></li> <li>Run the application <pre><code>mvn spring-boot:run\n</code></pre></li> </ol> <p>For more information, check the Java tutorial.</p> <p>To run this server application, you need Python 3  installed on your device.</p> <ol> <li> <p>Navigate into the server directory</p> <pre><code>cd openvidu-livekit-tutorials/application-server/python\n</code></pre> </li> <li> <p>Create a python virtual environment</p> <pre><code>python -m venv venv\n</code></pre> </li> <li> <p>Activate the virtual environment</p>  Windows macOS Linux <pre><code>.\\venv\\Scripts\\activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> </li> <li> <p>Install dependencies</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the application</p> <pre><code>python app.py\n</code></pre> </li> </ol> <p>For more information, check the Python tutorial.</p> <p>To run this server application, you need Rust  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/rust\n</code></pre></li> <li>Run the application <pre><code>cargo run\n</code></pre></li> </ol> <p>For more information, check the Rust tutorial.</p> <p>To run this server application, you need PHP  and Composer  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/php\n</code></pre></li> <li>Install dependencies <pre><code>composer install\n</code></pre></li> <li>Run the application <pre><code>composer start\n</code></pre></li> </ol> <p>Warning</p> <p>LiveKit PHP SDK requires library BCMath . This is available out-of-the-box in PHP for Windows, but a manual installation might be necessary in other OS. Run <code>sudo apt install php-bcmath</code> or <code>sudo yum install php-bcmath</code></p> <p>For more information, check the PHP tutorial.</p> <p>To run this server application, you need .NET  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/dotnet\n</code></pre></li> <li>Run the application <pre><code>dotnet run\n</code></pre></li> </ol> <p>Warning</p> <p>This .NET server application needs the <code>LIVEKIT_API_SECRET</code> env variable to be at least 32 characters long. Make sure to update it here  and in your OpenVidu Server.</p> <p>For more information, check the .NET tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-participant-panel-item/#4-run-the-openvidu-custom-participant-panel-item-tutorial","title":"4. Run the openvidu-custom-participant-panel-item tutorial","text":"<p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>  cd openvidu-tutorials/openvidu-components/openvidu-custom-participant-panel-item\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>  npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>  npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>.</p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-participant-panel-item/#understanding-the-code","title":"Understanding the code","text":"<p>This tutorial is an Angular project generated with Angular CLI tool. Therefore, you will see many configuration files and other components that are not the primary focus of this tutorial. We will concentrate on the following files in the <code>src</code> directory:</p> <ul> <li><code>main.ts</code>: This file defines the root application component. It imports the <code>OpenViduComponentsModule</code>, where we configure the OpenVidu Components Angular library.</li> <li><code>app/app.component.ts</code>: This file defines the AppComponent, the primary and sole component of the application. It is responsible for requesting the OpenVidu token and passing it to the videoconference component, facilitating the connection to the OpenVidu Room.</li> <li><code>styles.scss</code>: This file defines the global styles of the application. Here, you can customize the UI of the OpenVidu Components Angular library.</li> </ul> <p>To use OpenVidu Components Angular in your application, you need to install the library and import the <code>OpenViduComponentsModule</code> in your Angular module. Let's see how to do this:</p> <ol> <li> <p>Create an Angular Project (version 17 or higher)</p> <p>To begin, you will need to create a new Angular project if you haven't already. Ensure you have Node.js and the Angular CLI installed. Then, run the following command to create a new Angular project:</p> <pre><code>ng new your-project-name\n</code></pre> <p>Replace <code>your-project-name</code> with the desired name for your project.</p> </li> <li> <p>Add Angular Material to your project</p> <p>OpenVidu Components Angular needs Angular Material, which provides a range of UI components. To add Angular Material to your project, navigate to your project directory and run:</p> <pre><code>ng add @angular/material\n</code></pre> </li> <li> <p>Install OpenVidu Components Angular</p> <p>With your Angular project set up, it's time to add videoconferencing capabilities with OpenVidu Components Angular. Install the library using npm:</p> <pre><code>npm install openvidu-components-angular\n</code></pre> </li> <li> <p>Import and use OpenVidu Components Angular</p> <p>To use OpenVidu Components Angular in your application, you need to:</p> <ol> <li>Import the <code>OpenViduComponentsModule</code> in your Angular application.</li> <li>Configure the module with the <code>OpenViduComponentsConfig</code> object.</li> <li>Add the component to your template file.</li> <li>Assign the OpenVidu token and LiveKit URL to the component.</li> <li>Customize the appearance of the components using CSS variables.</li> </ol> </li> </ol> main.tsapp.component.tsstyles.scss <p>In your <code>main.ts</code> application file, import the it and configure it as follows:</p> <pre><code>// Other imports ...\n\nimport { OpenViduComponentsModule, OpenViduComponentsConfig } from 'openvidu-components-angular';\n\nconst config: OpenViduComponentsConfig = {\n    production: true,\n};\n\nbootstrapApplication(AppComponent, {\n    providers: [\n        importProvidersFrom(\n            OpenViduComponentsModule.forRoot(config)\n            // Other imports ...\n        ),\n        provideAnimations(),\n    ],\n}).catch((err) =&gt; console.error(err));\n</code></pre> <p>Use the <code>ov-videoconference</code> component to create a videoconference. This component requires a token to connect to the OpenVidu Room. The <code>AppComponent</code> class is responsible for requesting the token and passing it to the <code>ov-videoconference</code> component.</p> <pre><code>import {\n  ParticipantModel,\n    ParticipantService,\n  OpenViduComponentsModule\n} from 'openvidu-components-angular';\n\n@Component({\n  selector: 'app-root',\n  template:`\n    &lt;!-- OpenVidu Video Conference Component --&gt;\n    &lt;ov-videoconference\n        [token]=\"token\"\n        [livekitUrl]=\"LIVEKIT_URL\"\n        (onTokenRequested)=\"onTokenRequested($event)\"\n    &gt;\n        &lt;!-- Participant Panel Items --&gt;\n        &lt;div *ovParticipantPanelItem=\"let participant\" style=\"display: flex\"&gt;\n            &lt;p&gt;{{ participant.name }}&lt;/p&gt;\n\n            &lt;!-- More Options Menu --&gt;\n            &lt;button mat-icon-button [matMenuTriggerFor]=\"menu\"&gt;\n                &lt;mat-icon&gt;more_vert&lt;/mat-icon&gt;\n            &lt;/button&gt;\n\n            &lt;!-- Menu Content --&gt;\n            &lt;mat-menu #menu=\"matMenu\"&gt;\n                &lt;button mat-menu-item&gt;Button 1&lt;/button&gt;\n                &lt;button mat-menu-item&gt;Button 2&lt;/button&gt;\n            &lt;/mat-menu&gt;\n        &lt;/div&gt;\n    &lt;/ov-videoconference&gt;\n  `,\n  styles: [''],\n  standalone: true,\n    imports: [\n    OpenViduComponentsModule,\n    MatIconButton,\n    MatMenuTrigger,\n    MatIcon,\n    MatMenu,\n    MatMenuItem,\n  ],\n})\nexport class AppComponent {\n  // For local development, leave these variables empty\n  // For production, configure them with correct URLs depending on your deployment\n\n  APPLICATION_SERVER_URL = '';  // (1)!\n  LIVEKIT_URL = ''; // (2)!\n\n  // The name of the room to join.\n  roomName = 'openvidu-custom-participant-panel-item';  // (3)!\n\n  // The token used to join the room.\n  token!: string; // (4)!\n\n  constructor(private httpClient: HttpClient) {\n    this.configureUrls();\n  }\n\n  private configureUrls() {\n    // If APPLICATION_SERVER_URL is not configured, use default value from local development\n    if (!this.APPLICATION_SERVER_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.APPLICATION_SERVER_URL = 'http://localhost:6080/';\n      } else {\n        this.APPLICATION_SERVER_URL =\n          'https://' + window.location.hostname + ':6443/';\n      }\n    }\n\n    // If LIVEKIT_URL is not configured, use default value from local development\n    if (!this.LIVEKIT_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.LIVEKIT_URL = 'ws://localhost:7880/';\n      } else {\n        this.LIVEKIT_URL = 'wss://' + window.location.hostname + ':7443/';\n      }\n    }\n  }\n\n  // Requests a token to join the room with the given participant name.\n  async onTokenRequested(participantName: string) { // (5)!\n    const { token } = await this.getToken(this.roomName, participantName);\n    this.token = token;\n  }\n\n  // Retrieves a token to join the room with the given name and participant name.\n  getToken(roomName: string, participantName: string): Promise&lt;any&gt; { // (6)!\n    // Requesting token to the server application\n  }\n}\n</code></pre> <ol> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect.</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ol> <p>The <code>app.component.ts</code> file declares the following properties and methods:</p> <ul> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect.</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ul> <p>Configure the URLs</p> <p>When running OpenVidu locally, leave <code>APPLICATION_SERVER_URL</code> and <code>LIVEKIT_URL</code> variables empty. The function <code>configureUrls()</code> will automatically configure them with default values. However, for other deployment type, you should configure these variables with the correct URLs depending on your deployment.</p> <p>The OpenVidu Components Angular library provides a set of CSS variables that you can use to customize the appearance of the components. You can define these variables in your application's global styles file (e.g. <code>styles.scss</code>).</p> <pre><code>:root {\n    /* Basic colors */\n    --ov-background-color: #303030; // Background color\n    --ov-surface-color: #ffffff; // Surfaces colors (panels, dialogs)\n\n    /* Text colors */\n    --ov-text-primary-color: #ffffff; // Text color over primary background\n    --ov-text-surface-color: #1d1d1d; // Text color over surface background\n\n    /* Action colors */\n    --ov-primary-action-color: #273235; // Primary color for buttons, etc.\n    --ov-secondary-action-color: #f1f1f1; // Secondary color for buttons, etc.\n    --ov-accent-action-color: #0089ab; // Color for highlighted elements\n\n    /* Status colors */\n    --ov-error-color: #eb5144; // Error color\n    --ov-warn-color: #ffba53; // Warning color\n\n    /* Radius */\n    --ov-toolbar-buttons-radius: 50%; // Radius for toolbar buttons\n    --ov-leave-button-radius: 10px; // Radius for leave button\n    --ov-video-radius: 5px; // Radius for videos\n    --ov-surface-radius: 5px; // Radius for surfaces\n}\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-participant-panel-item/#customizing-participant-item","title":"Customizing participant item","text":"<p>This tutorial uses the <code>*ovParticipantPanelItem</code> directive with the aim of replacing the default participant item, inside of the participants panel, with a custom one.</p> <p>In the <code>app.component.ts</code> file, you can see the following code snippet:</p> <pre><code>@Component({\n    selector: 'app-root',\n    template: `\n        &lt;!-- OpenVidu Video Conference Component --&gt;\n        &lt;ov-videoconference\n            [token]=\"token\"\n            [livekitUrl]=\"LIVEKIT_URL\"\n            (onTokenRequested)=\"onTokenRequested($event)\"\n        &gt;\n            &lt;!-- Participant Panel Items --&gt;\n            &lt;div *ovParticipantPanelItem=\"let participant\" style=\"display: flex\"&gt;\n                &lt;p&gt;{{ participant.name }}&lt;/p&gt;\n\n                &lt;!-- More Options Menu --&gt;\n                &lt;button mat-icon-button [matMenuTriggerFor]=\"menu\"&gt;\n                    &lt;mat-icon&gt;more_vert&lt;/mat-icon&gt;\n                &lt;/button&gt;\n\n                &lt;!-- Menu Content --&gt;\n                &lt;mat-menu #menu=\"matMenu\"&gt;\n                    &lt;button mat-menu-item&gt;Button 1&lt;/button&gt;\n                    &lt;button mat-menu-item&gt;Button 2&lt;/button&gt;\n                &lt;/mat-menu&gt;\n            &lt;/div&gt;\n        &lt;/ov-videoconference&gt;\n    `,\n    styles: [''],\n    standalone: true,\n    imports: [\n        OpenViduComponentsModule,\n        MatIconButton,\n        MatMenuTrigger,\n        MatIcon,\n        MatMenu,\n        MatMenuItem,\n    ],\n})\nexport class AppComponent {\n    // ...\n}\n</code></pre> <p>In this code snippet, the <code>*ovParticipantPanelItem</code> directive is used to replace the default participant item inside of the participants panel with a custom one. The <code>*ovParticipantPanelItem</code> directive provides a way to access the participant object and customize the participant item component to your needs.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-participants-panel/","title":"Custom participants panel using Angular Components","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-participants-panel/#custom-participants-panel-using-angular-components","title":"Custom participants panel using Angular Components","text":"<p>Source code </p> <p>The openvidu-custom-participants-panel tutorial demonstrates how to customize the participants panel, providing a more tailored user experience.</p> <p>Replacing the default participants panel is made simple with the ParticipantsPanelDirective, which offers a straightforward way to replace and adapt the ParticipantsPanelComponent to your needs.</p> <p> </p> OpenVidu Components - Custom Participants Panel","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-participants-panel/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-participants-panel/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-participants-panel/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\ngit clone https://github.com/OpenVidu/openvidu-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-participants-panel/#3-run-a-server-application","title":"3. Run a server application","text":"Node.js Go Ruby Java Python Rust PHP .NET <p>To run this server application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/node\n</code></pre></li> <li>Install dependencies <pre><code>npm install\n</code></pre></li> <li>Run the application <pre><code>npm start\n</code></pre></li> </ol> <p>For more information, check the Node.js tutorial.</p> <p>To run this server application, you need Go  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/go\n</code></pre></li> <li>Run the application <pre><code>go run main.go\n</code></pre></li> </ol> <p>For more information, check the Go tutorial.</p> <p>To run this server application, you need Ruby  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/ruby\n</code></pre></li> <li>Install dependencies <pre><code>bundle install\n</code></pre></li> <li>Run the application <pre><code>ruby app.rb\n</code></pre></li> </ol> <p>For more information, check the Ruby tutorial.</p> <p>To run this server application, you need Java  and Maven  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/java\n</code></pre></li> <li>Run the application <pre><code>mvn spring-boot:run\n</code></pre></li> </ol> <p>For more information, check the Java tutorial.</p> <p>To run this server application, you need Python 3  installed on your device.</p> <ol> <li> <p>Navigate into the server directory</p> <pre><code>cd openvidu-livekit-tutorials/application-server/python\n</code></pre> </li> <li> <p>Create a python virtual environment</p> <pre><code>python -m venv venv\n</code></pre> </li> <li> <p>Activate the virtual environment</p>  Windows macOS Linux <pre><code>.\\venv\\Scripts\\activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> </li> <li> <p>Install dependencies</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the application</p> <pre><code>python app.py\n</code></pre> </li> </ol> <p>For more information, check the Python tutorial.</p> <p>To run this server application, you need Rust  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/rust\n</code></pre></li> <li>Run the application <pre><code>cargo run\n</code></pre></li> </ol> <p>For more information, check the Rust tutorial.</p> <p>To run this server application, you need PHP  and Composer  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/php\n</code></pre></li> <li>Install dependencies <pre><code>composer install\n</code></pre></li> <li>Run the application <pre><code>composer start\n</code></pre></li> </ol> <p>Warning</p> <p>LiveKit PHP SDK requires library BCMath . This is available out-of-the-box in PHP for Windows, but a manual installation might be necessary in other OS. Run <code>sudo apt install php-bcmath</code> or <code>sudo yum install php-bcmath</code></p> <p>For more information, check the PHP tutorial.</p> <p>To run this server application, you need .NET  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/dotnet\n</code></pre></li> <li>Run the application <pre><code>dotnet run\n</code></pre></li> </ol> <p>Warning</p> <p>This .NET server application needs the <code>LIVEKIT_API_SECRET</code> env variable to be at least 32 characters long. Make sure to update it here  and in your OpenVidu Server.</p> <p>For more information, check the .NET tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-participants-panel/#4-run-the-openvidu-custom-participants-panel-tutorial","title":"4. Run the openvidu-custom-participants-panel tutorial","text":"<p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>  cd openvidu-tutorials/openvidu-components/openvidu-custom-participants-panel\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>  npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>  npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>.</p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-participants-panel/#understanding-the-code","title":"Understanding the code","text":"<p>This tutorial is an Angular project generated with Angular CLI tool. Therefore, you will see many configuration files and other components that are not the primary focus of this tutorial. We will concentrate on the following files in the <code>src</code> directory:</p> <ul> <li><code>main.ts</code>: This file defines the root application component. It imports the <code>OpenViduComponentsModule</code>, where we configure the OpenVidu Components Angular library.</li> <li><code>app/app.component.ts</code>: This file defines the AppComponent, the primary and sole component of the application. It is responsible for requesting the OpenVidu token and passing it to the videoconference component, facilitating the connection to the OpenVidu Room.</li> <li><code>styles.scss</code>: This file defines the global styles of the application. Here, you can customize the UI of the OpenVidu Components Angular library.</li> </ul> <p>To use OpenVidu Components Angular in your application, you need to install the library and import the <code>OpenViduComponentsModule</code> in your Angular module. Let's see how to do this:</p> <ol> <li> <p>Create an Angular Project (version 17 or higher)</p> <p>To begin, you will need to create a new Angular project if you haven't already. Ensure you have Node.js and the Angular CLI installed. Then, run the following command to create a new Angular project:</p> <pre><code>ng new your-project-name\n</code></pre> <p>Replace <code>your-project-name</code> with the desired name for your project.</p> </li> <li> <p>Add Angular Material to your project</p> <p>OpenVidu Components Angular needs Angular Material, which provides a range of UI components. To add Angular Material to your project, navigate to your project directory and run:</p> <pre><code>ng add @angular/material\n</code></pre> </li> <li> <p>Install OpenVidu Components Angular</p> <p>With your Angular project set up, it's time to add videoconferencing capabilities with OpenVidu Components Angular. Install the library using npm:</p> <pre><code>npm install openvidu-components-angular\n</code></pre> </li> <li> <p>Import and use OpenVidu Components Angular</p> <p>To use OpenVidu Components Angular in your application, you need to:</p> <ol> <li>Import the <code>OpenViduComponentsModule</code> in your Angular application.</li> <li>Configure the module with the <code>OpenViduComponentsConfig</code> object.</li> <li>Add the component to your template file.</li> <li>Assign the OpenVidu token and LiveKit URL to the component.</li> <li>Customize the appearance of the components using CSS variables.</li> </ol> </li> </ol> main.tsapp.component.tsstyles.scss <p>In your <code>main.ts</code> application file, import the it and configure it as follows:</p> <pre><code>// Other imports ...\n\nimport { OpenViduComponentsModule, OpenViduComponentsConfig } from 'openvidu-components-angular';\n\nconst config: OpenViduComponentsConfig = {\n    production: true,\n};\n\nbootstrapApplication(AppComponent, {\n    providers: [\n        importProvidersFrom(\n            OpenViduComponentsModule.forRoot(config)\n            // Other imports ...\n        ),\n        provideAnimations(),\n    ],\n}).catch((err) =&gt; console.error(err));\n</code></pre> <p>Use the <code>ov-videoconference</code> component to create a videoconference. This component requires a token to connect to the OpenVidu Room. The <code>AppComponent</code> class is responsible for requesting the token and passing it to the <code>ov-videoconference</code> component.</p> <pre><code>import {\n  ParticipantModel,\n  ParticipantService,\n  OpenViduComponentsModule\n} from 'openvidu-components-angular';\n\n@Component({\n  selector: 'app-root',\n  template:`\n    &lt;!-- OpenVidu Video Conference Component --&gt;\n    &lt;ov-videoconference\n      [token]=\"token\"\n      [livekitUrl]=\"LIVEKIT_URL\"\n      (onTokenRequested)=\"onTokenRequested($event)\"\n    &gt;\n      &lt;!-- Custom Participants Panel --&gt;\n      &lt;div *ovParticipantsPanel id=\"my-panel\"&gt;\n        &lt;ul id=\"local\"&gt;\n          &lt;li&gt;{{ localParticipant.name }}&lt;/li&gt;\n        &lt;/ul&gt;\n        &lt;ul id=\"remote\"&gt;\n          @for (p of remoteParticipants; track p) {\n          &lt;li&gt;{{ p.name }}&lt;/li&gt;\n          }\n        &lt;/ul&gt;\n      &lt;/div&gt;\n    &lt;/ov-videoconference&gt;\n  `,\n  styles: [''],\n  standalone: true,\n  imports: [OpenViduComponentsModule],\n})\nexport class AppComponent implements OnInit, OnDestroy {\n  // For local development, leave these variables empty\n  // For production, configure them with correct URLs depending on your deployment\n\n  APPLICATION_SERVER_URL = '';  // (1)!\n  LIVEKIT_URL = ''; // (2)!\n\n  // The name of the room to join.\n  roomName = 'openvidu-custom-participants-panel';  // (3)!\n\n  // The token used to join the room.\n  token!: string; // (4)!\n\n  // Participant-related properties\n  localParticipant!: ParticipantModel; // (5)!\n  remoteParticipants!: ParticipantModel[]; // (6)!\n  localParticipantSubs!: Subscription; // (7)!\n  remoteParticipantsSubs!: Subscription; // (8)!\n\n  constructor(private httpClient: HttpClient, private participantService: ParticipantService) {\n    this.configureUrls();\n  }\n\n  private configureUrls() {\n    // If APPLICATION_SERVER_URL is not configured, use default value from local development\n    if (!this.APPLICATION_SERVER_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.APPLICATION_SERVER_URL = 'http://localhost:6080/';\n      } else {\n        this.APPLICATION_SERVER_URL =\n          'https://' + window.location.hostname + ':6443/';\n      }\n    }\n\n    // If LIVEKIT_URL is not configured, use default value from local development\n    if (!this.LIVEKIT_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.LIVEKIT_URL = 'ws://localhost:7880/';\n      } else {\n        this.LIVEKIT_URL = 'wss://' + window.location.hostname + ':7443/';\n      }\n    }\n  }\n\n  ngOnInit() {\n    // Subscribe to participants' updates\n    this.subscribeToParticipants();\n  }\n\n  ngOnDestroy() {\n    // Unsubscribe from participant updates to prevent memory leaks\n    this.localParticipantSubs?.unsubscribe();\n    this.remoteParticipantsSubs?.unsubscribe();\n  }\n\n  // Requests a token to join the room with the given participant name.\n  async onTokenRequested(participantName: string) { // (9)!\n    const { token } = await this.getToken(this.roomName, participantName);\n    this.token = token;\n  }\n\n  // Subscribe to updates for local and remote participants\n  private subscribeToParticipants() { // (10)!\n    this.localParticipantSubs = this.participantService.localParticipant$.subscribe((p) =&gt; {\n      if (p) this.localParticipant = p;\n    });\n\n    this.remoteParticipantsSubs = this.participantService.remoteParticipants$.subscribe((participants) =&gt; {\n      this.remoteParticipants = participants;\n    });\n  }\n\n  // Retrieves a token to join the room with the given name and participant name.\n  getToken(roomName: string, participantName: string): Promise&lt;any&gt; { // (11)!\n    // Requesting token to the server application\n  }\n}\n</code></pre> <ol> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect.</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>localParticipant</code>: Local participant model.</li> <li><code>remoteParticipants</code>: Remote participants model.</li> <li><code>localParticipantSubs</code>: Subscription to the local participant updates.</li> <li><code>remoteParticipantsSubs</code>: Subscription to the remote participants updates.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>subscribeToParticipants</code> method that subscribes to updates for local and remote participants.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ol> <p>The <code>app.component.ts</code> file declares the following properties and methods:</p> <ul> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect.</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>localParticipant</code>: Local participant model.</li> <li><code>remoteParticipants</code>: Remote participants model.</li> <li><code>localParticipantSubs</code>: Subscription to the local participant updates.</li> <li><code>remoteParticipantsSubs</code>: Subscription to the remote participants updates.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>subscribeToParticipants</code> method that subscribes to updates for local and remote participants.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ul> <p>Configure the URLs</p> <p>When running OpenVidu locally, leave <code>APPLICATION_SERVER_URL</code> and <code>LIVEKIT_URL</code> variables empty. The function <code>configureUrls()</code> will automatically configure them with default values. However, for other deployment type, you should configure these variables with the correct URLs depending on your deployment.</p> <p>The OpenVidu Components Angular library provides a set of CSS variables that you can use to customize the appearance of the components. You can define these variables in your application's global styles file (e.g. <code>styles.scss</code>).</p> <pre><code>:root {\n    /* Basic colors */\n    --ov-background-color: #303030; // Background color\n    --ov-surface-color: #ffffff; // Surfaces colors (panels, dialogs)\n\n    /* Text colors */\n    --ov-text-primary-color: #ffffff; // Text color over primary background\n    --ov-text-surface-color: #1d1d1d; // Text color over surface background\n\n    /* Action colors */\n    --ov-primary-action-color: #273235; // Primary color for buttons, etc.\n    --ov-secondary-action-color: #f1f1f1; // Secondary color for buttons, etc.\n    --ov-accent-action-color: #0089ab; // Color for highlighted elements\n\n    /* Status colors */\n    --ov-error-color: #eb5144; // Error color\n    --ov-warn-color: #ffba53; // Warning color\n\n    /* Radius */\n    --ov-toolbar-buttons-radius: 50%; // Radius for toolbar buttons\n    --ov-leave-button-radius: 10px; // Radius for leave button\n    --ov-video-radius: 5px; // Radius for videos\n    --ov-surface-radius: 5px; // Radius for surfaces\n}\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-participants-panel/#customizing-participants-panel","title":"Customizing participants panel","text":"<p>This tutorial uses the <code>*ovParticipantsPanel</code> directive with the aim of replacing the default participant panel with a custom one.</p> <p>In the <code>app.component.ts</code> file, you can see the following code snippet:</p> <pre><code>@Component({\n    selector: 'app-root',\n    template: `\n        &lt;!-- OpenVidu Video Conference Component --&gt;\n    &lt;ov-videoconference\n      [token]=\"token\"\n      [livekitUrl]=\"LIVEKIT_URL\"\n      (onTokenRequested)=\"onTokenRequested($event)\"\n    &gt;\n      &lt;!-- Custom Participants Panel --&gt;\n      &lt;div *ovParticipantsPanel id=\"my-panel\"&gt;\n        &lt;ul id=\"local\"&gt;\n          &lt;li&gt;{{ localParticipant.name }}&lt;/li&gt;\n        &lt;/ul&gt;\n        &lt;ul id=\"remote\"&gt;\n          @for (p of remoteParticipants; track p) {\n          &lt;li&gt;{{ p.name }}&lt;/li&gt;\n          }\n        &lt;/ul&gt;\n      &lt;/div&gt;\n    &lt;/ov-videoconference&gt;\n    `,\n    styles: [''],\n    standalone: true,\n    imports: [OpenViduComponentsModule],\n})\nexport class AppComponent implements OnInit, OnDestroy{\n    // ...\n}\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-stream/","title":"Custom stream using Angular Components","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-stream/#custom-stream-using-angular-components","title":"Custom stream using Angular Components","text":"<p>Source code </p> <p>The openvidu-custom-stream tutorial demonstrates how to replace the default video stream with a custom one, providing a more tailored user experience.</p> <p>Customizing the video stream component is made simple with the StreamDirective, which offers a straightforward way to replace and adapt the StreamComponent to your needs.</p> <p> </p> OpenVidu Components - Custom Stream","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-stream/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-stream/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-stream/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\ngit clone https://github.com/OpenVidu/openvidu-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-stream/#3-run-a-server-application","title":"3. Run a server application","text":"Node.js Go Ruby Java Python Rust PHP .NET <p>To run this server application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/node\n</code></pre></li> <li>Install dependencies <pre><code>npm install\n</code></pre></li> <li>Run the application <pre><code>npm start\n</code></pre></li> </ol> <p>For more information, check the Node.js tutorial.</p> <p>To run this server application, you need Go  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/go\n</code></pre></li> <li>Run the application <pre><code>go run main.go\n</code></pre></li> </ol> <p>For more information, check the Go tutorial.</p> <p>To run this server application, you need Ruby  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/ruby\n</code></pre></li> <li>Install dependencies <pre><code>bundle install\n</code></pre></li> <li>Run the application <pre><code>ruby app.rb\n</code></pre></li> </ol> <p>For more information, check the Ruby tutorial.</p> <p>To run this server application, you need Java  and Maven  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/java\n</code></pre></li> <li>Run the application <pre><code>mvn spring-boot:run\n</code></pre></li> </ol> <p>For more information, check the Java tutorial.</p> <p>To run this server application, you need Python 3  installed on your device.</p> <ol> <li> <p>Navigate into the server directory</p> <pre><code>cd openvidu-livekit-tutorials/application-server/python\n</code></pre> </li> <li> <p>Create a python virtual environment</p> <pre><code>python -m venv venv\n</code></pre> </li> <li> <p>Activate the virtual environment</p>  Windows macOS Linux <pre><code>.\\venv\\Scripts\\activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> </li> <li> <p>Install dependencies</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the application</p> <pre><code>python app.py\n</code></pre> </li> </ol> <p>For more information, check the Python tutorial.</p> <p>To run this server application, you need Rust  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/rust\n</code></pre></li> <li>Run the application <pre><code>cargo run\n</code></pre></li> </ol> <p>For more information, check the Rust tutorial.</p> <p>To run this server application, you need PHP  and Composer  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/php\n</code></pre></li> <li>Install dependencies <pre><code>composer install\n</code></pre></li> <li>Run the application <pre><code>composer start\n</code></pre></li> </ol> <p>Warning</p> <p>LiveKit PHP SDK requires library BCMath . This is available out-of-the-box in PHP for Windows, but a manual installation might be necessary in other OS. Run <code>sudo apt install php-bcmath</code> or <code>sudo yum install php-bcmath</code></p> <p>For more information, check the PHP tutorial.</p> <p>To run this server application, you need .NET  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/dotnet\n</code></pre></li> <li>Run the application <pre><code>dotnet run\n</code></pre></li> </ol> <p>Warning</p> <p>This .NET server application needs the <code>LIVEKIT_API_SECRET</code> env variable to be at least 32 characters long. Make sure to update it here  and in your OpenVidu Server.</p> <p>For more information, check the .NET tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-stream/#4-run-the-openvidu-custom-stream-tutorial","title":"4. Run the openvidu-custom-stream tutorial","text":"<p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>  cd openvidu-tutorials/openvidu-components/openvidu-custom-stream\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>  npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>  npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>.</p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-stream/#understanding-the-code","title":"Understanding the code","text":"<p>This tutorial is an Angular project generated with Angular CLI tool. Therefore, you will see many configuration files and other components that are not the primary focus of this tutorial. We will concentrate on the following files in the <code>src</code> directory:</p> <ul> <li><code>main.ts</code>: This file defines the root application component. It imports the <code>OpenViduComponentsModule</code>, where we configure the OpenVidu Components Angular library.</li> <li><code>app/app.component.ts</code>: This file defines the AppComponent, the primary and sole component of the application. It is responsible for requesting the OpenVidu token and passing it to the videoconference component, facilitating the connection to the OpenVidu Room.</li> <li><code>styles.scss</code>: This file defines the global styles of the application. Here, you can customize the UI of the OpenVidu Components Angular library.</li> </ul> <p>To use OpenVidu Components Angular in your application, you need to install the library and import the <code>OpenViduComponentsModule</code> in your Angular module. Let's see how to do this:</p> <ol> <li> <p>Create an Angular Project (version 17 or higher)</p> <p>To begin, you will need to create a new Angular project if you haven't already. Ensure you have Node.js and the Angular CLI installed. Then, run the following command to create a new Angular project:</p> <pre><code>ng new your-project-name\n</code></pre> <p>Replace <code>your-project-name</code> with the desired name for your project.</p> </li> <li> <p>Add Angular Material to your project</p> <p>OpenVidu Components Angular needs Angular Material, which provides a range of UI components. To add Angular Material to your project, navigate to your project directory and run:</p> <pre><code>ng add @angular/material\n</code></pre> </li> <li> <p>Install OpenVidu Components Angular</p> <p>With your Angular project set up, it's time to add videoconferencing capabilities with OpenVidu Components Angular. Install the library using npm:</p> <pre><code>npm install openvidu-components-angular\n</code></pre> </li> <li> <p>Import and use OpenVidu Components Angular</p> <p>To use OpenVidu Components Angular in your application, you need to:</p> <ol> <li>Import the <code>OpenViduComponentsModule</code> in your Angular application.</li> <li>Configure the module with the <code>OpenViduComponentsConfig</code> object.</li> <li>Add the component to your template file.</li> <li>Assign the OpenVidu token and LiveKit URL to the component.</li> <li>Customize the appearance of the components using CSS variables.</li> </ol> </li> </ol> main.tsapp.component.tsstyles.scss <p>In your <code>main.ts</code> application file, import the it and configure it as follows:</p> <pre><code>// Other imports ...\n\nimport { OpenViduComponentsModule, OpenViduComponentsConfig } from 'openvidu-components-angular';\n\nconst config: OpenViduComponentsConfig = {\n    production: true,\n};\n\nbootstrapApplication(AppComponent, {\n    providers: [\n        importProvidersFrom(\n            OpenViduComponentsModule.forRoot(config)\n            // Other imports ...\n        ),\n        provideAnimations(),\n    ],\n}).catch((err) =&gt; console.error(err));\n</code></pre> <p>Use the <code>ov-videoconference</code> component to create a videoconference. This component requires a token to connect to the OpenVidu Room. The <code>AppComponent</code> class is responsible for requesting the token and passing it to the <code>ov-videoconference</code> component.</p> <pre><code>import { OpenViduComponentsModule } from 'openvidu-components-angular';\n\n@Component({\n  selector: 'app-root',\n  template:`\n        &lt;!-- OpenVidu Video Conference Component --&gt;\n      &lt;ov-videoconference\n        [token]=\"token\"\n        [livekitUrl]=\"LIVEKIT_URL\"\n        (onTokenRequested)=\"onTokenRequested($event)\"\n      &gt;\n        &lt;!-- Display Video Streams --&gt;\n        &lt;div *ovStream=\"let track\"&gt;\n          &lt;!-- Video Stream Component --&gt;\n          &lt;ov-stream [track]=\"track\" [displayParticipantName]=\"false\"&gt;&lt;/ov-stream&gt;\n\n          &lt;!-- Display Participant's Name --&gt;\n          &lt;p&gt;{{ track.participant.name }}&lt;/p&gt;\n        &lt;/div&gt;\n      &lt;/ov-videoconference&gt;\n  `,\n  styles: [''],\n  standalone: true,\n  imports: [OpenViduComponentsModule],\n})\nexport class AppComponent {\n  // For local development, leave these variables empty\n  // For production, configure them with correct URLs depending on your deployment\n\n  APPLICATION_SERVER_URL = '';  // (1)!\n  LIVEKIT_URL = ''; // (2)!\n\n  // The name of the room to join.\n  roomName = 'openvidu-custom-stream';  // (3)!\n\n  // The token used to join the room.\n  token!: string; // (4)!\n\n  constructor(private httpClient: HttpClient) {\n    this.configureUrls();\n  }\n\n  private configureUrls() {\n    // If APPLICATION_SERVER_URL is not configured, use default value from local development\n    if (!this.APPLICATION_SERVER_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.APPLICATION_SERVER_URL = 'http://localhost:6080/';\n      } else {\n        this.APPLICATION_SERVER_URL =\n          'https://' + window.location.hostname + ':6443/';\n      }\n    }\n\n    // If LIVEKIT_URL is not configured, use default value from local development\n    if (!this.LIVEKIT_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.LIVEKIT_URL = 'ws://localhost:7880/';\n      } else {\n        this.LIVEKIT_URL = 'wss://' + window.location.hostname + ':7443/';\n      }\n    }\n  }\n\n  // Requests a token to join the room with the given participant name.\n  async onTokenRequested(participantName: string) { // (5)!\n    const { token } = await this.getToken(this.roomName, participantName);\n    this.token = token;\n  }\n\n  // Retrieves a token to join the room with the given name and participant name.\n  getToken(roomName: string, participantName: string): Promise&lt;any&gt; { // (6)!\n    // Requesting token to the server application\n  }\n}\n</code></pre> <ol> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect.</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ol> <p>The <code>app.component.ts</code> file declares the following properties and methods:</p> <ul> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect.</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ul> <p>Configure the URLs</p> <p>When running OpenVidu locally, leave <code>APPLICATION_SERVER_URL</code> and <code>LIVEKIT_URL</code> variables empty. The function <code>configureUrls()</code> will automatically configure them with default values. However, for other deployment type, you should configure these variables with the correct URLs depending on your deployment.</p> <p>The OpenVidu Components Angular library provides a set of CSS variables that you can use to customize the appearance of the components. You can define these variables in your application's global styles file (e.g. <code>styles.scss</code>).</p> <pre><code>:root {\n    /* Basic colors */\n    --ov-background-color: #303030; // Background color\n    --ov-surface-color: #ffffff; // Surfaces colors (panels, dialogs)\n\n    /* Text colors */\n    --ov-text-primary-color: #ffffff; // Text color over primary background\n    --ov-text-surface-color: #1d1d1d; // Text color over surface background\n\n    /* Action colors */\n    --ov-primary-action-color: #273235; // Primary color for buttons, etc.\n    --ov-secondary-action-color: #f1f1f1; // Secondary color for buttons, etc.\n    --ov-accent-action-color: #0089ab; // Color for highlighted elements\n\n    /* Status colors */\n    --ov-error-color: #eb5144; // Error color\n    --ov-warn-color: #ffba53; // Warning color\n\n    /* Radius */\n    --ov-toolbar-buttons-radius: 50%; // Radius for toolbar buttons\n    --ov-leave-button-radius: 10px; // Radius for leave button\n    --ov-video-radius: 5px; // Radius for videos\n    --ov-surface-radius: 5px; // Radius for surfaces\n}\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-stream/#customizing-the-video-stream","title":"Customizing the video stream","text":"<p>The <code>*ovStream</code> directive is used to replace the default video stream with a custom one and allows you to customize the video stream component to your needs. It provides a way to access the video stream track and the participant name.</p> <p>In the <code>app.component.ts</code> file, you can see the following code snippet:</p> <pre><code>@Component({\n    selector: 'app-root',\n    template: `\n        &lt;!-- OpenVidu Video Conference Component --&gt;\n        &lt;ov-videoconference\n            [token]=\"token\"\n            [livekitUrl]=\"LIVEKIT_URL\"\n            (onTokenRequested)=\"onTokenRequested($event)\"\n        &gt;\n            &lt;!-- Display Video Streams --&gt;\n            &lt;div *ovStream=\"let track\"&gt;\n                &lt;!-- Video Stream Component --&gt;\n                &lt;ov-stream [track]=\"track\" [displayParticipantName]=\"false\"&gt;&lt;/ov-stream&gt;\n\n                &lt;!-- Display Participant's Name --&gt;\n                &lt;p&gt;{{ track.participant.name }}&lt;/p&gt;\n            &lt;/div&gt;\n        &lt;/ov-videoconference&gt;\n    `,\n    styles: [''],\n    standalone: true,\n    imports: [OpenViduComponentsModule],\n})\nexport class AppComponent {\n    // ...\n}\n</code></pre> <p>In this code snippet, the <code>*ovStream</code> directive provides access to the ParticipantTrackPublication object, which contains the video stream track and the participant name.</p> <p>The <code>track</code> object is passed to the <code>ov-stream</code> component to display the video stream. The <code>track.participant.name</code> object is used to display the participant's name.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-toolbar/","title":"Custom toolbar using Angular Components","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-toolbar/#custom-toolbar-using-angular-components","title":"Custom toolbar using Angular Components","text":"<p>Source code </p> <p>The openvidu-custom-toolbar tutorial demonstrates how to replace the default toolbar with a custom one, providing a more tailored user experience.</p> <p>Customizing the toolbar is made simple with the ToolbarDirective, which offers a straightforward way to replace and adapt the ToolbarComponent to your needs.</p> <p> </p> OpenVidu Components - Custom Toolbar","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-toolbar/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-toolbar/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-toolbar/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\ngit clone https://github.com/OpenVidu/openvidu-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-toolbar/#3-run-a-server-application","title":"3. Run a server application","text":"Node.js Go Ruby Java Python Rust PHP .NET <p>To run this server application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/node\n</code></pre></li> <li>Install dependencies <pre><code>npm install\n</code></pre></li> <li>Run the application <pre><code>npm start\n</code></pre></li> </ol> <p>For more information, check the Node.js tutorial.</p> <p>To run this server application, you need Go  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/go\n</code></pre></li> <li>Run the application <pre><code>go run main.go\n</code></pre></li> </ol> <p>For more information, check the Go tutorial.</p> <p>To run this server application, you need Ruby  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/ruby\n</code></pre></li> <li>Install dependencies <pre><code>bundle install\n</code></pre></li> <li>Run the application <pre><code>ruby app.rb\n</code></pre></li> </ol> <p>For more information, check the Ruby tutorial.</p> <p>To run this server application, you need Java  and Maven  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/java\n</code></pre></li> <li>Run the application <pre><code>mvn spring-boot:run\n</code></pre></li> </ol> <p>For more information, check the Java tutorial.</p> <p>To run this server application, you need Python 3  installed on your device.</p> <ol> <li> <p>Navigate into the server directory</p> <pre><code>cd openvidu-livekit-tutorials/application-server/python\n</code></pre> </li> <li> <p>Create a python virtual environment</p> <pre><code>python -m venv venv\n</code></pre> </li> <li> <p>Activate the virtual environment</p>  Windows macOS Linux <pre><code>.\\venv\\Scripts\\activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> </li> <li> <p>Install dependencies</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the application</p> <pre><code>python app.py\n</code></pre> </li> </ol> <p>For more information, check the Python tutorial.</p> <p>To run this server application, you need Rust  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/rust\n</code></pre></li> <li>Run the application <pre><code>cargo run\n</code></pre></li> </ol> <p>For more information, check the Rust tutorial.</p> <p>To run this server application, you need PHP  and Composer  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/php\n</code></pre></li> <li>Install dependencies <pre><code>composer install\n</code></pre></li> <li>Run the application <pre><code>composer start\n</code></pre></li> </ol> <p>Warning</p> <p>LiveKit PHP SDK requires library BCMath . This is available out-of-the-box in PHP for Windows, but a manual installation might be necessary in other OS. Run <code>sudo apt install php-bcmath</code> or <code>sudo yum install php-bcmath</code></p> <p>For more information, check the PHP tutorial.</p> <p>To run this server application, you need .NET  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/dotnet\n</code></pre></li> <li>Run the application <pre><code>dotnet run\n</code></pre></li> </ol> <p>Warning</p> <p>This .NET server application needs the <code>LIVEKIT_API_SECRET</code> env variable to be at least 32 characters long. Make sure to update it here  and in your OpenVidu Server.</p> <p>For more information, check the .NET tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-toolbar/#4-run-the-openvidu-custom-toolbar-tutorial","title":"4. Run the openvidu-custom-toolbar tutorial","text":"<p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>  cd openvidu-tutorials/openvidu-components/openvidu-custom-toolbar\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>  npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>  npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>.</p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-toolbar/#understanding-the-code","title":"Understanding the code","text":"<p>This tutorial is an Angular project generated with Angular CLI tool. Therefore, you will see many configuration files and other components that are not the primary focus of this tutorial. We will concentrate on the following files in the <code>src</code> directory:</p> <ul> <li><code>main.ts</code>: This file defines the root application component. It imports the <code>OpenViduComponentsModule</code>, where we configure the OpenVidu Components Angular library.</li> <li><code>app/app.component.ts</code>: This file defines the AppComponent, the primary and sole component of the application. It is responsible for requesting the OpenVidu token and passing it to the videoconference component, facilitating the connection to the OpenVidu Room.</li> <li><code>styles.scss</code>: This file defines the global styles of the application. Here, you can customize the UI of the OpenVidu Components Angular library.</li> </ul> <p>To use OpenVidu Components Angular in your application, you need to install the library and import the <code>OpenViduComponentsModule</code> in your Angular module. Let's see how to do this:</p> <ol> <li> <p>Create an Angular Project (version 17 or higher)</p> <p>To begin, you will need to create a new Angular project if you haven't already. Ensure you have Node.js and the Angular CLI installed. Then, run the following command to create a new Angular project:</p> <pre><code>ng new your-project-name\n</code></pre> <p>Replace <code>your-project-name</code> with the desired name for your project.</p> </li> <li> <p>Add Angular Material to your project</p> <p>OpenVidu Components Angular needs Angular Material, which provides a range of UI components. To add Angular Material to your project, navigate to your project directory and run:</p> <pre><code>ng add @angular/material\n</code></pre> </li> <li> <p>Install OpenVidu Components Angular</p> <p>With your Angular project set up, it's time to add videoconferencing capabilities with OpenVidu Components Angular. Install the library using npm:</p> <pre><code>npm install openvidu-components-angular\n</code></pre> </li> <li> <p>Import and use OpenVidu Components Angular</p> <p>To use OpenVidu Components Angular in your application, you need to:</p> <ol> <li>Import the <code>OpenViduComponentsModule</code> in your Angular application.</li> <li>Configure the module with the <code>OpenViduComponentsConfig</code> object.</li> <li>Add the component to your template file.</li> <li>Assign the OpenVidu token and LiveKit URL to the component.</li> <li>Customize the appearance of the components using CSS variables.</li> </ol> </li> </ol> main.tsapp.component.tsstyles.scss <p>In your <code>main.ts</code> application file, import the it and configure it as follows:</p> <pre><code>// Other imports ...\n\nimport { OpenViduComponentsModule, OpenViduComponentsConfig } from 'openvidu-components-angular';\n\nconst config: OpenViduComponentsConfig = {\n    production: true,\n};\n\nbootstrapApplication(AppComponent, {\n    providers: [\n        importProvidersFrom(\n            OpenViduComponentsModule.forRoot(config)\n            // Other imports ...\n        ),\n        provideAnimations(),\n    ],\n}).catch((err) =&gt; console.error(err));\n</code></pre> <p>Use the <code>ov-videoconference</code> component to create a videoconference. This component requires a token to connect to the OpenVidu Room. The <code>AppComponent</code> class is responsible for requesting the token and passing it to the <code>ov-videoconference</code> component.</p> <pre><code>import { OpenViduComponentsModule, ParticipantService } from 'openvidu-components-angular';\n\n@Component({\n  selector: 'app-root',\n  template:`\n    &lt;ov-videoconference\n      [token]=\"token\"\n      [livekitUrl]=\"LIVEKIT_URL\"\n      (onTokenRequested)=\"onTokenRequested($event)\"\n    &gt;\n      &lt;div *ovToolbar style=\"text-align: center;\"&gt;\n        &lt;button (click)=\"toggleVideo()\"&gt;Toggle Video&lt;/button&gt;\n        &lt;button (click)=\"toggleAudio()\"&gt;Toggle Audio&lt;/button&gt;\n      &lt;/div&gt;\n    &lt;/ov-videoconference&gt;\n  `,\n  styles: [''],\n  standalone: true,\n  imports: [OpenViduComponentsModule],\n})\nexport class AppComponent {\n  // For local development, leave these variables empty\n  // For production, configure them with correct URLs depending on your deployment\n\n  APPLICATION_SERVER_URL = '';  // (1)!\n  LIVEKIT_URL = ''; // (2)!\n\n  // The name of the room to join.\n  roomName = 'openvidu-custom-toolbar';  // (3)!\n\n  // The token used to join the room.\n  token!: string; // (4)!\n\n  constructor(private httpClient: HttpClient, private participantService: ParticipantService) {\n    this.configureUrls();\n  }\n\n  private configureUrls() {\n    // If APPLICATION_SERVER_URL is not configured, use default value from local development\n    if (!this.APPLICATION_SERVER_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.APPLICATION_SERVER_URL = 'http://localhost:6080/';\n      } else {\n        this.APPLICATION_SERVER_URL =\n          'https://' + window.location.hostname + ':6443/';\n      }\n    }\n\n    // If LIVEKIT_URL is not configured, use default value from local development\n    if (!this.LIVEKIT_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.LIVEKIT_URL = 'ws://localhost:7880/';\n      } else {\n        this.LIVEKIT_URL = 'wss://' + window.location.hostname + ':7443/';\n      }\n    }\n  }\n\n  // Requests a token to join the room with the given participant name.\n  async onTokenRequested(participantName: string) { // (5)!\n    const { token } = await this.getToken(this.roomName, participantName);\n    this.token = token;\n  }\n\n  // Toggles the camera on and off.\n  async toggleVideo() { // (6)!\n    const isCameraEnabled = this.participantService.isMyCameraEnabled();\n    await this.participantService.setCameraEnabled(!isCameraEnabled);\n  }\n\n  // Toggles the microphone on and off.\n  async toggleAudio() { // (7)!\n    const isMicrophoneEnabled = this.participantService.isMyMicrophoneEnabled();\n    await this.participantService.setMicrophoneEnabled(!isMicrophoneEnabled);\n  }\n\n  // Retrieves a token to join the room with the given name and participant name.\n  getToken(roomName: string, participantName: string): Promise&lt;any&gt; { // (8)!\n    // Requesting token to the server application\n  }\n}\n</code></pre> <ol> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect.</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>toggleVideo</code> method that toggles the camera on and off.</li> <li><code>toggleAudio</code> method that toggles the microphone on and off.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ol> <p>The <code>app.component.ts</code> file declares the following properties and methods:</p> <ul> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect.</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>toggleVideo</code> method that toggles the camera on and off.</li> <li><code>toggleAudio</code> method that toggles the microphone on and off.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ul> <p>Configure the URLs</p> <p>When running OpenVidu locally, leave <code>APPLICATION_SERVER_URL</code> and <code>LIVEKIT_URL</code> variables empty. The function <code>configureUrls()</code> will automatically configure them with default values. However, for other deployment type, you should configure these variables with the correct URLs depending on your deployment.</p> <p>The OpenVidu Components Angular library provides a set of CSS variables that you can use to customize the appearance of the components. You can define these variables in your application's global styles file (e.g. <code>styles.scss</code>).</p> <pre><code>:root {\n    /* Basic colors */\n    --ov-background-color: #303030; // Background color\n    --ov-surface-color: #ffffff; // Surfaces colors (panels, dialogs)\n\n    /* Text colors */\n    --ov-text-primary-color: #ffffff; // Text color over primary background\n    --ov-text-surface-color: #1d1d1d; // Text color over surface background\n\n    /* Action colors */\n    --ov-primary-action-color: #273235; // Primary color for buttons, etc.\n    --ov-secondary-action-color: #f1f1f1; // Secondary color for buttons, etc.\n    --ov-accent-action-color: #0089ab; // Color for highlighted elements\n\n    /* Status colors */\n    --ov-error-color: #eb5144; // Error color\n    --ov-warn-color: #ffba53; // Warning color\n\n    /* Radius */\n    --ov-toolbar-buttons-radius: 50%; // Radius for toolbar buttons\n    --ov-leave-button-radius: 10px; // Radius for leave button\n    --ov-video-radius: 5px; // Radius for videos\n    --ov-surface-radius: 5px; // Radius for surfaces\n}\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-toolbar/#customizing-the-toolbar","title":"Customizing the toolbar","text":"<p>The <code>*ov-toolbar</code> directive allows you to replace the default toolbar with a custom one. This directive is applied to a <code>div</code> element that contains the custom toolbar elements.</p> <p>In the <code>app.component.ts</code> file, you can see the following code snippet:</p> <pre><code>@Component({\n  selector: 'app-root',\n  template:`\n    &lt;ov-videoconference\n      [token]=\"token\"\n      [livekitUrl]=\"LIVEKIT_URL\"\n      (onTokenRequested)=\"onTokenRequested($event)\"\n    &gt;\n      &lt;div *ovToolbar style=\"text-align: center;\"&gt;\n        &lt;button (click)=\"toggleVideo()\"&gt;Toggle Video&lt;/button&gt;\n        &lt;button (click)=\"toggleAudio()\"&gt;Toggle Audio&lt;/button&gt;\n      &lt;/div&gt;\n\n    &lt;/ov-videoconference&gt;\n  `,\n  styles: [''],\n  standalone: true,\n  imports: [OpenViduComponentsModule],\n})\nexport class AppComponent {\n  // ...\n}\n</code></pre> <p>In this code snippet, the <code>*ov-toolbar</code> directive is applied to a <code>div</code> element that contains two buttons. These buttons are used to toggle the camera and microphone on and off.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-ui/","title":"Custom UI using Angular Components","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-ui/#custom-ui-using-angular-components","title":"Custom UI using Angular Components","text":"<p>Source code </p> <p>Creating a unique and intuitive user interface (UI) is essential for ensuring a great user experience. OpenVidu Components Angular allows for flexibility in UI customization to fit your application's design requirements.</p> <p> </p> OpenVidu Components - Custom UI","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-ui/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-ui/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-ui/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\ngit clone https://github.com/OpenVidu/openvidu-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-ui/#3-run-a-server-application","title":"3. Run a server application","text":"Node.js Go Ruby Java Python Rust PHP .NET <p>To run this server application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/node\n</code></pre></li> <li>Install dependencies <pre><code>npm install\n</code></pre></li> <li>Run the application <pre><code>npm start\n</code></pre></li> </ol> <p>For more information, check the Node.js tutorial.</p> <p>To run this server application, you need Go  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/go\n</code></pre></li> <li>Run the application <pre><code>go run main.go\n</code></pre></li> </ol> <p>For more information, check the Go tutorial.</p> <p>To run this server application, you need Ruby  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/ruby\n</code></pre></li> <li>Install dependencies <pre><code>bundle install\n</code></pre></li> <li>Run the application <pre><code>ruby app.rb\n</code></pre></li> </ol> <p>For more information, check the Ruby tutorial.</p> <p>To run this server application, you need Java  and Maven  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/java\n</code></pre></li> <li>Run the application <pre><code>mvn spring-boot:run\n</code></pre></li> </ol> <p>For more information, check the Java tutorial.</p> <p>To run this server application, you need Python 3  installed on your device.</p> <ol> <li> <p>Navigate into the server directory</p> <pre><code>cd openvidu-livekit-tutorials/application-server/python\n</code></pre> </li> <li> <p>Create a python virtual environment</p> <pre><code>python -m venv venv\n</code></pre> </li> <li> <p>Activate the virtual environment</p>  Windows macOS Linux <pre><code>.\\venv\\Scripts\\activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> </li> <li> <p>Install dependencies</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the application</p> <pre><code>python app.py\n</code></pre> </li> </ol> <p>For more information, check the Python tutorial.</p> <p>To run this server application, you need Rust  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/rust\n</code></pre></li> <li>Run the application <pre><code>cargo run\n</code></pre></li> </ol> <p>For more information, check the Rust tutorial.</p> <p>To run this server application, you need PHP  and Composer  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/php\n</code></pre></li> <li>Install dependencies <pre><code>composer install\n</code></pre></li> <li>Run the application <pre><code>composer start\n</code></pre></li> </ol> <p>Warning</p> <p>LiveKit PHP SDK requires library BCMath . This is available out-of-the-box in PHP for Windows, but a manual installation might be necessary in other OS. Run <code>sudo apt install php-bcmath</code> or <code>sudo yum install php-bcmath</code></p> <p>For more information, check the PHP tutorial.</p> <p>To run this server application, you need .NET  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/dotnet\n</code></pre></li> <li>Run the application <pre><code>dotnet run\n</code></pre></li> </ol> <p>Warning</p> <p>This .NET server application needs the <code>LIVEKIT_API_SECRET</code> env variable to be at least 32 characters long. Make sure to update it here  and in your OpenVidu Server.</p> <p>For more information, check the .NET tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-ui/#4-run-the-openvidu-custom-ui-tutorial","title":"4. Run the openvidu-custom-ui tutorial","text":"<p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>  cd openvidu-tutorials/openvidu-components/openvidu-custom-ui\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>  npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>  npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>.</p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-ui/#understanding-the-code","title":"Understanding the code","text":"<p>This tutorial is an Angular project generated with Angular CLI tool. Therefore, you will see many configuration files and other components that are not the primary focus of this tutorial. We will concentrate on the following files in the <code>src</code> directory:</p> <ul> <li><code>main.ts</code>: This file defines the root application component. It imports the <code>OpenViduComponentsModule</code>, where we configure the OpenVidu Components Angular library.</li> <li><code>app/app.component.ts</code>: This file defines the AppComponent, the primary and sole component of the application. It is responsible for requesting the OpenVidu token and passing it to the videoconference component, facilitating the connection to the OpenVidu Room.</li> <li><code>styles.scss</code>: This file defines the global styles of the application. Here, you can customize the UI of the OpenVidu Components Angular library.</li> </ul> <p>To use OpenVidu Components Angular in your application, you need to install the library and import the <code>OpenViduComponentsModule</code> in your Angular module. Let's see how to do this:</p> <ol> <li> <p>Create an Angular Project (version 17 or higher)</p> <p>To begin, you will need to create a new Angular project if you haven't already. Ensure you have Node.js and the Angular CLI installed. Then, run the following command to create a new Angular project:</p> <pre><code>ng new your-project-name\n</code></pre> <p>Replace <code>your-project-name</code> with the desired name for your project.</p> </li> <li> <p>Add Angular Material to your project</p> <p>OpenVidu Components Angular needs Angular Material, which provides a range of UI components. To add Angular Material to your project, navigate to your project directory and run:</p> <pre><code>ng add @angular/material\n</code></pre> </li> <li> <p>Install OpenVidu Components Angular</p> <p>With your Angular project set up, it's time to add videoconferencing capabilities with OpenVidu Components Angular. Install the library using npm:</p> <pre><code>npm install openvidu-components-angular\n</code></pre> </li> <li> <p>Import and use OpenVidu Components Angular</p> <p>To use OpenVidu Components Angular in your application, you need to:</p> <ol> <li>Import the <code>OpenViduComponentsModule</code> in your Angular application.</li> <li>Configure the module with the <code>OpenViduComponentsConfig</code> object.</li> <li>Add the component to your template file.</li> <li>Assign the OpenVidu token and LiveKit URL to the component.</li> <li>Customize the appearance of the components using CSS variables.</li> </ol> </li> </ol> main.tsapp.component.tsstyles.scss <p>In your <code>main.ts</code> application file, import the it and configure it as follows:</p> <pre><code>// Other imports ...\n\nimport { OpenViduComponentsModule, OpenViduComponentsConfig } from 'openvidu-components-angular';\n\nconst config: OpenViduComponentsConfig = {\n    production: true,\n};\n\nbootstrapApplication(AppComponent, {\n    providers: [\n        importProvidersFrom(\n            OpenViduComponentsModule.forRoot(config)\n            // Other imports ...\n        ),\n        provideAnimations(),\n    ],\n}).catch((err) =&gt; console.error(err));\n</code></pre> <p>Use the <code>ov-videoconference</code> component to create a videoconference. This component requires a token to connect to the OpenVidu Room. The <code>AppComponent</code> class is responsible for requesting the token and passing it to the <code>ov-videoconference</code> component.</p> <pre><code>import { OpenViduComponentsModule } from 'openvidu-components-angular';\n\n@Component({\n  selector: 'app-root',\n  template:`\n    &lt;ov-videoconference\n      [token]=\"token\"\n      [livekitUrl]=\"LIVEKIT_URL\"\n      (onTokenRequested)=\"onTokenRequested($event)\"\n    &gt;\n    &lt;/ov-videoconference&gt;\n  `,\n  styles: [''],\n  standalone: true,\n  imports: [OpenViduComponentsModule],\n})\nexport class AppComponent {\n  // For local development, leave these variables empty\n  // For production, configure them with correct URLs depending on your deployment\n\n  APPLICATION_SERVER_URL = '';  // (1)!\n  LIVEKIT_URL = ''; // (2)!\n\n  // The name of the room to join.\n  roomName = 'openvidu-custom-ui';  // (3)!\n\n  // The token used to join the room.\n  token!: string; // (4)!\n\n  constructor(private httpClient: HttpClient) {\n    this.configureUrls();\n  }\n\n  private configureUrls() {\n    // If APPLICATION_SERVER_URL is not configured, use default value from local development\n    if (!this.APPLICATION_SERVER_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.APPLICATION_SERVER_URL = 'http://localhost:6080/';\n      } else {\n        this.APPLICATION_SERVER_URL =\n          'https://' + window.location.hostname + ':6443/';\n      }\n    }\n\n    // If LIVEKIT_URL is not configured, use default value from local development\n    if (!this.LIVEKIT_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.LIVEKIT_URL = 'ws://localhost:7880/';\n      } else {\n        this.LIVEKIT_URL = 'wss://' + window.location.hostname + ':7443/';\n      }\n    }\n  }\n\n  // Requests a token to join the room with the given participant name.\n  async onTokenRequested(participantName: string) { // (5)!\n    const { token } = await this.getToken(this.roomName, participantName);\n    this.token = token;\n  }\n\n  // Retrieves a token to join the room with the given name and participant name.\n  getToken(roomName: string, participantName: string): Promise&lt;any&gt; { // (6)!\n    // Requesting token to the server application\n  }\n}\n</code></pre> <ol> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ol> <p>The <code>app.component.ts</code> file declares the following properties and methods:</p> <ul> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ul> <p>Configure the URLs</p> <p>When running OpenVidu locally, leave <code>APPLICATION_SERVER_URL</code> and <code>LIVEKIT_URL</code> variables empty. The function <code>configureUrls()</code> will automatically configure them with default values. However, for other deployment type, you should configure these variables with the correct URLs depending on your deployment.</p> <p>The OpenVidu Components Angular library provides a set of CSS variables that you can use to customize the appearance of the components. You can define these variables in your application's global styles file (e.g. <code>styles.scss</code>).</p> <pre><code>:root {\n    /* Basic colors */\n    --ov-background-color: #303030; // Background color\n    --ov-surface-color: #ffffff; // Surfaces colors (panels, dialogs)\n\n    /* Text colors */\n    --ov-text-primary-color: #ffffff; // Text color over primary background\n    --ov-text-surface-color: #1d1d1d; // Text color over surface background\n\n    /* Action colors */\n    --ov-primary-action-color: #273235; // Primary color for buttons, etc.\n    --ov-secondary-action-color: #f1f1f1; // Secondary color for buttons, etc.\n    --ov-accent-action-color: #0089ab; // Color for highlighted elements\n\n    /* Status colors */\n    --ov-error-color: #eb5144; // Error color\n    --ov-warn-color: #ffba53; // Warning color\n\n    /* Radius */\n    --ov-toolbar-buttons-radius: 50%; // Radius for toolbar buttons\n    --ov-leave-button-radius: 10px; // Radius for leave button\n    --ov-video-radius: 5px; // Radius for videos\n    --ov-surface-radius: 5px; // Radius for surfaces\n}\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-ui/#customizing-the-ui","title":"Customizing the UI","text":"<p>To customize the appearance of OpenVidu Components, simply redefine the necessary CSS variables in your <code>styles.scss</code> file. For instance, to change the primary color used throughout your application, you would update the <code>--ov-primary-color</code> variable as shown below:</p> <pre><code>:root {\n  --ov-primary-color: #yourNewColor; /* Replace #yourNewColor with your chosen hex color code */\n\n  /* Others variables ... */\n}\n</code></pre> <p>Once you redefine a variable, the new style will automatically apply to all components in the OpenVidu UI that use that variable.</p> <p>The library also allows you to customize shape of buttons, panels and videos customization, the background color personalization of panels, buttons and videoconference and also you can change the text color.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-custom-ui/#replacing-the-branding-logo","title":"Replacing the branding logo","text":"<p>You can replace the branding logo with your own. Just modify the <code>src/assets/images/logo.png</code> file with your own logo.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-toggle-hand/","title":"Add toggle hand feature using Angular Components","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-toggle-hand/#add-toggle-hand-feature-using-angular-components","title":"Add toggle hand feature using Angular Components","text":"<p>Source code </p> <p>The openvidu-toggle-hand tutorial demonstrates how to add a toggle hand feature to the OpenVidu Components Angular library.</p> <p>The toggle hand feature allows participants to raise and lower their hand during a videoconference. This feature is useful for participants to signal that they want to speak or ask a question.</p> <p>This tutorial combines the use of the ToolbarAdditionalButtonsDirective, the StreamDirective and the ParticipantsPanelItemElementsDirective to create a custom toolbar button, a custom stream component element and a custom participant panel item element. Check the openvidu-toolbar-buttons and the openvidu-custom-stream tutorials documentation for learning more about these directives.</p> <p> </p> OpenVidu Components - Toggle Hand","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-toggle-hand/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-toggle-hand/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-toggle-hand/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\ngit clone https://github.com/OpenVidu/openvidu-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-toggle-hand/#3-run-a-server-application","title":"3. Run a server application","text":"Node.js Go Ruby Java Python Rust PHP .NET <p>To run this server application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/node\n</code></pre></li> <li>Install dependencies <pre><code>npm install\n</code></pre></li> <li>Run the application <pre><code>npm start\n</code></pre></li> </ol> <p>For more information, check the Node.js tutorial.</p> <p>To run this server application, you need Go  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/go\n</code></pre></li> <li>Run the application <pre><code>go run main.go\n</code></pre></li> </ol> <p>For more information, check the Go tutorial.</p> <p>To run this server application, you need Ruby  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/ruby\n</code></pre></li> <li>Install dependencies <pre><code>bundle install\n</code></pre></li> <li>Run the application <pre><code>ruby app.rb\n</code></pre></li> </ol> <p>For more information, check the Ruby tutorial.</p> <p>To run this server application, you need Java  and Maven  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/java\n</code></pre></li> <li>Run the application <pre><code>mvn spring-boot:run\n</code></pre></li> </ol> <p>For more information, check the Java tutorial.</p> <p>To run this server application, you need Python 3  installed on your device.</p> <ol> <li> <p>Navigate into the server directory</p> <pre><code>cd openvidu-livekit-tutorials/application-server/python\n</code></pre> </li> <li> <p>Create a python virtual environment</p> <pre><code>python -m venv venv\n</code></pre> </li> <li> <p>Activate the virtual environment</p>  Windows macOS Linux <pre><code>.\\venv\\Scripts\\activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> </li> <li> <p>Install dependencies</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the application</p> <pre><code>python app.py\n</code></pre> </li> </ol> <p>For more information, check the Python tutorial.</p> <p>To run this server application, you need Rust  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/rust\n</code></pre></li> <li>Run the application <pre><code>cargo run\n</code></pre></li> </ol> <p>For more information, check the Rust tutorial.</p> <p>To run this server application, you need PHP  and Composer  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/php\n</code></pre></li> <li>Install dependencies <pre><code>composer install\n</code></pre></li> <li>Run the application <pre><code>composer start\n</code></pre></li> </ol> <p>Warning</p> <p>LiveKit PHP SDK requires library BCMath . This is available out-of-the-box in PHP for Windows, but a manual installation might be necessary in other OS. Run <code>sudo apt install php-bcmath</code> or <code>sudo yum install php-bcmath</code></p> <p>For more information, check the PHP tutorial.</p> <p>To run this server application, you need .NET  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/dotnet\n</code></pre></li> <li>Run the application <pre><code>dotnet run\n</code></pre></li> </ol> <p>Warning</p> <p>This .NET server application needs the <code>LIVEKIT_API_SECRET</code> env variable to be at least 32 characters long. Make sure to update it here  and in your OpenVidu Server.</p> <p>For more information, check the .NET tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-toggle-hand/#4-run-the-openvidu-toggle-hand-tutorial","title":"4. Run the openvidu-toggle-hand tutorial","text":"<p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>  cd openvidu-tutorials/openvidu-components/openvidu-toggle-hand\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>  npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>  npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>.</p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-toggle-hand/#understanding-the-code","title":"Understanding the code","text":"<p>This tutorial is an Angular project generated with Angular CLI tool. Therefore, you will see many configuration files and other components that are not the primary focus of this tutorial. We will concentrate on the following files in the <code>src</code> directory:</p> <ul> <li><code>main.ts</code>: This file defines the root application component. It imports the <code>OpenViduComponentsModule</code>, where we configure the OpenVidu Components Angular library.</li> <li><code>app/app.component.ts</code>: This file defines the AppComponent, the primary and sole component of the application. It is responsible for requesting the OpenVidu token and passing it to the videoconference component, facilitating the connection to the OpenVidu Room.</li> <li> <p><code>styles.scss</code>: This file defines the global styles of the application. Here, you can customize the UI of the OpenVidu Components Angular library.</p> </li> <li> <p><code>app/models/participant-app.model.ts</code>: Contains the <code>ParticipantAppModel</code> class that extends the <code>ParticipantModel</code> class to add the ability to raise and lower the hand.</p> </li> </ul> <p>To use OpenVidu Components Angular in your application, you need to install the library and import the <code>OpenViduComponentsModule</code> in your Angular module. Let's see how to do this:</p> <ol> <li> <p>Create an Angular Project (version 17 or higher)</p> <p>To begin, you will need to create a new Angular project if you haven't already. Ensure you have Node.js and the Angular CLI installed. Then, run the following command to create a new Angular project:</p> <pre><code>ng new your-project-name\n</code></pre> <p>Replace <code>your-project-name</code> with the desired name for your project.</p> </li> <li> <p>Add Angular Material to your project</p> <p>OpenVidu Components Angular needs Angular Material, which provides a range of UI components. To add Angular Material to your project, navigate to your project directory and run:</p> <pre><code>ng add @angular/material\n</code></pre> </li> <li> <p>Install OpenVidu Components Angular</p> <p>With your Angular project set up, it's time to add videoconferencing capabilities with OpenVidu Components Angular. Install the library using npm:</p> <pre><code>npm install openvidu-components-angular\n</code></pre> </li> <li> <p>Import and use OpenVidu Components Angular</p> <p>To use OpenVidu Components Angular in your application, you need to:</p> <ol> <li>Import the <code>OpenViduComponentsModule</code> in your Angular application.</li> <li>Configure the module with the <code>OpenViduComponentsConfig</code> object.</li> <li>Add the component to your template file.</li> <li>Assign the OpenVidu token and LiveKit URL to the component.</li> <li>Customize the appearance of the components using CSS variables.</li> </ol> </li> </ol> main.tsapp.component.tsmodels/participant-app.model.tsstyles.scss <p>In your <code>main.ts</code> application file, import the it and configure it as follows:</p> <pre><code>// Other imports ...\n\nimport { OpenViduComponentsModule, OpenViduComponentsConfig } from 'openvidu-components-angular';\n\nconst config: OpenViduComponentsConfig = {\n    production: true,\n};\n\nbootstrapApplication(AppComponent, {\n    providers: [\n        importProvidersFrom(\n            OpenViduComponentsModule.forRoot(config)\n            // Other imports ...\n        ),\n        provideAnimations(),\n    ],\n}).catch((err) =&gt; console.error(err));\n</code></pre> <p>Use the <code>ov-videoconference</code> component to create a videoconference. This component requires a token to connect to the OpenVidu Room. The <code>AppComponent</code> class is responsible for requesting the token and passing it to the <code>ov-videoconference</code> component.</p> <pre><code>import {\n  ParticipantModel,\n  ParticipantService,\n  OpenViduComponentsModule\n} from 'openvidu-components-angular';\n\nenum DataTopicApp {\n  HAND_TOGGLE = 'handToggle'\n}\n\n@Component({\n  selector: 'app-root',\n  template:`\n    &lt;!-- OpenVidu Video Conference Component --&gt;\n    &lt;ov-videoconference\n      [prejoin]=\"true\"\n      [token]=\"token\"\n      [livekitUrl]=\"LIVEKIT_URL\"\n      (onTokenRequested)=\"onTokenRequested($event)\"\n      (onRoomCreated)=\"handleRemoteHand($event)\"\n    &gt;\n      &lt;div *ovToolbarAdditionalButtons&gt;\n        &lt;button toolbar-btn mat-icon-button (click)=\"handleLocalHand()\" [class.active-btn]=\"hasHandRaised\"&gt;\n          &lt;mat-icon matTooltip=\"Toggle hand\"&gt;front_hand&lt;/mat-icon&gt;\n        &lt;/button&gt;\n      &lt;/div&gt;\n\n      &lt;div *ovStream=\"let track\" style=\"height: 100%\"&gt;\n        &lt;ov-stream [track]=\"track\"&gt;&lt;/ov-stream&gt;\n        @if (track.participant.hasHandRaised) {\n        &lt;mat-icon @inOutHandAnimation id=\"hand-notification\"&gt;front_hand&lt;/mat-icon&gt;\n        }\n      &lt;/div&gt;\n\n      &lt;div *ovParticipantPanelItemElements=\"let participant\"&gt;\n        @if (participant.hasHandRaised) {\n        &lt;mat-icon&gt;front_hand&lt;/mat-icon&gt;\n        }\n      &lt;/div&gt;\n    &lt;/ov-videoconference&gt;\n  `,\n  styles: [''],\n  standalone: true,\n  imports: [OpenViduComponentsModule, MatIconButton, MatIcon]\n})\nexport class AppComponent {\n  // For local development, leave these variables empty\n  // For production, configure them with correct URLs depending on your deployment\n\n  APPLICATION_SERVER_URL = '';  // (1)!\n  LIVEKIT_URL = ''; // (2)!\n\n  // The name of the room to join.\n  roomName = 'openvidu-toggle-hand';  // (3)!\n\n  // The token used to join the room.\n  token!: string; // (4)!\n\n  // Whether the local participant has raised their hand.\n  hasHandRaised: boolean = false; // (5)!\n\n  constructor(private httpClient: HttpClient, private participantService: ParticipantService) {\n    this.configureUrls();\n  }\n\n  private configureUrls() {\n    // If APPLICATION_SERVER_URL is not configured, use default value from local development\n    if (!this.APPLICATION_SERVER_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.APPLICATION_SERVER_URL = 'http://localhost:6080/';\n      } else {\n        this.APPLICATION_SERVER_URL =\n          'https://' + window.location.hostname + ':6443/';\n      }\n    }\n\n    // If LIVEKIT_URL is not configured, use default value from local development\n    if (!this.LIVEKIT_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.LIVEKIT_URL = 'ws://localhost:7880/';\n      } else {\n        this.LIVEKIT_URL = 'wss://' + window.location.hostname + ':7443/';\n      }\n    }\n  }\n\n  // Requests a token to join the room with the given participant name.\n  async onTokenRequested(participantName: string) { // (6)!\n    const { token } = await this.getToken(this.roomName, participantName);\n    this.token = token;\n  }\n\n  // Handles the reception of a remote hand-raising event.\n  handleRemoteHand(room: Room) { // (7)!\n    // Subscribe to hand toggling events from other participants\n    room.on(RoomEvent.DataReceived, (payload: Uint8Array, participant?: RemoteParticipant, _?: DataPacket_Kind, topic?: string) =&gt; { // (8)!\n      if (topic === DataTopicApp.HAND_TOGGLE) {\n        const p = this.participantService.getRemoteParticipantBySid(participant.sid); // (9)!\n        if (p) {\n          (&lt;ParticipantAppModel&gt;p).toggleHandRaised(); // (10)!\n        }\n        this.participantService.updateRemoteParticipants(); // (11)!\n      }\n    });\n  }\n\n  // Handles the local hand-raising event.\n  async handleLocalHand() {  // (12)!\n    // Get local participant with ParticipantService\n    const participant = &lt;ParticipantAppModel&gt;this.participantService.getLocalParticipant(); // (13)!\n\n    // Toggle the participant hand with the method we wil add in our ParticipantAppModel\n    participant.toggleHandRaised(); // (14)!\n\n    // Refresh the local participant object for others component and services\n    this.participantService.updateLocalParticipant(); // (15)!\n\n    // Send a signal with the new value to others participant using the openvidu-browser signal\n    const strData = JSON.stringify({});\n    const data: Uint8Array = new TextEncoder().encode(strData);\n    const options: DataPublishOptions = { topic: DataTopicApp.HAND_TOGGLE };\n\n    await this.participantService.publishData(data, options); // (16)!\n  }\n\n  // Retrieves a token to join the room with the given name and participant name.\n  getToken(roomName: string, participantName: string): Promise&lt;any&gt; { // (17)!\n    // Requesting token to the server application\n  }\n}\n</code></pre> <ol> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect.</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>hasHandRaised</code>: Boolean that indicates if the local participant has raised their hand.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>handleRemoteHand</code> method that handles the reception of a remote <code>HAND_TOGGLE</code>  event.</li> <li><code>on</code> method that subscribes to the <code>DataReceived</code> event to handle the reception of a remote <code>HAND_TOGGLE</code> event.</li> <li><code>getRemoteParticipantBySid</code> method that retrieves a remote participant by its unique ID.</li> <li><code>toggleHandRaised</code> method that toggles the hand raising status of a remote participant.</li> <li><code>updateRemoteParticipants</code> method that updates the list of remote participants.</li> <li><code>handleLocalHand</code> method that handles the local <code>HAND_TOGGLE</code> event.</li> <li><code>getLocalParticipant</code> method that retrieves the local participant.</li> <li><code>toggleHandRaised</code> method that toggles the hand raising status of the local participant.</li> <li><code>updateLocalParticipant</code> method that updates the local participant.</li> <li><code>publishData</code> method that sends a signal to other participants.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ol> <p>The <code>app.component.ts</code> file declares the following properties and methods:</p> <ul> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect.</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>hasHandRaised</code>: Boolean that indicates if the local participant has raised their hand.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>handleRemoteHand</code> method that handles the reception of a remote <code>HAND_TOGGLE</code>  event.</li> <li><code>on</code> method that subscribes to the <code>DataReceived</code> event to handle the reception of a remote <code>HAND_TOGGLE</code> event.</li> <li><code>getRemoteParticipantBySid</code> method that retrieves a remote participant by its unique ID.</li> <li><code>toggleHandRaised</code> method that toggles the hand raising status of a remote participant.</li> <li><code>updateRemoteParticipants</code> method that updates the list of remote participants.</li> <li><code>handleLocalHand</code> method that handles the local <code>HAND_TOGGLE</code> event.</li> <li><code>getLocalParticipant</code> method that retrieves the local participant.</li> <li><code>toggleHandRaised</code> method that toggles the hand raising status of the local participant.</li> <li><code>updateLocalParticipant</code> method that updates the local participant.</li> <li><code>publishData</code> method that sends a signal to other participants.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ul> <p>Configure the URLs</p> <p>When running OpenVidu locally, leave <code>APPLICATION_SERVER_URL</code> and <code>LIVEKIT_URL</code> variables empty. The function <code>configureUrls()</code> will automatically configure them with default values. However, for other deployment type, you should configure these variables with the correct URLs depending on your deployment.</p> <p>The <code>ParticipantAppModel</code> class extends the <code>ParticipantModel</code> class to add the ability to raise and lower the hand.</p> <pre><code>  import { ParticipantModel, ParticipantProperties } from 'openvidu-components-angular';\n\n  // Represents a participant in the application, with the ability to raise their hand.\n  export class ParticipantAppModel extends ParticipantModel {\n\n    // Indicates whether the participant has raised their hand.\n    hasHandRaised: boolean;\n\n    //  Creates a new instance of ParticipantAppModel.\n    constructor(props: ParticipantProperties) {\n      super(props);\n      this.hasHandRaised = false;\n    }\n\n    // Toggles the participant's hand raised status.\n    toggleHandRaised() {\n      this.hasHandRaised = !this.hasHandRaised;\n    }\n  }\n</code></pre> <p>The OpenVidu Components Angular library provides a set of CSS variables that you can use to customize the appearance of the components. You can define these variables in your application's global styles file (e.g. <code>styles.scss</code>).</p> <pre><code>:root {\n    /* Basic colors */\n    --ov-background-color: #303030; // Background color\n    --ov-surface-color: #ffffff; // Surfaces colors (panels, dialogs)\n\n    /* Text colors */\n    --ov-text-primary-color: #ffffff; // Text color over primary background\n    --ov-text-surface-color: #1d1d1d; // Text color over surface background\n\n    /* Action colors */\n    --ov-primary-action-color: #273235; // Primary color for buttons, etc.\n    --ov-secondary-action-color: #f1f1f1; // Secondary color for buttons, etc.\n    --ov-accent-action-color: #0089ab; // Color for highlighted elements\n\n    /* Status colors */\n    --ov-error-color: #eb5144; // Error color\n    --ov-warn-color: #ffba53; // Warning color\n\n    /* Radius */\n    --ov-toolbar-buttons-radius: 50%; // Radius for toolbar buttons\n    --ov-leave-button-radius: 10px; // Radius for leave button\n    --ov-video-radius: 5px; // Radius for videos\n    --ov-surface-radius: 5px; // Radius for surfaces\n}\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-toolbar-buttons/","title":"Add toolbar buttons using Angular Components","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-toolbar-buttons/#add-toolbar-buttons-using-angular-components","title":"Add toolbar buttons using Angular Components","text":"<p>Source code </p> <p>The openvidu-toolbar-buttons tutorial demonstrates how to add custom buttons to the central part of the default toolbar in the OpenVidu Components Angular library.</p> <p>Adding toolbar buttons is made simple with the ToolbarAdditionalButtonsDirective, which offers a straightforward way to add custom buttons to the ToolbarComponent.</p> <p> </p> OpenVidu Components - Toolbar Buttons","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-toolbar-buttons/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-toolbar-buttons/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-toolbar-buttons/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\ngit clone https://github.com/OpenVidu/openvidu-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-toolbar-buttons/#3-run-a-server-application","title":"3. Run a server application","text":"Node.js Go Ruby Java Python Rust PHP .NET <p>To run this server application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/node\n</code></pre></li> <li>Install dependencies <pre><code>npm install\n</code></pre></li> <li>Run the application <pre><code>npm start\n</code></pre></li> </ol> <p>For more information, check the Node.js tutorial.</p> <p>To run this server application, you need Go  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/go\n</code></pre></li> <li>Run the application <pre><code>go run main.go\n</code></pre></li> </ol> <p>For more information, check the Go tutorial.</p> <p>To run this server application, you need Ruby  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/ruby\n</code></pre></li> <li>Install dependencies <pre><code>bundle install\n</code></pre></li> <li>Run the application <pre><code>ruby app.rb\n</code></pre></li> </ol> <p>For more information, check the Ruby tutorial.</p> <p>To run this server application, you need Java  and Maven  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/java\n</code></pre></li> <li>Run the application <pre><code>mvn spring-boot:run\n</code></pre></li> </ol> <p>For more information, check the Java tutorial.</p> <p>To run this server application, you need Python 3  installed on your device.</p> <ol> <li> <p>Navigate into the server directory</p> <pre><code>cd openvidu-livekit-tutorials/application-server/python\n</code></pre> </li> <li> <p>Create a python virtual environment</p> <pre><code>python -m venv venv\n</code></pre> </li> <li> <p>Activate the virtual environment</p>  Windows macOS Linux <pre><code>.\\venv\\Scripts\\activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> </li> <li> <p>Install dependencies</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the application</p> <pre><code>python app.py\n</code></pre> </li> </ol> <p>For more information, check the Python tutorial.</p> <p>To run this server application, you need Rust  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/rust\n</code></pre></li> <li>Run the application <pre><code>cargo run\n</code></pre></li> </ol> <p>For more information, check the Rust tutorial.</p> <p>To run this server application, you need PHP  and Composer  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/php\n</code></pre></li> <li>Install dependencies <pre><code>composer install\n</code></pre></li> <li>Run the application <pre><code>composer start\n</code></pre></li> </ol> <p>Warning</p> <p>LiveKit PHP SDK requires library BCMath . This is available out-of-the-box in PHP for Windows, but a manual installation might be necessary in other OS. Run <code>sudo apt install php-bcmath</code> or <code>sudo yum install php-bcmath</code></p> <p>For more information, check the PHP tutorial.</p> <p>To run this server application, you need .NET  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/dotnet\n</code></pre></li> <li>Run the application <pre><code>dotnet run\n</code></pre></li> </ol> <p>Warning</p> <p>This .NET server application needs the <code>LIVEKIT_API_SECRET</code> env variable to be at least 32 characters long. Make sure to update it here  and in your OpenVidu Server.</p> <p>For more information, check the .NET tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-toolbar-buttons/#4-run-the-openvidu-toolbar-buttons-tutorial","title":"4. Run the openvidu-toolbar-buttons tutorial","text":"<p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>  cd openvidu-tutorials/openvidu-components/openvidu-toolbar-buttons\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>  npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>  npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>.</p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-toolbar-buttons/#understanding-the-code","title":"Understanding the code","text":"<p>This tutorial is an Angular project generated with Angular CLI tool. Therefore, you will see many configuration files and other components that are not the primary focus of this tutorial. We will concentrate on the following files in the <code>src</code> directory:</p> <ul> <li><code>main.ts</code>: This file defines the root application component. It imports the <code>OpenViduComponentsModule</code>, where we configure the OpenVidu Components Angular library.</li> <li><code>app/app.component.ts</code>: This file defines the AppComponent, the primary and sole component of the application. It is responsible for requesting the OpenVidu token and passing it to the videoconference component, facilitating the connection to the OpenVidu Room.</li> <li><code>styles.scss</code>: This file defines the global styles of the application. Here, you can customize the UI of the OpenVidu Components Angular library.</li> </ul> <p>To use OpenVidu Components Angular in your application, you need to install the library and import the <code>OpenViduComponentsModule</code> in your Angular module. Let's see how to do this:</p> <ol> <li> <p>Create an Angular Project (version 17 or higher)</p> <p>To begin, you will need to create a new Angular project if you haven't already. Ensure you have Node.js and the Angular CLI installed. Then, run the following command to create a new Angular project:</p> <pre><code>ng new your-project-name\n</code></pre> <p>Replace <code>your-project-name</code> with the desired name for your project.</p> </li> <li> <p>Add Angular Material to your project</p> <p>OpenVidu Components Angular needs Angular Material, which provides a range of UI components. To add Angular Material to your project, navigate to your project directory and run:</p> <pre><code>ng add @angular/material\n</code></pre> </li> <li> <p>Install OpenVidu Components Angular</p> <p>With your Angular project set up, it's time to add videoconferencing capabilities with OpenVidu Components Angular. Install the library using npm:</p> <pre><code>npm install openvidu-components-angular\n</code></pre> </li> <li> <p>Import and use OpenVidu Components Angular</p> <p>To use OpenVidu Components Angular in your application, you need to:</p> <ol> <li>Import the <code>OpenViduComponentsModule</code> in your Angular application.</li> <li>Configure the module with the <code>OpenViduComponentsConfig</code> object.</li> <li>Add the component to your template file.</li> <li>Assign the OpenVidu token and LiveKit URL to the component.</li> <li>Customize the appearance of the components using CSS variables.</li> </ol> </li> </ol> main.tsapp.component.tsstyles.scss <p>In your <code>main.ts</code> application file, import the it and configure it as follows:</p> <pre><code>// Other imports ...\n\nimport { OpenViduComponentsModule, OpenViduComponentsConfig } from 'openvidu-components-angular';\n\nconst config: OpenViduComponentsConfig = {\n    production: true,\n};\n\nbootstrapApplication(AppComponent, {\n    providers: [\n        importProvidersFrom(\n            OpenViduComponentsModule.forRoot(config)\n            // Other imports ...\n        ),\n        provideAnimations(),\n    ],\n}).catch((err) =&gt; console.error(err));\n</code></pre> <p>Use the <code>ov-videoconference</code> component to create a videoconference. This component requires a token to connect to the OpenVidu Room. The <code>AppComponent</code> class is responsible for requesting the token and passing it to the <code>ov-videoconference</code> component.</p> <pre><code>import { MatIcon } from '@angular/material/icon';\nimport { MatIconButton } from '@angular/material/button';\nimport { OpenViduComponentsModule, ParticipantService } from 'openvidu-components-angular';\n\n@Component({\n  selector: 'app-root',\n  template:`\n    &lt;ov-videoconference\n      [token]=\"token\"\n      [livekitUrl]=\"LIVEKIT_URL\"\n      (onTokenRequested)=\"onTokenRequested($event)\"\n    &gt;\n      &lt;div *ovToolbarAdditionalButtons style=\"text-align: center;\"&gt;\n        &lt;button mat-icon-button (click)=\"toggleVideo()\"&gt;\n          &lt;mat-icon&gt;videocam&lt;/mat-icon&gt;\n        &lt;/button&gt;\n        &lt;button mat-icon-button (click)=\"toggleAudio()\"&gt;\n          &lt;mat-icon&gt;mic&lt;/mat-icon&gt;\n        &lt;/button&gt;\n      &lt;/div&gt;\n    &lt;/ov-videoconference&gt;\n  `,\n  styles: [''],\n  standalone: true,\n  imports: [OpenViduComponentsModule, MatIconButton, MatIcon],\n})\nexport class AppComponent {\n  // For local development, leave these variables empty\n  // For production, configure them with correct URLs depending on your deployment\n\n  APPLICATION_SERVER_URL = '';  // (1)!\n  LIVEKIT_URL = ''; // (2)!\n\n  // The name of the room to join.\n  roomName = 'openvidu-toolbar-buttons';  // (3)!\n\n  // The token used to join the room.\n  token!: string; // (4)!\n\n  constructor(private httpClient: HttpClient, private participantService: ParticipantService) {\n    this.configureUrls();\n  }\n\n  private configureUrls() {\n    // If APPLICATION_SERVER_URL is not configured, use default value from local development\n    if (!this.APPLICATION_SERVER_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.APPLICATION_SERVER_URL = 'http://localhost:6080/';\n      } else {\n        this.APPLICATION_SERVER_URL =\n          'https://' + window.location.hostname + ':6443/';\n      }\n    }\n\n    // If LIVEKIT_URL is not configured, use default value from local development\n    if (!this.LIVEKIT_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.LIVEKIT_URL = 'ws://localhost:7880/';\n      } else {\n        this.LIVEKIT_URL = 'wss://' + window.location.hostname + ':7443/';\n      }\n    }\n  }\n\n  // Requests a token to join the room with the given participant name.\n  async onTokenRequested(participantName: string) { // (5)!\n    const { token } = await this.getToken(this.roomName, participantName);\n    this.token = token;\n  }\n\n  // Toggles the camera on and off.\n  async toggleVideo() { // (6)!\n    const isCameraEnabled = this.participantService.isMyCameraEnabled();\n    await this.participantService.setCameraEnabled(!isCameraEnabled);\n  }\n\n  // Toggles the microphone on and off.\n  async toggleAudio() { // (7)!\n    const isMicrophoneEnabled = this.participantService.isMyMicrophoneEnabled();\n    await this.participantService.setMicrophoneEnabled(!isMicrophoneEnabled);\n  }\n\n  // Retrieves a token to join the room with the given name and participant name.\n  getToken(roomName: string, participantName: string): Promise&lt;any&gt; { // (8)!\n    // Requesting token to the server application\n  }\n}\n</code></pre> <ol> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect.</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>toggleVideo</code> method that toggles the camera on and off.</li> <li><code>toggleAudio</code> method that toggles the microphone on and off.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ol> <p>The <code>app.component.ts</code> file declares the following properties and methods:</p> <ul> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect.</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>toggleVideo</code> method that toggles the camera on and off.</li> <li><code>toggleAudio</code> method that toggles the microphone on and off.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ul> <p>Configure the URLs</p> <p>When running OpenVidu locally, leave <code>APPLICATION_SERVER_URL</code> and <code>LIVEKIT_URL</code> variables empty. The function <code>configureUrls()</code> will automatically configure them with default values. However, for other deployment type, you should configure these variables with the correct URLs depending on your deployment.</p> <p>The OpenVidu Components Angular library provides a set of CSS variables that you can use to customize the appearance of the components. You can define these variables in your application's global styles file (e.g. <code>styles.scss</code>).</p> <pre><code>:root {\n    /* Basic colors */\n    --ov-background-color: #303030; // Background color\n    --ov-surface-color: #ffffff; // Surfaces colors (panels, dialogs)\n\n    /* Text colors */\n    --ov-text-primary-color: #ffffff; // Text color over primary background\n    --ov-text-surface-color: #1d1d1d; // Text color over surface background\n\n    /* Action colors */\n    --ov-primary-action-color: #273235; // Primary color for buttons, etc.\n    --ov-secondary-action-color: #f1f1f1; // Secondary color for buttons, etc.\n    --ov-accent-action-color: #0089ab; // Color for highlighted elements\n\n    /* Status colors */\n    --ov-error-color: #eb5144; // Error color\n    --ov-warn-color: #ffba53; // Warning color\n\n    /* Radius */\n    --ov-toolbar-buttons-radius: 50%; // Radius for toolbar buttons\n    --ov-leave-button-radius: 10px; // Radius for leave button\n    --ov-video-radius: 5px; // Radius for videos\n    --ov-surface-radius: 5px; // Radius for surfaces\n}\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-toolbar-buttons/#adding-additional-buttons-to-the-toolbar","title":"Adding additional buttons to the toolbar","text":"<p>OpenVidu Components Angular provides a directive called <code>*ovToolbarAdditionalButtons</code> that allows you to add custom buttons to the toolbar.</p> <p>In the <code>app.component.ts</code> file, you can see the following code snippet:</p> <pre><code>@Component({\n  selector: 'app-root',\n  template:`\n    &lt;ov-videoconference\n      [token]=\"token\"\n      [livekitUrl]=\"LIVEKIT_URL\"\n      (onTokenRequested)=\"onTokenRequested($event)\"\n    &gt;\n      &lt;div *ovToolbarAdditionalButtons style=\"text-align: center;\"&gt;\n        &lt;button mat-icon-button (click)=\"toggleVideo()\"&gt;\n          &lt;mat-icon&gt;videocam&lt;/mat-icon&gt;\n        &lt;/button&gt;\n        &lt;button mat-icon-button (click)=\"toggleAudio()\"&gt;\n          &lt;mat-icon&gt;mic&lt;/mat-icon&gt;\n        &lt;/button&gt;\n      &lt;/div&gt;\n\n    &lt;/ov-videoconference&gt;\n  `,\n  styles: [''],\n  standalone: true,\n  imports: [OpenViduComponentsModule, MatIconButton, MatIcon],\n})\nexport class AppComponent {\n  // ...\n}\n</code></pre> <p>In this code snippet, the <code>*ovToolbarAdditionalButtons</code> directive is used to add two buttons to the toolbar. The <code>mat-icon-button</code> component from Angular Material is used to create the buttons. The <code>toggleVideo</code> and <code>toggleAudio</code> methods are called when the buttons are clicked.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-toolbar-panel-buttons/","title":"Add toolbar panel buttons using Angular Components","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-toolbar-panel-buttons/#add-toolbar-panel-buttons-using-angular-components","title":"Add toolbar panel buttons using Angular Components","text":"<p>Source code </p> <p>The openvidu-toolbar-panel-buttons tutorial demonstrates how to add custom buttons to the right part of the default toolbar in the OpenVidu Components Angular library.</p> <p>Adding toolbar buttons is made simple with the ToolbarAdditionalPanelButtonsDirective, which offers a straightforward way to add custom buttons to the ToolbarComponent.</p> <p> </p> OpenVidu Components - Toolbar Panel Buttons","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-toolbar-panel-buttons/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-toolbar-panel-buttons/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-toolbar-panel-buttons/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\ngit clone https://github.com/OpenVidu/openvidu-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-toolbar-panel-buttons/#3-run-a-server-application","title":"3. Run a server application","text":"Node.js Go Ruby Java Python Rust PHP .NET <p>To run this server application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/node\n</code></pre></li> <li>Install dependencies <pre><code>npm install\n</code></pre></li> <li>Run the application <pre><code>npm start\n</code></pre></li> </ol> <p>For more information, check the Node.js tutorial.</p> <p>To run this server application, you need Go  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/go\n</code></pre></li> <li>Run the application <pre><code>go run main.go\n</code></pre></li> </ol> <p>For more information, check the Go tutorial.</p> <p>To run this server application, you need Ruby  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/ruby\n</code></pre></li> <li>Install dependencies <pre><code>bundle install\n</code></pre></li> <li>Run the application <pre><code>ruby app.rb\n</code></pre></li> </ol> <p>For more information, check the Ruby tutorial.</p> <p>To run this server application, you need Java  and Maven  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/java\n</code></pre></li> <li>Run the application <pre><code>mvn spring-boot:run\n</code></pre></li> </ol> <p>For more information, check the Java tutorial.</p> <p>To run this server application, you need Python 3  installed on your device.</p> <ol> <li> <p>Navigate into the server directory</p> <pre><code>cd openvidu-livekit-tutorials/application-server/python\n</code></pre> </li> <li> <p>Create a python virtual environment</p> <pre><code>python -m venv venv\n</code></pre> </li> <li> <p>Activate the virtual environment</p>  Windows macOS Linux <pre><code>.\\venv\\Scripts\\activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> </li> <li> <p>Install dependencies</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the application</p> <pre><code>python app.py\n</code></pre> </li> </ol> <p>For more information, check the Python tutorial.</p> <p>To run this server application, you need Rust  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/rust\n</code></pre></li> <li>Run the application <pre><code>cargo run\n</code></pre></li> </ol> <p>For more information, check the Rust tutorial.</p> <p>To run this server application, you need PHP  and Composer  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/php\n</code></pre></li> <li>Install dependencies <pre><code>composer install\n</code></pre></li> <li>Run the application <pre><code>composer start\n</code></pre></li> </ol> <p>Warning</p> <p>LiveKit PHP SDK requires library BCMath . This is available out-of-the-box in PHP for Windows, but a manual installation might be necessary in other OS. Run <code>sudo apt install php-bcmath</code> or <code>sudo yum install php-bcmath</code></p> <p>For more information, check the PHP tutorial.</p> <p>To run this server application, you need .NET  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/dotnet\n</code></pre></li> <li>Run the application <pre><code>dotnet run\n</code></pre></li> </ol> <p>Warning</p> <p>This .NET server application needs the <code>LIVEKIT_API_SECRET</code> env variable to be at least 32 characters long. Make sure to update it here  and in your OpenVidu Server.</p> <p>For more information, check the .NET tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-toolbar-panel-buttons/#4-run-the-openvidu-toolbar-panel-buttons-tutorial","title":"4. Run the openvidu-toolbar-panel-buttons tutorial","text":"<p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>  cd openvidu-tutorials/openvidu-components/openvidu-toolbar-panel-buttons\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>  npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>  npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>.</p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-toolbar-panel-buttons/#understanding-the-code","title":"Understanding the code","text":"<p>This tutorial is an Angular project generated with Angular CLI tool. Therefore, you will see many configuration files and other components that are not the primary focus of this tutorial. We will concentrate on the following files in the <code>src</code> directory:</p> <ul> <li><code>main.ts</code>: This file defines the root application component. It imports the <code>OpenViduComponentsModule</code>, where we configure the OpenVidu Components Angular library.</li> <li><code>app/app.component.ts</code>: This file defines the AppComponent, the primary and sole component of the application. It is responsible for requesting the OpenVidu token and passing it to the videoconference component, facilitating the connection to the OpenVidu Room.</li> <li><code>styles.scss</code>: This file defines the global styles of the application. Here, you can customize the UI of the OpenVidu Components Angular library.</li> </ul> <p>To use OpenVidu Components Angular in your application, you need to install the library and import the <code>OpenViduComponentsModule</code> in your Angular module. Let's see how to do this:</p> <ol> <li> <p>Create an Angular Project (version 17 or higher)</p> <p>To begin, you will need to create a new Angular project if you haven't already. Ensure you have Node.js and the Angular CLI installed. Then, run the following command to create a new Angular project:</p> <pre><code>ng new your-project-name\n</code></pre> <p>Replace <code>your-project-name</code> with the desired name for your project.</p> </li> <li> <p>Add Angular Material to your project</p> <p>OpenVidu Components Angular needs Angular Material, which provides a range of UI components. To add Angular Material to your project, navigate to your project directory and run:</p> <pre><code>ng add @angular/material\n</code></pre> </li> <li> <p>Install OpenVidu Components Angular</p> <p>With your Angular project set up, it's time to add videoconferencing capabilities with OpenVidu Components Angular. Install the library using npm:</p> <pre><code>npm install openvidu-components-angular\n</code></pre> </li> <li> <p>Import and use OpenVidu Components Angular</p> <p>To use OpenVidu Components Angular in your application, you need to:</p> <ol> <li>Import the <code>OpenViduComponentsModule</code> in your Angular application.</li> <li>Configure the module with the <code>OpenViduComponentsConfig</code> object.</li> <li>Add the component to your template file.</li> <li>Assign the OpenVidu token and LiveKit URL to the component.</li> <li>Customize the appearance of the components using CSS variables.</li> </ol> </li> </ol> main.tsapp.component.tsstyles.scss <p>In your <code>main.ts</code> application file, import the it and configure it as follows:</p> <pre><code>// Other imports ...\n\nimport { OpenViduComponentsModule, OpenViduComponentsConfig } from 'openvidu-components-angular';\n\nconst config: OpenViduComponentsConfig = {\n    production: true,\n};\n\nbootstrapApplication(AppComponent, {\n    providers: [\n        importProvidersFrom(\n            OpenViduComponentsModule.forRoot(config)\n            // Other imports ...\n        ),\n        provideAnimations(),\n    ],\n}).catch((err) =&gt; console.error(err));\n</code></pre> <p>Use the <code>ov-videoconference</code> component to create a videoconference. This component requires a token to connect to the OpenVidu Room. The <code>AppComponent</code> class is responsible for requesting the token and passing it to the <code>ov-videoconference</code> component.</p> <pre><code>import { MatIcon } from '@angular/material/icon';\nimport { MatIconButton } from '@angular/material/button';\nimport { OpenViduComponentsModule } from 'openvidu-components-angular';\n\n@Component({\n  selector: 'app-root',\n  template:`\n      &lt;ov-videoconference\n        [token]=\"token\"\n        [livekitUrl]=\"LIVEKIT_URL\"\n        [toolbarDisplayRoomName]=\"false\"\n        (onTokenRequested)=\"onTokenRequested($event)\"\n      &gt;\n        &lt;div *ovToolbarAdditionalPanelButtons style=\"text-align: center;\"&gt;\n          &lt;button mat-icon-button (click)=\"onButtonClicked()\"&gt;\n            &lt;mat-icon&gt;star&lt;/mat-icon&gt;\n          &lt;/button&gt;\n        &lt;/div&gt;\n      &lt;/ov-videoconference&gt;\n  `,\n  styles: [''],\n  standalone: true,\n    imports: [OpenViduComponentsModule, MatIconButton, MatIcon],\n})\nexport class AppComponent {\n  // For local development, leave these variables empty\n  // For production, configure them with correct URLs depending on your deployment\n\n  APPLICATION_SERVER_URL = '';  // (1)!\n  LIVEKIT_URL = ''; // (2)!\n\n  // The name of the room to join.\n  roomName = 'openvidu-toolbar-panel-buttons';  // (3)!\n\n  // The token used to join the room.\n  token!: string; // (4)!\n\n  constructor(private httpClient: HttpClient) {\n    this.configureUrls();\n  }\n\n  private configureUrls() {\n    // If APPLICATION_SERVER_URL is not configured, use default value from local development\n    if (!this.APPLICATION_SERVER_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.APPLICATION_SERVER_URL = 'http://localhost:6080/';\n      } else {\n        this.APPLICATION_SERVER_URL =\n          'https://' + window.location.hostname + ':6443/';\n      }\n    }\n\n    // If LIVEKIT_URL is not configured, use default value from local development\n    if (!this.LIVEKIT_URL) {\n      if (window.location.hostname === 'localhost') {\n        this.LIVEKIT_URL = 'ws://localhost:7880/';\n      } else {\n        this.LIVEKIT_URL = 'wss://' + window.location.hostname + ':7443/';\n      }\n    }\n  }\n\n  // Requests a token to join the room with the given participant name.\n  async onTokenRequested(participantName: string) { // (5)!\n    const { token } = await this.getToken(this.roomName, participantName);\n    this.token = token;\n  }\n\n  // Method to handle button click\n  onButtonClicked() { // (6)!\n    alert('button clicked');\n  }\n\n  // Retrieves a token to join the room with the given name and participant name.\n  getToken(roomName: string, participantName: string): Promise&lt;any&gt; { // (7)!\n    // Requesting token to the server application\n  }\n}\n</code></pre> <ol> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect.</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>onButtonClicked</code> method that fires when the custom button is clicked.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ol> <p>The <code>app.component.ts</code> file declares the following properties and methods:</p> <ul> <li><code>APPLICATION_SERVER_URL</code>: URL to communicate the client application with the server application to request OpenVidu tokens.</li> <li><code>LIVEKIT_URL</code>: URL to communicate the client application with the LiveKit server.</li> <li><code>roomName</code>: OpenVidu Room identifier. This is the room where the VideoconferenceComponent will connect.</li> <li><code>token</code>: OpenVidu Token used to connect to the OpenVidu Room.</li> <li><code>onTokenRequested</code> method that fires when the VideoconferenceComponent requests a token to connect to the OpenVidu Room.</li> <li><code>onButtonClicked</code> method that fires when the custom button is clicked.</li> <li><code>getToken</code> method that requests a token to the server application.</li> </ul> <p>Configure the URLs</p> <p>When running OpenVidu locally, leave <code>APPLICATION_SERVER_URL</code> and <code>LIVEKIT_URL</code> variables empty. The function <code>configureUrls()</code> will automatically configure them with default values. However, for other deployment type, you should configure these variables with the correct URLs depending on your deployment.</p> <p>The OpenVidu Components Angular library provides a set of CSS variables that you can use to customize the appearance of the components. You can define these variables in your application's global styles file (e.g. <code>styles.scss</code>).</p> <pre><code>:root {\n    /* Basic colors */\n    --ov-background-color: #303030; // Background color\n    --ov-surface-color: #ffffff; // Surfaces colors (panels, dialogs)\n\n    /* Text colors */\n    --ov-text-primary-color: #ffffff; // Text color over primary background\n    --ov-text-surface-color: #1d1d1d; // Text color over surface background\n\n    /* Action colors */\n    --ov-primary-action-color: #273235; // Primary color for buttons, etc.\n    --ov-secondary-action-color: #f1f1f1; // Secondary color for buttons, etc.\n    --ov-accent-action-color: #0089ab; // Color for highlighted elements\n\n    /* Status colors */\n    --ov-error-color: #eb5144; // Error color\n    --ov-warn-color: #ffba53; // Warning color\n\n    /* Radius */\n    --ov-toolbar-buttons-radius: 50%; // Radius for toolbar buttons\n    --ov-leave-button-radius: 10px; // Radius for leave button\n    --ov-video-radius: 5px; // Radius for videos\n    --ov-surface-radius: 5px; // Radius for surfaces\n}\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/angular-components/openvidu-toolbar-panel-buttons/#adding-custom-buttons-to-the-toolbar","title":"Adding custom buttons to the toolbar","text":"<p>OpenVidu Components Angular provides a directive called <code>*ovToolbarAdditionalPanelButtons</code> that allows you to add custom buttons to the toolbar. This directive can be used to add buttons to the right part of the toolbar.</p> <p>In the <code>app.component.ts</code> file, you can see the following code snippet:</p> <pre><code>@Component({\n    selector: 'app-root',\n    template: `\n        &lt;ov-videoconference\n            [token]=\"token\"\n            [livekitUrl]=\"LIVEKIT_URL\"\n            [toolbarDisplayRoomName]=\"false\"\n            (onTokenRequested)=\"onTokenRequested($event)\"\n        &gt;\n            &lt;div *ovToolbarAdditionalPanelButtons style=\"text-align: center;\"&gt;\n                &lt;button mat-icon-button (click)=\"onButtonClicked()\"&gt;\n                    &lt;mat-icon&gt;star&lt;/mat-icon&gt;\n                &lt;/button&gt;\n            &lt;/div&gt;\n        &lt;/ov-videoconference&gt;\n    `,\n    styles: [''],\n    standalone: true,\n    imports: [OpenViduComponentsModule, MatIconButton, MatIcon],\n})\nexport class AppComponent {\n    // ...\n}\n</code></pre> <p>In this code snippet, the <code>*ovToolbarAdditionalPanelButtons</code> directive is used to add a custom button to the right part of the toolbar and is displayed as a star icon, and the <code>onButtonClicked</code> method is called when the button is clicked.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/","title":"Application Client Tutorials","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-client/#application-client-tutorials","title":"Application Client Tutorials","text":"<p>Every application client below shares the same core functionality:</p> <ul> <li>Users request a LiveKit token to any application server to connect to a room.</li> <li>Users may publish their camera, microphone and screen-share.</li> <li>Users automatically subscribe to all media published by other users.</li> <li>Users may leave the room at any time.</li> </ul> <p>Every application client below is interchangeable with the others, because:</p> <ul> <li>All of them are compatible with each other, meaning that participants are able to join the same LiveKit room from any of the client applications.</li> <li>All of them are compatible with any application server, meaning that they can request a LiveKit token from any of the server applications.</li> </ul> <p> JavaScript</p> <p> React</p> <p> Angular</p> <p> Vue</p> <p> Electron</p> <p> Ionic</p> <p> Android</p> <p> iOS</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/android/","title":"Android Tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-client/android/#android-tutorial","title":"Android Tutorial","text":"<p>Source code </p> <p>This tutorial is a simple video-call application built for Android, using Kotlin, that allows:</p> <ul> <li>Joining a video call room by requesting a token from any application server.</li> <li>Publishing your camera and microphone.</li> <li>Subscribing to all other participants' video and audio tracks automatically.</li> <li>Leaving the video call room at any time.</li> </ul> <p>It uses the LiveKit Android Kotlin SDK  to connect to the LiveKit server and interact with the video call room.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/android/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-client/android/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/android/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/application-client/android/#3-run-a-server-application","title":"3. Run a server application","text":"Node.js Go Ruby Java Python Rust PHP .NET <p>To run this server application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/node\n</code></pre></li> <li>Install dependencies <pre><code>npm install\n</code></pre></li> <li>Run the application <pre><code>npm start\n</code></pre></li> </ol> <p>For more information, check the Node.js tutorial.</p> <p>To run this server application, you need Go  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/go\n</code></pre></li> <li>Run the application <pre><code>go run main.go\n</code></pre></li> </ol> <p>For more information, check the Go tutorial.</p> <p>To run this server application, you need Ruby  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/ruby\n</code></pre></li> <li>Install dependencies <pre><code>bundle install\n</code></pre></li> <li>Run the application <pre><code>ruby app.rb\n</code></pre></li> </ol> <p>For more information, check the Ruby tutorial.</p> <p>To run this server application, you need Java  and Maven  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/java\n</code></pre></li> <li>Run the application <pre><code>mvn spring-boot:run\n</code></pre></li> </ol> <p>For more information, check the Java tutorial.</p> <p>To run this server application, you need Python 3  installed on your device.</p> <ol> <li> <p>Navigate into the server directory</p> <pre><code>cd openvidu-livekit-tutorials/application-server/python\n</code></pre> </li> <li> <p>Create a python virtual environment</p> <pre><code>python -m venv venv\n</code></pre> </li> <li> <p>Activate the virtual environment</p>  Windows macOS Linux <pre><code>.\\venv\\Scripts\\activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> </li> <li> <p>Install dependencies</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the application</p> <pre><code>python app.py\n</code></pre> </li> </ol> <p>For more information, check the Python tutorial.</p> <p>To run this server application, you need Rust  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/rust\n</code></pre></li> <li>Run the application <pre><code>cargo run\n</code></pre></li> </ol> <p>For more information, check the Rust tutorial.</p> <p>To run this server application, you need PHP  and Composer  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/php\n</code></pre></li> <li>Install dependencies <pre><code>composer install\n</code></pre></li> <li>Run the application <pre><code>composer start\n</code></pre></li> </ol> <p>Warning</p> <p>LiveKit PHP SDK requires library BCMath . This is available out-of-the-box in PHP for Windows, but a manual installation might be necessary in other OS. Run <code>sudo apt install php-bcmath</code> or <code>sudo yum install php-bcmath</code></p> <p>For more information, check the PHP tutorial.</p> <p>To run this server application, you need .NET  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/dotnet\n</code></pre></li> <li>Run the application <pre><code>dotnet run\n</code></pre></li> </ol> <p>Warning</p> <p>This .NET server application needs the <code>LIVEKIT_API_SECRET</code> env variable to be at least 32 characters long. Make sure to update it here  and in your OpenVidu Server.</p> <p>For more information, check the .NET tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/android/#4-run-the-client-application","title":"4. Run the client application","text":"<p>To run the client application tutorial, you need Android Studio  installed on your development computer.</p> <ol> <li> <p>Open Android Studio and import the project located at <code>openvidu-livekit-tutorials/application-client/openvidu-android</code>.</p> </li> <li> <p>Run the application in an emulator or a physical device by clicking the \"Run\" button in Android Studio. Check out the official documentation  for further information.</p> </li> </ol> <p>The application will initiate as a native Android program. Once the application is opened, you should see a screen like this:</p> <p></p> <p>This screen allows you to configure the URLs of the application server and the LiveKit server. You need to set them up for requesting tokens to your application server and connecting to the LiveKit server.</p> <p>Connecting real Android device to application server running in you local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client in a real Android device and be able to reach the application server very easily without worrying about SSL certificates if they are both running in the same local network. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Once you have configured the URLs, you can join a video call room by providing a room name and a user name. After joining the room, you will be able to see your own video and audio tracks, as well as the video and audio tracks of the other participants in the room.</p> <p></p> <p></p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/android/#understanding-the-code","title":"Understanding the code","text":"<p>This Android project has been generated with Android Studio. You may come across various configuration files and other items that are not essential for this tutorial. Our focus will be on the key files located within the <code>app/src/main/java</code> directory:</p> <ul> <li><code>MainActivity.kt</code>: This file defines the main activity of the application, which allows the user to join a video call room by providing a room name and a user name.</li> <li><code>RoomLayoutActivity.kt</code>: Activity responsible for managing the video call room, including publishing and subscribing to video and audio tracks.</li> <li><code>PaticipantAdapter.kt</code> and <code>ParticipantViewHolder.kt</code>: These files define the Adapter and ViewHolder for the RecyclerView that displays the participants video tracks in the video call room.</li> <li><code>Urls.kt</code>: Object that contains the URLs of the application server and the LiveKit server.</li> <li><code>ConfigureUrlsActivity.kt</code>: Activity that allows the user to configure the URLs of the application server and the LiveKit server.</li> </ul> <p>The activity layout files are located in the <code>app/src/main/res/layout</code> directory.</p> <p>To use LiveKit in an Android application, you need to add the LiveKit Android Kotlin SDK  as a dependency in the <code>build.gradle.kts</code> file. This dependecy provides the necessary classes and methods to interact with the LiveKit server:</p> build.gradle.kts<pre><code>dependencies {\n    implementation 'io.livekit:livekit-android:2.5.0'\n}\n</code></pre> <p>You will also need JitPack as a repository in the <code>settings.gradle.kts</code> file:</p> settings.gradle.kts<pre><code>dependencyResolutionManagement {\n    //...\n    repositories {\n        google()\n        mavenCentral()\n        maven(\"https://jitpack.io\")\n    }\n}\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/application-client/android/#android-specific-requirements","title":"Android specific requirements","text":"<p>In order to be able to test the application on an Android device, the application must ask for the necessary permissions to access the device's camera and microphone.</p> <p>First, you need to add the following permissions to the <code>AndroidManifest.xml</code> file located in the <code>app/src/main</code> directory:</p> AndroidManifest.xml<pre><code>&lt;uses-permission android:name=\"android.permission.INTERNET\" /&gt;\n&lt;uses-permission android:name=\"android.permission.CAMERA\" /&gt;\n&lt;uses-permission android:name=\"android.permission.RECORD_AUDIO\" /&gt;\n&lt;uses-permission android:name=\"android.permission.MODIFY_AUDIO_SETTINGS\" /&gt;\n</code></pre> <p>Then, the app need to request these permissions when the user joins the video call room. This is done in the <code>RoomLayoutActivity.kt</code> file by calling the <code>requestNeededPermissions</code> method in the <code>onCreate</code> method:</p> RoomLayoutActivity.kt<pre><code>private fun requestNeededPermissions(onHasPermissions: () -&gt; Unit) {\n    val requestPermissionLauncher =\n        registerForActivityResult(ActivityResultContracts.RequestMultiplePermissions()) { grants -&gt;\n            var hasDenied = false\n\n            // Check if any permissions weren't granted\n            for (grant in grants.entries) {\n                if (!grant.value) {\n                    Toast.makeText(this, \"Missing permission: ${grant.key}\", Toast.LENGTH_SHORT)\n                        .show()\n\n                    hasDenied = true\n                }\n            }\n\n            if (!hasDenied) {\n                onHasPermissions()\n            }\n        }\n\n    // Assemble the needed permissions to request\n    val neededPermissions =\n        listOf(Manifest.permission.RECORD_AUDIO, Manifest.permission.CAMERA).filter {\n            ContextCompat.checkSelfPermission(\n                this, it\n            ) == PackageManager.PERMISSION_DENIED\n        }.toTypedArray()\n\n    if (neededPermissions.isNotEmpty()) {\n        requestPermissionLauncher.launch(neededPermissions)\n    } else {\n        onHasPermissions()\n    }\n}\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/application-client/android/#configuring-urls","title":"Configuring URLs","text":"<p>The <code>Urls.kt</code> file defines an object that contains the following URLs required for the application:</p> <ul> <li><code>applicationServerUrl</code>: The URL of the application server. This variable is used to make requests to the server to obtain a token for joining the video call room.</li> <li><code>livekitUrl</code>: The URL of the LiveKit server. This variable is used to connect to the LiveKit server and interact with the video call room.</li> </ul> <p>You should configure these URLs according to your deployment settings. In case you are running OpenVidu locally, you can set the <code>applicationServerUrl</code> to <code>https://xxx-yyy-zzz-www.openvidu-local.dev:6443</code> and the <code>livekitUrl</code> to <code>wss://xxx-yyy-zzz-www.openvidu-local.dev:7443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is the LAN private IP address of the machine running OpenVidu, with dashes (-) instead of dots (.).</p> <p>If these URLs are left empty, the user will be prompted to enter the URLs when the application starts. This configuration is managed in the <code>ConfigureUrlsActivity.kt</code> file:</p> <p></p> <p>When the user clicks the <code>Save</code> button, the <code>onSaveUrls()</code> method is called, which saves the URLs in the <code>Urls</code> object and finishes the activity, returning to the MainActivity:</p> ConfigureUrlsActivity.kt<pre><code>private fun onSaveUrls() {\n    val serverUrl = binding.serverUrl.text.toString()\n    val livekitUrl = binding.livekitUrl.text.toString()\n\n    if (serverUrl.isNotEmpty() &amp;&amp; livekitUrl.isNotEmpty()) {\n        Urls.livekitUrl = binding.livekitUrl.text.toString()\n        Urls.applicationServerUrl = binding.serverUrl.text.toString()\n        finish()\n    } else {\n        Toast.makeText(this, \"Please fill in all fields\", Toast.LENGTH_SHORT).show()\n    }\n}\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/application-client/android/#joining-a-room","title":"Joining a room","text":"<p>Before joining a room, the user must provide a room name and a user name. After the user specifies them, when they click the <code>Join</code> button, the <code>navigateToRoomLayoutActivity()</code> method of the <code>MainActivity.kt</code> file is called, which simply set the values of the participant name and room name in the intent and starts the <code>RoomLayoutActivity</code>:</p> MainActivity.kt<pre><code>private fun navigateToRoomLayoutActivity() {\n    binding.joinButton.isEnabled = false\n\n    val participantName = binding.participantName.text.toString()\n    val roomName = binding.roomName.text.toString()\n\n    if (participantName.isNotEmpty() &amp;&amp; roomName.isNotEmpty()) {\n        val intent = Intent(this, RoomLayoutActivity::class.java)\n        intent.putExtra(\"participantName\", participantName)\n        intent.putExtra(\"roomName\", roomName)\n        startActivity(intent)\n    } else {\n        Toast.makeText(this, \"Please fill in all fields\", Toast.LENGTH_SHORT).show()\n    }\n\n    binding.joinButton.isEnabled = true\n}\n</code></pre> <p>Now let's see the code of the <code>RoomLayoutActivity.kt</code> file:</p> RoomLayoutActivity.kt<pre><code>data class TrackInfo( // (1)!\n    val track: VideoTrack,\n    val participantIdentity: String,\n    val isLocal: Boolean = false\n)\n\nclass RoomLayoutActivity : AppCompatActivity() {\n    private lateinit var binding: ActivityRoomLayoutBinding // (2)!\n    private lateinit var participantAdapter: ParticipantAdapter // (3)!\n\n    private lateinit var room: Room // (4)!\n    private val participantTracks: MutableList&lt;TrackInfo&gt; = mutableListOf() // (5)!\n\n    private val client = HttpClient(CIO) { // (6)!\n        expectSuccess = true\n        install(ContentNegotiation) {\n            json()\n        }\n    }\n</code></pre> <ol> <li><code>TrackInfo</code> data class, which groups a video track with the participant's identity.</li> <li>The binding object for the activity layout.</li> <li>The adapter for the RecyclerView that displays the participants' video tracks.</li> <li>The room object, which represents the video call room.</li> <li>A list of <code>TrackInfo</code> objects, which represent the video tracks of the participants in the room.</li> <li>The HTTP client used to make requests to the application server.</li> </ol> <p>The <code>RoomLayoutActivity.kt</code> file defines the following variables:</p> <ul> <li><code>room</code>: The room object, which represents the video call room.</li> <li><code>participantTracks</code>: A list of <code>TrackInfo</code> objects, which represent the video tracks of the participants in the room.</li> </ul> <p>When the activity is created, the <code>onCreate</code> method is called. This method initializes the activity layout, create a <code>Room</code> object, initializes the <code>RecyclerView</code> and request needed permissions:</p> RoomLayoutActivity.kt<pre><code>override fun onCreate(savedInstanceState: Bundle?) {\n    super.onCreate(savedInstanceState)\n    binding = ActivityRoomLayoutBinding.inflate(layoutInflater)\n    setContentView(binding.root)\n\n    binding.loader.visibility = View.VISIBLE\n    binding.leaveButton.setOnClickListener {\n        leaveRoom()\n    }\n\n    // Create Room object\n    room = LiveKit.create(applicationContext)\n\n    initRecyclerView()\n\n    // Check for audio and camera permissions before connecting to the room\n    requestNeededPermissions { connectToRoom() }\n}\n</code></pre> <p>After the application check if the user has granted permissions, the <code>connectToRoom()</code> method is called:</p> RoomLayoutActivity.kt<pre><code>private fun connectToRoom() {\n    // Get the room name and participant name from the intent\n    val participantName = intent.getStringExtra(\"participantName\") ?: \"Participant1\" // (1)!\n    val roomName = intent.getStringExtra(\"roomName\") ?: \"Test Room\"\n\n    binding.roomName.text = roomName // (2)!\n\n    lifecycleScope.launch {\n        // Specify the actions when events take place in the room\n        launch {\n            room.events.collect { event -&gt;\n                when (event) {\n                    // On every new Track received...\n                    is RoomEvent.TrackSubscribed -&gt; onTrackSubscribed(event) // (3)!\n                    // On every new Track destroyed...\n                    is RoomEvent.TrackUnsubscribed -&gt; onTrackUnsubscribed(event) // (4)!\n                    else -&gt; {}\n                }\n            }\n        }\n\n        try {\n            // Get token from your application server with the room name and participant name\n            val token = getToken(roomName, participantName) // (5)!\n\n            // Connect to the room with the LiveKit URL and the token\n            room.connect(Urls.livekitUrl, token) // (6)!\n\n            // Publish your camera and microphone\n            val localParticipant = room.localParticipant\n            localParticipant.setMicrophoneEnabled(true) // (7)!\n            localParticipant.setCameraEnabled(true)\n\n            // Add local video track to the participantTracks list\n            launch {\n                localParticipant::videoTrackPublications.flow\n                    .collect { publications -&gt;\n                        val videoTrack = publications.firstOrNull()?.second as? VideoTrack\n\n                        if (videoTrack != null) {\n                            participantTracks.add( // (8)!\n                                0,\n                                TrackInfo(videoTrack, participantName, true)\n                            )\n                            participantAdapter.notifyItemInserted(0)\n                        }\n                    }\n            }\n\n            binding.loader.visibility = View.GONE\n        } catch (e: Exception) {\n            println(\"There was an error connecting to the room: ${e.message}\")\n            Toast.makeText(this@RoomLayoutActivity, \"Failed to join room\", Toast.LENGTH_SHORT)\n                .show()\n            leaveRoom()\n        }\n    }\n}\n</code></pre> <ol> <li>Get the room name and participant name from the intent.</li> <li>Set the room title in the layout.</li> <li>Event handling for when a new track is received in the room.</li> <li>Event handling for when a track is destroyed.</li> <li>Get a token from the application server with the room name and participant name.</li> <li>Connect to the room with the LiveKit URL and the token.</li> <li>Publish your camera and microphone.</li> <li>Add local video track to the <code>participantTracks</code> list</li> </ol> <p>The <code>connectToRoom()</code> method performs the following actions:</p> <ol> <li>It retrieves the room name and participant name from the intent.</li> <li>Set the room title in the layout.</li> <li> <p>Event handling is configured for different scenarios within the room. These events are fired when new tracks are subscribed to and when existing tracks are unsubscribed.</p> <ul> <li><code>RoomEvent.TrackSubscribed</code>: This event is triggered when a new track is received in the room. It manages the storage of the new track in the <code>participantTracks</code> list if it is a video track and notify the Adapter that a new item has been inserted.</li> </ul> RoomLayoutActivity.kt<pre><code>private fun onTrackSubscribed(event: RoomEvent.TrackSubscribed) {\n    val track = event.track\n\n    // If the track is a video track, add it to the participantTracks list\n    if (track is VideoTrack) {\n        participantTracks.add(TrackInfo(track, event.participant.identity!!.value))\n        participantAdapter.notifyItemInserted(participantTracks.size - 1)\n    }\n}\n</code></pre> <ul> <li><code>RoomEvent.TrackUnsubscribed</code>: This event occurs when a track is destroyed, and it takes care of removing the video track from the <code>participantTracks</code> list and notify the Adapter that an item has been removed.</li> </ul> RoomLayoutActivity.kt<pre><code>private fun onTrackUnsubscribed(event: RoomEvent.TrackUnsubscribed) {\n    val track = event.track\n\n    // If the track is a video track, remove it from the participantTracks list\n    if (track is VideoTrack) {\n        val index = participantTracks.indexOfFirst { it.track.sid == track.sid }\n\n        if (index != -1) {\n            participantTracks.removeAt(index)\n            participantAdapter.notifyItemRemoved(index)\n        }\n    }\n}\n</code></pre> <p>These event handlers are essential for managing the behavior of tracks within the video call.</p> <p>Take a look at all events</p> <p>You can take a look at all the events in the Livekit Documentation</p> </li> <li> <p>It requests a token from the application server using the room name and participant name. This is done by calling the <code>getToken()</code> method:</p> RoomLayoutActivity.kt<pre><code>/**\n * --------------------------------------------\n * GETTING A TOKEN FROM YOUR APPLICATION SERVER\n * --------------------------------------------\n * The method below request the creation of a token to\n * your application server. This prevents the need to expose\n * your LiveKit API key and secret to the client side.\n *\n * In this sample code, there is no user control at all. Anybody could\n * access your application server endpoints. In a real production\n * environment, your application server must identify the user to allow\n * access to the endpoints.\n */\nprivate suspend fun getToken(roomName: String, participantName: String): String {\n    val response = client.post(Urls.applicationServerUrl + \"token\") {\n        contentType(ContentType.Application.Json)\n        setBody(TokenRequest(participantName, roomName))\n    }\n    return response.body&lt;TokenResponse&gt;().token\n}\n</code></pre> <p>This method sends a POST request using Ktor Client  to the application server's <code>/token</code> endpoint. The request body contains the room name and participant name. The server responds with a token that is used to connect to the room.</p> </li> <li> <p>It connects to the room using the LiveKit URL and the token.</p> </li> <li>It publishes the camera and microphone tracks to the room using <code>setMicrophoneEnabled()</code> and <code>setCameraEnabled()</code> methods from <code>room.localParticipant</code>.</li> <li>It adds the local video track to the <code>participantTracks</code> list.</li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/application-client/android/#displaying-video-tracks","title":"Displaying Video Tracks","text":"<p>In order to display the video tracks of the participants in the room, the <code>RoomLayoutActivity</code> uses a <code>RecyclerView</code> with a custom <code>Adapter</code> and <code>ViewHolder</code>. This allows the application to load and display the video tracks dynamically as they are received.</p> <p>Whenever a new video track is added to the <code>participantTracks</code> list, the <code>ParticipantAdapter</code> is notified that a new item has been inserted. The <code>ParticipantAdapter</code> then updates the <code>RecyclerView</code> to display the new video track by calling the <code>render</code> method of the <code>ParticipantViewHolder</code>:</p> ParticipantViewHolder.kt<pre><code>fun render(trackInfo: TrackInfo, room: Room) {\n    val participantIdentity = if (trackInfo.isLocal) {\n        trackInfo.participantIdentity + \" (You)\"\n    } else {\n        trackInfo.participantIdentity\n    }\n\n    binding.identity.text = participantIdentity // (1)!\n\n    // Only initialize the renderer once\n    if (!used) {\n        room.initVideoRenderer(binding.renderer) // (2)!\n        used = true\n    }\n\n    trackInfo.track.addRenderer(binding.renderer) // (3)!\n}\n</code></pre> <ol> <li>Set the participant identity in the layout.</li> <li>Initialize the video renderer for the participant.</li> <li>Add the video track to the renderer.</li> </ol> <p>The <code>render</code> method performs the following actions:</p> <ul> <li>It sets the participant identity in the layout.</li> <li>It initializes the video renderer for the participant. This is done only once for each participant.</li> <li>It adds the video track to the renderer.</li> </ul>","tags":["Platform"]},{"location":"docs/tutorials/application-client/android/#leaving-the-room","title":"Leaving the room","text":"<p>When the user wants to leave the room, they can click the <code>Leave Room</code> button. This action calls the <code>leaveRoom()</code> method:</p> RoomLayoutActivity.kt<pre><code>private fun leaveRoom() {\n    // Leave the room by calling 'disconnect' method over the Room object\n    room.disconnect() // (1)!\n\n    client.close() // (2)!\n\n    // Go back to the previous activity.\n    finish() // (3)!\n}\n\noverride fun onDestroy() { // (4)!\n    super.onDestroy()\n    leaveRoom()\n}\n</code></pre> <ol> <li>Disconnect the user from the room.</li> <li>Close the HTTP client.</li> <li>Finish the activity and go back to the previous activity.</li> <li>Call the <code>leaveRoom()</code> method when the activity is destroyed.</li> </ol> <p>The <code>leaveRoom()</code> method performs the following actions:</p> <ul> <li>It disconnects the user from the room by calling the <code>disconnect()</code> method on the <code>room</code> object.</li> <li>It closes the HTTP client.</li> <li>It finishes the activity and goes back to the previous activity.</li> </ul> <p>The <code>onDestroy()</code> lifecycle method is used to ensure that the user leaves the room when the activity is destroyed.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/angular/","title":"Angular Tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-client/angular/#angular-tutorial","title":"Angular Tutorial","text":"<p>Source code </p> <p>This tutorial is a simple video-call application built with Angular that allows:</p> <ul> <li>Joining a video call room by requesting a token from any application server.</li> <li>Publishing your camera and microphone.</li> <li>Subscribing to all other participants' video and audio tracks automatically.</li> <li>Leaving the video call room at any time.</li> </ul> <p>It uses the LiveKit JS SDK  to connect to the LiveKit server and interact with the video call room.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/angular/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-client/angular/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/angular/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/application-client/angular/#3-run-a-server-application","title":"3. Run a server application","text":"Node.js Go Ruby Java Python Rust PHP .NET <p>To run this server application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/node\n</code></pre></li> <li>Install dependencies <pre><code>npm install\n</code></pre></li> <li>Run the application <pre><code>npm start\n</code></pre></li> </ol> <p>For more information, check the Node.js tutorial.</p> <p>To run this server application, you need Go  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/go\n</code></pre></li> <li>Run the application <pre><code>go run main.go\n</code></pre></li> </ol> <p>For more information, check the Go tutorial.</p> <p>To run this server application, you need Ruby  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/ruby\n</code></pre></li> <li>Install dependencies <pre><code>bundle install\n</code></pre></li> <li>Run the application <pre><code>ruby app.rb\n</code></pre></li> </ol> <p>For more information, check the Ruby tutorial.</p> <p>To run this server application, you need Java  and Maven  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/java\n</code></pre></li> <li>Run the application <pre><code>mvn spring-boot:run\n</code></pre></li> </ol> <p>For more information, check the Java tutorial.</p> <p>To run this server application, you need Python 3  installed on your device.</p> <ol> <li> <p>Navigate into the server directory</p> <pre><code>cd openvidu-livekit-tutorials/application-server/python\n</code></pre> </li> <li> <p>Create a python virtual environment</p> <pre><code>python -m venv venv\n</code></pre> </li> <li> <p>Activate the virtual environment</p>  Windows macOS Linux <pre><code>.\\venv\\Scripts\\activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> </li> <li> <p>Install dependencies</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the application</p> <pre><code>python app.py\n</code></pre> </li> </ol> <p>For more information, check the Python tutorial.</p> <p>To run this server application, you need Rust  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/rust\n</code></pre></li> <li>Run the application <pre><code>cargo run\n</code></pre></li> </ol> <p>For more information, check the Rust tutorial.</p> <p>To run this server application, you need PHP  and Composer  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/php\n</code></pre></li> <li>Install dependencies <pre><code>composer install\n</code></pre></li> <li>Run the application <pre><code>composer start\n</code></pre></li> </ol> <p>Warning</p> <p>LiveKit PHP SDK requires library BCMath . This is available out-of-the-box in PHP for Windows, but a manual installation might be necessary in other OS. Run <code>sudo apt install php-bcmath</code> or <code>sudo yum install php-bcmath</code></p> <p>For more information, check the PHP tutorial.</p> <p>To run this server application, you need .NET  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/dotnet\n</code></pre></li> <li>Run the application <pre><code>dotnet run\n</code></pre></li> </ol> <p>Warning</p> <p>This .NET server application needs the <code>LIVEKIT_API_SECRET</code> env variable to be at least 32 characters long. Make sure to update it here  and in your OpenVidu Server.</p> <p>For more information, check the .NET tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/angular/#4-run-the-client-application","title":"4. Run the client application","text":"<p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-angular\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p> <p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/angular/#understanding-the-code","title":"Understanding the code","text":"<p>This Angular project has been created using the Angular CLI tool. You may come across various configuration files and other items that are not essential for this tutorial. Our focus will be on the key files located within the <code>src/app/</code> directory:</p> <ul> <li><code>app.component.ts</code>: This file defines the <code>AppComponent</code>, which serves as the main component of the application. It is responsible for handling tasks such as joining a video call and managing the video calls themselves.</li> <li><code>app.component.html</code>: This HTML file is associated with the <code>AppComponent</code>, and it dictates the structure and layout of the main application component.</li> <li><code>app.component.css</code>: The CSS file linked to <code>AppComponent</code>, which controls the styling and appearance of the application's main component.</li> <li><code>VideoComponent</code>: Component responsible for displaying video tracks along with participant's data. It is defined in the <code>video.component.ts</code> file within the <code>video</code> directory, along with its associated HTML and CSS files.</li> <li><code>AudioComponent</code>: Component responsible for displaying audio tracks. It is defined in the <code>audio.component.ts</code> file within the <code>audio</code> directory, along with its associated HTML and CSS files.</li> </ul> <p>To use the LiveKit JS SDK in an Angular application, you need to install the <code>livekit-client</code> package. This package provides the necessary classes and methods to interact with the LiveKit server. You can install it using the following command:</p> <pre><code>npm install livekit-client\n</code></pre> <p>Now let's see the code of the <code>app.component.ts</code> file:</p> app.component.ts<pre><code>type TrackInfo = { // (1)!\n    trackPublication: RemoteTrackPublication;\n    participantIdentity: string;\n};\n\n// When running OpenVidu locally, leave these variables empty\n// For other deployment type, configure them with correct URLs depending on your deployment\nvar APPLICATION_SERVER_URL = ''; // (2)!\nvar LIVEKIT_URL = ''; // (3)!\n\n@Component({ // (4)!\n    selector: 'app-root',\n    standalone: true,\n    imports: [ReactiveFormsModule, AudioComponent, VideoComponent],\n    templateUrl: './app.component.html',\n    styleUrl: './app.component.css',\n})\nexport class AppComponent implements OnDestroy {\n    roomForm = new FormGroup({ // (5)!\n        roomName: new FormControl('Test Room', Validators.required),\n        participantName: new FormControl('Participant' + Math.floor(Math.random() * 100), Validators.required),\n    });\n\n    room = signal&lt;Room | undefined&gt;(undefined); // (6)!\n    localTrack = signal&lt;LocalVideoTrack | undefined&gt;(undefined); // (7)!\n    remoteTracksMap = signal&lt;Map&lt;string, TrackInfo&gt;&gt;(new Map()); // (8)!\n\n    constructor(private httpClient: HttpClient) {\n        this.configureUrls();\n    }\n\n    configureUrls() {\n        // If APPLICATION_SERVER_URL is not configured, use default value from OpenVidu Local deployment\n        if (!APPLICATION_SERVER_URL) {\n            if (window.location.hostname === 'localhost') {\n                APPLICATION_SERVER_URL = 'http://localhost:6080/';\n            } else {\n                APPLICATION_SERVER_URL = 'https://' + window.location.hostname + ':6443/';\n            }\n        }\n\n        // If LIVEKIT_URL is not configured, use default value from OpenVidu Local deployment\n        if (!LIVEKIT_URL) {\n            if (window.location.hostname === 'localhost') {\n                LIVEKIT_URL = 'ws://localhost:7880/';\n            } else {\n                LIVEKIT_URL = 'wss://' + window.location.hostname + ':7443/';\n            }\n        }\n    }\n</code></pre> <ol> <li><code>TrackInfo</code> type, which groups a track publication with the participant's identity.</li> <li>The URL of the application server.</li> <li>The URL of the LiveKit server.</li> <li>Angular component decorator that defines the <code>AppComponent</code> class and associates the HTML and CSS files with it.</li> <li>The <code>roomForm</code> object, which is a form group that contains the <code>roomName</code> and <code>participantName</code> fields. These fields are used to join a video call room.</li> <li>The room object, which represents the video call room.</li> <li>The local video track, which represents the user's camera.</li> <li>Map that links track SIDs with <code>TrackInfo</code> objects. This map is used to store remote tracks and their associated participant identities.</li> </ol> <p>The <code>app.component.ts</code> file defines the following variables:</p> <ul> <li><code>APPLICATION_SERVER_URL</code>: The URL of the application server. This variable is used to make requests to the server to obtain a token for joining the video call room.</li> <li><code>LIVEKIT_URL</code>: The URL of the LiveKit server. This variable is used to connect to the LiveKit server and interact with the video call room.</li> <li><code>roomForm</code>: A form group that contains the <code>roomName</code> and <code>participantName</code> fields. These fields are used to join a video call room.</li> <li><code>room</code>: The room object, which represents the video call room.</li> <li><code>localTrack</code>: The local video track, which represents the user's camera.</li> <li><code>remoteTracksMap</code>: A map that links track SIDs with <code>TrackInfo</code> objects. This map is used to store remote tracks and their associated participant identities.</li> </ul> <p>Configure the URLs</p> <p>When running OpenVidu locally, leave <code>APPLICATION_SERVER_URL</code> and <code>LIVEKIT_URL</code> variables empty. The function <code>configureUrls()</code> will automatically configure them with default values. However, for other deployment type, you should configure these variables with the correct URLs depending on your deployment.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/angular/#joining-a-room","title":"Joining a Room","text":"<p>After the user specifies their participant name and the name of the room they want to join, when they click the <code>Join</code> button, the <code>joinRoom()</code> method is called:</p> app.component.ts<pre><code>async joinRoom() {\n    // Initialize a new Room object\n    const room = new Room();\n    this.room.set(room); // (1)!\n\n    // Specify the actions when events take place in the room\n    // On every new Track received...\n    this.room.on(\n        RoomEvent.TrackSubscribed,\n        (_track: RemoteTrack, publication: RemoteTrackPublication, participant: RemoteParticipant) =&gt; { // (2)!\n            this.remoteTracksMap.update((map) =&gt; {\n                map.set(publication.trackSid, {\n                    trackPublication: publication,\n                    participantIdentity: participant.identity,\n                });\n                return map;\n            });\n        }\n    );\n\n    // On every new Track destroyed...\n    room.on(RoomEvent.TrackUnsubscribed, (_track: RemoteTrack, publication: RemoteTrackPublication) =&gt; { // (3)!\n        this.remoteTracksMap.update((map) =&gt; {\n            map.delete(publication.trackSid);\n            return map;\n        });\n    });\n\n    try {\n        // Get the room name and participant name from the form\n        const roomName = this.roomForm.value.roomName!; // (4)!\n        const participantName = this.roomForm.value.participantName!;\n\n        // Get a token from your application server with the room name and participant name\n        const token = await this.getToken(roomName, participantName); // (5)!\n\n        // Connect to the room with the LiveKit URL and the token\n        await room.connect(LIVEKIT_URL, token); // (6)!\n\n        // Publish your camera and microphone\n        await room.localParticipant.enableCameraAndMicrophone(); // (7)!\n        this.localTrack.set(room.localParticipant.videoTrackPublications.values().next().value.videoTrack);\n    } catch (error: any) {\n        console.log(\n            'There was an error connecting to the room:',\n            error?.error?.errorMessage || error?.message || error\n        );\n        await this.leaveRoom();\n    }\n}\n</code></pre> <ol> <li>Initialize a new <code>Room</code> object.</li> <li>Event handling for when a new track is received in the room.</li> <li>Event handling for when a track is destroyed.</li> <li>Get the room name and participant name from the form.</li> <li>Get a token from the application server with the room name and participant name.</li> <li>Connect to the room with the LiveKit URL and the token.</li> <li>Publish your camera and microphone.</li> </ol> <p>The <code>joinRoom()</code> method performs the following actions:</p> <ol> <li> <p>It creates a new <code>Room</code> object. This object represents the video call room.</p> <p>Info</p> <p>When the room object is defined, the HTML template is automatically updated hiding the \"Join room\" page and showing the \"Room\" layout.</p> </li> <li> <p>Event handling is configured for different scenarios within the room. These events are fired when new tracks are subscribed to and when existing tracks are unsubscribed.</p> <ul> <li> <p><code>RoomEvent.TrackSubscribed</code>: This event is triggered when a new track is received in the room. It manages the storage of the new track in the <code>remoteTracksMap</code>, which links track SIDs with <code>TrackInfo</code> objects containing the track publication and the participant's identity.</p> </li> <li> <p><code>RoomEvent.TrackUnsubscribed</code>: This event occurs when a track is destroyed, and it takes care of removing the track from the <code>remoteTracksMap</code>.</p> </li> </ul> <p>These event handlers are essential for managing the behavior of tracks within the video call. You can further extend the event handling as needed for your application.</p> <p>Take a look at all events</p> <p>You can take a look at all the events in the Livekit Documentation</p> </li> <li> <p>It retrieves the room name and participant name from the form.</p> </li> <li> <p>It requests a token from the application server using the room name and participant name. This is done by calling the <code>getToken()</code> method:</p> app.component.ts<pre><code>/**\n * --------------------------------------------\n * GETTING A TOKEN FROM YOUR APPLICATION SERVER\n * --------------------------------------------\n * The method below request the creation of a token to\n * your application server. This prevents the need to expose\n * your LiveKit API key and secret to the client side.\n *\n * In this sample code, there is no user control at all. Anybody could\n * access your application server endpoints. In a real production\n * environment, your application server must identify the user to allow\n * access to the endpoints.\n */\nasync getToken(roomName: string, participantName: string): Promise&lt;string&gt; {\n    const response = await lastValueFrom(\n        this.httpClient.post&lt;{ token: string }&gt;(APPLICATION_SERVER_URL + 'token', { roomName, participantName })\n    );\n    return response.token;\n}\n</code></pre> <p>This function sends a POST request using HttpClient  to the application server's <code>/token</code> endpoint. The request body contains the room name and participant name. The server responds with a token that is used to connect to the room.</p> </li> <li> <p>It connects to the room using the LiveKit URL and the token.</p> </li> <li>It publishes the camera and microphone tracks to the room using <code>room.localParticipant.enableCameraAndMicrophone()</code>, which asks the user for permission to access their camera and microphone at the same time. The local video track is then stored in the <code>localTrack</code> variable.</li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/application-client/angular/#displaying-video-and-audio-tracks","title":"Displaying Video and Audio Tracks","text":"<p>In order to display participants' video and audio tracks, the <code>app.component.html</code> file integrates the <code>VideoComponent</code> and <code>AudioComponent</code>.</p> app.component.html<pre><code>&lt;div id=\"layout-container\"&gt;\n    @if (localTrack()) {\n    &lt;video-component\n        [track]=\"localTrack()!\"\n        [participantIdentity]=\"roomForm.value.participantName!\"\n        [local]=\"true\"\n    &gt;&lt;/video-component&gt;\n    }\n    @for (remoteTrack of remoteTracksMap().values(); track remoteTrack.trackPublication.trackSid) {\n        @if (remoteTrack.trackPublication.kind === 'video') {\n        &lt;video-component\n            [track]=\"remoteTrack.trackPublication.videoTrack!\"\n            [participantIdentity]=\"remoteTrack.participantIdentity\"\n        &gt;&lt;/video-component&gt;\n        } @else {\n        &lt;audio-component [track]=\"remoteTrack.trackPublication.audioTrack!\" hidden&gt;&lt;/audio-component&gt;\n        }\n    }\n&lt;/div&gt;\n</code></pre> <p>This code snippet does the following:</p> <ul> <li> <p>We use the Angular <code>@if</code> block to conditionally display the local video track using the <code>VideoComponent</code>. The <code>local</code> property is set to <code>true</code> to indicate that the video track belongs to the local participant.</p> <p>Info</p> <p>The audio track is not displayed for the local participant because there is no need to hear one's own audio.</p> </li> <li> <p>Then, we use the Angular <code>@for</code> block to iterate over the <code>remoteTracksMap</code>. For each remote track, we create a <code>VideoComponent</code> or an <code>AudioComponent</code> depending on the track's kind (video or audio). The <code>participantIdentity</code> property is set to the participant's identity, and the <code>track</code> property is set to the video or audio track. The <code>hidden</code> attribute is added to the <code>AudioComponent</code> to hide the audio tracks from the layout.</p> </li> </ul> <p>Let's see now the code of the <code>video.component.ts</code> file:</p> video.component.ts<pre><code>// (1)!\n@Component({\n    selector: \"video-component\",\n    standalone: true,\n    imports: [],\n    templateUrl: \"./video.component.html\",\n    styleUrl: \"./video.component.css\"\n})\nexport class VideoComponent implements AfterViewInit, OnDestroy {\n    videoElement = viewChild&lt;ElementRef&lt;HTMLVideoElement&gt;&gt;(\"videoElement\"); // (2)!\n\n    track = input.required&lt;LocalVideoTrack | RemoteVideoTrack&gt;(); // (3)!\n    participantIdentity = input.required&lt;string&gt;(); // (4)!\n    local = input(false); // (5)!\n\n    ngAfterViewInit() {\n        if (this.videoElement()) {\n            this.track().attach(this.videoElement()!.nativeElement); // (6)!\n        }\n    }\n\n    ngOnDestroy() {\n        this.track().detach(); // (7)!\n    }\n}\n</code></pre> <ol> <li>Angular component decorator that defines the <code>VideoComponent</code> class and associates the HTML and CSS files with it.</li> <li>The reference to the video element in the HTML template.</li> <li>The video track object, which can be a <code>LocalVideoTrack</code> or a <code>RemoteVideoTrack</code>.</li> <li>The participant identity associated with the video track.</li> <li>A boolean flag that indicates whether the video track belongs to the local participant.</li> <li>Attach the video track to the video element when the track is set.</li> <li>Detach the video track when the component is destroyed.</li> </ol> <p>The <code>VideoComponent</code> does the following:</p> <ul> <li> <p>It defines the properties <code>track</code>, <code>participantIdentity</code>, and <code>local</code> as inputs of the component:</p> <ul> <li><code>track</code>: The video track object, which can be a <code>LocalVideoTrack</code> or a <code>RemoteVideoTrack</code>.</li> <li><code>participantIdentity</code>: The participant identity associated with the video track.</li> <li><code>local</code>: A boolean flag that indicates whether the video track belongs to the local participant. This flag is set to <code>false</code> by default.</li> </ul> </li> <li> <p>It creates a reference to the video element in the HTML template.</p> </li> <li>It attaches the video track to the video element when the view is initialized.</li> <li>It detaches the video track when the component is destroyed.</li> </ul> <p>Finally, let's see the code of the <code>audio.component.ts</code> file:</p> audio.component.ts<pre><code>// (1)!\n@Component({\n    selector: \"audio-component\",\n    standalone: true,\n    imports: [],\n    templateUrl: \"./audio.component.html\",\n    styleUrl: \"./audio.component.css\"\n})\nexport class AudioComponent implements AfterViewInit, OnDestroy {\n    audioElement = viewChild&lt;ElementRef&lt;HTMLAudioElement&gt;&gt;(\"audioElement\"); // (2)!\n\n    track = input.required&lt;LocalAudioTrack | RemoteAudioTrack&gt;(); // (3)!\n\n    ngAfterViewInit() {\n        if (this.audioElement()) {\n            this.track().attach(this.audioElement()!.nativeElement); // (4)!\n        }\n    }\n\n    ngOnDestroy() {\n        this.track().detach(); // (5)!\n    }\n}\n</code></pre> <ol> <li>Angular component decorator that defines the <code>AudioComponent</code> class and associates the HTML and CSS files with it.</li> <li>The reference to the audio element in the HTML template.</li> <li>The audio track object, which can be a <code>RemoteAudioTrack</code> or a <code>LocalAudioTrack</code>, although in this case, it will always be a <code>RemoteAudioTrack</code>.</li> <li>Attach the audio track to the audio element when view is initialized.</li> <li>Detach the audio track when the component is destroyed.</li> </ol> <p>The <code>AudioComponent</code> class is similar to the <code>VideoComponent</code> class, but it is used to display audio tracks. It attaches the audio track to the audio element when view is initialized and detaches the audio track when the component is destroyed.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/angular/#leaving-the-room","title":"Leaving the Room","text":"<p>When the user wants to leave the room, they can click the <code>Leave Room</code> button. This action calls the <code>leaveRoom()</code> method:</p> app.component.ts<pre><code>async leaveRoom() {\n    // Leave the room by calling 'disconnect' method over the Room object\n    await this.room()?.disconnect(); // (1)!\n\n    // Reset all variables\n    this.room.set(undefined); // (2)!\n    this.localTrack.set(undefined);\n    this.remoteTracksMap.set(new Map());\n}\n\n@HostListener('window:beforeunload') // (3)!\nasync ngOnDestroy() {\n    // On window closed or component destroyed, leave the room\n    await this.leaveRoom();\n}\n</code></pre> <ol> <li>Disconnect the user from the room.</li> <li>Reset all variables.</li> <li>Call the <code>leaveRoom()</code> method when the user closes the browser window or navigates to another page.</li> </ol> <p>The <code>leaveRoom()</code> method performs the following actions:</p> <ul> <li>It disconnects the user from the room by calling the <code>disconnect()</code> method on the <code>room</code> object.</li> <li>It resets all variables.</li> </ul> <p>The <code>window.onbeforeunload</code> event and the <code>ngOnDestroy()</code> lifecycle hook are used to ensure that the user leaves the room when the browser window is closed or the component is destroyed.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/electron/","title":"Electron Tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-client/electron/#electron-tutorial","title":"Electron Tutorial","text":"<p>Source code </p> <p>This tutorial is a simple video-call application built with Electron that allows:</p> <ul> <li>Joining a video call room by requesting a token from any application server.</li> <li>Publishing your camera and microphone.</li> <li>Subscribing to all other participants' video and audio tracks automatically.</li> <li>Leaving the video call room at any time.</li> </ul> <p>It uses the LiveKit JS SDK  to connect to the LiveKit server and interact with the video call room.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/electron/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-client/electron/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/electron/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/application-client/electron/#3-run-a-server-application","title":"3. Run a server application","text":"Node.js Go Ruby Java Python Rust PHP .NET <p>To run this server application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/node\n</code></pre></li> <li>Install dependencies <pre><code>npm install\n</code></pre></li> <li>Run the application <pre><code>npm start\n</code></pre></li> </ol> <p>For more information, check the Node.js tutorial.</p> <p>To run this server application, you need Go  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/go\n</code></pre></li> <li>Run the application <pre><code>go run main.go\n</code></pre></li> </ol> <p>For more information, check the Go tutorial.</p> <p>To run this server application, you need Ruby  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/ruby\n</code></pre></li> <li>Install dependencies <pre><code>bundle install\n</code></pre></li> <li>Run the application <pre><code>ruby app.rb\n</code></pre></li> </ol> <p>For more information, check the Ruby tutorial.</p> <p>To run this server application, you need Java  and Maven  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/java\n</code></pre></li> <li>Run the application <pre><code>mvn spring-boot:run\n</code></pre></li> </ol> <p>For more information, check the Java tutorial.</p> <p>To run this server application, you need Python 3  installed on your device.</p> <ol> <li> <p>Navigate into the server directory</p> <pre><code>cd openvidu-livekit-tutorials/application-server/python\n</code></pre> </li> <li> <p>Create a python virtual environment</p> <pre><code>python -m venv venv\n</code></pre> </li> <li> <p>Activate the virtual environment</p>  Windows macOS Linux <pre><code>.\\venv\\Scripts\\activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> </li> <li> <p>Install dependencies</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the application</p> <pre><code>python app.py\n</code></pre> </li> </ol> <p>For more information, check the Python tutorial.</p> <p>To run this server application, you need Rust  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/rust\n</code></pre></li> <li>Run the application <pre><code>cargo run\n</code></pre></li> </ol> <p>For more information, check the Rust tutorial.</p> <p>To run this server application, you need PHP  and Composer  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/php\n</code></pre></li> <li>Install dependencies <pre><code>composer install\n</code></pre></li> <li>Run the application <pre><code>composer start\n</code></pre></li> </ol> <p>Warning</p> <p>LiveKit PHP SDK requires library BCMath . This is available out-of-the-box in PHP for Windows, but a manual installation might be necessary in other OS. Run <code>sudo apt install php-bcmath</code> or <code>sudo yum install php-bcmath</code></p> <p>For more information, check the PHP tutorial.</p> <p>To run this server application, you need .NET  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/dotnet\n</code></pre></li> <li>Run the application <pre><code>dotnet run\n</code></pre></li> </ol> <p>Warning</p> <p>This .NET server application needs the <code>LIVEKIT_API_SECRET</code> env variable to be at least 32 characters long. Make sure to update it here  and in your OpenVidu Server.</p> <p>For more information, check the .NET tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/electron/#4-run-the-client-application","title":"4. Run the client application","text":"<p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-electron\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Run the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>The application will seamlessly initiate as a native desktop program, adapting itself to the specific operating system you are using. Once the application is open, you should see a screen like this:</p> <p></p> <p></p> <p>Running your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates. For more information, see section Accessing your local deployment from other devices on your network.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/electron/#understanding-the-code","title":"Understanding the code","text":"<p>This Electron project has been created using electron-forge. As an Electron application, the code is divided into two main parts, the main process and the renderer process. The most important files are located within the <code>src/</code> directory:</p> <ul> <li><code>index.js</code>: This file is the entry point (main process) for the Electron application. It creates the main window and loads the <code>index.html</code> file.</li> <li><code>app.js</code>: This file constitutes the renderer process code, responsible for the application UI and logic. It uses the LiveKit JS SDK  to connect to the LiveKit server and interact with the video call room.</li> <li><code>index.html</code>: This HTML file is responsible for creating the user interface. It contains the form to connect to a video call and the video call layout.</li> <li><code>styles.css</code>: This file contains CSS classes that are used to style the <code>index.html</code> page.</li> </ul> <p>To use the LiveKit JS SDK in an Electron application, you need to install the <code>livekit-client</code> package. This package provides the necessary classes and methods to interact with the LiveKit server. You can install it using the following command:</p> <pre><code>npm install livekit-client\n</code></pre> <p>Now let's see the code of the <code>app.js</code> file:</p> app.js<pre><code>const { Room, RoomEvent } = require(\"livekit-client\"); // (1)!\n\n// Configure these constants with correct URLs depending on your deployment\nconst APPLICATION_SERVER_URL = \"http://localhost:6080/\"; // (2)!\nconst LIVEKIT_URL = \"ws://localhost:7880/\"; // (3)!\n\nvar room; // (4)!\n</code></pre> <ol> <li>Import the <code>Room</code> and <code>RoomEvent</code> classes from the <code>livekit-client</code> package.</li> <li>The URL of the application server.</li> <li>The URL of the LiveKit server.</li> <li>The room object, which represents the video call room.</li> </ol> <p>The <code>app.js</code> file defines the following variables:</p> <ul> <li><code>APPLICATION_SERVER_URL</code>: The URL of the application server. This variable is used to make requests to the server to obtain a token for joining the video call room.</li> <li><code>LIVEKIT_URL</code>: The URL of the LiveKit server. This variable is used to connect to the LiveKit server and interact with the video call room.</li> <li><code>room</code>: The room object, which represents the video call room.</li> </ul> <p>Configure the URLs</p> <p>You should configure <code>APPLICATION_SERVER_URL</code> and <code>LIVEKIT_URL</code> constants with the correct URLs depending on your deployment.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/electron/#joining-a-room","title":"Joining a Room","text":"<p>After the user specifies their participant name and the name of the room they want to join, when they click the <code>Join</code> button, the <code>joinRoom()</code> function is called:</p> app.js<pre><code>async function joinRoom() {\n    // Disable 'Join' button\n    document.getElementById(\"join-button\").disabled = true;\n    document.getElementById(\"join-button\").innerText = \"Joining...\";\n\n    // Initialize a new Room object\n    room = new Room(); // (1)!\n\n    // Specify the actions when events take place in the room\n    // On every new Track received...\n    room.on(RoomEvent.TrackSubscribed, (track, _publication, participant) =&gt; {\n        // (2)!\n        addTrack(track, participant.identity);\n    });\n\n    // On every new Track destroyed...\n    room.on(RoomEvent.TrackUnsubscribed, (track, _publication, participant) =&gt; {\n        // (3)!\n        track.detach();\n        document.getElementById(track.sid)?.remove();\n\n        if (track.kind === \"video\") {\n            removeVideoContainer(participant.identity);\n        }\n    });\n\n    try {\n        // Get the room name and participant name from the form\n        const roomName = document.getElementById(\"room-name\").value; // (4)!\n        const userName = document.getElementById(\"participant-name\").value;\n\n        // Get a token from your application server with the room name and participant name\n        const token = await getToken(roomName, userName); // (5)!\n\n        // Connect to the room with the LiveKit URL and the token\n        await room.connect(LIVEKIT_URL, token); // (6)!\n\n        // Hide the 'Join room' page and show the 'Room' page\n        document.getElementById(\"room-title\").innerText = roomName; // (7)!\n        document.getElementById(\"join\").hidden = true;\n        document.getElementById(\"room\").hidden = false;\n\n        // Publish your camera and microphone\n        await room.localParticipant.enableCameraAndMicrophone(); // (8)!\n        const localVideoTrack = this.room.localParticipant.videoTrackPublications.values().next().value.track;\n        addTrack(localVideoTrack, userName, true);\n    } catch (error) {\n        console.log(\"There was an error connecting to the room:\", error.message);\n    }\n}\n</code></pre> <ol> <li>Initialize a new <code>Room</code> object.</li> <li>Event handling for when a new track is received in the room.</li> <li>Event handling for when a track is destroyed.</li> <li>Get the room name and participant name from the form.</li> <li>Get a token from the application server with the room name and participant name.</li> <li>Connect to the room with the LiveKit URL and the token.</li> <li>Hide the \"Join room\" page and show the \"Room\" page.</li> <li>Publish your camera and microphone.</li> </ol> <p>The <code>joinRoom()</code> function performs the following actions:</p> <ol> <li>It creates a new <code>Room</code> object. This object represents the video call room.</li> <li> <p>Event handling is configured for different scenarios within the room. These events are fired when new tracks are subscribed to and when existing tracks are unsubscribed.</p> <ul> <li><code>RoomEvent.TrackSubscribed</code>: This event is triggered when a new track is received in the room. It handles the attachment of the track to the HTML page, assigning an ID, and appending it to the <code>layout-container</code> element. If the track is of kind <code>video</code>, a <code>video-container</code> is created and participant data is appended as well.</li> </ul> app.js<pre><code>function addTrack(track, participantIdentity, local = false) {\n    const element = track.attach(); // (1)!\n    element.id = track.sid;\n\n    /* If the track is a video track, we create a container and append the video element to it\n    with the participant's identity */\n    if (track.kind === \"video\") {\n        const videoContainer = createVideoContainer(participantIdentity, local);\n        videoContainer.append(element);\n        appendParticipantData(videoContainer, participantIdentity + (local ? \" (You)\" : \"\"));\n    } else {\n        document.getElementById(\"layout-container\").append(element);\n    }\n}\n</code></pre> <ol> <li>Attach the track to an HTML element.</li> </ol> app.js<pre><code>function createVideoContainer(participantIdentity, local = false) {\n    const videoContainer = document.createElement(\"div\");\n    videoContainer.id = `camera-${participantIdentity}`;\n    videoContainer.className = \"video-container\";\n    const layoutContainer = document.getElementById(\"layout-container\");\n\n    if (local) {\n        layoutContainer.prepend(videoContainer);\n    } else {\n        layoutContainer.append(videoContainer);\n    }\n\n    return videoContainer;\n}\n\nfunction appendParticipantData(videoContainer, participantIdentity) {\n    const dataElement = document.createElement(\"div\");\n    dataElement.className = \"participant-data\";\n    dataElement.innerHTML = `&lt;p&gt;${participantIdentity}&lt;/p&gt;`;\n    videoContainer.prepend(dataElement);\n}\n</code></pre> <ul> <li><code>RoomEvent.TrackUnsubscribed</code>: This event occurs when a track is destroyed, and it takes care of detaching the track from the HTML page and removing it from the DOM. If the track is a <code>video</code> track, <code>video-container</code> with the participant's identity is removed as well.</li> </ul> app.js<pre><code>function removeVideoContainer(participantIdentity) {\n    const videoContainer = document.getElementById(`camera-${participantIdentity}`);\n    videoContainer?.remove();\n}\n</code></pre> <p>These event handlers are essential for managing the behavior of tracks within the video call.</p> <p>Take a look at all events</p> <p>You can take a look at all the events in the Livekit Documentation</p> </li> <li> <p>It retrieves the room name and participant name from the form.</p> </li> <li> <p>It requests a token from the application server using the room name and participant name. This is done by calling the <code>getToken()</code> function:</p> app.js<pre><code>/**\n * --------------------------------------------\n * GETTING A TOKEN FROM YOUR APPLICATION SERVER\n * --------------------------------------------\n * The method below request the creation of a token to\n * your application server. This prevents the need to expose\n * your LiveKit API key and secret to the client side.\n *\n * In this sample code, there is no user control at all. Anybody could\n * access your application server endpoints. In a real production\n * environment, your application server must identify the user to allow\n * access to the endpoints.\n */\nasync function getToken(roomName, participantName) {\n    const response = await fetch(APPLICATION_SERVER_URL + \"token\", {\n        method: \"POST\",\n        headers: {\n            \"Content-Type\": \"application/json\"\n        },\n        body: JSON.stringify({\n            roomName,\n            participantName\n        })\n    });\n\n    if (!response.ok) {\n        const error = await response.json();\n        throw new Error(`Failed to get token: ${error.errorMessage}`);\n    }\n\n    const token = await response.json();\n    return token.token;\n}\n</code></pre> <p>This function sends a POST request using <code>fetch()</code> to the application server's <code>/token</code> endpoint. The request body contains the room name and participant name. The server responds with a token that is used to connect to the room.</p> </li> <li> <p>It connects to the room using the LiveKit URL and the token.</p> </li> <li>It updates the UI to hide the \"Join room\" page and show the \"Room\" layout.</li> <li>It publishes the camera and microphone tracks to the room using <code>room.localParticipant.enableCameraAndMicrophone()</code>, which asks the user for permission to access their camera and microphone at the same time. The local video track is then added to the layout.</li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/application-client/electron/#leaving-the-room","title":"Leaving the Room","text":"<p>When the user wants to leave the room, they can click the <code>Leave Room</code> button. This action calls the <code>leaveRoom()</code> function:</p> app.js<pre><code>async function leaveRoom() {\n    // Leave the room by calling 'disconnect' method over the Room object\n    await room.disconnect(); // (1)!\n\n    // Remove all HTML elements inside the layout container\n    removeAllLayoutElements(); // (2)!\n\n    // Back to 'Join room' page\n    document.getElementById(\"join\").hidden = false; // (3)!\n    document.getElementById(\"room\").hidden = true;\n\n    // Enable 'Join' button\n    document.getElementById(\"join-button\").disabled = false;\n    document.getElementById(\"join-button\").innerText = \"Join!\";\n}\n\n// (4)!\nwindow.onbeforeunload = () =&gt; {\n    room?.disconnect();\n};\n</code></pre> <ol> <li>Disconnect the user from the room.</li> <li>Remove all HTML elements inside the layout container.</li> <li>Show the \"Join room\" page and hide the \"Room\" layout.</li> <li>Call the <code>disconnect()</code> method on the <code>room</code> object when the user closes the tab or navigates to another page.</li> </ol> <p>The <code>leaveRoom()</code> function performs the following actions:</p> <ul> <li>It disconnects the user from the room by calling the <code>disconnect()</code> method on the <code>room</code> object.</li> <li>It removes all HTML elements inside the layout container by calling the <code>removeAllLayoutElements()</code> function.</li> <li>It shows the \"Join room\" page and hides the \"Room\" layout.</li> </ul> <p>The <code>window.onbeforeunload</code> event is used to ensure that the user is disconnected from the room before the page is unloaded. This event is triggered when the user closes the tab or navigates to another page.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/ionic/","title":"Ionic Tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-client/ionic/#ionic-tutorial","title":"Ionic Tutorial","text":"<p>Source code </p> <p>This tutorial is a simple video-call application built with Ionic, using Angular and Capacitor, that allows:</p> <ul> <li>Joining a video call room by requesting a token from any application server.</li> <li>Publishing your camera and microphone.</li> <li>Subscribing to all other participants' video and audio tracks automatically.</li> <li>Leaving the video call room at any time.</li> </ul> <p>It uses the LiveKit JS SDK  to connect to the LiveKit server and interact with the video call room.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/ionic/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-client/ionic/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/ionic/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/application-client/ionic/#3-run-a-server-application","title":"3. Run a server application","text":"Node.js Go Ruby Java Python Rust PHP .NET <p>To run this server application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/node\n</code></pre></li> <li>Install dependencies <pre><code>npm install\n</code></pre></li> <li>Run the application <pre><code>npm start\n</code></pre></li> </ol> <p>For more information, check the Node.js tutorial.</p> <p>To run this server application, you need Go  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/go\n</code></pre></li> <li>Run the application <pre><code>go run main.go\n</code></pre></li> </ol> <p>For more information, check the Go tutorial.</p> <p>To run this server application, you need Ruby  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/ruby\n</code></pre></li> <li>Install dependencies <pre><code>bundle install\n</code></pre></li> <li>Run the application <pre><code>ruby app.rb\n</code></pre></li> </ol> <p>For more information, check the Ruby tutorial.</p> <p>To run this server application, you need Java  and Maven  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/java\n</code></pre></li> <li>Run the application <pre><code>mvn spring-boot:run\n</code></pre></li> </ol> <p>For more information, check the Java tutorial.</p> <p>To run this server application, you need Python 3  installed on your device.</p> <ol> <li> <p>Navigate into the server directory</p> <pre><code>cd openvidu-livekit-tutorials/application-server/python\n</code></pre> </li> <li> <p>Create a python virtual environment</p> <pre><code>python -m venv venv\n</code></pre> </li> <li> <p>Activate the virtual environment</p>  Windows macOS Linux <pre><code>.\\venv\\Scripts\\activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> </li> <li> <p>Install dependencies</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the application</p> <pre><code>python app.py\n</code></pre> </li> </ol> <p>For more information, check the Python tutorial.</p> <p>To run this server application, you need Rust  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/rust\n</code></pre></li> <li>Run the application <pre><code>cargo run\n</code></pre></li> </ol> <p>For more information, check the Rust tutorial.</p> <p>To run this server application, you need PHP  and Composer  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/php\n</code></pre></li> <li>Install dependencies <pre><code>composer install\n</code></pre></li> <li>Run the application <pre><code>composer start\n</code></pre></li> </ol> <p>Warning</p> <p>LiveKit PHP SDK requires library BCMath . This is available out-of-the-box in PHP for Windows, but a manual installation might be necessary in other OS. Run <code>sudo apt install php-bcmath</code> or <code>sudo yum install php-bcmath</code></p> <p>For more information, check the PHP tutorial.</p> <p>To run this server application, you need .NET  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/dotnet\n</code></pre></li> <li>Run the application <pre><code>dotnet run\n</code></pre></li> </ol> <p>Warning</p> <p>This .NET server application needs the <code>LIVEKIT_API_SECRET</code> env variable to be at least 32 characters long. Make sure to update it here  and in your OpenVidu Server.</p> <p>For more information, check the .NET tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/ionic/#4-run-the-client-application","title":"4. Run the client application","text":"<p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-ionic\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <p>You have two options for running the client application: browser-based or mobile device-based:</p>  Browser Mobile <p>To run the application in a browser, you will need to start the Ionic server. To do so, run the following command:</p> <pre><code>npm start\n</code></pre> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p>Mobile appearance</p> <p>To show the app with a mobile device appearance, open the dev tools in your browser and find the button to adapt the viewport to a mobile device aspect ratio. You may also choose predefined types of devices to see the behavior of your app in different resolutions.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Running the tutorial on a mobile device presents additional challenges compared to running it in a browser, mainly due to the application being launched on a different device, such as an Android smartphone or iPhone, rather than our computer. To overcome these challenges, the following steps need to be taken:</p> <ol> <li> <p>Localhost limitations:</p> <p>The usage of <code>localhost</code> in our Ionic app is restricted, preventing seamless communication between the application client and the server.</p> </li> <li> <p>Serve over local network:</p> <p>The application must be served over our local network to enable communication between the device and the server.</p> </li> <li> <p>Secure connection requirement for WebRTC API:</p> <p>The WebRTC API demands a secure connection for functionality outside of localhost, necessitating the serving of the application over HTTPS.</p> </li> </ol> <p>If you run OpenVidu locally you don't need to worry about this. OpenVidu will handle all of the above requirements for you. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Now, let's explore how to run the application on a mobile device:</p> <p>Requirements</p> <p>Before running the application on a mobile device, make sure that the device is connected to the same network as your PC and the mobile is connected to the PC via USB or Wi-Fi.</p>  Android device iOS device <pre><code>npm run android\n</code></pre> <p>You will need Ruby  and Cocoapods  installed in your computer.</p> <p>The app must be signed with a development team. To do so, open the project in Xcode and select a development team in the Signing &amp; Capabilities editor.</p> <pre><code>npm run ios\n</code></pre> <p>The script will ask you for the device you want to run the application on. You should select the real device you have connected to your computer.</p> <p>Once the mobile device has been selected, the script will launch the application on the device and you will see a screen like this:</p> <p></p><p></p><p></p> <p>This screen allows you to configure the URLs of the application server and the LiveKit server. You need to set them up for requesting tokens to your application server and connecting to the LiveKit server.</p> <p>Once you have configured the URLs, you can join a video call room by providing a room name and a user name. After joining the room, you will be able to see your own video and audio tracks, as well as the video and audio tracks of the other participants in the room.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> </li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/application-client/ionic/#understanding-the-code","title":"Understanding the code","text":"<p>This Ionic project has been created using the Ionic CLI tool. You may come across various configuration files and other items that are not essential for this tutorial. Our focus will be on the key files located within the <code>src/app/</code> directory:</p> <ul> <li><code>app.component.ts</code>: This file defines the <code>AppComponent</code>, which serves as the main component of the application. It is responsible for handling tasks such as joining a video call and managing the video calls themselves.</li> <li><code>app.component.html</code>: This HTML file is associated with the <code>AppComponent</code>, and it dictates the structure and layout of the main application component.</li> <li><code>app.component.scss</code>: The CSS file linked to <code>AppComponent</code>, which controls the styling and appearance of the application's main component.</li> <li><code>VideoComponent</code>: Component responsible for displaying video tracks along with participant's data. It is defined in the <code>video.component.ts</code> file within the <code>video</code> directory, along with its associated HTML and CSS files.</li> <li><code>AudioComponent</code>: Component responsible for displaying audio tracks. It is defined in the <code>audio.component.ts</code> file within the <code>audio</code> directory, along with its associated HTML and CSS files.</li> </ul> <p>To use the LiveKit JS SDK in an Ionic application, you need to install the <code>livekit-client</code> package. This package provides the necessary classes and methods to interact with the LiveKit server. You can install it using the following command:</p> <pre><code>npm install livekit-client\n</code></pre> <p>Now let's see the code of the <code>app.component.ts</code> file:</p> app.component.ts<pre><code>type TrackInfo = { // (1)!\n    trackPublication: RemoteTrackPublication;\n    participantIdentity: string;\n};\n\n// When running OpenVidu locally and launching app in web browser, leave these variables empty\n// For other deployment type or when launching app in a mobile device, configure them with correct URLs\n// If you leave them empty when launching app in a mobile device, the user will be prompted to enter the URLs\nvar APPLICATION_SERVER_URL = ''; // (2)!\nvar LIVEKIT_URL = ''; // (3)!\n\n@Component({ // (4)!\n    selector: 'app-root',\n    templateUrl: 'app.component.html',\n    styleUrl: 'app.component.scss',\n    standalone: true,\n    imports: [\n        IonApp,\n        VideoComponent,\n        AudioComponent,\n        ReactiveFormsModule,\n        IonHeader,\n        IonToolbar,\n        IonTitle,\n        IonButtons,\n        IonButton,\n        IonIcon,\n        IonContent,\n        IonList,\n        IonItem,\n        IonInput,\n        IonFooter,\n    ],\n})\nexport class AppComponent implements OnDestroy {\n    roomForm = new FormGroup({ // (5)!\n        roomName: new FormControl('Test Room', Validators.required),\n        participantName: new FormControl('Participant' + Math.floor(Math.random() * 100), Validators.required),\n    });\n\n    urlsForm = new FormGroup({ // (6)!\n        serverUrl: new FormControl(APPLICATION_SERVER_URL, Validators.required),\n        livekitUrl: new FormControl(LIVEKIT_URL, Validators.required),\n    });\n\n    room = signal&lt;Room | undefined&gt;(undefined); // (7)!\n    localTrack = signal&lt;LocalVideoTrack | undefined&gt;(undefined); // (8)!\n    remoteTracksMap = signal&lt;Map&lt;string, TrackInfo&gt;&gt;(new Map()); // (9)!\n\n    settingUrls = signal(false); // (10)!\n\n    constructor(private httpClient: HttpClient, private platform: Platform) {\n        this.configureUrls();\n        addIcons({\n            logoGithub,\n            book,\n            settings,\n        });\n    }\n\n    configureUrls() {\n        const mobileMode = this.platform.is('hybrid');\n\n        // If URLs are not configured and app is launched in a mobile device,\n        // prompt the user to configure them\n        if (mobileMode) {\n            if (!APPLICATION_SERVER_URL || !LIVEKIT_URL) {\n                this.settingUrls.set(true);\n            }\n        } else {\n            // If APPLICATION_SERVER_URL is not configured and app is not launched in a mobile device,\n            // use default value from OpenVidu Local deployment\n            if (!APPLICATION_SERVER_URL) {\n                if (window.location.hostname === 'localhost') {\n                    APPLICATION_SERVER_URL = 'http://localhost:6080/';\n                } else {\n                    APPLICATION_SERVER_URL = 'https://' + window.location.hostname + ':6443/';\n                }\n            }\n\n            // If LIVEKIT_URL is not configured and app is not launched in a mobile device,\n            // use default value from OpenVidu Local deployment\n            if (!LIVEKIT_URL) {\n                if (window.location.hostname === 'localhost') {\n                    LIVEKIT_URL = 'ws://localhost:7880/';\n                } else {\n                    LIVEKIT_URL = 'wss://' + window.location.hostname + ':7443/';\n                }\n            }\n        }\n    }\n</code></pre> <ol> <li><code>TrackInfo</code> type, which groups a track publication with the participant's identity.</li> <li>The URL of the application server.</li> <li>The URL of the LiveKit server.</li> <li>Angular component decorator that defines the <code>AppComponent</code> class and associates the HTML and CSS files with it.</li> <li>The <code>roomForm</code> object, which is a form group that contains the <code>roomName</code> and <code>participantName</code> fields. These fields are used to join a video call room.</li> <li>The <code>urlsForm</code> object, which is a form group that contains the <code>serverUrl</code> and <code>livekitUrl</code> fields. These fields are used to configure the application server and LiveKit URLs.</li> <li>The room object, which represents the video call room.</li> <li>The local video track, which represents the user's camera.</li> <li>Map that links track SIDs with <code>TrackInfo</code> objects. This map is used to store remote tracks and their associated participant identities.</li> <li>A boolean flag that indicates whether the user is configuring the application server and LiveKit URLs.</li> </ol> <p>The <code>app.component.ts</code> file defines the following variables:</p> <ul> <li><code>APPLICATION_SERVER_URL</code>: The URL of the application server. This variable is used to make requests to the server to obtain a token for joining the video call room.</li> <li><code>LIVEKIT_URL</code>: The URL of the LiveKit server. This variable is used to connect to the LiveKit server and interact with the video call room.</li> <li><code>roomForm</code>: A form group that contains the <code>roomName</code> and <code>participantName</code> fields. These fields are used to join a video call room.</li> <li><code>urlsForm</code>: A form group that contains the <code>serverUrl</code> and <code>livekitUrl</code> fields. These fields are used to configure the application server and LiveKit URLs.</li> <li><code>room</code>: The room object, which represents the video call room.</li> <li><code>localTrack</code>: The local video track, which represents the user's camera.</li> <li><code>remoteTracksMap</code>: A map that links track SIDs with <code>TrackInfo</code> objects. This map is used to store remote tracks and their associated participant identities.</li> <li><code>settingUrls</code>: A boolean flag that indicates whether the user is configuring the application server and LiveKit URLs.</li> </ul>","tags":["Platform"]},{"location":"docs/tutorials/application-client/ionic/#configuring-urls","title":"Configuring URLs","text":"<p>When running OpenVidu locally and launching the app in a web browser, leave <code>APPLICATION_SERVER_URL</code> and <code>LIVEKIT_URL</code> variables empty. The function <code>configureUrls()</code> will automatically configure them with default values. However, for other deployment type or when launching the app in a mobile device, you should configure these variables with the correct URLs depending on your deployment.</p> <p>In case you are running OpenVidu locally and launching the app in a mobile device, you can set the <code>applicationServerUrl</code> to <code>https://xxx-yyy-zzz-www.openvidu-local.dev:6443</code> and the <code>livekitUrl</code> to <code>wss://xxx-yyy-zzz-www.openvidu-local.dev:7443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is the LAN private IP address of the machine running OpenVidu, with dashes (-) instead of dots (.).</p> <p>If you leave them empty and app is launched in a mobile device, the user will be prompted to enter the URLs when the application starts:</p> <p></p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/ionic/#joining-a-room","title":"Joining a Room","text":"<p>After the user specifies their participant name and the name of the room they want to join, when they click the <code>Join</code> button, the <code>joinRoom()</code> method is called:</p> app.component.ts<pre><code>async joinRoom() {\n    // Initialize a new Room object\n    const room = new Room();\n    this.room.set(room); // (1)!\n\n    // Specify the actions when events take place in the room\n    // On every new Track received...\n    this.room.on(\n        RoomEvent.TrackSubscribed,\n        (_track: RemoteTrack, publication: RemoteTrackPublication, participant: RemoteParticipant) =&gt; { // (2)!\n            this.remoteTracksMap.update((map) =&gt; {\n                map.set(publication.trackSid, {\n                    trackPublication: publication,\n                    participantIdentity: participant.identity,\n                });\n                return map;\n            });\n        }\n    );\n\n    // On every new Track destroyed...\n    room.on(RoomEvent.TrackUnsubscribed, (_track: RemoteTrack, publication: RemoteTrackPublication) =&gt; { // (3)!\n        this.remoteTracksMap.update((map) =&gt; {\n            map.delete(publication.trackSid);\n            return map;\n        });\n    });\n\n    try {\n        // Get the room name and participant name from the form\n        const roomName = this.roomForm.value.roomName!; // (4)!\n        const participantName = this.roomForm.value.participantName!;\n\n        // Get a token from your application server with the room name and participant name\n        const token = await this.getToken(roomName, participantName); // (5)!\n\n        // Connect to the room with the LiveKit URL and the token\n        await room.connect(LIVEKIT_URL, token); // (6)!\n\n        // Publish your camera and microphone\n        await room.localParticipant.enableCameraAndMicrophone(); // (7)!\n        this.localTrack.set(room.localParticipant.videoTrackPublications.values().next().value.videoTrack);\n    } catch (error: any) {\n        console.log(\n            'There was an error connecting to the room:',\n            error?.error?.errorMessage || error?.message || error\n        );\n        await this.leaveRoom();\n    }\n}\n</code></pre> <ol> <li>Initialize a new <code>Room</code> object.</li> <li>Event handling for when a new track is received in the room.</li> <li>Event handling for when a track is destroyed.</li> <li>Get the room name and participant name from the form.</li> <li>Get a token from the application server with the room name and participant name.</li> <li>Connect to the room with the LiveKit URL and the token.</li> <li>Publish your camera and microphone.</li> </ol> <p>The <code>joinRoom()</code> method performs the following actions:</p> <ol> <li> <p>It creates a new <code>Room</code> object. This object represents the video call room.</p> <p>Info</p> <p>When the room object is defined, the HTML template is automatically updated hiding the \"Join room\" page and showing the \"Room\" layout.</p> </li> <li> <p>Event handling is configured for different scenarios within the room. These events are fired when new tracks are subscribed to and when existing tracks are unsubscribed.</p> <ul> <li> <p><code>RoomEvent.TrackSubscribed</code>: This event is triggered when a new track is received in the room. It manages the storage of the new track in the <code>remoteTracksMap</code>, which links track SIDs with <code>TrackInfo</code> objects containing the track publication and the participant's identity.</p> </li> <li> <p><code>RoomEvent.TrackUnsubscribed</code>: This event occurs when a track is destroyed, and it takes care of removing the track from the <code>remoteTracksMap</code>.</p> </li> </ul> <p>These event handlers are essential for managing the behavior of tracks within the video call. You can further extend the event handling as needed for your application.</p> <p>Take a look at all events</p> <p>You can take a look at all the events in the Livekit Documentation</p> </li> <li> <p>It retrieves the room name and participant name from the form.</p> </li> <li> <p>It requests a token from the application server using the room name and participant name. This is done by calling the <code>getToken()</code> method:</p> app.component.ts<pre><code>/**\n * --------------------------------------------\n * GETTING A TOKEN FROM YOUR APPLICATION SERVER\n * --------------------------------------------\n * The method below request the creation of a token to\n * your application server. This prevents the need to expose\n * your LiveKit API key and secret to the client side.\n *\n * In this sample code, there is no user control at all. Anybody could\n * access your application server endpoints. In a real production\n * environment, your application server must identify the user to allow\n * access to the endpoints.\n */\nasync getToken(roomName: string, participantName: string): Promise&lt;string&gt; {\n    const response = await lastValueFrom(\n        this.httpClient.post&lt;{ token: string }&gt;(APPLICATION_SERVER_URL + 'token', { roomName, participantName })\n    );\n    return response.token;\n}\n</code></pre> <p>This function sends a POST request using HttpClient  to the application server's <code>/token</code> endpoint. The request body contains the room name and participant name. The server responds with a token that is used to connect to the room.</p> </li> <li> <p>It connects to the room using the LiveKit URL and the token.</p> </li> <li>It publishes the camera and microphone tracks to the room using <code>room.localParticipant.enableCameraAndMicrophone()</code>, which asks the user for permission to access their camera and microphone at the same time. The local video track is then stored in the <code>localTrack</code> variable.</li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/application-client/ionic/#displaying-video-and-audio-tracks","title":"Displaying Video and Audio Tracks","text":"<p>In order to display participants' video and audio tracks, the <code>app.component.html</code> file integrates the <code>VideoComponent</code> and <code>AudioComponent</code>.</p> app.component.html<pre><code>&lt;div id=\"layout-container\"&gt;\n    @if (localTrack()) {\n    &lt;video-component\n        [track]=\"localTrack()!\"\n        [participantIdentity]=\"roomForm.value.participantName!\"\n        [local]=\"true\"\n    &gt;&lt;/video-component&gt;\n    }\n    @for (remoteTrack of remoteTracksMap().values(); track remoteTrack.trackPublication.trackSid) {\n        @if (remoteTrack.trackPublication.kind === 'video') {\n        &lt;video-component\n            [track]=\"remoteTrack.trackPublication.videoTrack!\"\n            [participantIdentity]=\"remoteTrack.participantIdentity\"\n        &gt;&lt;/video-component&gt;\n        } @else {\n        &lt;audio-component [track]=\"remoteTrack.trackPublication.audioTrack!\" hidden&gt;&lt;/audio-component&gt;\n        }\n    }\n&lt;/div&gt;\n</code></pre> <p>This code snippet does the following:</p> <ul> <li> <p>We use the Angular <code>@if</code> block to conditionally display the local video track using the <code>VideoComponent</code>. The <code>local</code> property is set to <code>true</code> to indicate that the video track belongs to the local participant.</p> <p>Info</p> <p>The audio track is not displayed for the local participant because there is no need to hear one's own audio.</p> </li> <li> <p>Then, we use the Angular <code>@for</code> block to iterate over the <code>remoteTracksMap</code>. For each remote track, we create a <code>VideoComponent</code> or an <code>AudioComponent</code> depending on the track's kind (video or audio). The <code>participantIdentity</code> property is set to the participant's identity, and the <code>track</code> property is set to the video or audio track. The <code>hidden</code> attribute is added to the <code>AudioComponent</code> to hide the audio tracks from the layout.</p> </li> </ul> <p>Let's see now the code of the <code>video.component.ts</code> file:</p> video.component.ts<pre><code>// (1)!\n@Component({\n    selector: \"video-component\",\n    standalone: true,\n    imports: [],\n    templateUrl: \"./video.component.html\",\n    styleUrl: \"./video.component.css\"\n})\nexport class VideoComponent implements AfterViewInit, OnDestroy {\n    videoElement = viewChild&lt;ElementRef&lt;HTMLVideoElement&gt;&gt;(\"videoElement\"); // (2)!\n\n    track = input.required&lt;LocalVideoTrack | RemoteVideoTrack&gt;(); // (3)!\n    participantIdentity = input.required&lt;string&gt;(); // (4)!\n    local = input(false); // (5)!\n\n    ngAfterViewInit() {\n        if (this.videoElement()) {\n            this.track().attach(this.videoElement()!.nativeElement); // (6)!\n        }\n    }\n\n    ngOnDestroy() {\n        this.track().detach(); // (7)!\n    }\n}\n</code></pre> <ol> <li>Angular component decorator that defines the <code>VideoComponent</code> class and associates the HTML and CSS files with it.</li> <li>The reference to the video element in the HTML template.</li> <li>The video track object, which can be a <code>LocalVideoTrack</code> or a <code>RemoteVideoTrack</code>.</li> <li>The participant identity associated with the video track.</li> <li>A boolean flag that indicates whether the video track belongs to the local participant.</li> <li>Attach the video track to the video element when the track is set.</li> <li>Detach the video track when the component is destroyed.</li> </ol> <p>The <code>VideoComponent</code> does the following:</p> <ul> <li> <p>It defines the properties <code>track</code>, <code>participantIdentity</code>, and <code>local</code> as inputs of the component:</p> <ul> <li><code>track</code>: The video track object, which can be a <code>LocalVideoTrack</code> or a <code>RemoteVideoTrack</code>.</li> <li><code>participantIdentity</code>: The participant identity associated with the video track.</li> <li><code>local</code>: A boolean flag that indicates whether the video track belongs to the local participant. This flag is set to <code>false</code> by default.</li> </ul> </li> <li> <p>It creates a reference to the video element in the HTML template.</p> </li> <li>It attaches the video track to the video element when the view is initialized.</li> <li>It detaches the video track when the component is destroyed.</li> </ul> <p>Finally, let's see the code of the <code>audio.component.ts</code> file:</p> audio.component.ts<pre><code>// (1)!\n@Component({\n    selector: \"audio-component\",\n    standalone: true,\n    imports: [],\n    templateUrl: \"./audio.component.html\",\n    styleUrl: \"./audio.component.css\"\n})\nexport class AudioComponent implements AfterViewInit, OnDestroy {\n    audioElement = viewChild&lt;ElementRef&lt;HTMLAudioElement&gt;&gt;(\"audioElement\"); // (2)!\n\n    track = input.required&lt;LocalAudioTrack | RemoteAudioTrack&gt;(); // (3)!\n\n    ngAfterViewInit() {\n        if (this.audioElement()) {\n            this.track().attach(this.audioElement()!.nativeElement); // (4)!\n        }\n    }\n\n    ngOnDestroy() {\n        this.track().detach(); // (5)!\n    }\n}\n</code></pre> <ol> <li>Angular component decorator that defines the <code>AudioComponent</code> class and associates the HTML and CSS files with it.</li> <li>The reference to the audio element in the HTML template.</li> <li>The audio track object, which can be a <code>RemoteAudioTrack</code> or a <code>LocalAudioTrack</code>, although in this case, it will always be a <code>RemoteAudioTrack</code>.</li> <li>Attach the audio track to the audio element when view is initialized.</li> <li>Detach the audio track when the component is destroyed.</li> </ol> <p>The <code>AudioComponent</code> class is similar to the <code>VideoComponent</code> class, but it is used to display audio tracks. It attaches the audio track to the audio element when view is initialized and detaches the audio track when the component is destroyed.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/ionic/#leaving-the-room","title":"Leaving the room","text":"<p>When the user wants to leave the room, they can click the <code>Leave Room</code> button. This action calls the <code>leaveRoom()</code> method:</p> app.component.ts<pre><code>async leaveRoom() {\n    // Leave the room by calling 'disconnect' method over the Room object\n    await this.room()?.disconnect(); // (1)!\n\n    // Reset all variables\n    this.room.set(undefined); // (2)!\n    this.localTrack.set(undefined);\n    this.remoteTracksMap.set(new Map());\n}\n\nasync ngOnDestroy() { // (3)!\n    // On window closed or component destroyed, leave the room\n    await this.leaveRoom();\n}\n</code></pre> <ol> <li>Disconnect the user from the room.</li> <li>Reset all variables.</li> <li>Call the <code>leaveRoom()</code> method when the component is destroyed.</li> </ol> <p>The <code>leaveRoom()</code> method performs the following actions:</p> <ul> <li>It disconnects the user from the room by calling the <code>disconnect()</code> method on the <code>room</code> object.</li> <li>It resets all variables.</li> </ul> <p>The <code>ngOnDestroy()</code> lifecycle hook is used to ensure that the user leaves the room when the component is destroyed.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/ionic/#specific-mobile-requirements","title":"Specific mobile requirements","text":"<p>In order to be able to test the application on an Android or iOS device, the application must ask for the necessary permissions to access the device's camera and microphone. These permissions are requested when the user joins the video call room.</p>  Android iOS <p>The application must include the following permissions in the <code>AndroidManifest.xml</code> file located in the <code>android/app/src/main</code> directory:</p> AndroidManifest.xml<pre><code>&lt;uses-permission android:name=\"android.permission.CAMERA\" /&gt;\n&lt;uses-permission android:name=\"android.permission.RECORD_AUDIO\" /&gt;\n&lt;uses-permission android:name=\"android.permission.MODIFY_AUDIO_SETTINGS\" /&gt;\n</code></pre> <p>The application must include the following permissions in the <code>Info.plist</code> file located in the <code>ios/App/App</code> directory:</p> Info.plist<pre><code>&lt;key&gt;NSCameraUsageDescription&lt;/key&gt;\n&lt;string&gt;This Application uses your camera to make video calls.&lt;/string&gt;\n&lt;key&gt;NSMicrophoneUsageDescription&lt;/key&gt;\n&lt;string&gt;This Application uses your microphone to make calls.&lt;/string&gt;\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/application-client/ios/","title":"iOS Tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-client/ios/#ios-tutorial","title":"iOS Tutorial","text":"<p>Source code </p> <p>This tutorial is a simple video-call application built for iOS, using Swift, that allows:</p> <ul> <li>Joining a video call room by requesting a token from any application server.</li> <li>Publishing your camera and microphone.</li> <li>Subscribing to all other participants' video and audio tracks automatically.</li> <li>Leaving the video call room at any time.</li> </ul> <p>It uses the LiveKit Swift SDK  to connect to the LiveKit server and interact with the video call room.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/ios/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-client/ios/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/ios/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/application-client/ios/#3-run-a-server-application","title":"3. Run a server application","text":"Node.js Go Ruby Java Python Rust PHP .NET <p>To run this server application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/node\n</code></pre></li> <li>Install dependencies <pre><code>npm install\n</code></pre></li> <li>Run the application <pre><code>npm start\n</code></pre></li> </ol> <p>For more information, check the Node.js tutorial.</p> <p>To run this server application, you need Go  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/go\n</code></pre></li> <li>Run the application <pre><code>go run main.go\n</code></pre></li> </ol> <p>For more information, check the Go tutorial.</p> <p>To run this server application, you need Ruby  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/ruby\n</code></pre></li> <li>Install dependencies <pre><code>bundle install\n</code></pre></li> <li>Run the application <pre><code>ruby app.rb\n</code></pre></li> </ol> <p>For more information, check the Ruby tutorial.</p> <p>To run this server application, you need Java  and Maven  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/java\n</code></pre></li> <li>Run the application <pre><code>mvn spring-boot:run\n</code></pre></li> </ol> <p>For more information, check the Java tutorial.</p> <p>To run this server application, you need Python 3  installed on your device.</p> <ol> <li> <p>Navigate into the server directory</p> <pre><code>cd openvidu-livekit-tutorials/application-server/python\n</code></pre> </li> <li> <p>Create a python virtual environment</p> <pre><code>python -m venv venv\n</code></pre> </li> <li> <p>Activate the virtual environment</p>  Windows macOS Linux <pre><code>.\\venv\\Scripts\\activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> </li> <li> <p>Install dependencies</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the application</p> <pre><code>python app.py\n</code></pre> </li> </ol> <p>For more information, check the Python tutorial.</p> <p>To run this server application, you need Rust  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/rust\n</code></pre></li> <li>Run the application <pre><code>cargo run\n</code></pre></li> </ol> <p>For more information, check the Rust tutorial.</p> <p>To run this server application, you need PHP  and Composer  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/php\n</code></pre></li> <li>Install dependencies <pre><code>composer install\n</code></pre></li> <li>Run the application <pre><code>composer start\n</code></pre></li> </ol> <p>Warning</p> <p>LiveKit PHP SDK requires library BCMath . This is available out-of-the-box in PHP for Windows, but a manual installation might be necessary in other OS. Run <code>sudo apt install php-bcmath</code> or <code>sudo yum install php-bcmath</code></p> <p>For more information, check the PHP tutorial.</p> <p>To run this server application, you need .NET  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/dotnet\n</code></pre></li> <li>Run the application <pre><code>dotnet run\n</code></pre></li> </ol> <p>Warning</p> <p>This .NET server application needs the <code>LIVEKIT_API_SECRET</code> env variable to be at least 32 characters long. Make sure to update it here  and in your OpenVidu Server.</p> <p>For more information, check the .NET tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/ios/#4-run-the-client-application","title":"4. Run the client application","text":"<p>To run the client application tutorial, you need Xcode  installed on your MacOS.</p> <ol> <li> <p>Launch Xcode and open the <code>OpenViduIOS.xcodeproj</code> that you can find under <code>openvidu-livekit-tutorials/application-client/openvidu-ios</code>.</p> </li> <li> <p>Run the application in an emulator or a physical device by clicking on the menu Product &gt; Run or by \u2318R.</p> </li> </ol> <p>Emulator limitations</p> <p>Publishing the camera track is not supported by iOS Simulator.</p> <p>If you encounter code signing issues, make sure you change the Team and bundle id from the previous step.</p> <p>The application will initiate as a native iOS application. Once the app is opened, you should see a screen like this:</p> <p></p> <p>This screen allows you to configure the URLs of the application server and the LiveKit server. You need to set them up for requesting tokens to your application server and connecting to the LiveKit server.</p> <p>Connecting real iOS device to application server running in you local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client in a real iOS device and be able to reach the application server very easily without worrying about SSL certificates if they are both running in the same local network. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Once you have configured the URLs, you can join a video call room by providing a room name and a user name. After joining the room, you will be able to see your own video and audio tracks, as well as the video and audio tracks of the other participants in the room.</p> <p></p> <p></p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/ios/#understanding-the-code","title":"Understanding the Code","text":"<p>This iOS project, created with Xcode and written in Swift, includes various files and directories. For this tutorial, focus on the following key components within the <code>openvidu-ios/Shared</code> directory:</p> <ul> <li><code>OpenViduApp.swift</code>: Initializes the application and sets up the main view.</li> <li><code>Support</code>: Contains files for secure storage, token management, and other support functions.</li> <li><code>Utils</code>: Includes utility files like <code>HttpClient.swift</code> for HTTP networking.</li> <li><code>Views</code>: Houses the user interface components of the application.</li> <li><code>Contexts</code>: Manages application state and room contexts for LiveKit interaction.</li> <li><code>Assets.xcassets</code>: Stores images and color assets used in the app.</li> </ul>","tags":["Platform"]},{"location":"docs/tutorials/application-client/ios/#integrating-livekit","title":"Integrating LiveKit","text":"<p>To use LiveKit in your iOS app, you need to add the LiveKit Swift SDK as a Swift Package. You can do this using either <code>Package.swift</code> or Xcode.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/ios/#adding-livekit-via-packageswift","title":"Adding LiveKit via <code>Package.swift</code>","text":"<ol> <li>Open your <code>Package.swift</code> file.</li> <li>Add LiveKit to the <code>dependencies</code> array.</li> <li>Include LiveKit in the <code>targets</code> array.</li> </ol> <p>Example <code>Package.swift</code>:</p> <pre><code>// swift-tools-version:5.3\nimport PackageDescription\n\nlet package = Package(\n    name: \"MyApp\",\n    platforms: [.iOS(.v14)],\n    dependencies: [\n        .package(name: \"LiveKit\", url: \"https://github.com/livekit/client-sdk-swift.git\", .upToNextMajor(from: \"2.0.12\"))\n    ],\n    targets: [\n        .target(\n            name: \"MyApp\",\n            dependencies: [\"LiveKit\"]\n        )\n    ]\n)\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/application-client/ios/#adding-livekit-via-xcode","title":"Adding LiveKit via Xcode","text":"<ol> <li>Open your Xcode project.</li> <li>Go to Project Settings.</li> <li>Select the Swift Packages tab.</li> <li>Click the + button to add a new package.</li> <li>Enter the URL: <code>https://github.com/livekit/client-sdk-swift</code>.</li> <li>Choose the version you want, such as \"Up to Next Major Version\" with <code>2.0.12</code>.</li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/application-client/ios/#ios-specific-requirements","title":"iOS Specific Requirements","text":"<p>To test the application on an iOS device, you need to ensure it has permission to access the camera and microphone. These configurations are already included in this project. However, if you're starting a new project, follow these steps:</p> <ol> <li> <p>Add Permissions to <code>Info.plist</code></p> <p>Include the following keys in your <code>Info.plist</code> file to request access to the camera and microphone:</p> <pre><code>&lt;key&gt;NSCameraUsageDescription&lt;/key&gt;\n&lt;string&gt;$(PRODUCT_NAME) needs camera access to capture and transmit video&lt;/string&gt;\n&lt;key&gt;NSMicrophoneUsageDescription&lt;/key&gt;\n&lt;string&gt;$(PRODUCT_NAME) needs microphone access to capture and transmit audio&lt;/string&gt;\n</code></pre> </li> <li> <p>Automatic Permission Requests</p> <p>The app will automatically request these permissions when it runs.</p> </li> <li> <p>Check Permissions</p> <p>To verify if the permissions were granted, use the <code>AVCaptureDevice.requestAccess(for: .video)</code> method:</p> <pre><code>AVCaptureDevice.requestAccess(for: .video) { granted in\n    if granted {\n        print(\"Camera access granted\")\n    } else {\n        print(\"Camera access denied\")\n    }\n}\n</code></pre> </li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/application-client/ios/#configuring-urls","title":"Configuring URLs","text":"<p>The <code>ConfigureUrlsView.swift</code> file defines a SwiftUI view for configuring the URLs required for the application:</p> <ul> <li><code>applicationServerUrl</code>: The URL of the application server used to obtain tokens for joining the video call room.</li> <li><code>livekitUrl</code>: The URL of the LiveKit server used to connect to the video call room and handle video communication.</li> </ul> <p>You should configure these URLs according to your deployment settings. If you are running OpenVidu locally, you can set <code>applicationServerUrl</code> to <code>https://xxx-yyy-zzz-www.openvidu-local.dev:6443</code> and <code>livekitUrl</code> to <code>wss://xxx-yyy-zzz-www.openvidu-local.dev:7443</code>, where <code>xxx-yyy-zzz-www</code> represents the LAN private IP address of the machine running OpenVidu, with dashes (-) instead of dots (.).</p> <p>If these URLs are left empty, the user will be prompted to enter them when the application starts. This configuration is managed in the <code>ConfigureUrlsView.swift</code> file:</p> <p></p> <p>When the user clicks the <code>Save</code> button, the <code>LKButton</code> action triggers the validation and saves the URLs into the <code>AppContext</code> and <code>RoomContext</code>. The <code>ConfigureUrlsView</code> handles this logic:</p> ConfigureUrlsView.swift<pre><code>LKButton(title: \"Save\") {\n    Task.detached { @MainActor in\n        let isApplicationServerValid = isValidURL(self.applicationServerUrl)\n        let isLivekitUrlValid = isValidURL(self.livekitUrl)\n\n        if !isApplicationServerValid || !isLivekitUrlValid {\n            print(\"Invalid URLs\")\n            errorMessage = \"There was an error with the URL values\"\n            return\n        }\n        appCtx.applicationServerUrl = self.applicationServerUrl\n        roomCtx.livekitUrl = self.livekitUrl\n        errorMessage = \"\"\n    }\n}\n</code></pre> <p>In this code snippet, the <code>isValidURL</code> function checks the validity of the URLs. If both URLs are valid, they are saved into the <code>appCtx</code> and <code>roomCtx</code> contexts. If any URL is invalid, an error message is displayed.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/ios/#joining-a-room","title":"Joining a room","text":"<p>Before joining a room, the <code>ConnectView.swift</code> defines the view for the connection screen. It includes a logo, text fields for participant name and room name, and buttons for joining the room and resetting URLs.</p> <p></p> <p>After define the participant and room name, the user can click the <code>Join</code> button to connect to the room. This action triggers the <code>connectToRoom</code> method asynchronously:</p> ConnectView.swift<pre><code>func connectToRoom() async {\n    let livekitUrl = roomCtx.livekitUrl\n    let roomName = roomCtx.name\n    let participantName = roomCtx.localParticipantName\n    let applicationServerUrl = appCtx.applicationServerUrl\n\n    guard !livekitUrl.isEmpty, !roomName.isEmpty else {\n        print(\"LiveKit URL or room name is empty\")\n        return\n    }\n\n    do {\n        let token = try await httpService.getToken(\n            applicationServerUrl: applicationServerUrl, roomName: roomName,\n            participantName: participantName)// (1)!\n\n        if token.isEmpty {\n            print(\"Received empty token\")\n            return\n        }\n\n        roomCtx.token = token\n        print(\"Connecting to room...\")\n        try await roomCtx.connect() // (2)!\n        print(\"Room connected\")\n        await enableCameraAndMicrophone() // (3)!\n\n    } catch {\n        print(\"Failed to get token: \\(error.localizedDescription)\")\n    }\n}\n\nfunc enableCameraAndMicrophone() async {\n    do {\n        try await room.localParticipant.setCamera(enabled: true) // (4)!\n        try await room.localParticipant.setMicrophone(enabled: true) // (5)!\n    } catch {\n        print(\"Error enabling camera and microphone: \\(error.localizedDescription)\")\n    }\n}\n</code></pre> <ol> <li>The <code>getToken</code> method is called to request a token from the application server.</li> <li>The <code>connect</code> method is called to connect to the room using the LiveKit URL and the token.</li> <li>The <code>enableCameraAndMicrophone</code> method is called to enable the camera and microphone for the local participant.</li> <li>The <code>setCamera</code> method is called to enable the camera for the local participant.</li> <li>The <code>setMicrophone</code> method is called to enable the microphone for the local participant.</li> </ol> <p>The <code>OpenViduApp.swift</code> handle the navigation page. When room status is <code>connected</code>, the user is redirected to the <code>RoomView</code>:</p> OpenViduApp.swift<pre><code>struct RoomSwitchView: View {\n    @EnvironmentObject var appCtx: AppContext\n    @EnvironmentObject var roomCtx: RoomContext\n    @EnvironmentObject var room: Room\n\n    var shouldShowRoomView: Bool {\n        room.connectionState == .connected || room.connectionState == .reconnecting\n    }\n\n    var shouldShowConfigureUrlsView: Bool {\n        appCtx.applicationServerUrl.isEmpty || roomCtx.livekitUrl.isEmpty\n\n    }\n\n    var body: some View {\n        ZStack {\n            Color.black\n                .ignoresSafeArea()\n\n            // Navigation logic\n            if shouldShowRoomView {\n                RoomView() // (1)!\n            } else {\n                if shouldShowConfigureUrlsView {\n                    ConfigureUrlsView() // (2)!\n                } else {\n                    ConnectView() // (3)!\n                }\n            }\n        }\n        .navigationTitle(computeTitle())\n    }\n}\n</code></pre> <ol> <li>If the room is connected, the user is redirected to the <code>RoomView</code>.</li> <li>If the URLs are not configured, the user is redirected to the <code>ConfigureUrlsView</code>.</li> <li>If the room is not connected and the URLs are configured, the user is redirected to the <code>ConnectView</code>.</li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/application-client/ios/#displaying-video-tracks","title":"Displaying Video Tracks","text":"<p>To display the video tracks of participants in the room, the <code>RoomView.swift</code> uses various SwiftUI views and custom components. This approach allows the application to dynamically load and display the video tracks as they are received.</p> RoomView.swift<pre><code>struct RoomView: View {\n    @EnvironmentObject var appCtx: AppContext\n    @EnvironmentObject var roomCtx: RoomContext\n    @EnvironmentObject var room: Room\n\n    @State var isCameraPublishingBusy = false\n    @State var isMicrophonePublishingBusy = false\n\n    // ...\n\n    func content(geometry: GeometryProxy) -&gt; some View {\n        VStack {\n            // ...\n\n            // Display Participant layout\n            HorVStack(axis: geometry.isTall ? .vertical : .horizontal, spacing: 5) {\n                Group {\n                    ParticipantLayout(sortedParticipants(), spacing: 5) { participant in // (1)!\n                        ParticipantView(participant: participant, videoViewMode: .fill) // (2)!\n                    }\n                }\n                .frame(\n                    minWidth: 0,\n                    maxWidth: .infinity,\n                    minHeight: 0,\n                    maxHeight: .infinity\n                )\n            }\n            .padding(5)\n        }\n    }\n}\n</code></pre> <ol> <li>The <code>ParticipantLayout</code> component is used to display the video tracks of all participants in the room. It receives the sorted list of participants and a closure that returns a <code>ParticipantView</code> for each participant.</li> <li>The <code>ParticipantView</code> component is used to display the video track of a participant.</li> </ol> <p>The <code>ParticipantView</code> component is responsible for rendering the video track of a participant. It uses the <code>SwiftUIVideoView</code> component to display the video track and the <code>VideoView.LayoutMode</code> enum to define the layout mode.</p> <p>The LiveKit Swift SDK includes a VideoView class, based on UIKit, specifically designed for rendering video tracks. Additionally, subscribed audio tracks are automatically played by default.</p> ParticipantView.swift<pre><code>struct ParticipantView: View {\n    @ObservedObject var participant: Participant\n    @EnvironmentObject var appCtx: AppContext\n\n    var videoViewMode: VideoView.LayoutMode = .fill\n\n\n    // ...\n\n     var body: some View {\n        GeometryReader { geometry in\n            ZStack(alignment: .bottom) {\n\n                // ...\n\n                // VideoView for the Participant\n                if let publication = participant.mainVideoPublication,\n                    !publication.isMuted,\n                    let track = publication.track as? VideoTrack\n                {\n                    ZStack(alignment: .topLeading) {\n                        SwiftUIVideoView(track, // (1)!\n                                            layoutMode: videoViewMode,\n                                            isRendering: $isRendering)\n                    }\n                }\n            }\n        }\n     }\n\n}\n</code></pre> <ol> <li>The <code>SwiftUIVideoView</code> component renders the participant's video track.</li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/application-client/ios/#leaving-the-room","title":"Leaving the room","text":"<p>To leave the room, the user can click the <code>Leave</code> button in the <code>RoomView</code>. This action triggers the <code>leaveRoom</code> method asynchronously:</p> RoomView.swift<pre><code>func content(geometry: GeometryProxy) -&gt; some View {\n\n    // ...\n\n    Button(action: {\n        Task {\n            await roomCtx.disconnect()\n        }\n    }, label: {\n        HStack {\n            Image(systemSymbol: .xmarkCircleFill)\n                .renderingMode(.original)\n            Text(\"Leave Room\")\n                .font(.headline)\n                .fontWeight(.semibold)\n        }\n        .padding(8)\n        .background(Color.red.opacity(0.8)) // Background color for the button\n        .foregroundColor(.white) // Text color\n        .cornerRadius(8)\n    })\n}\n</code></pre> <p>After rome is disconnected, the room status is updated to <code>disconnected</code> and the <code>OpenViduApp.swift</code> handle this update to redirect the user to the <code>ConnectView</code>.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/javascript/","title":"JavaScript Tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-client/javascript/#javascript-tutorial","title":"JavaScript Tutorial","text":"<p>Source code </p> <p>This tutorial is a simple video-call application built with plain JavaScript, HTML and CSS that allows:</p> <ul> <li>Joining a video call room by requesting a token from any application server.</li> <li>Publishing your camera and microphone.</li> <li>Subscribing to all other participants' video and audio tracks automatically.</li> <li>Leaving the video call room at any time.</li> </ul> <p>It uses the LiveKit JS SDK  to connect to the LiveKit server and interact with the video call room.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/javascript/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-client/javascript/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/javascript/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/application-client/javascript/#3-run-a-server-application","title":"3. Run a server application","text":"Node.js Go Ruby Java Python Rust PHP .NET <p>To run this server application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/node\n</code></pre></li> <li>Install dependencies <pre><code>npm install\n</code></pre></li> <li>Run the application <pre><code>npm start\n</code></pre></li> </ol> <p>For more information, check the Node.js tutorial.</p> <p>To run this server application, you need Go  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/go\n</code></pre></li> <li>Run the application <pre><code>go run main.go\n</code></pre></li> </ol> <p>For more information, check the Go tutorial.</p> <p>To run this server application, you need Ruby  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/ruby\n</code></pre></li> <li>Install dependencies <pre><code>bundle install\n</code></pre></li> <li>Run the application <pre><code>ruby app.rb\n</code></pre></li> </ol> <p>For more information, check the Ruby tutorial.</p> <p>To run this server application, you need Java  and Maven  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/java\n</code></pre></li> <li>Run the application <pre><code>mvn spring-boot:run\n</code></pre></li> </ol> <p>For more information, check the Java tutorial.</p> <p>To run this server application, you need Python 3  installed on your device.</p> <ol> <li> <p>Navigate into the server directory</p> <pre><code>cd openvidu-livekit-tutorials/application-server/python\n</code></pre> </li> <li> <p>Create a python virtual environment</p> <pre><code>python -m venv venv\n</code></pre> </li> <li> <p>Activate the virtual environment</p>  Windows macOS Linux <pre><code>.\\venv\\Scripts\\activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> </li> <li> <p>Install dependencies</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the application</p> <pre><code>python app.py\n</code></pre> </li> </ol> <p>For more information, check the Python tutorial.</p> <p>To run this server application, you need Rust  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/rust\n</code></pre></li> <li>Run the application <pre><code>cargo run\n</code></pre></li> </ol> <p>For more information, check the Rust tutorial.</p> <p>To run this server application, you need PHP  and Composer  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/php\n</code></pre></li> <li>Install dependencies <pre><code>composer install\n</code></pre></li> <li>Run the application <pre><code>composer start\n</code></pre></li> </ol> <p>Warning</p> <p>LiveKit PHP SDK requires library BCMath . This is available out-of-the-box in PHP for Windows, but a manual installation might be necessary in other OS. Run <code>sudo apt install php-bcmath</code> or <code>sudo yum install php-bcmath</code></p> <p>For more information, check the PHP tutorial.</p> <p>To run this server application, you need .NET  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/dotnet\n</code></pre></li> <li>Run the application <pre><code>dotnet run\n</code></pre></li> </ol> <p>Warning</p> <p>This .NET server application needs the <code>LIVEKIT_API_SECRET</code> env variable to be at least 32 characters long. Make sure to update it here  and in your OpenVidu Server.</p> <p>For more information, check the .NET tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/javascript/#4-run-the-client-application","title":"4. Run the client application","text":"<p>To run the client application tutorial, you need an HTTP web server installed on your development computer. A great option is http-server . You can install it via NPM :</p> <pre><code>npm install -g http-server\n</code></pre> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-js\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>http-server -p 5080 ./src\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p> <p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/javascript/#understanding-the-code","title":"Understanding the code","text":"<p>This application is designed to be beginner-friendly and consists of only three essential files that are located in the <code>src</code> directory:</p> <ul> <li><code>app.js</code>: This is the main JavaScript file for the sample application. It uses the LiveKit JS SDK  to connect to the LiveKit server and interact with the video call room.</li> <li><code>index.html</code>: This HTML file is responsible for creating the user interface. It contains the form to connect to a video call and the video call layout.</li> <li><code>styles.css</code>: This file contains CSS classes that are used to style the <code>index.html</code> page.</li> </ul> <p>To use the LiveKit JS SDK in your application, you need to include the library in your HTML file. The tutorial does this by adding the following script tag to the <code>&lt;head&gt;</code> section of the HTML file:</p> index.html<pre><code>&lt;script src=\"https://cdn.jsdelivr.net/npm/livekit-client@2.5.9/dist/livekit-client.umd.js\"&gt;&lt;/script&gt;\n</code></pre> <p>Then, you can use the <code>LivekitClient</code> object in your JavaScript code by referencing it from the <code>window</code> object under <code>LivekitClient</code>. When accessing symbols from the class, you will need to prefix them with <code>LivekitClient.</code>. For example, <code>Room</code> becomes <code>LivekitClient.Room</code>.</p> <p>Now let's see the code of the <code>app.js</code> file:</p> app.js<pre><code>// When running OpenVidu locally, leave these variables empty\n// For other deployment type, configure them with correct URLs depending on your deployment\nvar APPLICATION_SERVER_URL = \"\"; // (1)!\nvar LIVEKIT_URL = \"\"; // (2)!\nconfigureUrls();\n\nconst LivekitClient = window.LivekitClient; // (3)!\nvar room; // (4)!\n\nfunction configureUrls() {\n    // If APPLICATION_SERVER_URL is not configured, use default value from OpenVidu Local deployment\n    if (!APPLICATION_SERVER_URL) {\n        if (window.location.hostname === \"localhost\") {\n            APPLICATION_SERVER_URL = \"http://localhost:6080/\";\n        } else {\n            APPLICATION_SERVER_URL = \"https://\" + window.location.hostname + \":6443/\";\n        }\n    }\n\n    // If LIVEKIT_URL is not configured, use default value from OpenVidu Local deployment\n    if (!LIVEKIT_URL) {\n        if (window.location.hostname === \"localhost\") {\n            LIVEKIT_URL = \"ws://localhost:7880/\";\n        } else {\n            LIVEKIT_URL = \"wss://\" + window.location.hostname + \":7443/\";\n        }\n    }\n}\n</code></pre> <ol> <li>The URL of the application server.</li> <li>The URL of the LiveKit server.</li> <li>The LivekitClient object, which is the entry point to the LiveKit JS SDK.</li> <li>The room object, which represents the video call room.</li> </ol> <p>The <code>app.js</code> file defines the following variables:</p> <ul> <li><code>APPLICATION_SERVER_URL</code>: The URL of the application server. This variable is used to make requests to the server to obtain a token for joining the video call room.</li> <li><code>LIVEKIT_URL</code>: The URL of the LiveKit server. This variable is used to connect to the LiveKit server and interact with the video call room.</li> <li><code>LivekitClient</code>: The LiveKit JS SDK object, which is the entry point to the LiveKit JS SDK.</li> <li><code>room</code>: The room object, which represents the video call room.</li> </ul> <p>Configure the URLs</p> <p>When running OpenVidu locally, leave <code>APPLICATION_SERVER_URL</code> and <code>LIVEKIT_URL</code> variables empty. The function <code>configureUrls()</code> will automatically configure them with default values. However, for other deployment type, you should configure these variables with the correct URLs depending on your deployment.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/javascript/#joining-a-room","title":"Joining a Room","text":"<p>After the user specifies their participant name and the name of the room they want to join, when they click the <code>Join</code> button, the <code>joinRoom()</code> function is called:</p> app.js<pre><code>async function joinRoom() {\n    // Disable 'Join' button\n    document.getElementById(\"join-button\").disabled = true;\n    document.getElementById(\"join-button\").innerText = \"Joining...\";\n\n    // Initialize a new Room object\n    room = new LivekitClient.Room(); // (1)!\n\n    // Specify the actions when events take place in the room\n    // On every new Track received...\n    room.on(LivekitClient.RoomEvent.TrackSubscribed, (track, _publication, participant) =&gt; {\n        // (2)!\n        addTrack(track, participant.identity);\n    });\n\n    // On every new Track destroyed...\n    room.on(LivekitClient.RoomEvent.TrackUnsubscribed, (track, _publication, participant) =&gt; {\n        // (3)!\n        track.detach();\n        document.getElementById(track.sid)?.remove();\n\n        if (track.kind === \"video\") {\n            removeVideoContainer(participant.identity);\n        }\n    });\n\n    try {\n        // Get the room name and participant name from the form\n        const roomName = document.getElementById(\"room-name\").value; // (4)!\n        const userName = document.getElementById(\"participant-name\").value;\n\n        // Get a token from your application server with the room name and participant name\n        const token = await getToken(roomName, userName); // (5)!\n\n        // Connect to the room with the LiveKit URL and the token\n        await room.connect(LIVEKIT_URL, token); // (6)!\n\n        // Hide the 'Join room' page and show the 'Room' page\n        document.getElementById(\"room-title\").innerText = roomName; // (7)!\n        document.getElementById(\"join\").hidden = true;\n        document.getElementById(\"room\").hidden = false;\n\n        // Publish your camera and microphone\n        await room.localParticipant.enableCameraAndMicrophone(); // (8)!\n        const localVideoTrack = this.room.localParticipant.videoTrackPublications.values().next().value.track;\n        addTrack(localVideoTrack, userName, true);\n    } catch (error) {\n        console.log(\"There was an error connecting to the room:\", error.message);\n    }\n}\n</code></pre> <ol> <li>Initialize a new <code>Room</code> object.</li> <li>Event handling for when a new track is received in the room.</li> <li>Event handling for when a track is destroyed.</li> <li>Get the room name and participant name from the form.</li> <li>Get a token from the application server with the room name and participant name.</li> <li>Connect to the room with the LiveKit URL and the token.</li> <li>Hide the \"Join room\" page and show the \"Room\" page.</li> <li>Publish your camera and microphone.</li> </ol> <p>The <code>joinRoom()</code> function performs the following actions:</p> <ol> <li>It creates a new <code>Room</code> object using <code>LivekitClient.Room()</code>. This object represents the video call room.</li> <li> <p>Event handling is configured for different scenarios within the room. These events are fired when new tracks are subscribed to and when existing tracks are unsubscribed.</p> <ul> <li><code>LivekitClient.RoomEvent.TrackSubscribed</code>: This event is triggered when a new track is received in the room. It handles the attachment of the track to the HTML page, assigning an ID, and appending it to the <code>layout-container</code> element. If the track is of kind <code>video</code>, a <code>video-container</code> is created and participant data is appended as well.</li> </ul> app.js<pre><code>function addTrack(track, participantIdentity, local = false) {\n    const element = track.attach(); // (1)!\n    element.id = track.sid;\n\n    /* If the track is a video track, we create a container and append the video element to it\n    with the participant's identity */\n    if (track.kind === \"video\") {\n        const videoContainer = createVideoContainer(participantIdentity, local);\n        videoContainer.append(element);\n        appendParticipantData(videoContainer, participantIdentity + (local ? \" (You)\" : \"\"));\n    } else {\n        document.getElementById(\"layout-container\").append(element);\n    }\n}\n</code></pre> <ol> <li>Attach the track to an HTML element.</li> </ol> app.js<pre><code>function createVideoContainer(participantIdentity, local = false) {\n    const videoContainer = document.createElement(\"div\");\n    videoContainer.id = `camera-${participantIdentity}`;\n    videoContainer.className = \"video-container\";\n    const layoutContainer = document.getElementById(\"layout-container\");\n\n    if (local) {\n        layoutContainer.prepend(videoContainer);\n    } else {\n        layoutContainer.append(videoContainer);\n    }\n\n    return videoContainer;\n}\n\nfunction appendParticipantData(videoContainer, participantIdentity) {\n    const dataElement = document.createElement(\"div\");\n    dataElement.className = \"participant-data\";\n    dataElement.innerHTML = `&lt;p&gt;${participantIdentity}&lt;/p&gt;`;\n    videoContainer.prepend(dataElement);\n}\n</code></pre> <ul> <li><code>LivekitClient.RoomEvent.TrackUnsubscribed</code>: This event occurs when a track is destroyed, and it takes care of detaching the track from the HTML page and removing it from the DOM. If the track is a <code>video</code> track, <code>video-container</code> with the participant's identity is removed as well.</li> </ul> app.js<pre><code>function removeVideoContainer(participantIdentity) {\n    const videoContainer = document.getElementById(`camera-${participantIdentity}`);\n    videoContainer?.remove();\n}\n</code></pre> <p>These event handlers are essential for managing the behavior of tracks within the video call.</p> <p>Take a look at all events</p> <p>You can take a look at all the events in the Livekit Documentation</p> </li> <li> <p>It retrieves the room name and participant name from the form.</p> </li> <li> <p>It requests a token from the application server using the room name and participant name. This is done by calling the <code>getToken()</code> function:</p> app.js<pre><code>/**\n * --------------------------------------------\n * GETTING A TOKEN FROM YOUR APPLICATION SERVER\n * --------------------------------------------\n * The method below request the creation of a token to\n * your application server. This prevents the need to expose\n * your LiveKit API key and secret to the client side.\n *\n * In this sample code, there is no user control at all. Anybody could\n * access your application server endpoints. In a real production\n * environment, your application server must identify the user to allow\n * access to the endpoints.\n */\nasync function getToken(roomName, participantName) {\n    const response = await fetch(APPLICATION_SERVER_URL + \"token\", {\n        method: \"POST\",\n        headers: {\n            \"Content-Type\": \"application/json\"\n        },\n        body: JSON.stringify({\n            roomName,\n            participantName\n        })\n    });\n\n    if (!response.ok) {\n        const error = await response.json();\n        throw new Error(`Failed to get token: ${error.errorMessage}`);\n    }\n\n    const token = await response.json();\n    return token.token;\n}\n</code></pre> <p>This function sends a POST request using <code>fetch()</code> to the application server's <code>/token</code> endpoint. The request body contains the room name and participant name. The server responds with a token that is used to connect to the room.</p> </li> <li> <p>It connects to the room using the LiveKit URL and the token.</p> </li> <li>It updates the UI to hide the \"Join room\" page and show the \"Room\" layout.</li> <li>It publishes the camera and microphone tracks to the room using <code>room.localParticipant.enableCameraAndMicrophone()</code>, which asks the user for permission to access their camera and microphone at the same time. The local video track is then added to the layout.</li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/application-client/javascript/#leaving-the-room","title":"Leaving the Room","text":"<p>When the user wants to leave the room, they can click the <code>Leave Room</code> button. This action calls the <code>leaveRoom()</code> function:</p> app.js<pre><code>async function leaveRoom() {\n    // Leave the room by calling 'disconnect' method over the Room object\n    await room.disconnect(); // (1)!\n\n    // Remove all HTML elements inside the layout container\n    removeAllLayoutElements(); // (2)!\n\n    // Back to 'Join room' page\n    document.getElementById(\"join\").hidden = false; // (3)!\n    document.getElementById(\"room\").hidden = true;\n\n    // Enable 'Join' button\n    document.getElementById(\"join-button\").disabled = false;\n    document.getElementById(\"join-button\").innerText = \"Join!\";\n}\n\n// (4)!\nwindow.onbeforeunload = () =&gt; {\n    room?.disconnect();\n};\n</code></pre> <ol> <li>Disconnect the user from the room.</li> <li>Remove all HTML elements inside the layout container.</li> <li>Show the \"Join room\" page and hide the \"Room\" layout.</li> <li>Call the <code>disconnect()</code> method on the <code>room</code> object when the user closes the tab or navigates to another page.</li> </ol> <p>The <code>leaveRoom()</code> function performs the following actions:</p> <ul> <li>It disconnects the user from the room by calling the <code>disconnect()</code> method on the <code>room</code> object.</li> <li>It removes all HTML elements inside the layout container by calling the <code>removeAllLayoutElements()</code> function.</li> <li>It shows the \"Join room\" page and hides the \"Room\" layout.</li> </ul> <p>The <code>window.onbeforeunload</code> event is used to ensure that the user is disconnected from the room before the page is unloaded. This event is triggered when the user closes the tab or navigates to another page.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/react/","title":"React Tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-client/react/#react-tutorial","title":"React Tutorial","text":"<p>Source code </p> <p>This tutorial is a simple video-call application built with React that allows:</p> <ul> <li>Joining a video call room by requesting a token from any application server.</li> <li>Publishing your camera and microphone.</li> <li>Subscribing to all other participants' video and audio tracks automatically.</li> <li>Leaving the video call room at any time.</li> </ul> <p>It uses the LiveKit JS SDK  to connect to the LiveKit server and interact with the video call room.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/react/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-client/react/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/react/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/application-client/react/#3-run-a-server-application","title":"3. Run a server application","text":"Node.js Go Ruby Java Python Rust PHP .NET <p>To run this server application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/node\n</code></pre></li> <li>Install dependencies <pre><code>npm install\n</code></pre></li> <li>Run the application <pre><code>npm start\n</code></pre></li> </ol> <p>For more information, check the Node.js tutorial.</p> <p>To run this server application, you need Go  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/go\n</code></pre></li> <li>Run the application <pre><code>go run main.go\n</code></pre></li> </ol> <p>For more information, check the Go tutorial.</p> <p>To run this server application, you need Ruby  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/ruby\n</code></pre></li> <li>Install dependencies <pre><code>bundle install\n</code></pre></li> <li>Run the application <pre><code>ruby app.rb\n</code></pre></li> </ol> <p>For more information, check the Ruby tutorial.</p> <p>To run this server application, you need Java  and Maven  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/java\n</code></pre></li> <li>Run the application <pre><code>mvn spring-boot:run\n</code></pre></li> </ol> <p>For more information, check the Java tutorial.</p> <p>To run this server application, you need Python 3  installed on your device.</p> <ol> <li> <p>Navigate into the server directory</p> <pre><code>cd openvidu-livekit-tutorials/application-server/python\n</code></pre> </li> <li> <p>Create a python virtual environment</p> <pre><code>python -m venv venv\n</code></pre> </li> <li> <p>Activate the virtual environment</p>  Windows macOS Linux <pre><code>.\\venv\\Scripts\\activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> </li> <li> <p>Install dependencies</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the application</p> <pre><code>python app.py\n</code></pre> </li> </ol> <p>For more information, check the Python tutorial.</p> <p>To run this server application, you need Rust  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/rust\n</code></pre></li> <li>Run the application <pre><code>cargo run\n</code></pre></li> </ol> <p>For more information, check the Rust tutorial.</p> <p>To run this server application, you need PHP  and Composer  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/php\n</code></pre></li> <li>Install dependencies <pre><code>composer install\n</code></pre></li> <li>Run the application <pre><code>composer start\n</code></pre></li> </ol> <p>Warning</p> <p>LiveKit PHP SDK requires library BCMath . This is available out-of-the-box in PHP for Windows, but a manual installation might be necessary in other OS. Run <code>sudo apt install php-bcmath</code> or <code>sudo yum install php-bcmath</code></p> <p>For more information, check the PHP tutorial.</p> <p>To run this server application, you need .NET  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/dotnet\n</code></pre></li> <li>Run the application <pre><code>dotnet run\n</code></pre></li> </ol> <p>Warning</p> <p>This .NET server application needs the <code>LIVEKIT_API_SECRET</code> env variable to be at least 32 characters long. Make sure to update it here  and in your OpenVidu Server.</p> <p>For more information, check the .NET tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/react/#4-run-the-client-application","title":"4. Run the client application","text":"<p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-react\n</code></pre> </li> <li> <p>Install dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Run the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p> <p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/react/#understanding-the-code","title":"Understanding the code","text":"<p>This React project has been generated using the Vite. You may come across various configuration files and other items that are not essential for this tutorial. Our focus will be on the key files located within the <code>src/</code> directory:</p> <ul> <li><code>App.tsx</code>: This file defines the main application component. It is responsible for handling tasks such as joining a video call and managing the video calls themselves.</li> <li><code>App.css</code>: This file contains the styles for the main application component.</li> <li><code>VideoComponent.tsx</code>: This file defines the <code>VideoComponent</code>. This component is responsible for displaying video tracks along with participant's data. Its associated styles are in <code>VideoComponent.css</code>.</li> <li><code>AudioComponent.vue</code>: This file defines the <code>AudioComponent</code>. This component is responsible for displaying audio tracks.</li> </ul> <p>To use the LiveKit JS SDK in a Vue application, you need to install the <code>livekit-client</code> package. This package provides the necessary classes and methods to interact with the LiveKit server. You can install it using the following command:</p> <pre><code>npm install livekit-client\n</code></pre> <p>Now let's see the code of the <code>App.tsx</code> file:</p> App.tsx<pre><code>type TrackInfo = { // (1)!\n    trackPublication: RemoteTrackPublication;\n    participantIdentity: string;\n};\n\n// When running OpenVidu locally, leave these variables empty\n// For other deployment type, configure them with correct URLs depending on your deployment\nlet APPLICATION_SERVER_URL = \"\"; // (2)!\nlet LIVEKIT_URL = \"\"; // (3)!\nconfigureUrls();\n\nfunction configureUrls() {\n    // If APPLICATION_SERVER_URL is not configured, use default value from OpenVidu Local deployment\n    if (!APPLICATION_SERVER_URL) {\n        if (window.location.hostname === \"localhost\") {\n            APPLICATION_SERVER_URL = \"http://localhost:6080/\";\n        } else {\n            APPLICATION_SERVER_URL = \"https://\" + window.location.hostname + \":6443/\";\n        }\n    }\n\n    // If LIVEKIT_URL is not configured, use default value from OpenVidu Local deployment\n    if (!LIVEKIT_URL) {\n        if (window.location.hostname === \"localhost\") {\n            LIVEKIT_URL = \"ws://localhost:7880/\";\n        } else {\n            LIVEKIT_URL = \"wss://\" + window.location.hostname + \":7443/\";\n        }\n    }\n}\n\nfunction App() {\n    const [room, setRoom] = useState&lt;Room | undefined&gt;(undefined); // (4)!\n    const [localTrack, setLocalTrack] = useState&lt;LocalVideoTrack | undefined&gt;(undefined); // (5)!\n    const [remoteTracks, setRemoteTracks] = useState&lt;TrackInfo[]&gt;([]); // (6)!\n\n    const [participantName, setParticipantName] = useState(\"Participant\" + Math.floor(Math.random() * 100)); // (7)!\n    const [roomName, setRoomName] = useState(\"Test Room\"); // (8)!\n</code></pre> <ol> <li><code>TrackInfo</code> type, which groups a track publication with the participant's identity.</li> <li>The URL of the application server.</li> <li>The URL of the LiveKit server.</li> <li>The room object, which represents the video call room.</li> <li>The local video track, which represents the user's camera.</li> <li>The remote tracks array.</li> <li>The participant's name.</li> <li>The room name.</li> </ol> <p>The <code>App.tsx</code> file defines the following variables:</p> <ul> <li><code>APPLICATION_SERVER_URL</code>: The URL of the application server. This variable is used to make requests to the server to obtain a token for joining the video call room.</li> <li><code>LIVEKIT_URL</code>: The URL of the LiveKit server. This variable is used to connect to the LiveKit server and interact with the video call room.</li> <li><code>room</code>: The room object, which represents the video call room.</li> <li><code>localTrack</code>: The local video track, which represents the user's camera.</li> <li><code>remoteTracks</code>: An array of <code>TrackInfo</code> objects, which group a track publication with the participant's identity.</li> <li><code>participantName</code>: The participant's name.</li> <li><code>roomName</code>: The room name.</li> </ul> <p>Configure the URLs</p> <p>When running OpenVidu locally, leave <code>APPLICATION_SERVER_URL</code> and <code>LIVEKIT_URL</code> variables empty. The function <code>configureUrls()</code> will automatically configure them with default values. However, for other deployment type, you should configure these variables with the correct URLs depending on your deployment.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/react/#joining-a-room","title":"Joining a Room","text":"<p>After the user specifies their participant name and the name of the room they want to join, when they click the <code>Join</code> button, the <code>joinRoom()</code> function is called:</p> App.tsx<pre><code>async function joinRoom() {\n    // Initialize a new Room object\n    const room = new Room(); // (1)!\n    setRoom(room);\n\n    // Specify the actions when events take place in the room\n    // On every new Track received...\n    room.on(\n        RoomEvent.TrackSubscribed,\n        (_track: RemoteTrack, publication: RemoteTrackPublication, participant: RemoteParticipant) =&gt; {\n            // (2)!\n            setRemoteTracks((prev) =&gt; [\n                ...prev,\n                { trackPublication: publication, participantIdentity: participant.identity }\n            ]);\n        }\n    );\n\n    // On every Track destroyed...\n    room.on(RoomEvent.TrackUnsubscribed, (_track: RemoteTrack, publication: RemoteTrackPublication) =&gt; {\n        // (3)!\n        setRemoteTracks((prev) =&gt; prev.filter((track) =&gt; track.trackPublication.trackSid !== publication.trackSid));\n    });\n\n    try {\n        // Get a token from your application server with the room name and participant name\n        const token = await getToken(roomName, participantName); // (4)!\n\n        // Connect to the room with the LiveKit URL and the token\n        await room.connect(LIVEKIT_URL, token); // (5)!\n\n        // Publish your camera and microphone\n        await room.localParticipant.enableCameraAndMicrophone(); // (6)!\n        setLocalTrack(room.localParticipant.videoTrackPublications.values().next().value.videoTrack);\n    } catch (error) {\n        console.log(\"There was an error connecting to the room:\", (error as Error).message);\n        await leaveRoom();\n    }\n}\n</code></pre> <ol> <li>Initialize a new <code>Room</code> object.</li> <li>Event handling for when a new track is received in the room.</li> <li>Event handling for when a track is destroyed.</li> <li>Get a token from the application server with the room name and participant name from the form.</li> <li>Connect to the room with the LiveKit URL and the token.</li> <li>Publish your camera and microphone.</li> </ol> <p>The <code>joinRoom()</code> function performs the following actions:</p> <ol> <li> <p>It creates a new <code>Room</code> object. This object represents the video call room.</p> <p>Info</p> <p>When the room object is defined, the HTML template is automatically updated hiding the \"Join room\" page and showing the \"Room\" layout.</p> </li> <li> <p>Event handling is configured for different scenarios within the room. These events are fired when new tracks are subscribed to and when existing tracks are unsubscribed.</p> <ul> <li> <p><code>RoomEvent.TrackSubscribed</code>: This event is triggered when a new track is received in the room. It manages the storage of the new track in the <code>remoteTracks</code> array as a <code>TrackInfo</code> object containing the track publication and the participant's identity.</p> </li> <li> <p><code>RoomEvent.TrackUnsubscribed</code>: This event occurs when a track is destroyed, and it takes care of removing the track from the <code>remoteTracks</code> array.</p> </li> </ul> <p>These event handlers are essential for managing the behavior of tracks within the video call. You can further extend the event handling as needed for your application.</p> <p>Take a look at all events</p> <p>You can take a look at all the events in the Livekit Documentation</p> </li> <li> <p>It requests a token from the application server using the room name and participant name. This is done by calling the <code>getToken()</code> function:</p> App.tsx<pre><code>/**\n * --------------------------------------------\n * GETTING A TOKEN FROM YOUR APPLICATION SERVER\n * --------------------------------------------\n * The method below request the creation of a token to\n * your application server. This prevents the need to expose\n * your LiveKit API key and secret to the client side.\n *\n * In this sample code, there is no user control at all. Anybody could\n * access your application server endpoints. In a real production\n * environment, your application server must identify the user to allow\n * access to the endpoints.\n */\nasync function getToken(roomName: string, participantName: string) {\n    const response = await fetch(APPLICATION_SERVER_URL + \"token\", {\n        method: \"POST\",\n        headers: {\n            \"Content-Type\": \"application/json\"\n        },\n        body: JSON.stringify({\n            roomName: roomName,\n            participantName: participantName\n        })\n    });\n\n    if (!response.ok) {\n        const error = await response.json();\n        throw new Error(`Failed to get token: ${error.errorMessage}`);\n    }\n\n    const data = await response.json();\n    return data.token;\n}\n</code></pre> <p>This function sends a POST request using <code>fetch()</code> to the application server's <code>/token</code> endpoint. The request body contains the room name and participant name. The server responds with a token that is used to connect to the room.</p> </li> <li> <p>It connects to the room using the LiveKit URL and the token.</p> </li> <li>It publishes the camera and microphone tracks to the room using <code>room.localParticipant.enableCameraAndMicrophone()</code>, which asks the user for permission to access their camera and microphone at the same time. The local video track is then stored in the <code>localTrack</code> variable.</li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/application-client/react/#displaying-video-and-audio-tracks","title":"Displaying Video and Audio Tracks","text":"<p>In order to display participants' video and audio tracks, the main component integrates the <code>VideoComponent</code> and <code>AudioComponent</code>.</p> App.tsx<pre><code>&lt;div id=\"layout-container\"&gt;\n    {localTrack &amp;&amp; (\n        &lt;VideoComponent track={localTrack} participantIdentity={participantName} local={true} /&gt;\n    )}\n    {remoteTracks.map((remoteTrack) =&gt;\n        remoteTrack.trackPublication.kind === \"video\" ? (\n            &lt;VideoComponent\n                key={remoteTrack.trackPublication.trackSid}\n                track={remoteTrack.trackPublication.videoTrack!}\n                participantIdentity={remoteTrack.participantIdentity}\n            /&gt;\n        ) : (\n            &lt;AudioComponent\n                key={remoteTrack.trackPublication.trackSid}\n                track={remoteTrack.trackPublication.audioTrack!}\n            /&gt;\n        )\n    )}\n&lt;/div&gt;\n</code></pre> <p>This code snippet does the following:</p> <ul> <li> <p>If the property <code>localTrack</code> is defined, we display the local video track using the <code>VideoComponent</code>. The <code>local</code> property is set to <code>true</code> to indicate that the video track belongs to the local participant.</p> <p>Info</p> <p>The audio track is not displayed for the local participant because there is no need to hear one's own audio.</p> </li> <li> <p>Then, we iterate over the <code>remoteTracks</code> array and, for each remote track, we create a <code>VideoComponent</code> or an <code>AudioComponent</code> depending on the track's kind (video or audio). The <code>participantIdentity</code> property is set to the participant's identity, and the <code>track</code> property is set to the video or audio track.</p> </li> </ul> <p>Let's see now the code of the <code>VideoComponent.txs</code> file:</p> VideoComponent.tsx<pre><code>interface VideoComponentProps {\n    track: LocalVideoTrack | RemoteVideoTrack; // (1)!\n    participantIdentity: string; // (2)!\n    local?: boolean; // (3)!\n}\n\nfunction VideoComponent({ track, participantIdentity, local = false }: VideoComponentProps) {\n    const videoElement = useRef&lt;HTMLVideoElement | null&gt;(null); // (4)!\n\n    useEffect(() =&gt; {\n        if (videoElement.current) {\n            track.attach(videoElement.current); // (5)!\n        }\n\n        return () =&gt; {\n            track.detach(); // (6)!\n        };\n    }, [track]);\n\n    return (\n        &lt;div id={\"camera-\" + participantIdentity} className=\"video-container\"&gt;\n            &lt;div className=\"participant-data\"&gt;\n                &lt;p&gt;{participantIdentity + (local ? \" (You)\" : \"\")}&lt;/p&gt;\n            &lt;/div&gt;\n            &lt;video ref={videoElement} id={track.sid}&gt;&lt;/video&gt;\n        &lt;/div&gt;\n    );\n}\n</code></pre> <ol> <li>The video track object, which can be a <code>LocalVideoTrack</code> or a <code>RemoteVideoTrack</code>.</li> <li>The participant identity associated with the video track.</li> <li>A boolean flag that indicates whether the video track belongs to the local participant.</li> <li>The reference to the video element in the HTML template.</li> <li>Attach the video track to the video element when the component is mounted.</li> <li>Detach the video track when the component is unmounted.</li> </ol> <p>The <code>VideoComponent</code> does the following:</p> <ul> <li> <p>It defines the properties <code>track</code>, <code>participantIdentity</code>, and <code>local</code> as props of the component:</p> <ul> <li><code>track</code>: The video track object, which can be a <code>LocalVideoTrack</code> or a <code>RemoteVideoTrack</code>.</li> <li><code>participantIdentity</code>: The participant identity associated with the video track.</li> <li><code>local</code>: A boolean flag that indicates whether the video track belongs to the local participant. This flag is set to <code>false</code> by default.</li> </ul> </li> <li> <p>It creates a reference to the video element in the HTML template.</p> </li> <li>It attaches the video track to the video element when the component is mounted.</li> <li>It detaches the video track when the component is unmounted.</li> </ul> <p>Finally, let's see the code of the <code>AudioComponent.tsx</code> file:</p> AudioComponent.tsx<pre><code>interface AudioComponentProps {\n    track: LocalAudioTrack | RemoteAudioTrack; // (1)!\n}\n\nfunction AudioComponent({ track }: AudioComponentProps) {\n    const audioElement = useRef&lt;HTMLAudioElement | null&gt;(null); // (2)!\n\n    useEffect(() =&gt; {\n        if (audioElement.current) {\n            track.attach(audioElement.current); // (3)!\n        }\n\n        return () =&gt; {\n            track.detach(); // (4)!\n        };\n    }, [track]);\n\n    return &lt;audio ref={audioElement} id={track.sid} /&gt;;\n}\n</code></pre> <ol> <li>The audio track object, which can be a <code>LocalAudioTrack</code> or a <code>RemoteAudioTrack</code>, although in this case, it will always be a <code>RemoteAudioTrack</code>.</li> <li>The reference to the audio element in the HTML template.</li> <li>Attach the audio track to the audio element when the component is mounted.</li> <li>Detach the audio track when the component is unmounted.</li> </ol> <p>The <code>AudioComponent</code> is similar to the <code>VideoComponent</code> but is used to display audio tracks. It defines the <code>track</code> property as a prop for the component and creates a reference to the audio element in the HTML template. The audio track is attached to the audio element when the component is mounted and detached when the component is unmounted.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/react/#leaving-the-room","title":"Leaving the Room","text":"<p>When the user wants to leave the room, they can click the <code>Leave Room</code> button. This action calls the <code>leaveRoom()</code> function:</p> App.tsx<pre><code>async function leaveRoom() {\n    // Leave the room by calling 'disconnect' method over the Room object\n    await room?.disconnect(); // (1)!\n\n    // Reset the state\n    setRoom(undefined); // (2)!\n    setLocalTrack(undefined);\n    setRemoteTracks([]);\n}\n</code></pre> <ol> <li>Disconnect the user from the room.</li> <li>Reset all variables to their initial state.</li> </ol> <p>The <code>leaveRoom()</code> function performs the following actions:</p> <ul> <li>It disconnects the user from the room by calling the <code>disconnect()</code> method on the <code>Room</code> object.</li> <li>It resets all variables to their initial state.</li> </ul>","tags":["Platform"]},{"location":"docs/tutorials/application-client/vue/","title":"Vue Tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-client/vue/#vue-tutorial","title":"Vue Tutorial","text":"<p>Source code </p> <p>This tutorial is a simple video-call application built with Vue that allows:</p> <ul> <li>Joining a video call room by requesting a token from any application server.</li> <li>Publishing your camera and microphone.</li> <li>Subscribing to all other participants' video and audio tracks automatically.</li> <li>Leaving the video call room at any time.</li> </ul> <p>It uses the LiveKit JS SDK  to connect to the LiveKit server and interact with the video call room.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/vue/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-client/vue/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/vue/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/application-client/vue/#3-run-a-server-application","title":"3. Run a server application","text":"Node.js Go Ruby Java Python Rust PHP .NET <p>To run this server application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/node\n</code></pre></li> <li>Install dependencies <pre><code>npm install\n</code></pre></li> <li>Run the application <pre><code>npm start\n</code></pre></li> </ol> <p>For more information, check the Node.js tutorial.</p> <p>To run this server application, you need Go  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/go\n</code></pre></li> <li>Run the application <pre><code>go run main.go\n</code></pre></li> </ol> <p>For more information, check the Go tutorial.</p> <p>To run this server application, you need Ruby  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/ruby\n</code></pre></li> <li>Install dependencies <pre><code>bundle install\n</code></pre></li> <li>Run the application <pre><code>ruby app.rb\n</code></pre></li> </ol> <p>For more information, check the Ruby tutorial.</p> <p>To run this server application, you need Java  and Maven  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/java\n</code></pre></li> <li>Run the application <pre><code>mvn spring-boot:run\n</code></pre></li> </ol> <p>For more information, check the Java tutorial.</p> <p>To run this server application, you need Python 3  installed on your device.</p> <ol> <li> <p>Navigate into the server directory</p> <pre><code>cd openvidu-livekit-tutorials/application-server/python\n</code></pre> </li> <li> <p>Create a python virtual environment</p> <pre><code>python -m venv venv\n</code></pre> </li> <li> <p>Activate the virtual environment</p>  Windows macOS Linux <pre><code>.\\venv\\Scripts\\activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> </li> <li> <p>Install dependencies</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the application</p> <pre><code>python app.py\n</code></pre> </li> </ol> <p>For more information, check the Python tutorial.</p> <p>To run this server application, you need Rust  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/rust\n</code></pre></li> <li>Run the application <pre><code>cargo run\n</code></pre></li> </ol> <p>For more information, check the Rust tutorial.</p> <p>To run this server application, you need PHP  and Composer  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/php\n</code></pre></li> <li>Install dependencies <pre><code>composer install\n</code></pre></li> <li>Run the application <pre><code>composer start\n</code></pre></li> </ol> <p>Warning</p> <p>LiveKit PHP SDK requires library BCMath . This is available out-of-the-box in PHP for Windows, but a manual installation might be necessary in other OS. Run <code>sudo apt install php-bcmath</code> or <code>sudo yum install php-bcmath</code></p> <p>For more information, check the PHP tutorial.</p> <p>To run this server application, you need .NET  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/dotnet\n</code></pre></li> <li>Run the application <pre><code>dotnet run\n</code></pre></li> </ol> <p>Warning</p> <p>This .NET server application needs the <code>LIVEKIT_API_SECRET</code> env variable to be at least 32 characters long. Make sure to update it here  and in your OpenVidu Server.</p> <p>For more information, check the .NET tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/vue/#4-run-the-client-application","title":"4. Run the client application","text":"<p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-vue\n</code></pre> </li> <li> <p>Install dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Run the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p> <p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/vue/#understanding-the-code","title":"Understanding the code","text":"<p>This Vue project has been generated using the Vue CLI tool. You may come across various configuration files and other items that are not essential for this tutorial. Our focus will be on the key files located within the <code>src/</code> directory:</p> <ul> <li> <p><code>App.vue</code>: This file defines the main application component along with its HTML template and styles. It is responsible for handling tasks such as joining a video call and managing the video calls themselves.</p> </li> <li> <p><code>VideoComponent.vue</code>: This file defines the <code>VideoComponent</code>. This component is responsible for displaying video tracks along with participant's data.</p> </li> <li><code>AudioComponent.vue</code>: This file defines the <code>AudioComponent</code>. This component is responsible for displaying audio tracks.</li> </ul> <p>To use the LiveKit JS SDK in a Vue application, you need to install the <code>livekit-client</code> package. This package provides the necessary classes and methods to interact with the LiveKit server. You can install it using the following command:</p> <pre><code>npm install livekit-client\n</code></pre> <p>Now let's see the code of the <code>App.vue</code> file:</p> App.vue<pre><code>type TrackInfo = {\n    // (1)!\n    trackPublication: RemoteTrackPublication;\n    participantIdentity: string;\n};\n\n// When running OpenVidu locally, leave these variables empty\n// For other deployment type, configure them with correct URLs depending on your deployment\nlet APPLICATION_SERVER_URL = \"\"; // (2)!\nlet LIVEKIT_URL = \"\"; // (3)!\nconfigureUrls();\n\nfunction configureUrls() {\n    // If APPLICATION_SERVER_URL is not configured, use default value from OpenVidu Local deployment\n    if (!APPLICATION_SERVER_URL) {\n        if (window.location.hostname === \"localhost\") {\n            APPLICATION_SERVER_URL = \"http://localhost:6080/\";\n        } else {\n            APPLICATION_SERVER_URL = \"https://\" + window.location.hostname + \":6443/\";\n        }\n    }\n\n    // If LIVEKIT_URL is not configured, use default value from OpenVidu Local deployment\n    if (!LIVEKIT_URL) {\n        if (window.location.hostname === \"localhost\") {\n            LIVEKIT_URL = \"ws://localhost:7880/\";\n        } else {\n            LIVEKIT_URL = \"wss://\" + window.location.hostname + \":7443/\";\n        }\n    }\n}\n\nconst room = ref&lt;Room&gt;(); // (4)!\nconst localTrack = ref&lt;LocalVideoTrack&gt;(); // (5)!\nconst remoteTracksMap: Ref&lt;Map&lt;string, TrackInfo&gt;&gt; = ref(new Map()); // (6)!\n\nlet participantName = ref(\"Participant\" + Math.floor(Math.random() * 100)); // (7)!\nlet roomName = ref(\"Test Room\"); // (8)!\n</code></pre> <ol> <li><code>TrackInfo</code> type, which groups a track publication with the participant's identity.</li> <li>The URL of the application server.</li> <li>The URL of the LiveKit server.</li> <li>The room object, which represents the video call room.</li> <li>The local video track, which represents the user's camera.</li> <li>Map that links track SIDs with <code>TrackInfo</code> objects. This map is used to store remote tracks and their associated participant identities.</li> <li>The participant's name.</li> <li>The room name.</li> </ol> <p>The <code>App.vue</code> file defines the following variables:</p> <ul> <li><code>APPLICATION_SERVER_URL</code>: The URL of the application server. This variable is used to make requests to the server to obtain a token for joining the video call room.</li> <li><code>LIVEKIT_URL</code>: The URL of the LiveKit server. This variable is used to connect to the LiveKit server and interact with the video call room.</li> <li><code>room</code>: The room object, which represents the video call room.</li> <li><code>localTrack</code>: The local video track, which represents the user's camera.</li> <li><code>remoteTracksMap</code>: A map that links track SIDs with <code>TrackInfo</code> objects. This map is used to store remote tracks and their associated participant identities.</li> <li><code>participantName</code>: The participant's name.</li> <li><code>roomName</code>: The room name.</li> </ul> <p>Configure the URLs</p> <p>When running OpenVidu locally, leave <code>APPLICATION_SERVER_URL</code> and <code>LIVEKIT_URL</code> variables empty. The function <code>configureUrls()</code> will automatically configure them with default values. However, for other deployment type, you should configure these variables with the correct URLs depending on your deployment.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/vue/#joining-a-room","title":"Joining a Room","text":"<p>After the user specifies their participant name and the name of the room they want to join, when they click the <code>Join</code> button, the <code>joinRoom()</code> function is called:</p> App.vue<pre><code>async function joinRoom() {\n    // Initialize a new Room object\n    room.value = new Room(); // (1)!\n\n    // Specify the actions when events take place in the room\n    // On every new Track received...\n    room.value.on(\n        RoomEvent.TrackSubscribed,\n        (_track: RemoteTrack, publication: RemoteTrackPublication, participant: RemoteParticipant) =&gt; {\n            // (2)!\n            remoteTracksMap.value.set(publication.trackSid, {\n                trackPublication: publication,\n                participantIdentity: participant.identity\n            });\n        }\n    );\n\n    // On every Track destroyed...\n    room.value.on(RoomEvent.TrackUnsubscribed, (_track: RemoteTrack, publication: RemoteTrackPublication) =&gt; {\n        // (3)!\n        remoteTracksMap.value.delete(publication.trackSid);\n    });\n\n    try {\n        // Get a token from your application server with the room name and participant name\n        const token = await getToken(roomName.value, participantName.value); // (4)!\n\n        // Connect to the room with the LiveKit URL and the token\n        await room.value.connect(LIVEKIT_URL, token); // (5)!\n\n        // Publish your camera and microphone\n        await room.value.localParticipant.enableCameraAndMicrophone(); // (6)!\n        localTrack.value = room.value.localParticipant.videoTrackPublications.values().next().value.videoTrack;\n    } catch (error: any) {\n        console.log(\"There was an error connecting to the room:\", error.message);\n        await leaveRoom();\n    }\n\n    // Add listener for beforeunload event to leave the room when the user closes the tab\n    window.addEventListener(\"beforeunload\", leaveRoom); // (7)!\n}\n</code></pre> <ol> <li>Initialize a new <code>Room</code> object.</li> <li>Event handling for when a new track is received in the room.</li> <li>Event handling for when a track is destroyed.</li> <li>Get a token from the application server with the room name and participant name from the form.</li> <li>Connect to the room with the LiveKit URL and the token.</li> <li>Publish your camera and microphone.</li> <li>Add a listener for the <code>beforeunload</code> event to leave the room when the user closes the tab.</li> </ol> <p>The <code>joinRoom()</code> function performs the following actions:</p> <ol> <li> <p>It creates a new <code>Room</code> object. This object represents the video call room.</p> <p>Info</p> <p>When the room object is defined, the HTML template is automatically updated hiding the \"Join room\" page and showing the \"Room\" layout.</p> </li> <li> <p>Event handling is configured for different scenarios within the room. These events are fired when new tracks are subscribed to and when existing tracks are unsubscribed.</p> <ul> <li> <p><code>RoomEvent.TrackSubscribed</code>: This event is triggered when a new track is received in the room. It manages the storage of the new track in the <code>remoteTracksMap</code>, which links track SIDs with <code>TrackInfo</code> objects containing the track publication and the participant's identity.</p> </li> <li> <p><code>RoomEvent.TrackUnsubscribed</code>: This event occurs when a track is destroyed, and it takes care of removing the track from the <code>remoteTracksMap</code>.</p> </li> </ul> <p>These event handlers are essential for managing the behavior of tracks within the video call. You can further extend the event handling as needed for your application.</p> <p>Take a look at all events</p> <p>You can take a look at all the events in the Livekit Documentation</p> </li> <li> <p>It requests a token from the application server using the room name and participant name. This is done by calling the <code>getToken()</code> function:</p> App.vue<pre><code>/**\n * --------------------------------------------\n * GETTING A TOKEN FROM YOUR APPLICATION SERVER\n * --------------------------------------------\n * The method below request the creation of a token to\n * your application server. This prevents the need to expose\n * your LiveKit API key and secret to the client side.\n *\n * In this sample code, there is no user control at all. Anybody could\n * access your application server endpoints. In a real production\n * environment, your application server must identify the user to allow\n * access to the endpoints.\n */\nasync function getToken(roomName: string, participantName: string) {\n    const response = await fetch(APPLICATION_SERVER_URL + \"token\", {\n        method: \"POST\",\n        headers: {\n            \"Content-Type\": \"application/json\"\n        },\n        body: JSON.stringify({\n            roomName,\n            participantName\n        })\n    });\n\n    if (!response.ok) {\n        const error = await response.json();\n        throw new Error(`Failed to get token: ${error.errorMessage}`);\n    }\n\n    const data = await response.json();\n    return data.token;\n}\n</code></pre> <p>This function sends a POST request using <code>fetch()</code> to the application server's <code>/token</code> endpoint. The request body contains the room name and participant name. The server responds with a token that is used to connect to the room.</p> </li> <li> <p>It connects to the room using the LiveKit URL and the token.</p> </li> <li>It publishes the camera and microphone tracks to the room using <code>room.localParticipant.enableCameraAndMicrophone()</code>, which asks the user for permission to access their camera and microphone at the same time. The local video track is then stored in the <code>localTrack</code> variable.</li> <li>It adds a listener for the <code>beforeunload</code> event to leave the room when the user closes the tab.</li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/application-client/vue/#displaying-video-and-audio-tracks","title":"Displaying Video and Audio Tracks","text":"<p>In order to display participants' video and audio tracks, the main component integrates the <code>VideoComponent</code> and <code>AudioComponent</code>.</p> App.vue<pre><code>&lt;div id=\"layout-container\"&gt;\n    &lt;VideoComponent v-if=\"localTrack\" :track=\"localTrack\" :participantIdentity=\"participantName\" :local=\"true\" /&gt;\n    &lt;template v-for=\"remoteTrack of remoteTracksMap.values()\" :key=\"remoteTrack.trackPublication.trackSid\"&gt;\n        &lt;VideoComponent\n            v-if=\"remoteTrack.trackPublication.kind === 'video'\"\n            :track=\"remoteTrack.trackPublication.videoTrack!\"\n            :participantIdentity=\"remoteTrack.participantIdentity\"\n        /&gt;\n        &lt;AudioComponent v-else :track=\"remoteTrack.trackPublication.audioTrack!\" hidden /&gt;\n    &lt;/template&gt;\n&lt;/div&gt;\n</code></pre> <p>This code snippet does the following:</p> <ul> <li> <p>We use the <code>v-if</code> directive to conditionally display the local video track using the <code>VideoComponent</code>. The <code>local</code> property is set to <code>true</code> to indicate that the video track belongs to the local participant.</p> <p>Info</p> <p>The audio track is not displayed for the local participant because there is no need to hear one's own audio.</p> </li> <li> <p>Then, we use the <code>v-for</code> directive to iterate over the <code>remoteTracksMap</code>. For each remote track, we create a <code>VideoComponent</code> or an <code>AudioComponent</code> depending on the track's kind (video or audio). The <code>participantIdentity</code> property is set to the participant's identity, and the <code>track</code> property is set to the video or audio track. The <code>hidden</code> attribute is added to the <code>AudioComponent</code> to hide the audio tracks from the layout.</p> </li> </ul> <p>Let's see now the code of the <code>VideoComponent.vue</code> file:</p> VideoComponent.vue<pre><code>const props = withDefaults(\n    defineProps&lt;{\n        track: LocalVideoTrack | RemoteVideoTrack; // (1)!\n        participantIdentity: string; // (2)!\n        local?: boolean; // (3)!\n    }&gt;(),\n    {\n        local: false\n    }\n);\n\nconst videoElement = ref&lt;HTMLMediaElement | null&gt;(null); // (4)!\n\nonMounted(() =&gt; {\n    if (videoElement.value) {\n        props.track.attach(videoElement.value); // (5)!\n    }\n});\n\nonUnmounted(() =&gt; {\n    props.track.detach(); // (6)!\n});\n</code></pre> <ol> <li>The video track object, which can be a <code>LocalVideoTrack</code> or a <code>RemoteVideoTrack</code>.</li> <li>The participant identity associated with the video track.</li> <li>A boolean flag that indicates whether the video track belongs to the local participant.</li> <li>The reference to the video element in the HTML template.</li> <li>Attach the video track to the video element when the component is mounted.</li> <li>Detach the video track when the component is unmounted.</li> </ol> <p>The <code>VideoComponent</code> does the following:</p> <ul> <li> <p>It defines the properties <code>track</code>, <code>participantIdentity</code>, and <code>local</code> using the <code>defineProps()</code> function:</p> <ul> <li><code>track</code>: The video track object, which can be a <code>LocalVideoTrack</code> or a <code>RemoteVideoTrack</code>.</li> <li><code>participantIdentity</code>: The participant identity associated with the video track.</li> <li><code>local</code>: A boolean flag that indicates whether the video track belongs to the local participant. This flag is set to <code>false</code> by default.</li> </ul> </li> <li> <p>It creates a reference to the video element in the HTML template.</p> </li> <li>It attaches the video track to the video element when the component is mounted.</li> <li>It detaches the video track when the component is unmounted.</li> </ul> <p>Finally, let's see the code of the <code>AudioComponent.vue</code> file:</p> AudioComponent.vue<pre><code>const props = defineProps&lt;{\n    track: LocalAudioTrack | RemoteAudioTrack; // (1)!\n}&gt;();\nconst audioElement = ref&lt;HTMLMediaElement | null&gt;(null); // (2)!\n\nonMounted(() =&gt; {\n    if (audioElement.value) {\n        props.track.attach(audioElement.value); // (3)!\n    }\n});\n\nonUnmounted(() =&gt; {\n    props.track.detach(); // (4)!\n});\n</code></pre> <ol> <li>The audio track object, which can be a <code>LocalAudioTrack</code> or a <code>RemoteAudioTrack</code>, although in this case, it will always be a <code>RemoteAudioTrack</code>.</li> <li>The reference to the audio element in the HTML template.</li> <li>Attach the audio track to the audio element when the component is mounted.</li> <li>Detach the audio track when the component is unmounted.</li> </ol> <p>The <code>AudioComponent</code> is similar to the <code>VideoComponent</code> but is used to display audio tracks. It defines the <code>track</code> property using the <code>defineProps()</code> function and creates a reference to the audio element in the HTML template. The audio track is attached to the audio element when the component is mounted and detached when the component is unmounted.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-client/vue/#leaving-the-room","title":"Leaving the Room","text":"<p>When the user wants to leave the room, they can click the <code>Leave Room</code> button. This action calls the <code>leaveRoom()</code> function:</p> App.vue<pre><code>async function leaveRoom() {\n    // Leave the room by calling 'disconnect' method over the Room object\n    await room.value?.disconnect(); // (1)!\n\n    // Empty all variables\n    room.value = undefined; // (2)!\n    localTrack.value = undefined;\n    remoteTracksMap.value.clear();\n\n    window.removeEventListener(\"beforeunload\", leaveRoom); // (3)!\n}\n\nonUnmounted(() =&gt; {\n    // (4)!\n    // On component unmount, leave the room\n    leaveRoom();\n});\n</code></pre> <ol> <li>Disconnect the user from the room.</li> <li>Reset all variables to their initial state.</li> <li>Remove the <code>beforeunload</code> event listener.</li> <li>Call the <code>leaveRoom()</code> function when the component is unmounted.</li> </ol> <p>The <code>leaveRoom()</code> function performs the following actions:</p> <ul> <li>It disconnects the user from the room by calling the <code>disconnect()</code> method on the <code>Room</code> object.</li> <li>It resets all variables to their initial state.</li> <li>It removes the <code>beforeunload</code> event listener.</li> </ul> <p>The <code>leaveRoom()</code> function is also called when the component is unmounted using the <code>onUnmounted()</code> lifecycle hook. This ensures that the user leaves the room when the component is no longer needed.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/","title":"Application Server Tutorials","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-server/#application-server-tutorials","title":"Application Server Tutorials","text":"<p>Every application server below has two specific purposes: </p> <ul> <li>Generate LiveKit tokens on demand for any application client.</li> <li>Receive LiveKit webhook events .</li> </ul> <p>To do so they all define two REST endpoints:</p> <ul> <li><code>/token</code>: takes a room and participant name and returns a token.</li> <li><code>/webhook</code>: for receiving webhook events from LiveKit Server.</li> </ul> <p>They use the proper LiveKit Server SDK  for their language, if available.</p> <p> Node.js</p> <p> Go</p> <p> Ruby</p> <p> Java</p> <p> Python</p> <p> Rust</p> <p> PHP</p> <p> .NET</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/dotnet/","title":".NET Server Tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-server/dotnet/#net-server-tutorial","title":".NET Server Tutorial","text":"<p>Source code </p> <p>This is a minimal server application built for .NET with ASP.NET Core Minimal APIs  that allows:</p> <ul> <li>Generating LiveKit tokens on demand for any application client.</li> <li>Receiving LiveKit webhook events .</li> </ul> <p>It internally uses the LiveKit .NET SDK .</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/dotnet/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-server/dotnet/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/dotnet/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/application-server/dotnet/#3-run-the-server-application","title":"3. Run the server application","text":"<p>To run this server application, you need .NET  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/dotnet\n</code></pre></li> <li>Run the application <pre><code>dotnet run\n</code></pre></li> </ol> <p>Warning</p> <p>This .NET server application needs the <code>LIVEKIT_API_SECRET</code> env variable to be at least 32 characters long. Make sure to update it here  and in your OpenVidu Server.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/dotnet/#4-run-a-client-application-to-test-against-this-server","title":"4. Run a client application to test against this server","text":"JavaScript React Angular Vue Electron Ionic Android iOS <p>To run the client application tutorial, you need an HTTP web server installed on your development computer. A great option is http-server . You can install it via NPM :</p> <pre><code>npm install -g http-server\n</code></pre> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-js\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>http-server -p 5080 ./src\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the JavaScript tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-react\n</code></pre> </li> <li> <p>Install dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Run the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the React tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-angular\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the Angular tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-vue\n</code></pre> </li> <li> <p>Install dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Run the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the Vue tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-electron\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Run the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>The application will seamlessly initiate as a native desktop program, adapting itself to the specific operating system you are using. Once the application is open, you should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Running your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the Electron tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-ionic\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <p>You have two options for running the client application: browser-based or mobile device-based:</p>  Browser Mobile <p>To run the application in a browser, you will need to start the Ionic server. To do so, run the following command:</p> <pre><code>npm start\n</code></pre> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p>Mobile appearance</p> <p>To show the app with a mobile device appearance, open the dev tools in your browser and find the button to adapt the viewport to a mobile device aspect ratio. You may also choose predefined types of devices to see the behavior of your app in different resolutions.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Running the tutorial on a mobile device presents additional challenges compared to running it in a browser, mainly due to the application being launched on a different device, such as an Android smartphone or iPhone, rather than our computer. To overcome these challenges, the following steps need to be taken:</p> <ol> <li> <p>Localhost limitations:</p> <p>The usage of <code>localhost</code> in our Ionic app is restricted, preventing seamless communication between the application client and the server.</p> </li> <li> <p>Serve over local network:</p> <p>The application must be served over our local network to enable communication between the device and the server.</p> </li> <li> <p>Secure connection requirement for WebRTC API:</p> <p>The WebRTC API demands a secure connection for functionality outside of localhost, necessitating the serving of the application over HTTPS.</p> </li> </ol> <p>If you run OpenVidu locally you don't need to worry about this. OpenVidu will handle all of the above requirements for you. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Now, let's explore how to run the application on a mobile device:</p> <p>Requirements</p> <p>Before running the application on a mobile device, make sure that the device is connected to the same network as your PC and the mobile is connected to the PC via USB or Wi-Fi.</p>  Android device iOS device <pre><code>npm run android\n</code></pre> <p>You will need Ruby  and Cocoapods  installed in your computer.</p> <p>The app must be signed with a development team. To do so, open the project in Xcode and select a development team in the Signing &amp; Capabilities editor.</p> <pre><code>npm run ios\n</code></pre> <p>The script will ask you for the device you want to run the application on. You should select the real device you have connected to your computer.</p> <p>Once the mobile device has been selected, the script will launch the application on the device and you will see a screen like this:</p> <p></p><p></p><p></p> <p>This screen allows you to configure the URLs of the application server and the LiveKit server. You need to set them up for requesting tokens to your application server and connecting to the LiveKit server.</p> <p>Once you have configured the URLs, you can join a video call room by providing a room name and a user name. After joining the room, you will be able to see your own video and audio tracks, as well as the video and audio tracks of the other participants in the room.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> </li> </ol> <p>For more information, check the Ionic tutorial.</p> <p>To run the client application tutorial, you need Android Studio  installed on your development computer.</p> <ol> <li> <p>Open Android Studio and import the project located at <code>openvidu-livekit-tutorials/application-client/openvidu-android</code>.</p> </li> <li> <p>Run the application in an emulator or a physical device by clicking the \"Run\" button in Android Studio. Check out the official documentation  for further information.</p> </li> </ol> <p>The application will initiate as a native Android program. Once the application is opened, you should see a screen like this:</p> <p></p><p></p><p></p> <p>This screen allows you to configure the URLs of the application server and the LiveKit server. You need to set them up for requesting tokens to your application server and connecting to the LiveKit server.</p> <p>Connecting real Android device to application server running in you local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client in a real Android device and be able to reach the application server very easily without worrying about SSL certificates if they are both running in the same local network. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Once you have configured the URLs, you can join a video call room by providing a room name and a user name. After joining the room, you will be able to see your own video and audio tracks, as well as the video and audio tracks of the other participants in the room.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>For more information, check the Android tutorial.</p> <p>To run the client application tutorial, you need Xcode  installed on your MacOS.</p> <ol> <li> <p>Launch Xcode and open the <code>OpenViduIOS.xcodeproj</code> that you can find under <code>openvidu-livekit-tutorials/application-client/openvidu-ios</code>.</p> </li> <li> <p>Run the application in an emulator or a physical device by clicking on the menu Product &gt; Run or by \u2318R.</p> </li> </ol> <p>Emulator limitations</p> <p>Publishing the camera track is not supported by iOS Simulator.</p> <p>If you encounter code signing issues, make sure you change the Team and bundle id from the previous step.</p> <p>The application will initiate as a native iOS application. Once the app is opened, you should see a screen like this:</p> <p></p><p></p><p></p> <p>This screen allows you to configure the URLs of the application server and the LiveKit server. You need to set them up for requesting tokens to your application server and connecting to the LiveKit server.</p> <p>Connecting real iOS device to application server running in you local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client in a real iOS device and be able to reach the application server very easily without worrying about SSL certificates if they are both running in the same local network. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Once you have configured the URLs, you can join a video call room by providing a room name and a user name. After joining the room, you will be able to see your own video and audio tracks, as well as the video and audio tracks of the other participants in the room.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>For more information, check the iOS tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/dotnet/#understanding-the-code","title":"Understanding the code","text":"<p>The application is a simple ASP.NET Core Minimal APIs  app with a single file <code>Program.cs</code> that exports two endpoints:</p> <ul> <li><code>/token</code> : generate a token for a given Room name and Participant name.</li> <li><code>/livekit/webhook</code> : receive LiveKit webhook events.</li> </ul> <p>Let's see the code <code>Program.cs</code> file:</p> Program.cs<pre><code>using System.Text.Json;\nusing Livekit.Server.Sdk.Dotnet; // (1)!\n\nvar builder = WebApplication.CreateBuilder(args); // (2)!\nvar MyAllowSpecificOrigins = \"_myAllowSpecificOrigins\"; // (3)!\n\nIConfiguration config = new ConfigurationBuilder() // (4)!\n    .SetBasePath(Directory.GetCurrentDirectory())\n    .AddJsonFile(\"appsettings.json\")\n    .AddEnvironmentVariables()\n    .Build();\n\n// Load env variables\nvar SERVER_PORT = config.GetValue&lt;int&gt;(\"SERVER_PORT\"); // (5)!\nvar LIVEKIT_API_KEY = config.GetValue&lt;string&gt;(\"LIVEKIT_API_KEY\"); // (6)!\nvar LIVEKIT_API_SECRET = config.GetValue&lt;string&gt;(\"LIVEKIT_API_SECRET\"); // (7)!\n\n// Enable CORS support\nbuilder.Services.AddCors(options =&gt; // (8)!\n{\n    options.AddPolicy(\n        name: MyAllowSpecificOrigins,\n        builder =&gt;\n        {\n            builder.WithOrigins(\"*\").AllowAnyHeader();\n        }\n    );\n});\n\nbuilder.WebHost.UseKestrel(serverOptions =&gt; // (9)!\n{\n    serverOptions.ListenAnyIP(SERVER_PORT);\n});\n\nvar app = builder.Build(); // (10)!\napp.UseCors(MyAllowSpecificOrigins);\n</code></pre> <ol> <li>Import the LiveKit .NET SDK .</li> <li>A <code>WebApplicationBuilder</code> instance to build the application.</li> <li>The name of the CORS policy to be used in the application.</li> <li>A <code>IConfiguration</code> instance to load the configuration from the <code>appsettings.json</code> file, including the required environment variables.</li> <li>The port where the application will be listening.</li> <li>The API key of LiveKit Server.</li> <li>The API secret of LiveKit Server.</li> <li>Configure CORS support.</li> <li>Configure the port.</li> <li>Build the application and enable CORS support.</li> </ol> <p>The <code>Program.cs</code> file imports the required dependencies and loads the necessary environment variables (defined in <code>appsettings.json</code> file):</p> <ul> <li><code>SERVER_PORT</code>: the port where the application will be listening.</li> <li><code>LIVEKIT_API_KEY</code>: the API key of LiveKit Server.</li> <li><code>LIVEKIT_API_SECRET</code>: the API secret of LiveKit Server.</li> </ul> <p>Finally the application enables CORS support and the port where the application will be listening.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/dotnet/#create-token","title":"Create token","text":"<p>The endpoint <code>/token</code> accepts <code>POST</code> requests with a payload of type <code>application/json</code>, containing the following fields:</p> <ul> <li><code>roomName</code>: the name of the Room where the user wants to connect.</li> <li><code>participantName</code>: the name of the participant that wants to connect to the Room.</li> </ul> Program.cs<pre><code>app.MapPost(\n    \"/token\",\n    async (HttpRequest request) =&gt;\n    {\n        var body = new StreamReader(request.Body); // (1)!\n        string postData = await body.ReadToEndAsync();\n        Dictionary&lt;string, dynamic&gt; bodyParams =\n            JsonSerializer.Deserialize&lt;Dictionary&lt;string, dynamic&gt;&gt;(postData)\n            ?? new Dictionary&lt;string, dynamic&gt;();\n\n        if (\n            bodyParams.TryGetValue(\"roomName\", out var roomName)\n            &amp;&amp; bodyParams.TryGetValue(\"participantName\", out var participantName)\n        )\n        {\n            var token = new AccessToken(LIVEKIT_API_KEY, LIVEKIT_API_SECRET) // (2)!\n                .WithIdentity(participantName.ToString()) // (3)!\n                .WithName(participantName.ToString())\n                .WithGrants(new VideoGrants{ RoomJoin = true, Room = roomName.ToString() }); // (4)!\n\n            var jwt = token.ToJwt(); // (5)!\n            return Results.Json(new { token = jwt }); // (6)!\n        }\n        else\n        {\n            return Results.BadRequest(\n                new { errorMessage = \"roomName and participantName are required\" } // (7)!\n            );\n        }\n    }\n);\n</code></pre> <ol> <li>The endpoint obtains a Dictionary from the body request, and check if fields <code>roomName</code> and <code>participantName</code> are available.</li> <li>A new <code>AccessToken</code> is created providing the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code>.</li> <li>We set participant's name and identity in the AccessToken.</li> <li>We set the video grants in the AccessToken. <code>RoomJoin</code> allows the user to join a room and <code>RoomName</code> determines the specific room. Check out all Video Grants .</li> <li>Obtain the JWT string from the AccessToken.</li> <li>Return the token to the client.</li> <li>Return a <code>400</code> error if required fields are not available.</li> </ol> <p>The endpoint obtains a Dictionary from the body request, and check if fields <code>roomName</code> and <code>participantName</code> are available. If not, it returns a <code>400</code> error. If required fields are available, a new <code>AccessToken</code> is created with the proper participant's identity, name and video grants. The <code>RoomJoin</code> grant allows the user to join a room and the <code>Room</code> grant determines the specific room. Check out all Video Grants .</p> <p>Finally, the returned token is sent back to the client.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/dotnet/#receive-webhook","title":"Receive webhook","text":"<p>The endpoint <code>/livekit/webhook</code> accepts <code>POST</code> requests with a payload of type <code>application/webhook+json</code>. This is the endpoint where LiveKit Server will send webhook events .</p> Program.cs<pre><code>app.MapPost(\n    \"/livekit/webhook\",\n    async (HttpRequest request) =&gt;\n    {\n        var webhookReceiver = new WebhookReceiver(LIVEKIT_API_KEY, LIVEKIT_API_SECRET); // (1)!\n        try\n        {\n            StreamReader body = new StreamReader(request.Body); // (2)!\n            string postData = await body.ReadToEndAsync();\n            string authHeader =\n                request.Headers[\"Authorization\"].FirstOrDefault() // (3)!\n                ?? throw new Exception(\"Authorization header is missing\");\n\n            WebhookEvent webhookEvent = webhookReceiver.Receive(postData, authHeader); // (4)!\n\n            Console.Out.WriteLine(webhookEvent); // (5)!\n\n            return Results.Ok(); // (6)!\n        }\n        catch (Exception e)\n        {\n            Console.Error.WriteLine(\"Error validating webhook event: \" + e.Message); // (7)!\n            return Results.Unauthorized();\n        }\n    }\n);\n</code></pre> <ol> <li>Initialize the WebhookReceiver using the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code>. It will help validating and decoding incoming webhook events .</li> <li>The raw string body of the request contains the webhook event.</li> <li>The <code>Authorization</code> header is required to validate the webhook event.</li> <li>Obtain the <code>WebhookEvent</code> object using the <code>WebhookReceiver#Receive</code> method. It takes the raw body as a String and the Authorization header of the request.</li> <li>Consume the event as you whish.</li> <li>Return a response to LiveKit Server to let it know that the webhook was received correctly.</li> <li>You can handle any exception triggered by the validation process.</li> </ol> <p>We first initialize a <code>WebhookReceiver</code> object using the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code>.</p> <p>Then we need the raw body as a String and the <code>Authorization</code> header of the request. With them we obtain a <code>WebhookEvent</code> object calling method <code>WebhookReceiver#Receive</code>. If everything is correct, you can do whatever you want with the event (in this case, we just log it).</p> <p>Remember to return a <code>200</code> OK response at the end to let LiveKit Server know that the webhook was received correctly.</p> <p>Configure Webhooks</p> <p>If you are using a production deployment, remember to configure the webhook URL to point to your local application server as explained in the Send Webhooks to a Local Application Server section.</p> <p></p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/go/","title":"Go Server Tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-server/go/#go-server-tutorial","title":"Go Server Tutorial","text":"<p>Source code </p> <p>This is a minimal server application built for Go with Gin  that allows:</p> <ul> <li>Generating LiveKit tokens on demand for any application client.</li> <li>Receiving LiveKit webhook events .</li> </ul> <p>It internally uses the LiveKit Go SDK .</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/go/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-server/go/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/go/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/application-server/go/#3-run-the-server-application","title":"3. Run the server application","text":"<p>To run this server application, you need Go  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/go\n</code></pre></li> <li>Run the application <pre><code>go run main.go\n</code></pre></li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/application-server/go/#4-run-a-client-application-to-test-against-this-server","title":"4. Run a client application to test against this server","text":"JavaScript React Angular Vue Electron Ionic Android iOS <p>To run the client application tutorial, you need an HTTP web server installed on your development computer. A great option is http-server . You can install it via NPM :</p> <pre><code>npm install -g http-server\n</code></pre> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-js\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>http-server -p 5080 ./src\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the JavaScript tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-react\n</code></pre> </li> <li> <p>Install dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Run the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the React tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-angular\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the Angular tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-vue\n</code></pre> </li> <li> <p>Install dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Run the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the Vue tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-electron\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Run the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>The application will seamlessly initiate as a native desktop program, adapting itself to the specific operating system you are using. Once the application is open, you should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Running your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the Electron tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-ionic\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <p>You have two options for running the client application: browser-based or mobile device-based:</p>  Browser Mobile <p>To run the application in a browser, you will need to start the Ionic server. To do so, run the following command:</p> <pre><code>npm start\n</code></pre> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p>Mobile appearance</p> <p>To show the app with a mobile device appearance, open the dev tools in your browser and find the button to adapt the viewport to a mobile device aspect ratio. You may also choose predefined types of devices to see the behavior of your app in different resolutions.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Running the tutorial on a mobile device presents additional challenges compared to running it in a browser, mainly due to the application being launched on a different device, such as an Android smartphone or iPhone, rather than our computer. To overcome these challenges, the following steps need to be taken:</p> <ol> <li> <p>Localhost limitations:</p> <p>The usage of <code>localhost</code> in our Ionic app is restricted, preventing seamless communication between the application client and the server.</p> </li> <li> <p>Serve over local network:</p> <p>The application must be served over our local network to enable communication between the device and the server.</p> </li> <li> <p>Secure connection requirement for WebRTC API:</p> <p>The WebRTC API demands a secure connection for functionality outside of localhost, necessitating the serving of the application over HTTPS.</p> </li> </ol> <p>If you run OpenVidu locally you don't need to worry about this. OpenVidu will handle all of the above requirements for you. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Now, let's explore how to run the application on a mobile device:</p> <p>Requirements</p> <p>Before running the application on a mobile device, make sure that the device is connected to the same network as your PC and the mobile is connected to the PC via USB or Wi-Fi.</p>  Android device iOS device <pre><code>npm run android\n</code></pre> <p>You will need Ruby  and Cocoapods  installed in your computer.</p> <p>The app must be signed with a development team. To do so, open the project in Xcode and select a development team in the Signing &amp; Capabilities editor.</p> <pre><code>npm run ios\n</code></pre> <p>The script will ask you for the device you want to run the application on. You should select the real device you have connected to your computer.</p> <p>Once the mobile device has been selected, the script will launch the application on the device and you will see a screen like this:</p> <p></p><p></p><p></p> <p>This screen allows you to configure the URLs of the application server and the LiveKit server. You need to set them up for requesting tokens to your application server and connecting to the LiveKit server.</p> <p>Once you have configured the URLs, you can join a video call room by providing a room name and a user name. After joining the room, you will be able to see your own video and audio tracks, as well as the video and audio tracks of the other participants in the room.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> </li> </ol> <p>For more information, check the Ionic tutorial.</p> <p>To run the client application tutorial, you need Android Studio  installed on your development computer.</p> <ol> <li> <p>Open Android Studio and import the project located at <code>openvidu-livekit-tutorials/application-client/openvidu-android</code>.</p> </li> <li> <p>Run the application in an emulator or a physical device by clicking the \"Run\" button in Android Studio. Check out the official documentation  for further information.</p> </li> </ol> <p>The application will initiate as a native Android program. Once the application is opened, you should see a screen like this:</p> <p></p><p></p><p></p> <p>This screen allows you to configure the URLs of the application server and the LiveKit server. You need to set them up for requesting tokens to your application server and connecting to the LiveKit server.</p> <p>Connecting real Android device to application server running in you local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client in a real Android device and be able to reach the application server very easily without worrying about SSL certificates if they are both running in the same local network. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Once you have configured the URLs, you can join a video call room by providing a room name and a user name. After joining the room, you will be able to see your own video and audio tracks, as well as the video and audio tracks of the other participants in the room.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>For more information, check the Android tutorial.</p> <p>To run the client application tutorial, you need Xcode  installed on your MacOS.</p> <ol> <li> <p>Launch Xcode and open the <code>OpenViduIOS.xcodeproj</code> that you can find under <code>openvidu-livekit-tutorials/application-client/openvidu-ios</code>.</p> </li> <li> <p>Run the application in an emulator or a physical device by clicking on the menu Product &gt; Run or by \u2318R.</p> </li> </ol> <p>Emulator limitations</p> <p>Publishing the camera track is not supported by iOS Simulator.</p> <p>If you encounter code signing issues, make sure you change the Team and bundle id from the previous step.</p> <p>The application will initiate as a native iOS application. Once the app is opened, you should see a screen like this:</p> <p></p><p></p><p></p> <p>This screen allows you to configure the URLs of the application server and the LiveKit server. You need to set them up for requesting tokens to your application server and connecting to the LiveKit server.</p> <p>Connecting real iOS device to application server running in you local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client in a real iOS device and be able to reach the application server very easily without worrying about SSL certificates if they are both running in the same local network. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Once you have configured the URLs, you can join a video call room by providing a room name and a user name. After joining the room, you will be able to see your own video and audio tracks, as well as the video and audio tracks of the other participants in the room.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>For more information, check the iOS tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/go/#understanding-the-code","title":"Understanding the code","text":"<p>The application is a simple Go app with a single file <code>main.go</code> that exports two endpoints:</p> <ul> <li><code>/token</code> : generate a token for a given Room name and Participant name.</li> <li><code>/livekit/webhook</code> : receive LiveKit webhook events.</li> </ul> <p>Let's see the code of the <code>main.go</code> file:</p> main.go<pre><code>var SERVER_PORT string // (1)!\nvar LIVEKIT_API_KEY string // (2)!\nvar LIVEKIT_API_SECRET string // (3)!\n</code></pre> <ol> <li>The port where the application will be listening</li> <li>The API key of LiveKit Server</li> <li>The API secret of LiveKit Server</li> </ol> <p>The <code>main.go</code> file first declares the necessary global variables:</p> <ul> <li><code>SERVER_PORT</code>: the port where the application will be listening.</li> <li><code>LIVEKIT_API_KEY</code>: the API key of LiveKit Server.</li> <li><code>LIVEKIT_API_SECRET</code>: the API secret of LiveKit Server.</li> </ul> <p>The server launch takes place in the <code>main</code> function at the end of the file, where we first load the environment variables, then set the REST endpoints and finally start the server on <code>SERVER_PORT</code>:</p> main.go<pre><code>func main() {\n    loadEnv() // (1)!\n    router := gin.Default() // (2)!\n    router.Use(cors.Default()) // (3)!\n    router.POST(\"/token\", createToken) // (4)!\n    router.POST(\"/livekit/webhook\", receiveWebhook) // (5)!\n    router.Run(\":\" + SERVER_PORT) // (6)!\n}\n</code></pre> <ol> <li>Load environment variables</li> <li>Create a new Gin router</li> <li>Enable CORS support</li> <li>Create the <code>/token</code> endpoint</li> <li>Create the <code>/livekit/webhook</code> endpoint</li> <li>Start the server on the <code>SERVER_PORT</code></li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/application-server/go/#create-token","title":"Create token","text":"<p>The endpoint <code>/token</code> accepts <code>POST</code> requests with a payload of type <code>application/json</code>, containing the following fields:</p> <ul> <li><code>roomName</code>: the name of the Room where the user wants to connect.</li> <li><code>participantName</code>: the name of the participant that wants to connect to the Room.</li> </ul> main.go<pre><code>func createToken(context *gin.Context) {\n    var body struct {\n        RoomName        string `json:\"roomName\"`\n        ParticipantName string `json:\"participantName\"`\n    }\n\n    if err := context.BindJSON(&amp;body); err != nil {\n        context.JSON(http.StatusBadRequest, err.Error())\n        return\n    }\n\n    if body.RoomName == \"\" || body.ParticipantName == \"\" {\n        context.JSON(http.StatusBadRequest, gin.H{\"errorMessage\": \"roomName and participantName are required\"})\n        return\n    }\n\n    at := auth.NewAccessToken(LIVEKIT_API_KEY, LIVEKIT_API_SECRET) // (1)!\n    grant := &amp;auth.VideoGrant{\n        RoomJoin: true,\n        Room:     body.RoomName,\n    }\n    at.SetVideoGrant(grant).SetIdentity(body.ParticipantName) // (2)!\n\n    token, err := at.ToJWT() // (3)!\n    if err != nil {\n        context.JSON(http.StatusInternalServerError, err.Error())\n        return\n    }\n\n    context.JSON(http.StatusOK, gin.H{\"token\": token}) // (4)!\n}\n</code></pre> <ol> <li>A new <code>AccessToken</code> is created providing the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code>.</li> <li>We set the video grants and identity of the participant in the AccessToken. <code>RoomJoin</code> allows the user to join a room and <code>Room</code> determines the specific room. Check out all Video Grants .</li> <li>We convert the AccessToken to a JWT token.</li> <li>Finally, the token is sent back to the client.</li> </ol> <p>We first load the request body into a struct with <code>roomName</code> and <code>participantName</code> string fields. If they are not available, it returns a <code>400</code> error.</p> <p>If required fields are available, a new JWT token is created. For that we use the LiveKit Go SDK :</p> <ol> <li>A new <code>AccessToken</code> is created providing the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code>.</li> <li>We set the video grants and identity of the participant in the AccessToken. <code>RoomJoin</code> allows the user to join a room and <code>Room</code> determines the specific room. Check out all Video Grants .</li> <li>We convert the AccessToken to a JWT token and return it to the client.</li> <li>Finally, the token is sent back to the client.</li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/application-server/go/#receive-webhook","title":"Receive webhook","text":"<p>The endpoint <code>/livekit/webhook</code> accepts <code>POST</code> requests with a payload of type <code>application/webhook+json</code>. This is the endpoint where LiveKit Server will send webhook events .</p> main.go<pre><code>func receiveWebhook(context *gin.Context) {\n    authProvider := auth.NewSimpleKeyProvider( // (1)!\n        LIVEKIT_API_KEY, LIVEKIT_API_SECRET,\n    )\n    event, err := webhook.ReceiveWebhookEvent(context.Request, authProvider) // (2)!\n    if err != nil {\n        fmt.Fprintf(os.Stderr, \"error validating webhook event: %v\", err)\n        return\n    }\n    fmt.Println(\"LiveKit Webhook\", event) // (3)!\n}\n</code></pre> <ol> <li>Create a <code>SimpleKeyProvider</code> with the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API</code>.</li> <li>Receive the webhook event providing the <code>http.Request</code> in the Gin context and the <code>SimpleKeyProvider</code> we just created. This will validate and decode the incoming webhook event .</li> <li>Consume the event as you whish.</li> </ol> <p></p> <ol> <li>Create a <code>SimpleKeyProvider</code> with the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API</code>.</li> <li>Receive the webhook event providing the <code>http.Request</code> in the Gin context and the <code>SimpleKeyProvider</code> we just created. This will validate and decode the incoming webhook event .</li> <li>Consume the event as you whish.</li> </ol> <p>Configure Webhooks</p> <p>If you are using a production deployment, remember to configure the webhook URL to point to your local application server as explained in the Send Webhooks to a Local Application Server section.</p> <p></p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/java/","title":"Java Server Tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-server/java/#java-server-tutorial","title":"Java Server Tutorial","text":"<p>Source code </p> <p>This is a minimal server application built for Java with Spring Boot  that allows:</p> <ul> <li>Generating LiveKit tokens on demand for any application client.</li> <li>Receiving LiveKit webhook events .</li> </ul> <p>It internally uses LiveKit Kotlin SDK .</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/java/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-server/java/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/java/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/application-server/java/#3-run-the-server-application","title":"3. Run the server application","text":"<p>To run this server application, you need Java  and Maven  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/java\n</code></pre></li> <li>Run the application <pre><code>mvn spring-boot:run\n</code></pre></li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/application-server/java/#4-run-a-client-application-to-test-against-this-server","title":"4. Run a client application to test against this server","text":"JavaScript React Angular Vue Electron Ionic Android iOS <p>To run the client application tutorial, you need an HTTP web server installed on your development computer. A great option is http-server . You can install it via NPM :</p> <pre><code>npm install -g http-server\n</code></pre> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-js\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>http-server -p 5080 ./src\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the JavaScript tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-react\n</code></pre> </li> <li> <p>Install dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Run the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the React tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-angular\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the Angular tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-vue\n</code></pre> </li> <li> <p>Install dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Run the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the Vue tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-electron\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Run the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>The application will seamlessly initiate as a native desktop program, adapting itself to the specific operating system you are using. Once the application is open, you should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Running your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the Electron tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-ionic\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <p>You have two options for running the client application: browser-based or mobile device-based:</p>  Browser Mobile <p>To run the application in a browser, you will need to start the Ionic server. To do so, run the following command:</p> <pre><code>npm start\n</code></pre> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p>Mobile appearance</p> <p>To show the app with a mobile device appearance, open the dev tools in your browser and find the button to adapt the viewport to a mobile device aspect ratio. You may also choose predefined types of devices to see the behavior of your app in different resolutions.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Running the tutorial on a mobile device presents additional challenges compared to running it in a browser, mainly due to the application being launched on a different device, such as an Android smartphone or iPhone, rather than our computer. To overcome these challenges, the following steps need to be taken:</p> <ol> <li> <p>Localhost limitations:</p> <p>The usage of <code>localhost</code> in our Ionic app is restricted, preventing seamless communication between the application client and the server.</p> </li> <li> <p>Serve over local network:</p> <p>The application must be served over our local network to enable communication between the device and the server.</p> </li> <li> <p>Secure connection requirement for WebRTC API:</p> <p>The WebRTC API demands a secure connection for functionality outside of localhost, necessitating the serving of the application over HTTPS.</p> </li> </ol> <p>If you run OpenVidu locally you don't need to worry about this. OpenVidu will handle all of the above requirements for you. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Now, let's explore how to run the application on a mobile device:</p> <p>Requirements</p> <p>Before running the application on a mobile device, make sure that the device is connected to the same network as your PC and the mobile is connected to the PC via USB or Wi-Fi.</p>  Android device iOS device <pre><code>npm run android\n</code></pre> <p>You will need Ruby  and Cocoapods  installed in your computer.</p> <p>The app must be signed with a development team. To do so, open the project in Xcode and select a development team in the Signing &amp; Capabilities editor.</p> <pre><code>npm run ios\n</code></pre> <p>The script will ask you for the device you want to run the application on. You should select the real device you have connected to your computer.</p> <p>Once the mobile device has been selected, the script will launch the application on the device and you will see a screen like this:</p> <p></p><p></p><p></p> <p>This screen allows you to configure the URLs of the application server and the LiveKit server. You need to set them up for requesting tokens to your application server and connecting to the LiveKit server.</p> <p>Once you have configured the URLs, you can join a video call room by providing a room name and a user name. After joining the room, you will be able to see your own video and audio tracks, as well as the video and audio tracks of the other participants in the room.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> </li> </ol> <p>For more information, check the Ionic tutorial.</p> <p>To run the client application tutorial, you need Android Studio  installed on your development computer.</p> <ol> <li> <p>Open Android Studio and import the project located at <code>openvidu-livekit-tutorials/application-client/openvidu-android</code>.</p> </li> <li> <p>Run the application in an emulator or a physical device by clicking the \"Run\" button in Android Studio. Check out the official documentation  for further information.</p> </li> </ol> <p>The application will initiate as a native Android program. Once the application is opened, you should see a screen like this:</p> <p></p><p></p><p></p> <p>This screen allows you to configure the URLs of the application server and the LiveKit server. You need to set them up for requesting tokens to your application server and connecting to the LiveKit server.</p> <p>Connecting real Android device to application server running in you local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client in a real Android device and be able to reach the application server very easily without worrying about SSL certificates if they are both running in the same local network. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Once you have configured the URLs, you can join a video call room by providing a room name and a user name. After joining the room, you will be able to see your own video and audio tracks, as well as the video and audio tracks of the other participants in the room.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>For more information, check the Android tutorial.</p> <p>To run the client application tutorial, you need Xcode  installed on your MacOS.</p> <ol> <li> <p>Launch Xcode and open the <code>OpenViduIOS.xcodeproj</code> that you can find under <code>openvidu-livekit-tutorials/application-client/openvidu-ios</code>.</p> </li> <li> <p>Run the application in an emulator or a physical device by clicking on the menu Product &gt; Run or by \u2318R.</p> </li> </ol> <p>Emulator limitations</p> <p>Publishing the camera track is not supported by iOS Simulator.</p> <p>If you encounter code signing issues, make sure you change the Team and bundle id from the previous step.</p> <p>The application will initiate as a native iOS application. Once the app is opened, you should see a screen like this:</p> <p></p><p></p><p></p> <p>This screen allows you to configure the URLs of the application server and the LiveKit server. You need to set them up for requesting tokens to your application server and connecting to the LiveKit server.</p> <p>Connecting real iOS device to application server running in you local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client in a real iOS device and be able to reach the application server very easily without worrying about SSL certificates if they are both running in the same local network. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Once you have configured the URLs, you can join a video call room by providing a room name and a user name. After joining the room, you will be able to see your own video and audio tracks, as well as the video and audio tracks of the other participants in the room.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>For more information, check the iOS tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/java/#understanding-the-code","title":"Understanding the code","text":"<p>The application is a simple Spring Boot app with a single controller <code>Controller.java</code> that exports two endpoints:</p> <ul> <li><code>/token</code> : generate a token for a given Room name and Participant name.</li> <li><code>/livekit/webhook</code> : receive LiveKit webhook events.</li> </ul> <p>Let's see the code of the <code>Controller.java</code> file:</p> Controller.java<pre><code>@CrossOrigin(origins = \"*\") // (1)!\n@RestController // (2)!\npublic class Controller {\n\n    @Value(\"${livekit.api.key}\")\n    private String LIVEKIT_API_KEY; // (3)!\n\n    @Value(\"${livekit.api.secret}\")\n    private String LIVEKIT_API_SECRET; // (4)!\n\n    ...\n}\n</code></pre> <ol> <li>Allows the application to be accessed from any domain</li> <li>Marks the class as a controller where every method returns a domain object instead of a view</li> <li>The API key of LiveKit Server</li> <li>The API secret of LiveKit Server</li> </ol> <p>Starting by the top, the <code>Controller</code> class has the following annotations:</p> <ul> <li><code>@CrossOrigin(origins = \"*\")</code>: allows the application to be accessed from any domain.</li> <li><code>@RestController</code>: marks the class as a controller where every method returns a domain object instead of a view.</li> </ul> <p>Going deeper, the <code>Controller</code> class has the following fields:</p> <ul> <li><code>LIVEKIT_API_KEY</code>: the API key of LiveKit Server. It is injected from the property <code>livekit.api.key</code> defined in <code>application.properties</code>  using the <code>@Value(\"${livekit.api.key}\")</code> annotation.</li> <li><code>LIVEKIT_API_SECRET</code>: the API secret of LiveKit Server. It is injected from the the property <code>livekit.api.secret</code> defined in <code>application.properties</code>  using the <code>@Value(\"${livekit.api.secret}\")</code> annotation.</li> </ul>","tags":["Platform"]},{"location":"docs/tutorials/application-server/java/#create-token","title":"Create token","text":"<p>The endpoint <code>/token</code> accepts <code>POST</code> requests with a payload of type <code>application/json</code>, containing the following fields:</p> <ul> <li><code>roomName</code>: the name of the Room where the user wants to connect.</li> <li><code>participantName</code>: the name of the participant that wants to connect to the Room.</li> </ul> Controller.java<pre><code>@PostMapping(value = \"/token\")\npublic ResponseEntity&lt;Map&lt;String, String&gt;&gt; createToken(@RequestBody Map&lt;String, String&gt; params) {\n    String roomName = params.get(\"roomName\");\n    String participantName = params.get(\"participantName\");\n\n    if (roomName == null || participantName == null) {\n        return ResponseEntity.badRequest().body(Map.of(\"errorMessage\", \"roomName and participantName are required\"));\n    }\n\n    AccessToken token = new AccessToken(LIVEKIT_API_KEY, LIVEKIT_API_SECRET); // (1)!\n    token.setName(participantName); // (2)!\n    token.setIdentity(participantName);\n    token.addGrants(new RoomJoin(true), new RoomName(roomName)); // (3)!\n\n    return ResponseEntity.ok(Map.of(\"token\", token.toJwt())); // (4)!\n}\n</code></pre> <ol> <li>A new <code>AccessToken</code> is created providing the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code>.</li> <li>We set participant's name and identity in the AccessToken.</li> <li>We set the video grants in the AccessToken. <code>RoomJoin</code> allows the user to join a room and <code>RoomName</code> determines the specific room. Check out all Video Grants .</li> <li>Finally, the token is sent back to the client.</li> </ol> <p>The endpoint first obtains the <code>roomName</code> and <code>participantName</code> parameters from the request body. If they are not available, it returns a <code>400</code> error.</p> <p>If required fields are available, a new JWT token is created. For that we use the LiveKit Kotlin SDK :</p> <ol> <li>A new <code>AccessToken</code> is created providing the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code>.</li> <li>We set participant's name and identity in the AccessToken.</li> <li>We set the video grants in the AccessToken. <code>RoomJoin</code> allows the user to join a room and <code>RoomName</code> determines the specific room. Check out all Video Grants .</li> <li>Finally, the token is sent back to the client.</li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/application-server/java/#receive-webhook","title":"Receive webhook","text":"<p>The endpoint <code>/livekit/webhook</code> accepts <code>POST</code> requests with a payload of type <code>application/webhook+json</code>. This is the endpoint where LiveKit Server will send webhook events .</p> Controller.java<pre><code>@PostMapping(value = \"/livekit/webhook\", consumes = \"application/webhook+json\")\npublic ResponseEntity&lt;String&gt; receiveWebhook(@RequestHeader(\"Authorization\") String authHeader, @RequestBody String body) { // (1)!\n    WebhookReceiver webhookReceiver = new WebhookReceiver(LIVEKIT_API_KEY, LIVEKIT_API_SECRET); // (2)!\n    try {\n        WebhookEvent event = webhookReceiver.receive(body, authHeader); // (3)!\n        System.out.println(\"LiveKit Webhook: \" + event.toString()); // (4)!\n    } catch (Exception e) {\n        System.err.println(\"Error validating webhook event: \" + e.getMessage());\n    }\n    return ResponseEntity.ok(\"ok\");\n}\n</code></pre> <ol> <li>We need the 'Authorization' header and the raw body of the HTTP request.</li> <li>Initialize the WebhookReceiver using the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code>. It will help validating and decoding incoming webhook events .</li> <li>Obtain the <code>WebhookEvent</code> object using the <code>WebhookReceiver#receive</code> method. It takes the raw body as a String and the Authorization header of the request.</li> <li>Consume the event as you whish.</li> </ol> <p>We declare the 'Authorization' header and the raw body of the HTTP request as parameters of the our method. We need both of them to validate and decode the incoming webhook event.</p> <p>Then we initialize a <code>WebhookReceiver</code> object using the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code>.</p> <p>Finally we obtain a <code>WebhookEvent</code> object calling method <code>WebhookReceiver#receive</code>. It takes the raw body as a String and the <code>Authorization</code> header of the request. If everything is correct, you can do whatever you want with the event (in this case, we just log it).</p> <p>Remember to return a <code>200</code> OK response at the end to let LiveKit Server know that the webhook was received correctly.</p> <p>Configure Webhooks</p> <p>If you are using a production deployment, remember to configure the webhook URL to point to your local application server as explained in the Send Webhooks to a Local Application Server section.</p> <p></p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/node/","title":"Node.js Server Tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-server/node/#nodejs-server-tutorial","title":"Node.js Server Tutorial","text":"<p>Source code </p> <p>This is a minimal server application built for Node.js with Express  that allows:</p> <ul> <li>Generating LiveKit tokens on demand for any application client.</li> <li>Receiving LiveKit webhook events .</li> </ul> <p>It internally uses LiveKit JS SDK .</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/node/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-server/node/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/node/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/application-server/node/#3-run-the-server-application","title":"3. Run the server application","text":"<p>To run this server application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/node\n</code></pre></li> <li>Install dependencies <pre><code>npm install\n</code></pre></li> <li>Run the application <pre><code>npm start\n</code></pre></li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/application-server/node/#4-run-a-client-application-to-test-against-this-server","title":"4. Run a client application to test against this server","text":"JavaScript React Angular Vue Electron Ionic Android iOS <p>To run the client application tutorial, you need an HTTP web server installed on your development computer. A great option is http-server . You can install it via NPM :</p> <pre><code>npm install -g http-server\n</code></pre> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-js\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>http-server -p 5080 ./src\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the JavaScript tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-react\n</code></pre> </li> <li> <p>Install dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Run the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the React tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-angular\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the Angular tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-vue\n</code></pre> </li> <li> <p>Install dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Run the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the Vue tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-electron\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Run the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>The application will seamlessly initiate as a native desktop program, adapting itself to the specific operating system you are using. Once the application is open, you should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Running your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the Electron tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-ionic\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <p>You have two options for running the client application: browser-based or mobile device-based:</p>  Browser Mobile <p>To run the application in a browser, you will need to start the Ionic server. To do so, run the following command:</p> <pre><code>npm start\n</code></pre> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p>Mobile appearance</p> <p>To show the app with a mobile device appearance, open the dev tools in your browser and find the button to adapt the viewport to a mobile device aspect ratio. You may also choose predefined types of devices to see the behavior of your app in different resolutions.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Running the tutorial on a mobile device presents additional challenges compared to running it in a browser, mainly due to the application being launched on a different device, such as an Android smartphone or iPhone, rather than our computer. To overcome these challenges, the following steps need to be taken:</p> <ol> <li> <p>Localhost limitations:</p> <p>The usage of <code>localhost</code> in our Ionic app is restricted, preventing seamless communication between the application client and the server.</p> </li> <li> <p>Serve over local network:</p> <p>The application must be served over our local network to enable communication between the device and the server.</p> </li> <li> <p>Secure connection requirement for WebRTC API:</p> <p>The WebRTC API demands a secure connection for functionality outside of localhost, necessitating the serving of the application over HTTPS.</p> </li> </ol> <p>If you run OpenVidu locally you don't need to worry about this. OpenVidu will handle all of the above requirements for you. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Now, let's explore how to run the application on a mobile device:</p> <p>Requirements</p> <p>Before running the application on a mobile device, make sure that the device is connected to the same network as your PC and the mobile is connected to the PC via USB or Wi-Fi.</p>  Android device iOS device <pre><code>npm run android\n</code></pre> <p>You will need Ruby  and Cocoapods  installed in your computer.</p> <p>The app must be signed with a development team. To do so, open the project in Xcode and select a development team in the Signing &amp; Capabilities editor.</p> <pre><code>npm run ios\n</code></pre> <p>The script will ask you for the device you want to run the application on. You should select the real device you have connected to your computer.</p> <p>Once the mobile device has been selected, the script will launch the application on the device and you will see a screen like this:</p> <p></p><p></p><p></p> <p>This screen allows you to configure the URLs of the application server and the LiveKit server. You need to set them up for requesting tokens to your application server and connecting to the LiveKit server.</p> <p>Once you have configured the URLs, you can join a video call room by providing a room name and a user name. After joining the room, you will be able to see your own video and audio tracks, as well as the video and audio tracks of the other participants in the room.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> </li> </ol> <p>For more information, check the Ionic tutorial.</p> <p>To run the client application tutorial, you need Android Studio  installed on your development computer.</p> <ol> <li> <p>Open Android Studio and import the project located at <code>openvidu-livekit-tutorials/application-client/openvidu-android</code>.</p> </li> <li> <p>Run the application in an emulator or a physical device by clicking the \"Run\" button in Android Studio. Check out the official documentation  for further information.</p> </li> </ol> <p>The application will initiate as a native Android program. Once the application is opened, you should see a screen like this:</p> <p></p><p></p><p></p> <p>This screen allows you to configure the URLs of the application server and the LiveKit server. You need to set them up for requesting tokens to your application server and connecting to the LiveKit server.</p> <p>Connecting real Android device to application server running in you local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client in a real Android device and be able to reach the application server very easily without worrying about SSL certificates if they are both running in the same local network. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Once you have configured the URLs, you can join a video call room by providing a room name and a user name. After joining the room, you will be able to see your own video and audio tracks, as well as the video and audio tracks of the other participants in the room.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>For more information, check the Android tutorial.</p> <p>To run the client application tutorial, you need Xcode  installed on your MacOS.</p> <ol> <li> <p>Launch Xcode and open the <code>OpenViduIOS.xcodeproj</code> that you can find under <code>openvidu-livekit-tutorials/application-client/openvidu-ios</code>.</p> </li> <li> <p>Run the application in an emulator or a physical device by clicking on the menu Product &gt; Run or by \u2318R.</p> </li> </ol> <p>Emulator limitations</p> <p>Publishing the camera track is not supported by iOS Simulator.</p> <p>If you encounter code signing issues, make sure you change the Team and bundle id from the previous step.</p> <p>The application will initiate as a native iOS application. Once the app is opened, you should see a screen like this:</p> <p></p><p></p><p></p> <p>This screen allows you to configure the URLs of the application server and the LiveKit server. You need to set them up for requesting tokens to your application server and connecting to the LiveKit server.</p> <p>Connecting real iOS device to application server running in you local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client in a real iOS device and be able to reach the application server very easily without worrying about SSL certificates if they are both running in the same local network. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Once you have configured the URLs, you can join a video call room by providing a room name and a user name. After joining the room, you will be able to see your own video and audio tracks, as well as the video and audio tracks of the other participants in the room.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>For more information, check the iOS tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/node/#understanding-the-code","title":"Understanding the code","text":"<p>The application is a simple Express app with a single file <code>index.js</code> that exports two endpoints:</p> <ul> <li><code>/token</code> : generate a token for a given Room name and Participant name.</li> <li><code>/livekit/webhook</code> : receive LiveKit webhook events.</li> </ul> <p>Let's see the code of the <code>index.js</code> file:</p> index.js<pre><code>import \"dotenv/config\";\nimport express from \"express\";\nimport cors from \"cors\";\nimport { AccessToken, WebhookReceiver } from \"livekit-server-sdk\"; // (1)!\n\nconst SERVER_PORT = process.env.SERVER_PORT || 6080; // (2)!\nconst LIVEKIT_API_KEY = process.env.LIVEKIT_API_KEY || \"devkey\"; // (3)!\nconst LIVEKIT_API_SECRET = process.env.LIVEKIT_API_SECRET || \"secret\"; // (4)!\n\nconst app = express(); // (5)!\n\napp.use(cors()); // (6)!\napp.use(express.json()); // (7)!\napp.use(express.raw({ type: \"application/webhook+json\" })); // (8)!\n</code></pre> <ol> <li>Import <code>AccessToken</code> from <code>livekit-server-sdk</code>.</li> <li>The port where the application will be listening.</li> <li>The API key of LiveKit Server.</li> <li>The API secret of LiveKit Server.</li> <li>Initialize the Express application.</li> <li>Enable CORS support.</li> <li>Enable JSON body parsing for the <code>/token</code> endpoint.</li> <li>Enable raw body parsing for the <code>/livekit/webhook</code> endpoint.</li> </ol> <p>The <code>index.js</code> file imports the required dependencies and loads the necessary environment variables:</p> <ul> <li><code>SERVER_PORT</code>: the port where the application will be listening.</li> <li><code>LIVEKIT_API_KEY</code>: the API key of LiveKit Server.</li> <li><code>LIVEKIT_API_SECRET</code>: the API secret of LiveKit Server.</li> </ul> <p>It also initializes the <code>WebhookReceiver</code> object that will help validating and decoding incoming webhook events .</p> <p>Finally the <code>express</code> application is initialized. CORS is allowed, JSON body parsing is enabled for the <code>/token</code> endpoint and raw body parsing is enabled for the <code>/livekit/webhook</code> endpoint.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/node/#create-token","title":"Create token","text":"<p>The endpoint <code>/token</code> accepts <code>POST</code> requests with a payload of type <code>application/json</code>, containing the following fields:</p> <ul> <li><code>roomName</code>: the name of the Room where the user wants to connect.</li> <li><code>participantName</code>: the name of the participant that wants to connect to the Room.</li> </ul> index.js<pre><code>app.post(\"/token\", async (req, res) =&gt; {\n  const roomName = req.body.roomName;\n  const participantName = req.body.participantName;\n\n  if (!roomName || !participantName) {\n    res.status(400).json({ errorMessage: \"roomName and participantName are required\" });\n    return;\n  }\n\n  const at = new AccessToken(LIVEKIT_API_KEY, LIVEKIT_API_SECRET, { // (1)!\n    identity: participantName,\n  });\n  at.addGrant({ roomJoin: true, room: roomName }); // (2)!\n  const token = await at.toJwt(); // (3)!\n  res.json({ token }); // (4)!\n});\n</code></pre> <ol> <li>A new <code>AccessToken</code> is created providing the <code>LIVEKIT_API_KEY</code>, <code>LIVEKIT_API_SECRET</code> and setting the participant's identity.</li> <li>We set the video grants in the AccessToken. <code>roomJoin</code> allows the user to join a room and <code>room</code> determines the specific room. Check out all Video Grants .</li> <li>We convert the AccessToken to a JWT token.</li> <li>Finally, the token is sent back to the client.</li> </ol> <p>The endpoint first obtains the <code>roomName</code> and <code>participantName</code> parameters from the request body. If they are not available, it returns a <code>400</code> error.</p> <p>If required fields are available, a new JWT token is created. For that we use the LiveKit JS SDK :</p> <ol> <li>A new <code>AccessToken</code> is created providing the <code>LIVEKIT_API_KEY</code>, <code>LIVEKIT_API_SECRET</code> and setting the participant's identity.</li> <li>We set the video grants in the AccessToken. <code>roomJoin</code> allows the user to join a room and <code>room</code> determines the specific room. Check out all Video Grants .</li> <li>We convert the AccessToken to a JWT token.</li> <li>Finally, the token is sent back to the client.</li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/application-server/node/#receive-webhook","title":"Receive webhook","text":"<p>The endpoint <code>/livekit/webhook</code> accepts <code>POST</code> requests with a payload of type <code>application/webhook+json</code>. This is the endpoint where LiveKit Server will send webhook events .</p> index.js<pre><code>const webhookReceiver = new WebhookReceiver( // (1)!\n  LIVEKIT_API_KEY,\n  LIVEKIT_API_SECRET\n);\n\napp.post(\"/livekit/webhook\", async (req, res) =&gt; {\n  try {\n    const event = await webhookReceiver.receive(\n      req.body, // (2)!\n      req.get(\"Authorization\") // (3)!\n    );\n    console.log(event); // (4)!\n  } catch (error) {\n    console.error(\"Error validating webhook event\", error);\n  }\n  res.status(200).send();\n});\n</code></pre> <ol> <li>Initialize the WebhookReceiver using the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code>. It will help validating and decoding incoming webhook events .</li> <li>The body of the HTTP request.</li> <li>The <code>Authorization</code> header of the HTTP request.</li> <li>Consume the event as you whish.</li> </ol> <p>First of all we initialize the <code>WebhookReceiver</code> using the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code>. This object will validate and decode the incoming webhook events.</p> <p>The endpoint receives the incoming webhook with the async method <code>WebhookReceiver#receive</code>. It takes the body and the <code>Authorization</code> header of the request. If everything is correct, you can do whatever you want with the event (in this case, we just log it).</p> <p>Remember to return a <code>200</code> OK response at the end to let LiveKit Server know that the webhook was received correctly.</p> <p>Configure Webhooks</p> <p>If you are using a production deployment, remember to configure the webhook URL to point to your local application server as explained in the Send Webhooks to a Local Application Server section.</p> <p></p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/php/","title":"PHP Server Tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-server/php/#php-server-tutorial","title":"PHP Server Tutorial","text":"<p>Source code </p> <p>This is a minimal server application built for PHP that allows:</p> <ul> <li>Generating LiveKit tokens on demand for any application client.</li> <li>Receiving LiveKit webhook events .</li> </ul> <p>It internally uses LiveKit PHP SDK .</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/php/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-server/php/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/php/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/application-server/php/#3-run-the-server-application","title":"3. Run the server application","text":"<p>To run this server application, you need PHP  and Composer  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/php\n</code></pre></li> <li>Install dependencies <pre><code>composer install\n</code></pre></li> <li>Run the application <pre><code>composer start\n</code></pre></li> </ol> <p>Warning</p> <p>LiveKit PHP SDK requires library BCMath . This is available out-of-the-box in PHP for Windows, but a manual installation might be necessary in other OS. Run <code>sudo apt install php-bcmath</code> or <code>sudo yum install php-bcmath</code></p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/php/#4-run-a-client-application-to-test-against-this-server","title":"4. Run a client application to test against this server","text":"JavaScript React Angular Vue Electron Ionic Android iOS <p>To run the client application tutorial, you need an HTTP web server installed on your development computer. A great option is http-server . You can install it via NPM :</p> <pre><code>npm install -g http-server\n</code></pre> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-js\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>http-server -p 5080 ./src\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the JavaScript tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-react\n</code></pre> </li> <li> <p>Install dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Run the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the React tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-angular\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the Angular tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-vue\n</code></pre> </li> <li> <p>Install dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Run the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the Vue tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-electron\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Run the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>The application will seamlessly initiate as a native desktop program, adapting itself to the specific operating system you are using. Once the application is open, you should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Running your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the Electron tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-ionic\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <p>You have two options for running the client application: browser-based or mobile device-based:</p>  Browser Mobile <p>To run the application in a browser, you will need to start the Ionic server. To do so, run the following command:</p> <pre><code>npm start\n</code></pre> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p>Mobile appearance</p> <p>To show the app with a mobile device appearance, open the dev tools in your browser and find the button to adapt the viewport to a mobile device aspect ratio. You may also choose predefined types of devices to see the behavior of your app in different resolutions.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Running the tutorial on a mobile device presents additional challenges compared to running it in a browser, mainly due to the application being launched on a different device, such as an Android smartphone or iPhone, rather than our computer. To overcome these challenges, the following steps need to be taken:</p> <ol> <li> <p>Localhost limitations:</p> <p>The usage of <code>localhost</code> in our Ionic app is restricted, preventing seamless communication between the application client and the server.</p> </li> <li> <p>Serve over local network:</p> <p>The application must be served over our local network to enable communication between the device and the server.</p> </li> <li> <p>Secure connection requirement for WebRTC API:</p> <p>The WebRTC API demands a secure connection for functionality outside of localhost, necessitating the serving of the application over HTTPS.</p> </li> </ol> <p>If you run OpenVidu locally you don't need to worry about this. OpenVidu will handle all of the above requirements for you. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Now, let's explore how to run the application on a mobile device:</p> <p>Requirements</p> <p>Before running the application on a mobile device, make sure that the device is connected to the same network as your PC and the mobile is connected to the PC via USB or Wi-Fi.</p>  Android device iOS device <pre><code>npm run android\n</code></pre> <p>You will need Ruby  and Cocoapods  installed in your computer.</p> <p>The app must be signed with a development team. To do so, open the project in Xcode and select a development team in the Signing &amp; Capabilities editor.</p> <pre><code>npm run ios\n</code></pre> <p>The script will ask you for the device you want to run the application on. You should select the real device you have connected to your computer.</p> <p>Once the mobile device has been selected, the script will launch the application on the device and you will see a screen like this:</p> <p></p><p></p><p></p> <p>This screen allows you to configure the URLs of the application server and the LiveKit server. You need to set them up for requesting tokens to your application server and connecting to the LiveKit server.</p> <p>Once you have configured the URLs, you can join a video call room by providing a room name and a user name. After joining the room, you will be able to see your own video and audio tracks, as well as the video and audio tracks of the other participants in the room.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> </li> </ol> <p>For more information, check the Ionic tutorial.</p> <p>To run the client application tutorial, you need Android Studio  installed on your development computer.</p> <ol> <li> <p>Open Android Studio and import the project located at <code>openvidu-livekit-tutorials/application-client/openvidu-android</code>.</p> </li> <li> <p>Run the application in an emulator or a physical device by clicking the \"Run\" button in Android Studio. Check out the official documentation  for further information.</p> </li> </ol> <p>The application will initiate as a native Android program. Once the application is opened, you should see a screen like this:</p> <p></p><p></p><p></p> <p>This screen allows you to configure the URLs of the application server and the LiveKit server. You need to set them up for requesting tokens to your application server and connecting to the LiveKit server.</p> <p>Connecting real Android device to application server running in you local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client in a real Android device and be able to reach the application server very easily without worrying about SSL certificates if they are both running in the same local network. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Once you have configured the URLs, you can join a video call room by providing a room name and a user name. After joining the room, you will be able to see your own video and audio tracks, as well as the video and audio tracks of the other participants in the room.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>For more information, check the Android tutorial.</p> <p>To run the client application tutorial, you need Xcode  installed on your MacOS.</p> <ol> <li> <p>Launch Xcode and open the <code>OpenViduIOS.xcodeproj</code> that you can find under <code>openvidu-livekit-tutorials/application-client/openvidu-ios</code>.</p> </li> <li> <p>Run the application in an emulator or a physical device by clicking on the menu Product &gt; Run or by \u2318R.</p> </li> </ol> <p>Emulator limitations</p> <p>Publishing the camera track is not supported by iOS Simulator.</p> <p>If you encounter code signing issues, make sure you change the Team and bundle id from the previous step.</p> <p>The application will initiate as a native iOS application. Once the app is opened, you should see a screen like this:</p> <p></p><p></p><p></p> <p>This screen allows you to configure the URLs of the application server and the LiveKit server. You need to set them up for requesting tokens to your application server and connecting to the LiveKit server.</p> <p>Connecting real iOS device to application server running in you local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client in a real iOS device and be able to reach the application server very easily without worrying about SSL certificates if they are both running in the same local network. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Once you have configured the URLs, you can join a video call room by providing a room name and a user name. After joining the room, you will be able to see your own video and audio tracks, as well as the video and audio tracks of the other participants in the room.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>For more information, check the iOS tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/php/#understanding-the-code","title":"Understanding the code","text":"<p>The application is a simple PHP app with a single file <code>index.php</code> that exports two endpoints:</p> <ul> <li><code>/token</code> : generate a token for a given Room name and Participant name.</li> <li><code>/livekit/webhook</code> : receive LiveKit webhook events.</li> </ul> <p>Let's see the code of the <code>index.php</code> file:</p> index.php<pre><code>&lt;?php\nrequire __DIR__ . \"/vendor/autoload.php\";\n\nuse Agence104\\LiveKit\\AccessToken; // (1)!\nuse Agence104\\LiveKit\\AccessTokenOptions;\nuse Agence104\\LiveKit\\VideoGrant;\nuse Agence104\\LiveKit\\WebhookReceiver;\nuse Dotenv\\Dotenv;\n\nDotenv::createImmutable(__DIR__)-&gt;safeLoad();\n\nheader(\"Access-Control-Allow-Origin: *\"); // (2)!\nheader(\"Access-Control-Allow-Headers: Content-Type, Authorization\");\nheader(\"Content-type: application/json\");\n\n$LIVEKIT_API_KEY = $_ENV[\"LIVEKIT_API_KEY\"] ?? \"devkey\"; // (3)!\n$LIVEKIT_API_SECRET = $_ENV[\"LIVEKIT_API_SECRET\"] ?? \"secret\"; // (4)!\n</code></pre> <ol> <li>Import all necessary dependencies from the PHP LiveKit library.</li> <li>Configure HTTP headers for the web server: enable CORS support, allow the <code>Content-Type</code> and <code>Authorization</code> headers and set the response content type to <code>application/json</code>.</li> <li>The API key of LiveKit Server.</li> <li>The API secret of LiveKit Server.</li> </ol> <p>The <code>index.php</code> file imports the required dependencies, sets the HTTP headers for the web server and loads the necessary environment variables:</p> <ul> <li><code>LIVEKIT_API_KEY</code>: the API key of LiveKit Server.</li> <li><code>LIVEKIT_API_SECRET</code>: the API secret of LiveKit Server.</li> </ul>","tags":["Platform"]},{"location":"docs/tutorials/application-server/php/#create-token","title":"Create token","text":"<p>The endpoint <code>/token</code> accepts <code>POST</code> requests with a payload of type <code>application/json</code>, containing the following fields:</p> <ul> <li><code>roomName</code>: the name of the Room where the user wants to connect.</li> <li><code>participantName</code>: the name of the participant that wants to connect to the Room.</li> </ul> index.php<pre><code>&lt;?php\nif (isset($_SERVER[\"REQUEST_METHOD\"]) &amp;&amp; $_SERVER[\"REQUEST_METHOD\"] === \"POST\" &amp;&amp; $_SERVER[\"PATH_INFO\"] === \"/token\") {\n    $data = json_decode(file_get_contents(\"php://input\"), true);\n\n    $roomName = $data[\"roomName\"] ?? null;\n    $participantName = $data[\"participantName\"] ?? null;\n\n    if (!$roomName || !$participantName) {\n        http_response_code(400);\n        echo json_encode([\"errorMessage\" =&gt; \"roomName and participantName are required\"]);\n        exit();\n    }\n\n    $tokenOptions = (new AccessTokenOptions()) // (1)!\n        -&gt;setIdentity($participantName);\n    $videoGrant = (new VideoGrant()) // (2)!\n        -&gt;setRoomJoin()\n        -&gt;setRoomName($roomName);\n    $token = (new AccessToken($LIVEKIT_API_KEY, $LIVEKIT_API_SECRET)) // (3)!\n        -&gt;init($tokenOptions)\n        -&gt;setGrant($videoGrant)\n        -&gt;toJwt();\n\n    echo json_encode([\"token\" =&gt; $token]); // (4)!\n    exit();\n}\n</code></pre> <ol> <li>Create an <code>AccessTokenOptions</code> object with the participant's identity.</li> <li>Create a <code>VideoGrant</code> object setting the necessary video grants options. <code>setRoomJoin</code> allows the user to join a room and <code>setRoomName</code> determines the specific room. Check out all Video Grants .</li> <li>We create the <code>AccessToken</code> providing the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code>, initialize it with the token options, set the video grants and generate the JWT token.</li> <li>Finally, the token is sent back to the client.</li> </ol> <p>The endpoint first obtains the <code>roomName</code> and <code>participantName</code> parameters from the request body. If they are not available, it returns a <code>400</code> error.</p> <p>If required fields are available, a new JWT token is created. For that we use the LiveKit PHP SDK :</p> <ol> <li>Create an <code>AccessTokenOptions</code> object with the participant's identity.</li> <li>Create a <code>VideoGrant</code> object setting the necessary video grants options. <code>setRoomJoin</code> allows the user to join a room and <code>setRoomName</code> determines the specific room. Check out all Video Grants .</li> <li>We create the <code>AccessToken</code> providing the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code>, initialize it with the token options, set the video grants and generate the JWT token.</li> <li>Finally, the token is sent back to the client.</li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/application-server/php/#receive-webhook","title":"Receive webhook","text":"<p>The endpoint <code>/livekit/webhook</code> accepts <code>POST</code> requests with a payload of type <code>application/webhook+json</code>. This is the endpoint where LiveKit Server will send webhook events .</p> index.php<pre><code>&lt;?php\n$webhookReceiver = (new WebhookReceiver($LIVEKIT_API_KEY, $LIVEKIT_API_SECRET)); // (1)!\n\nif (isset($_SERVER[\"REQUEST_METHOD\"]) &amp;&amp; $_SERVER[\"REQUEST_METHOD\"] === \"POST\" &amp;&amp; $_SERVER[\"PATH_INFO\"] === \"/livekit/webhook\") {\n    $headers = getallheaders();\n    $authHeader = $headers[\"Authorization\"]; // (2)!\n    $body = file_get_contents(\"php://input\"); // (3)!\n    try {\n        $event = $webhookReceiver-&gt;receive($body, $authHeader); // (4)!\n        error_log(\"LiveKit Webhook:\");\n        error_log(print_r($event-&gt;getEvent(), true)); // (5)!\n        exit();\n    } catch (Exception $e) {\n        http_response_code(401);\n        echo \"Error validating webhook event\";\n        echo json_encode($e-&gt;getMessage());\n        exit();\n    }\n}\n</code></pre> <ol> <li>Create a new <code>WebhookReceiver</code> object providing the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code>. It will help validating and decoding incoming webhook events .</li> <li>The <code>Authorization</code> header of the HTTP request.</li> <li>The raw body of the HTTP request as a string.</li> <li>Obtain the <code>WebhookEvent</code> object using the <code>WebhookReceiver#receive</code> method. It takes the raw body as a String and the Authorization header of the request.</li> <li>Consume the event as you wish.</li> </ol> <p>We first create a <code>WebhookReceiver</code> object using the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code>. Then we must retrieve the <code>Authorization</code> header and the raw body of the HTTP request. We need both of them to validate and decode the incoming webhook event.</p> <p>Finally, we obtain the <code>WebhookEvent</code> object using the <code>WebhookReceiver#receive</code> method. It takes the raw body as a String and the Authorization header of the request. We can consume the event as we wish (in this case, we just log it using the error output).</p> <p>Configure Webhooks</p> <p>If you are using a production deployment, remember to configure the webhook URL to point to your local application server as explained in the Send Webhooks to a Local Application Server section.</p> <p></p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/python/","title":"Python Server Tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-server/python/#python-server-tutorial","title":"Python Server Tutorial","text":"<p>Source code </p> <p>This is a minimal server application built for Python with Flask  that allows:</p> <ul> <li>Generating LiveKit tokens on demand for any application client.</li> <li>Receiving LiveKit webhook events .</li> </ul> <p>It internally uses LiveKit Python SDK .</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/python/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-server/python/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/python/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/application-server/python/#3-run-the-server-application","title":"3. Run the server application","text":"<p>To run this server application, you need Python 3  installed on your device.</p> <ol> <li> <p>Navigate into the server directory</p> <pre><code>cd openvidu-livekit-tutorials/application-server/python\n</code></pre> </li> <li> <p>Create a python virtual environment</p> <pre><code>python -m venv venv\n</code></pre> </li> <li> <p>Activate the virtual environment</p>  Windows macOS Linux <pre><code>.\\venv\\Scripts\\activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> <pre><code>. ./venv/bin/activate\n</code></pre> </li> <li> <p>Install dependencies</p> <pre><code>pip install -r requirements.txt\n</code></pre> </li> <li> <p>Run the application</p> <pre><code>python app.py\n</code></pre> </li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/application-server/python/#4-run-a-client-application-to-test-against-this-server","title":"4. Run a client application to test against this server","text":"JavaScript React Angular Vue Electron Ionic Android iOS <p>To run the client application tutorial, you need an HTTP web server installed on your development computer. A great option is http-server . You can install it via NPM :</p> <pre><code>npm install -g http-server\n</code></pre> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-js\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>http-server -p 5080 ./src\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the JavaScript tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-react\n</code></pre> </li> <li> <p>Install dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Run the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the React tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-angular\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the Angular tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-vue\n</code></pre> </li> <li> <p>Install dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Run the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the Vue tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-electron\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Run the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>The application will seamlessly initiate as a native desktop program, adapting itself to the specific operating system you are using. Once the application is open, you should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Running your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the Electron tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-ionic\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <p>You have two options for running the client application: browser-based or mobile device-based:</p>  Browser Mobile <p>To run the application in a browser, you will need to start the Ionic server. To do so, run the following command:</p> <pre><code>npm start\n</code></pre> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p>Mobile appearance</p> <p>To show the app with a mobile device appearance, open the dev tools in your browser and find the button to adapt the viewport to a mobile device aspect ratio. You may also choose predefined types of devices to see the behavior of your app in different resolutions.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Running the tutorial on a mobile device presents additional challenges compared to running it in a browser, mainly due to the application being launched on a different device, such as an Android smartphone or iPhone, rather than our computer. To overcome these challenges, the following steps need to be taken:</p> <ol> <li> <p>Localhost limitations:</p> <p>The usage of <code>localhost</code> in our Ionic app is restricted, preventing seamless communication between the application client and the server.</p> </li> <li> <p>Serve over local network:</p> <p>The application must be served over our local network to enable communication between the device and the server.</p> </li> <li> <p>Secure connection requirement for WebRTC API:</p> <p>The WebRTC API demands a secure connection for functionality outside of localhost, necessitating the serving of the application over HTTPS.</p> </li> </ol> <p>If you run OpenVidu locally you don't need to worry about this. OpenVidu will handle all of the above requirements for you. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Now, let's explore how to run the application on a mobile device:</p> <p>Requirements</p> <p>Before running the application on a mobile device, make sure that the device is connected to the same network as your PC and the mobile is connected to the PC via USB or Wi-Fi.</p>  Android device iOS device <pre><code>npm run android\n</code></pre> <p>You will need Ruby  and Cocoapods  installed in your computer.</p> <p>The app must be signed with a development team. To do so, open the project in Xcode and select a development team in the Signing &amp; Capabilities editor.</p> <pre><code>npm run ios\n</code></pre> <p>The script will ask you for the device you want to run the application on. You should select the real device you have connected to your computer.</p> <p>Once the mobile device has been selected, the script will launch the application on the device and you will see a screen like this:</p> <p></p><p></p><p></p> <p>This screen allows you to configure the URLs of the application server and the LiveKit server. You need to set them up for requesting tokens to your application server and connecting to the LiveKit server.</p> <p>Once you have configured the URLs, you can join a video call room by providing a room name and a user name. After joining the room, you will be able to see your own video and audio tracks, as well as the video and audio tracks of the other participants in the room.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> </li> </ol> <p>For more information, check the Ionic tutorial.</p> <p>To run the client application tutorial, you need Android Studio  installed on your development computer.</p> <ol> <li> <p>Open Android Studio and import the project located at <code>openvidu-livekit-tutorials/application-client/openvidu-android</code>.</p> </li> <li> <p>Run the application in an emulator or a physical device by clicking the \"Run\" button in Android Studio. Check out the official documentation  for further information.</p> </li> </ol> <p>The application will initiate as a native Android program. Once the application is opened, you should see a screen like this:</p> <p></p><p></p><p></p> <p>This screen allows you to configure the URLs of the application server and the LiveKit server. You need to set them up for requesting tokens to your application server and connecting to the LiveKit server.</p> <p>Connecting real Android device to application server running in you local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client in a real Android device and be able to reach the application server very easily without worrying about SSL certificates if they are both running in the same local network. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Once you have configured the URLs, you can join a video call room by providing a room name and a user name. After joining the room, you will be able to see your own video and audio tracks, as well as the video and audio tracks of the other participants in the room.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>For more information, check the Android tutorial.</p> <p>To run the client application tutorial, you need Xcode  installed on your MacOS.</p> <ol> <li> <p>Launch Xcode and open the <code>OpenViduIOS.xcodeproj</code> that you can find under <code>openvidu-livekit-tutorials/application-client/openvidu-ios</code>.</p> </li> <li> <p>Run the application in an emulator or a physical device by clicking on the menu Product &gt; Run or by \u2318R.</p> </li> </ol> <p>Emulator limitations</p> <p>Publishing the camera track is not supported by iOS Simulator.</p> <p>If you encounter code signing issues, make sure you change the Team and bundle id from the previous step.</p> <p>The application will initiate as a native iOS application. Once the app is opened, you should see a screen like this:</p> <p></p><p></p><p></p> <p>This screen allows you to configure the URLs of the application server and the LiveKit server. You need to set them up for requesting tokens to your application server and connecting to the LiveKit server.</p> <p>Connecting real iOS device to application server running in you local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client in a real iOS device and be able to reach the application server very easily without worrying about SSL certificates if they are both running in the same local network. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Once you have configured the URLs, you can join a video call room by providing a room name and a user name. After joining the room, you will be able to see your own video and audio tracks, as well as the video and audio tracks of the other participants in the room.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>For more information, check the iOS tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/python/#understanding-the-code","title":"Understanding the code","text":"<p>The application is a simple Flask app with a single file <code>app.py</code> that exports two endpoints:</p> <ul> <li><code>/token</code> : generate a token for a given Room name and Participant name.</li> <li><code>/livekit/webhook</code> : receive LiveKit webhook events.</li> </ul> <p>Let's see the code of the <code>app.py</code> file:</p> app.py<pre><code>import os\nfrom flask import Flask, request\nfrom flask_cors import CORS\nfrom dotenv import load_dotenv\nfrom livekit.api import AccessToken, VideoGrants, TokenVerifier, WebhookReceiver # (1)!\n\nload_dotenv() # (2)!\n\nSERVER_PORT = os.environ.get(\"SERVER_PORT\", 6080) # (3)!\nLIVEKIT_API_KEY = os.environ.get(\"LIVEKIT_API_KEY\", \"devkey\") # (4)!\nLIVEKIT_API_SECRET = os.environ.get(\"LIVEKIT_API_SECRET\", \"secret\") # (5)!\n\napp = Flask(__name__) # (6)!\n\nCORS(app) # (7)!\n</code></pre> <ol> <li>Import all necessary dependencies from <code>livekit</code> library</li> <li>Load environment variables from <code>.env</code> file</li> <li>The port where the application will be listening</li> <li>The API key of LiveKit Server</li> <li>The API secret of LiveKit Server</li> <li>Initialize the Flask application</li> <li>Enable CORS support</li> </ol> <p>The <code>app.py</code> file imports the required dependencies and loads the necessary environment variables from <code>.env</code> file using <code>dotenv</code> library:</p> <ul> <li><code>SERVER_PORT</code>: the port where the application will be listening.</li> <li><code>LIVEKIT_API_KEY</code>: the API key of LiveKit Server.</li> <li><code>LIVEKIT_API_SECRET</code>: the API secret of LiveKit Server.</li> </ul> <p>Finally the <code>Flask</code> application is initialized and CORS support is enabled.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/python/#create-token","title":"Create token","text":"<p>The endpoint <code>/token</code> accepts <code>POST</code> requests with a payload of type <code>application/json</code>, containing the following fields:</p> <ul> <li><code>roomName</code>: the name of the Room where the user wants to connect.</li> <li><code>participantName</code>: the name of the participant that wants to connect to the Room.</li> </ul> app.py<pre><code>@app.post(\"/token\")\ndef create_token():\n    room_name = request.json.get(\"roomName\")\n    participant_name = request.json.get(\"participantName\")\n\n    if not room_name or not participant_name:\n        return {\"errorMessage\": \"roomName and participantName are required\"}, 400\n\n    token = (\n        AccessToken(LIVEKIT_API_KEY, LIVEKIT_API_SECRET) # (1)!\n        .with_identity(participant_name) # (2)!\n        .with_grants(api.VideoGrants(room_join=True, room=room_name)) # (3)!\n    )\n    return {\"token\": token.to_jwt()} # (4)!\n</code></pre> <ol> <li>A new <code>AccessToken</code> is created providing the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code>.</li> <li>We set participant's identity in the AccessToken.</li> <li>We set the video grants in the AccessToken. <code>room_join</code> allows the user to join a room and <code>room</code> determines the specific room. Check out all Video Grants .</li> <li>Finally, we convert the AccessToken to a JWT token and send it back to the client.</li> </ol> <p>The endpoint first obtains the <code>roomName</code> and <code>participantName</code> parameters from the request body. If they are not available, it returns a <code>400</code> error.</p> <p>If required fields are available, a new JWT token is created. For that we use the LiveKit Python SDK :</p> <ol> <li>A new <code>AccessToken</code> is created providing the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code>.</li> <li>We set participant's identity in the AccessToken.</li> <li>We set the video grants in the AccessToken. <code>room_join</code> allows the user to join a room and <code>room</code> determines the specific room. Check out all Video Grants .</li> <li>Finally, we convert the AccessToken to a JWT token and send it back to the client.</li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/application-server/python/#receive-webhook","title":"Receive webhook","text":"<p>The endpoint <code>/livekit/webhook</code> accepts <code>POST</code> requests with a payload of type <code>application/webhook+json</code>. This is the endpoint where LiveKit Server will send webhook events .</p> app.py<pre><code>token_verifier = TokenVerifier(LIVEKIT_API_KEY, LIVEKIT_API_SECRET) # (1)!\nwebhook_receiver = WebhookReceiver(token_verifier) # (2)!\n\n\n@app.post(\"/livekit/webhook\")\ndef receive_webhook():\n    auth_token = request.headers.get(\"Authorization\") # (3)!\n\n    if not auth_token:\n        return \"Authorization header is required\", 401\n\n    try:\n        event = webhook_receiver.receive(request.data.decode(\"utf-8\"), auth_token) # (4)!\n        print(\"LiveKit Webhook:\", event) # (5)!\n        return \"ok\"\n    except:\n        print(\"Authorization header is not valid\")\n        return \"Authorization header is not valid\", 401\n</code></pre> <ol> <li>Initialize a <code>TokenVerifier</code> using the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code>.</li> <li>Initialize a <code>WebhookReceiver</code> using the <code>TokenVerifier</code>. It will help validating and decoding incoming webhook events .</li> <li>Get the 'Authorization' header from the HTTP request.</li> <li>Obtain the webhook event using the <code>WebhookReceiver#receive</code> method. It expects the raw body of the request and the 'Authorization' header.</li> <li>Consume the event as you whish.</li> </ol> <p>First of all, we need a <code>WebhookReceiver</code> for validating and decoding incoming webhook events. We initialize it with a <code>TokenVerifier</code> built with the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code>.</p> <p>Inside the <code>receive_webhook</code> handler we:</p> <ol> <li>Get the <code>Authorization</code> header from the HTTP request.</li> <li>Obtain the webhook event using the <code>WebhookReceiver#receive</code> method. It expects the raw body of the request and the <code>Authorization</code> header. In this way, we can validate the event to confirm it is actually coming from our LiveKit Server.</li> <li>If everything is ok, you can consume the event as you whish (in this case, we just log it).</li> </ol> <p>Configure Webhooks</p> <p>If you are using a production deployment, remember to configure the webhook URL to point to your local application server as explained in the Send Webhooks to a Local Application Server section.</p> <p></p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/ruby/","title":"Ruby Server Tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-server/ruby/#ruby-server-tutorial","title":"Ruby Server Tutorial","text":"<p>Source code </p> <p>This is a minimal server application built for Ruby with Sinatra  that allows:</p> <ul> <li>Generating LiveKit tokens on demand for any application client.</li> <li>Receiving LiveKit webhook events .</li> </ul> <p>It internally uses LiveKit Ruby SDK .</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/ruby/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-server/ruby/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/ruby/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/application-server/ruby/#3-run-the-server-application","title":"3. Run the server application","text":"<p>To run this server application, you need Ruby  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/ruby\n</code></pre></li> <li>Install dependencies <pre><code>bundle install\n</code></pre></li> <li>Run the application <pre><code>ruby app.rb\n</code></pre></li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/application-server/ruby/#4-run-a-client-application-to-test-against-this-server","title":"4. Run a client application to test against this server","text":"JavaScript React Angular Vue Electron Ionic Android iOS <p>To run the client application tutorial, you need an HTTP web server installed on your development computer. A great option is http-server . You can install it via NPM :</p> <pre><code>npm install -g http-server\n</code></pre> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-js\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>http-server -p 5080 ./src\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the JavaScript tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-react\n</code></pre> </li> <li> <p>Install dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Run the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the React tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-angular\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the Angular tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-vue\n</code></pre> </li> <li> <p>Install dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Run the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the Vue tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-electron\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Run the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>The application will seamlessly initiate as a native desktop program, adapting itself to the specific operating system you are using. Once the application is open, you should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Running your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the Electron tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-ionic\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <p>You have two options for running the client application: browser-based or mobile device-based:</p>  Browser Mobile <p>To run the application in a browser, you will need to start the Ionic server. To do so, run the following command:</p> <pre><code>npm start\n</code></pre> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p>Mobile appearance</p> <p>To show the app with a mobile device appearance, open the dev tools in your browser and find the button to adapt the viewport to a mobile device aspect ratio. You may also choose predefined types of devices to see the behavior of your app in different resolutions.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Running the tutorial on a mobile device presents additional challenges compared to running it in a browser, mainly due to the application being launched on a different device, such as an Android smartphone or iPhone, rather than our computer. To overcome these challenges, the following steps need to be taken:</p> <ol> <li> <p>Localhost limitations:</p> <p>The usage of <code>localhost</code> in our Ionic app is restricted, preventing seamless communication between the application client and the server.</p> </li> <li> <p>Serve over local network:</p> <p>The application must be served over our local network to enable communication between the device and the server.</p> </li> <li> <p>Secure connection requirement for WebRTC API:</p> <p>The WebRTC API demands a secure connection for functionality outside of localhost, necessitating the serving of the application over HTTPS.</p> </li> </ol> <p>If you run OpenVidu locally you don't need to worry about this. OpenVidu will handle all of the above requirements for you. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Now, let's explore how to run the application on a mobile device:</p> <p>Requirements</p> <p>Before running the application on a mobile device, make sure that the device is connected to the same network as your PC and the mobile is connected to the PC via USB or Wi-Fi.</p>  Android device iOS device <pre><code>npm run android\n</code></pre> <p>You will need Ruby  and Cocoapods  installed in your computer.</p> <p>The app must be signed with a development team. To do so, open the project in Xcode and select a development team in the Signing &amp; Capabilities editor.</p> <pre><code>npm run ios\n</code></pre> <p>The script will ask you for the device you want to run the application on. You should select the real device you have connected to your computer.</p> <p>Once the mobile device has been selected, the script will launch the application on the device and you will see a screen like this:</p> <p></p><p></p><p></p> <p>This screen allows you to configure the URLs of the application server and the LiveKit server. You need to set them up for requesting tokens to your application server and connecting to the LiveKit server.</p> <p>Once you have configured the URLs, you can join a video call room by providing a room name and a user name. After joining the room, you will be able to see your own video and audio tracks, as well as the video and audio tracks of the other participants in the room.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> </li> </ol> <p>For more information, check the Ionic tutorial.</p> <p>To run the client application tutorial, you need Android Studio  installed on your development computer.</p> <ol> <li> <p>Open Android Studio and import the project located at <code>openvidu-livekit-tutorials/application-client/openvidu-android</code>.</p> </li> <li> <p>Run the application in an emulator or a physical device by clicking the \"Run\" button in Android Studio. Check out the official documentation  for further information.</p> </li> </ol> <p>The application will initiate as a native Android program. Once the application is opened, you should see a screen like this:</p> <p></p><p></p><p></p> <p>This screen allows you to configure the URLs of the application server and the LiveKit server. You need to set them up for requesting tokens to your application server and connecting to the LiveKit server.</p> <p>Connecting real Android device to application server running in you local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client in a real Android device and be able to reach the application server very easily without worrying about SSL certificates if they are both running in the same local network. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Once you have configured the URLs, you can join a video call room by providing a room name and a user name. After joining the room, you will be able to see your own video and audio tracks, as well as the video and audio tracks of the other participants in the room.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>For more information, check the Android tutorial.</p> <p>To run the client application tutorial, you need Xcode  installed on your MacOS.</p> <ol> <li> <p>Launch Xcode and open the <code>OpenViduIOS.xcodeproj</code> that you can find under <code>openvidu-livekit-tutorials/application-client/openvidu-ios</code>.</p> </li> <li> <p>Run the application in an emulator or a physical device by clicking on the menu Product &gt; Run or by \u2318R.</p> </li> </ol> <p>Emulator limitations</p> <p>Publishing the camera track is not supported by iOS Simulator.</p> <p>If you encounter code signing issues, make sure you change the Team and bundle id from the previous step.</p> <p>The application will initiate as a native iOS application. Once the app is opened, you should see a screen like this:</p> <p></p><p></p><p></p> <p>This screen allows you to configure the URLs of the application server and the LiveKit server. You need to set them up for requesting tokens to your application server and connecting to the LiveKit server.</p> <p>Connecting real iOS device to application server running in you local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client in a real iOS device and be able to reach the application server very easily without worrying about SSL certificates if they are both running in the same local network. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Once you have configured the URLs, you can join a video call room by providing a room name and a user name. After joining the room, you will be able to see your own video and audio tracks, as well as the video and audio tracks of the other participants in the room.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>For more information, check the iOS tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/ruby/#understanding-the-code","title":"Understanding the code","text":"<p>The application is a simple Ruby app using the popular Sinatra web library. It has a single file <code>app.rb</code> that exports two endpoints:</p> <ul> <li><code>/token</code> : generate a token for a given Room name and Participant name.</li> <li><code>/livekit/webhook</code> : receive LiveKit webhook events.</li> </ul> <p>Let's see the code of the <code>app.rb</code> file:</p> app.rb<pre><code>require 'sinatra'\nrequire 'sinatra/cors'\nrequire 'sinatra/json'\nrequire 'livekit' # (1)!\nrequire './env.rb'\n\nSERVER_PORT = ENV['SERVER_PORT'] || 6080 # (2)!\nLIVEKIT_API_KEY = ENV['LIVEKIT_API_KEY'] || 'devkey' # (3)!\nLIVEKIT_API_SECRET = ENV['LIVEKIT_API_SECRET'] || 'secret' # (4)!\n\nset :port, SERVER_PORT # (5)!\n\nregister Sinatra::Cors # (6)!\nset :allow_origin, '*' # (7)!\nset :allow_methods, 'POST,OPTIONS'\nset :allow_headers, 'content-type'\nset :bind, '0.0.0.0' # (8)!\n</code></pre> <ol> <li>Import <code>livekit</code> library</li> <li>The port where the application will be listening</li> <li>The API key of LiveKit Server</li> <li>The API secret of LiveKit Server</li> <li>Configure the port</li> <li>Enable CORS support</li> <li>Set allowed origin (any), methods and headers</li> <li>Listen in any available network interface of the host</li> </ol> <p>The <code>app.rb</code> file imports the required dependencies and loads the necessary environment variables (defined in <code>env.rb</code> file):</p> <ul> <li><code>SERVER_PORT</code>: the port where the application will be listening.</li> <li><code>LIVEKIT_API_KEY</code>: the API key of LiveKit Server.</li> <li><code>LIVEKIT_API_SECRET</code>: the API secret of LiveKit Server.</li> </ul> <p>Finally the application configures the port, sets the CORS configuration for Sinatra and binds the application to all available network interfaces (0.0.0.0).</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/ruby/#create-token-endpoint","title":"Create token endpoint","text":"<p>The endpoint <code>/token</code> accepts <code>POST</code> requests with a payload of type <code>application/json</code>, containing the following fields:</p> <ul> <li><code>roomName</code>: the name of the Room where the user wants to connect.</li> <li><code>participantName</code>: the name of the participant that wants to connect to the Room.</li> </ul> app.rb<pre><code>post '/token' do\n  body = JSON.parse(request.body.read)\n  room_name = body['roomName']\n  participant_name = body['participantName']\n\n  if room_name.nil? || participant_name.nil?\n    status 400\n    return json({errorMessage: 'roomName and participantName are required'})\n  end\n\n  token = LiveKit::AccessToken.new(api_key: LIVEKIT_API_KEY, api_secret: LIVEKIT_API_SECRET) # (1)!\n  token.identity = participant_name # (2)!\n  token.add_grant(roomJoin: true, room: room_name) # (3)!\n\n  return json({token: token.to_jwt}) # (4)!\nend\n</code></pre> <ol> <li>A new <code>AccessToken</code> is created providing the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code>.</li> <li>We set participant's identity in the AccessToken.</li> <li>We set the video grants in the AccessToken. <code>roomJoin</code> allows the user to join a room and <code>room</code> determines the specific room. Check out all Video Grants .</li> <li>Finally, we convert the AccessToken to a JWT token and send it back to the client.</li> </ol> <p>The endpoint first obtains the <code>roomName</code> and <code>participantName</code> parameters from the request body. If they are not available, it returns a <code>400</code> error.</p> <p>If required fields are available, a new JWT token is created. For that we use the LiveKit Ruby SDK :</p> <ol> <li>A new <code>AccessToken</code> is created providing the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code>.</li> <li>We set participant's identity in the AccessToken.</li> <li>We set the video grants in the AccessToken. <code>roomJoin</code> allows the user to join a room and <code>room</code> determines the specific room. Check out all Video Grants .</li> <li>Finally, we convert the AccessToken to a JWT token and send it back to the client.</li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/application-server/ruby/#receive-webhook","title":"Receive webhook","text":"<p>The endpoint <code>/livekit/webhook</code> accepts <code>POST</code> requests with a payload of type <code>application/webhook+json</code>. This is the endpoint where LiveKit Server will send webhook events .</p> app.rb<pre><code>post '/livekit/webhook' do\n  auth_header = request.env['HTTP_AUTHORIZATION'] # (1)!\n  token_verifier = LiveKit::TokenVerifier.new(api_key: LIVEKIT_API_KEY, api_secret: LIVEKIT_API_SECRET) # (2)!\n  begin\n    token_verifier.verify(auth_header) # (3)!\n    body = JSON.parse(request.body.read) # (4)!\n    puts \"LiveKit Webhook: #{body}\" # (5)!\n    return\n  rescue =&gt; e\n    puts \"Authorization header is not valid: #{e}\"\n  end\nend\n</code></pre> <ol> <li>Get the <code>Authorization</code> header from the HTTP request.</li> <li>Create a new <code>TokenVerifier</code> instance providing the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code>. This will validate the webhook event to confirm it is actually coming from our LiveKit Server.</li> <li>Verify the <code>Authorization</code> header with the <code>TokenVerifier</code>.</li> <li>Now that we are sure the event is valid, we can parse the request JSON body to get the actual webhook event.</li> <li>Consume the event as you whish.</li> </ol> <p></p> <p>We need to verify that the event is coming from our LiveKit Server. For that we need the <code>Authorization</code> header from the HTTP request and a <code>TokenVerifier</code> instance built with the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code>.</p> <p>If the verification is successful, we can parse the request JSON body and consume the event (in this case, we just log it).</p> <p>Remember to return a <code>200</code> OK response at the end to let LiveKit Server know that the webhook was received correctly.</p> <p>Configure Webhooks</p> <p>If you are using a production deployment, remember to configure the webhook URL to point to your local application server as explained in the Send Webhooks to a Local Application Server section.</p> <p></p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/rust/","title":"Rust Server Tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-server/rust/#rust-server-tutorial","title":"Rust Server Tutorial","text":"<p>Source code </p> <p>This is a minimal server application built for Rust with Axum  that allows:</p> <ul> <li>Generating LiveKit tokens on demand for any application client.</li> <li>Receiving LiveKit webhook events .</li> </ul> <p>It internally uses the LiveKit Rust SDK .</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/rust/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Platform"]},{"location":"docs/tutorials/application-server/rust/#1-run-openvidu-server","title":"1. Run OpenVidu Server","text":"Run OpenVidu locallyDeploy OpenVidu <ol> <li> <p>Download OpenVidu</p> <pre><code>git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.0\n</code></pre> </li> <li> <p>Configure the local deployment</p>  Windows macOS Linux <pre><code>cd openvidu-local-deployment/community\n.\\configure_lan_private_ip_windows.bat\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_macos.sh\n</code></pre> <pre><code>cd openvidu-local-deployment/community\n./configure_lan_private_ip_linux.sh\n</code></pre> </li> <li> <p>Run OpenVidu</p> <pre><code>docker compose up\n</code></pre> </li> </ol> <p>To use a production-ready OpenVidu deployment, visit the official deployment guide.</p> <p>Configure Webhooks</p> <p>All application servers have an endpoint to receive webhooks from OpenVidu. For this reason, when using a production deployment you need to configure webhooks to point to your local application server in order to make it work. Check the Send Webhooks to a Local Application Server section for more information.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/rust/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-livekit-tutorials.git -b 3.4.0\n</code></pre>","tags":["Platform"]},{"location":"docs/tutorials/application-server/rust/#3-run-the-server-application","title":"3. Run the server application","text":"<p>To run this server application, you need Rust  installed on your device.</p> <ol> <li>Navigate into the server directory <pre><code>cd openvidu-livekit-tutorials/application-server/rust\n</code></pre></li> <li>Run the application <pre><code>cargo run\n</code></pre></li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/application-server/rust/#4-run-a-client-application-to-test-against-this-server","title":"4. Run a client application to test against this server","text":"JavaScript React Angular Vue Electron Ionic Android iOS <p>To run the client application tutorial, you need an HTTP web server installed on your development computer. A great option is http-server . You can install it via NPM :</p> <pre><code>npm install -g http-server\n</code></pre> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-js\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>http-server -p 5080 ./src\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the JavaScript tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-react\n</code></pre> </li> <li> <p>Install dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Run the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the React tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-angular\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the Angular tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-vue\n</code></pre> </li> <li> <p>Install dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Run the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the Vue tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-electron\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Run the application:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>The application will seamlessly initiate as a native desktop program, adapting itself to the specific operating system you are using. Once the application is open, you should see a screen like this:</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Running your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>For more information, check the Electron tutorial.</p> <p>To run the client application tutorial, you need Node.js  installed on your development computer.</p> <ol> <li> <p>Navigate into the application client directory:</p> <pre><code>cd openvidu-livekit-tutorials/application-client/openvidu-ionic\n</code></pre> </li> <li> <p>Install the required dependencies:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Serve the application:</p> <p>You have two options for running the client application: browser-based or mobile device-based:</p>  Browser Mobile <p>To run the application in a browser, you will need to start the Ionic server. To do so, run the following command:</p> <pre><code>npm start\n</code></pre> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:5080</code>. You should see a screen like this:</p> <p>Mobile appearance</p> <p>To show the app with a mobile device appearance, open the dev tools in your browser and find the button to adapt the viewport to a mobile device aspect ratio. You may also choose predefined types of devices to see the behavior of your app in different resolutions.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>Accessing your application client from other devices in your local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client with other devices in your local network very easily without worrying about SSL certificates.</p> <p>Access your application client through <code>https://xxx-yyy-zzz-www.openvidu-local.dev:5443</code>, where <code>xxx-yyy-zzz-www</code> part of the domain is your LAN private IP address with dashes (-) instead of dots (.). For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Running the tutorial on a mobile device presents additional challenges compared to running it in a browser, mainly due to the application being launched on a different device, such as an Android smartphone or iPhone, rather than our computer. To overcome these challenges, the following steps need to be taken:</p> <ol> <li> <p>Localhost limitations:</p> <p>The usage of <code>localhost</code> in our Ionic app is restricted, preventing seamless communication between the application client and the server.</p> </li> <li> <p>Serve over local network:</p> <p>The application must be served over our local network to enable communication between the device and the server.</p> </li> <li> <p>Secure connection requirement for WebRTC API:</p> <p>The WebRTC API demands a secure connection for functionality outside of localhost, necessitating the serving of the application over HTTPS.</p> </li> </ol> <p>If you run OpenVidu locally you don't need to worry about this. OpenVidu will handle all of the above requirements for you. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Now, let's explore how to run the application on a mobile device:</p> <p>Requirements</p> <p>Before running the application on a mobile device, make sure that the device is connected to the same network as your PC and the mobile is connected to the PC via USB or Wi-Fi.</p>  Android device iOS device <pre><code>npm run android\n</code></pre> <p>You will need Ruby  and Cocoapods  installed in your computer.</p> <p>The app must be signed with a development team. To do so, open the project in Xcode and select a development team in the Signing &amp; Capabilities editor.</p> <pre><code>npm run ios\n</code></pre> <p>The script will ask you for the device you want to run the application on. You should select the real device you have connected to your computer.</p> <p>Once the mobile device has been selected, the script will launch the application on the device and you will see a screen like this:</p> <p></p><p></p><p></p> <p>This screen allows you to configure the URLs of the application server and the LiveKit server. You need to set them up for requesting tokens to your application server and connecting to the LiveKit server.</p> <p>Once you have configured the URLs, you can join a video call room by providing a room name and a user name. After joining the room, you will be able to see your own video and audio tracks, as well as the video and audio tracks of the other participants in the room.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> </li> </ol> <p>For more information, check the Ionic tutorial.</p> <p>To run the client application tutorial, you need Android Studio  installed on your development computer.</p> <ol> <li> <p>Open Android Studio and import the project located at <code>openvidu-livekit-tutorials/application-client/openvidu-android</code>.</p> </li> <li> <p>Run the application in an emulator or a physical device by clicking the \"Run\" button in Android Studio. Check out the official documentation  for further information.</p> </li> </ol> <p>The application will initiate as a native Android program. Once the application is opened, you should see a screen like this:</p> <p></p><p></p><p></p> <p>This screen allows you to configure the URLs of the application server and the LiveKit server. You need to set them up for requesting tokens to your application server and connecting to the LiveKit server.</p> <p>Connecting real Android device to application server running in you local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client in a real Android device and be able to reach the application server very easily without worrying about SSL certificates if they are both running in the same local network. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Once you have configured the URLs, you can join a video call room by providing a room name and a user name. After joining the room, you will be able to see your own video and audio tracks, as well as the video and audio tracks of the other participants in the room.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>For more information, check the Android tutorial.</p> <p>To run the client application tutorial, you need Xcode  installed on your MacOS.</p> <ol> <li> <p>Launch Xcode and open the <code>OpenViduIOS.xcodeproj</code> that you can find under <code>openvidu-livekit-tutorials/application-client/openvidu-ios</code>.</p> </li> <li> <p>Run the application in an emulator or a physical device by clicking on the menu Product &gt; Run or by \u2318R.</p> </li> </ol> <p>Emulator limitations</p> <p>Publishing the camera track is not supported by iOS Simulator.</p> <p>If you encounter code signing issues, make sure you change the Team and bundle id from the previous step.</p> <p>The application will initiate as a native iOS application. Once the app is opened, you should see a screen like this:</p> <p></p><p></p><p></p> <p>This screen allows you to configure the URLs of the application server and the LiveKit server. You need to set them up for requesting tokens to your application server and connecting to the LiveKit server.</p> <p>Connecting real iOS device to application server running in you local network</p> <p>One advantage of running OpenVidu locally is that you can test your application client in a real iOS device and be able to reach the application server very easily without worrying about SSL certificates if they are both running in the same local network. For more information, see section Accessing your local deployment from other devices on your network.</p> <p>Once you have configured the URLs, you can join a video call room by providing a room name and a user name. After joining the room, you will be able to see your own video and audio tracks, as well as the video and audio tracks of the other participants in the room.</p> <p></p><p></p><p></p> <p></p><p></p><p></p> <p>For more information, check the iOS tutorial.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/rust/#understanding-the-code","title":"Understanding the code","text":"<p>The application is a simple Rust app with a single file <code>main.rs</code> that exports two endpoints:</p> <ul> <li><code>/token</code> : generate a token for a given Room name and Participant name.</li> <li><code>/livekit/webhook</code> : receive LiveKit webhook events.</li> </ul> <p>Let's see the code of the <code>main.rs</code> file:</p> main.rs<pre><code>use axum::http::HeaderMap;\nuse axum::{\n    extract::Json, http::header::CONTENT_TYPE, http::Method, http::StatusCode, routing::post,\n    Router,\n};\nuse dotenv::dotenv;\nuse livekit_api::access_token::AccessToken; // (1)!\nuse livekit_api::access_token::TokenVerifier;\nuse livekit_api::access_token::VideoGrants;\nuse livekit_api::webhooks::WebhookReceiver;\nuse serde_json::{json, Value};\nuse std::env;\nuse tokio::net::TcpListener;\nuse tower_http::cors::{Any, CorsLayer};\n\n#[tokio::main]\nasync fn main() {\n    dotenv().ok(); // (2)!\n\n    let server_port = env::var(\"SERVER_PORT\").unwrap_or(\"6081\".to_string());\n\n    let cors = CorsLayer::new() // (3)!\n        .allow_methods([Method::POST])\n        .allow_origin(Any)\n        .allow_headers([CONTENT_TYPE]);\n\n    let app = Router::new() // (4)!\n        .route(\"/token\", post(create_token))\n        .route(\"/livekit/webhook\", post(receive_webhook))\n        .layer(cors);\n\n    let listener = tokio::net::TcpListener::bind(\"0.0.0.0:\".to_string() + &amp;server_port)\n        .await\n        .unwrap();\n    axum::serve(listener, app).await.unwrap(); // (5)!\n}\n</code></pre> <ol> <li>Import all necessary dependencies from the Rust LiveKit library.</li> <li>Load environment variables from <code>.env</code> file.</li> <li>Enable CORS support.</li> <li>Define <code>/token</code> and <code>/livekit/webhook</code> endpoints.</li> <li>Start the server listening on the specified port.</li> </ol> <p>The <code>main.rs</code> file imports the required dependencies and loads the necessary environment variables:</p> <ul> <li><code>SERVER_PORT</code>: the port where the application will be listening.</li> <li><code>LIVEKIT_API_KEY</code>: the API key of LiveKit Server.</li> <li><code>LIVEKIT_API_SECRET</code>: the API secret of LiveKit Server.</li> </ul> <p>Then CORS support is enabled and the endpoints are defined. Finally the <code>axum</code> application is initialized on the specified port.</p>","tags":["Platform"]},{"location":"docs/tutorials/application-server/rust/#create-token-endpoint","title":"Create token endpoint","text":"<p>The endpoint <code>/token</code> accepts <code>POST</code> requests with a payload of type <code>application/json</code>, containing the following fields:</p> <ul> <li><code>roomName</code>: the name of the Room where the user wants to connect.</li> <li><code>participantName</code>: the name of the participant that wants to connect to the Room.</li> </ul> main.rs<pre><code>async fn create_token(payload: Option&lt;Json&lt;Value&gt;&gt;) -&gt; (StatusCode, Json&lt;Value&gt;) {\n    if let Some(payload) = payload {\n        let livekit_api_key = env::var(\"LIVEKIT_API_KEY\").unwrap_or(\"devkey\".to_string());\n        let livekit_api_secret = env::var(\"LIVEKIT_API_SECRET\").unwrap_or(\"secret\".to_string());\n\n        let room_name = match payload.get(\"roomName\") {\n            Some(value) =&gt; value,\n            None =&gt; {\n                return (\n                    StatusCode::BAD_REQUEST,\n                    Json(json!({ \"errorMessage\": \"roomName is required\" })),\n                );\n            }\n        };\n        let participant_name = match payload.get(\"participantName\") {\n            Some(value) =&gt; value,\n            None =&gt; {\n                return (\n                    StatusCode::BAD_REQUEST,\n                    Json(json!({ \"errorMessage\": \"participantName is required\" })),\n                );\n            }\n        };\n\n        let token = match AccessToken::with_api_key(&amp;livekit_api_key, &amp;livekit_api_secret) // (1)!\n            .with_identity(&amp;participant_name.to_string()) // (2)!\n            .with_name(&amp;participant_name.to_string())\n            .with_grants(VideoGrants { // (3)!\n                room_join: true,\n                room: room_name.to_string(),\n                ..Default::default()\n            })\n            .to_jwt() // (4)!\n        {\n            Ok(token) =&gt; token,\n            Err(_) =&gt; {\n                return (\n                    StatusCode::INTERNAL_SERVER_ERROR,\n                    Json(json!({ \"errorMessage\": \"Error creating token\" })),\n                );\n            }\n        };\n\n        return (StatusCode::OK, Json(json!({ \"token\": token }))); // (5)!\n    } else {\n        return (\n            StatusCode::BAD_REQUEST,\n            Json(json!({ \"errorMessage\": \"roomName and participantName are required\" })),\n        );\n    }\n}\n</code></pre> <ol> <li>A new <code>AccessToken</code> is created providing the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code>.</li> <li>We set participant's name and identity in the AccessToken.</li> <li>We set the video grants in the AccessToken. <code>room_join</code> allows the user to join a room and <code>room</code> determines the specific room. Check out all Video Grants .</li> <li>We convert the AccessToken to a JWT token.</li> <li>Finally, the token is sent back to the client.</li> </ol> <p>The endpoint first obtains the <code>roomName</code> and <code>participantName</code> parameters from the request body. If they are not available, it returns a <code>400</code> error.</p> <p>If required fields are available, a new JWT token is created. For that we use the LiveKit Rust SDK :</p> <ol> <li>A new <code>AccessToken</code> is created providing the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code>.</li> <li>We set participant's name and identity in the AccessToken.</li> <li>We set the video grants in the AccessToken. <code>room_join</code> allows the user to join a room and <code>room</code> determines the specific room. Check out all Video Grants .</li> <li>We convert the AccessToken to a JWT token.</li> <li>Finally, the token is sent back to the client.</li> </ol>","tags":["Platform"]},{"location":"docs/tutorials/application-server/rust/#receive-webhook","title":"Receive webhook","text":"<p>The endpoint <code>/livekit/webhook</code> accepts <code>POST</code> requests with a payload of type <code>application/webhook+json</code>. This is the endpoint where LiveKit Server will send webhook events .</p> main.rs<pre><code>async fn receive_webhook(headers: HeaderMap, body: String) -&gt; (StatusCode, String) {\n    let livekit_api_key = env::var(\"LIVEKIT_API_KEY\").unwrap_or(\"devkey\".to_string());\n    let livekit_api_secret = env::var(\"LIVEKIT_API_SECRET\").unwrap_or(\"secret\".to_string());\n    let token_verifier = TokenVerifier::with_api_key(&amp;livekit_api_key, &amp;livekit_api_secret); // (1)!\n    let webhook_receiver = WebhookReceiver::new(token_verifier); // (2)!\n\n    let auth_header = match headers.get(\"Authorization\") { // (3)!\n        Some(header_value) =&gt; match header_value.to_str() {\n            Ok(header_str) =&gt; header_str,\n            Err(_) =&gt; {\n                return (\n                    StatusCode::BAD_REQUEST,\n                    \"Invalid Authorization header format\".to_string(),\n                );\n            }\n        },\n        None =&gt; {\n            return (\n                StatusCode::BAD_REQUEST,\n                \"Authorization header is required\".to_string(),\n            );\n        }\n    };\n\n    match webhook_receiver.receive(&amp;body, auth_header) { // (4)!\n        Ok(event) =&gt; {\n            println!(\"LiveKit WebHook: {:?}\", event); // (5)!\n            return (StatusCode::OK, \"ok\".to_string());\n        }\n        Err(_) =&gt; {\n            return (\n                StatusCode::UNAUTHORIZED,\n                \"Error validating webhook event\".to_string(),\n            );\n        }\n    }\n}\n</code></pre> <ol> <li>Create a <code>TokenVerifier</code> with the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code>. This will validate the webhook event to confirm it is actually coming from our LiveKit Server.</li> <li>Create a <code>WebhookReceiver</code> with the <code>TokenVerifier</code>.</li> <li>Get the <code>Authorization</code> header from the HTTP request.</li> <li>Obtain the webhook event using the <code>WebhookReceiver#receive</code> method. It expects the raw string body of the request and the <code>Authorization</code> header.</li> <li>Consume the event as you wish.</li> </ol> <p>We declare as function parameters the map of headers (<code>headers: HeaderMap</code>) and the raw body (<code>body: String</code>) of the HTTP request. We will need both of them to validate and decode the incoming webhook event. We then:</p> <ol> <li>Create a <code>TokenVerifier</code> with the <code>LIVEKIT_API_KEY</code> and <code>LIVEKIT_API_SECRET</code>. This will validate the webhook event to confirm it is actually coming from our LiveKit Server.</li> <li>Create a <code>WebhookReceiver</code> with the <code>TokenVerifier</code>.</li> <li>Get the <code>Authorization</code> header from the HTTP request.</li> <li>Obtain the webhook event using the <code>WebhookReceiver#receive</code> method. It expects the raw string body of the request and the <code>Authorization</code> header.</li> <li>Consume the event as you wish (in this case, we just log it).</li> </ol> <p>Remember to return a <code>200</code> OK response at the end to let LiveKit Server know that the webhook was received correctly.</p> <p>Configure Webhooks</p> <p>If you are using a production deployment, remember to configure the webhook URL to point to your local application server as explained in the Send Webhooks to a Local Application Server section.</p> <p></p>","tags":["Platform"]},{"location":"docs/ui-components/angular-components/","title":"Angular Components","text":"","tags":["Platform"]},{"location":"docs/ui-components/angular-components/#angular-components","title":"Angular Components","text":"","tags":["Platform"]},{"location":"docs/ui-components/angular-components/#introduction","title":"Introduction","text":"<p>Angular Components are the simplest way to create real-time videoconferencing apps with Angular. There's no need to manage state or low-level events; Angular Components from OpenVidu handle all the complexity for you.</p> <p>This Angular library, offers developers a robust set of powerful and comprehensive videoconferencing components. These components are highly adaptable, extendable, and easily replaceable, allowing you to tailor them to your application's specific requirements.</p> <p> </p> Angular Components <p>The primary goal of the OpenVidu team is to minimize the developer's effort when creating videoconferencing applications. Angular Components significantly contribute to this objective for several reasons:</p> <ul> <li> <p> Rapid Development</p> <p>Abstracts the complexity of videoconferencing applications, allowing you to focus on customizations</p> </li> <li> <p> Flexible Customization</p> <p>Offers maximum customization flexibility, allowing you to adapt, extend, and replace any component</p> </li> <li> <p> Easy Maintenance</p> <p>Ensures your code remains up to date, making it easier to update your application with each new OpenVidu release</p> </li> </ul>","tags":["Platform"]},{"location":"docs/ui-components/angular-components/#how-to-use","title":"How to use","text":"<p>Using Angular Components in your application is straightforward. The official Angular Components Tutorials cover everything Angular Components offers, from customizing colors and branding logos to injecting new custom features.</p>","tags":["Platform"]},{"location":"docs/ui-components/angular-components/#featured-components","title":"Featured Components","text":"<ul> <li> <p>Videoconference</p> <p>The Videoconference component is the core of Angular Components. You can nest HTML and Angular components inside it or leave it empty to use the default setup.</p> <p> See Reference</p> </li> <li> <p>Panel</p> <p>The Panel components is the root of side panels in the videoconference. You can nest HTML and Angular components inside it or leave it empty to use the default setup.</p> <p> See Reference</p> </li> </ul>","tags":["Platform"]},{"location":"docs/ui-components/angular-components/#prefabricated-components","title":"Prefabricated Components","text":"<p>Angular Components provides a wide range of prefabricated components that you can use to build your videoconferencing application in a matter of minutes. These components are designed for direct use without any extensions or modifications.</p> Toolbar Layout Stream ChatPanel ParticipantsPanel ParticipantPanelItem ActivitiesPanel RecordingActivity BroadcastingActivity AdminLogin AdminDashboard","tags":["Platform"]},{"location":"docs/ui-components/angular-components/#directives","title":"Directives","text":"<p>Angular Components provides two types of directives: Structural Directives and Attribute Directives.</p> <ul> <li> <p>Structural Directives: These directives manipulate the DOM by adding or removing elements from the view.</p> <p>They are distinguished by the asterisk (*) prefix and must be placed inside an HTML element within any Featured Component.</p> <p>For example, the <code>*ovToolbar</code> directive allows you to add a custom toolbar to the videoconference, replacing the default one.</p> <p>You can check the list of available structural directives in the Angular Components API Reference.</p> </li> <li> <p>Attribute Directives: Commonly known as Components Inputs, allow you to manipulate the appearance or behavior of an element.</p> <p>You can check the list of available structural directives in the Angular Components API Reference.</p> </li> </ul>","tags":["Platform"]},{"location":"docs/ui-components/angular-components/#events","title":"Events","text":"<p>Each component in Angular Components emits a set of events that you can listen to in your application to trigger specific actions.</p> <p>These events are designed to provide you with the flexibility to customize your videoconferencing application according to your requirements.</p> <p>You can check out all component events in the Angular Components API Reference.</p>","tags":["Platform"]},{"location":"docs/ui-components/angular-components/#applications","title":"Applications","text":"<p>A practical example showcases the potential of Angular Components is our production-ready flagship application, OpenVidu Meet. This application is built using Angular Components and demonstrates the power and flexibility of the library.</p>","tags":["Platform"]},{"location":"docs/ui-components/angular-components/#references","title":"References","text":"<ul> <li>Angular Components API Reference</li> </ul>","tags":["Platform"]},{"location":"docs/ui-components/react-components/","title":"React Components","text":"","tags":["Platform"]},{"location":"docs/ui-components/react-components/#react-components","title":"React Components","text":"","tags":["Platform"]},{"location":"docs/ui-components/react-components/#introduction","title":"Introduction","text":"<p>React Components are the simplest way to create real-time audio/video applications with React. There's no need to manage state or low level events, React Components from LiveKit handle all the complexity for you.</p>","tags":["Platform"]},{"location":"docs/ui-components/react-components/#featured-components","title":"Featured Components","text":"<p>A curated set of components that we believe are essential and serve as a solid foundation for most applications.</p> <ul> <li> <p>LiveKitRoom</p> <p>It provides the Room context to all its children, serving as the root component of your application, and also exposes the Room state through a React context.</p> <p> See Reference</p> </li> <li> <p>RoomAudioRenderer</p> <p>It manages remote participants' audio tracks and ensures that microphones and screen sharing are audible. It also provides a way to control the volume of each participant.</p> <p> See Reference</p> </li> <li> <p>TrackLoop</p> <p>Provides an easy way to loop through all participant camera and screen tracks. For each track, TrackLoop creates a TrackRefContext that you can use to render the track.</p> <p> See Reference</p> </li> </ul>","tags":["Platform"]},{"location":"docs/ui-components/react-components/#prefabricated-components","title":"Prefabricated Components","text":"<p>Prefabricated are constructed using components and enhanced with additional functionalities, unique styles, and practical defaults. They are designed for immediate use and are not meant to be extended.</p> AudioConference Chat ControlBar MediaDeviceMenu PreJoin VideoConference","tags":["Platform"]},{"location":"docs/ui-components/react-components/#contexts","title":"Contexts","text":"<p>Contexts are used to allow child components to access parent state without having to pass it down the component tree via props</p> Participant Room Chat Feature Layout Pin TrackRef","tags":["Platform"]},{"location":"docs/ui-components/react-components/#hooks","title":"Hooks","text":"<p>Hooks are functions that let you use state and other React features without writing a class. They are functions that let you \u201chook into\u201d React state and lifecycle features from function components.</p> <p>React Components provides a set of hooks that you can use to interact with the components and the underlying LiveKit client.</p> <p> See Reference</p>","tags":["Platform"]},{"location":"docs/ui-components/react-components/#applications","title":"Applications","text":"<p>A practical example showcases the potential of React Components is the production-ready flagship application, LiveKit Meet . This application is built using React Components and demonstrates the power and flexibility of the library.</p>","tags":["Platform"]},{"location":"docs/ui-components/react-components/#references","title":"References","text":"<ul> <li>React Components </li> </ul>","tags":["Platform"]},{"location":"meet/","title":"OpenVidu Meet","text":"","tags":["Meet","setupwowjs","setupcardglow","setupcarousel","setupcustomgallery"]},{"location":"meet/#intro","title":"Intro Host and customize your own high-quality video calling service in minutes  Built for all purposes. Customizable for your particular use case.","text":"<ul> <li> <p> Feature-rich for videoconferencing</p> <p>OpenVidu Meet brings all the features you expect from a professional video calling solution: HD video, HiFi audio, recording, broadcasting, screen sharing, chat, virtual backgrounds, and more.</p> </li> <li> <p> Integrate right into your app</p> <p>OpenVidu Meet can be used out-of-the-box via web, but it also offers everything you need to embed it into your existing application: a web component, a REST API and webhooks.</p> </li> </ul> <ul> <li> <p> Secure, self-hosted deployments</p> <p>OpenVidu Meet is designed from the ground up to be self-hosted on your own servers (AWS and Azure templates also available). It provides the highest level of privacy and security for your video calls.</p> </li> <li> <p> Designed for most common use cases</p> <p>OpenVidu Meet perfectly fits most common videoconferencing use cases: e-learning, telehealth, remote collaboration, customer support... And you can customize its branding to match your organization\u2019s identity.</p> </li> </ul>","tags":["Meet","setupwowjs","setupcardglow","setupcarousel","setupcustomgallery"]},{"location":"meet/#features","title":"Features With all the features you need to fine-tune your perfect video calling service.","text":"<p>Multi-Party smart layout</p> <p>Connect dozens of participants in a room. OpenVidu Meet automatically adapts to provide the best experience.</p> <p></p> <ul> <li> <p>Pre-join view</p> <p>Your users can set up their video/audio devices, virtual background and language before entering the room.</p> <p></p> </li> <li> <p>Background filters</p> <p>Allow your users to easily replace their video background with a blur effect or an image.</p> <p></p> </li> </ul> <p>Record and share</p> <p>OpenVidu Meet offers high-quality recordings and greatly simplifies their storage and access control.</p> <ul> <li> <p>Pre-configure your rooms</p> <p>Create and customize the behavior of your rooms in a few clicks: look-and-feel, user permissions, recording, chat and more.</p> <p></p> </li> <li> <p>Share room links</p> <p>Unique secure links give access to your rooms with different permission levels.</p> <p></p> </li> </ul> <ul> <li> <p> One-click video calls</p> <p>Share links to allow users to join video calls. Compatible with any web browser. No installations required.</p> </li> <li> <p> Your own branding</p> <p>Deliver a professional experience by customizing OpenVidu Meet with your own domain, branding colors and logo.</p> </li> <li> <p> Up to 4K video and HiFi audio</p> <p>Up to 4K video resolution, and crisp audio quality with noise cancellation and echo suppression.</p> </li> </ul> <ul> <li> <p> Recording</p> <p>Record your video calls with different layouts. Manage recording permissions and access with ease.</p> </li> <li> <p> Screen Sharing</p> <p>Screen sharing with the best quality.</p> </li> <li> <p> Background effects</p> <p>Apply effects to your videos, blurring the background or replacing it with an image.</p> </li> </ul> <ul> <li> <p> Advanced chat</p> <p>OpenVidu Meet integrates an advanced chat with support of rich messages, emojis, reactions and more.</p> </li> <li> <p> Broadcasting</p> <p>OpenVidu Meet allows you to broadcast your video calls to platforms such as YouTube or Twitch.</p> </li> <li> <p> Live Captions</p> <p>Support for a vast number of speech-to-text providers.</p> </li> </ul> <ul> <li> <p> E2E Encryption</p> <p>Avoid man-in-the-middle attacks: only your final users can decrypt the audio, video and chat messages.</p> </li> <li> <p> Locked rooms</p> <p>Prevent unwanted guests and require administrator approval to join.</p> </li> <li> <p> File sharing</p> <p>Allow participants to share files during calls with a simple drag and drop.</p> </li> </ul>","tags":["Meet","setupwowjs","setupcardglow","setupcarousel","setupcustomgallery"]},{"location":"meet/#integrations","title":"Integrations","text":"<p>OpenVidu Meet can be easily integrated with your existing applications and workflows:</p> <p>Pre-built web component</p> <p>Embed the OpenVidu Meet UI right into your app.</p> <p></p> <p></p> <p>REST API and webhooks</p> <p>Control your meetings from your backend.</p> <pre><code>curl --request POST \\\n    --url https://YOUR_DOMAIN/api/v1/rooms \\\n    --header 'Accept: application/json' \\\n    --header 'Content-Type: application/json' \\\n    --header 'X-API-KEY: YOUR_API_KEY' \\\n    --data '{\"roomName\": \"my-room\"}'\n</code></pre>","tags":["Meet","setupwowjs","setupcardglow","setupcarousel","setupcustomgallery"]},{"location":"meet/#deployments","title":"Deployments Check out the deployment documentation.","text":"<p>Self-host OpenVidu Meet on your own infrastructure for maximum security and cost-effectiveness. It is easy to deploy, protect, maintain, and scale. No advanced DevOps skills are required to run it in production.</p> <ul> <li> <p> On Premises</p> <p>Deploy on your own bare-metal servers</p> </li> <li> <p> AWS</p> <p>Deploy with AWS CloudFormation</p> </li> <li> <p> Azure</p> <p>Deploy with Azure Resource Manager</p> </li> <li> <p> GCP</p> <p>Deploy in GCP with Terraform</p> </li> </ul>","tags":["Meet","setupwowjs","setupcardglow","setupcarousel","setupcustomgallery"]},{"location":"meet/#use-cases","title":"Use cases","text":"<p>Team meetings</p> <p>Empower collaboration across your organization with customizable, secure, high-quality video meetings.</p> <p></p> <ul> <li>OpenVidu Meet is the perfect tool for collaborative work. With its user-friendly interface and powerful features, teams can easily connect, share ideas, and make decisions in real-time.</li> </ul> <ul> <li> <p>Collaboration tools</p> <p>Screen sharing with top-tier quality, advanced chat with rich features, file sharing and more.</p> </li> <li> <p>Quick access and flexibility</p> <p>One-click join via secure room links. No installation required, full support for any web browser.</p> </li> <li> <p>Custom branding</p> <p>Achieve a professional look and feel with customizable domain, colors and logo.</p> </li> </ul> <p>e-Learning</p> <p>Deliver a seamless learning experience by embedding OpenVidu Meet in your LMS or e-learning portal using OpenVidu Meet Embedded.</p> <ul> <li>With OpenVidu Meet instructors can engage with students through high quality video &amp; audio, as well as advanced interactive tools. Locked rooms, breakout groups and many more features to enhance the learning experience.</li> </ul> <p></p> <ul> <li> <p>High quality media</p> <p>Up to 4K video and HiFi audio for crystal-clear lessons. Stable experience across all kind of network thanks to simulcast, SVC, dynacast and adaptive streaming.</p> </li> <li> <p>Accessibility</p> <p>Live captions and real-time transcriptions. OpenVidu Meet is localized in multiple languages.</p> </li> <li> <p>Persistence and continuity</p> <p>Record and share lessons with multiple layouts. Manage recordings and share via secure links.</p> </li> </ul> <p>Telehealth</p> <p>The most secure videoconference platform is the one you host on your own servers.</p> <p></p> <ul> <li>OpenVidu Meet is the ideal solution for telehealth services. Practitioners can conduct remote consultations, share medical documents, and ensure patient privacy with end-to-end encryption.</li> </ul> <ul> <li> <p>Security and privacy</p> <p>End-to-end encryption for audio, video, and chat. Locked rooms and administrator-controlled access. No third-party data routing.</p> </li> <li> <p>Accessibility and trust</p> <p>Browser-based with no installation needed. Live Captions and real-time transcriptions with specific support for medical language models.</p> </li> <li> <p>Communication and clarity</p> <p>Up to 4K and HiFi audio for clear communication between practitioners and patients. File sharing for medical documents and images.</p> </li> </ul> <p>Customer support</p> <p>Build trust with instant, reliable support through embedded video calls that persist. Right where your clients need it.</p> <ul> <li>Connecting your remote assistance team with your customers has never been so easy. OpenVidu Meet provides all the necessary tools for effective communication and collaboration, ensuring a seamless support experience.</li> </ul> <p></p> <ul> <li> <p>Ease of access</p> <p>Simple, one-click access via web: embed support rooms directly into your platform.</p> </li> <li> <p>Record assistance</p> <p>Record your customer support meetings and generate transcriptions for future reference.</p> </li> <li> <p>Custom branding</p> <p>Customize the look and feel of your support rooms to match your brand identity.</p> </li> </ul>","tags":["Meet","setupwowjs","setupcardglow","setupcarousel","setupcustomgallery"]},{"location":"meet/#free-open-source-edition-vs-commercial-edition","title":"Free open-source edition vs Commercial edition","text":"<p>OpenVidu Meet is available in two editions:</p>","tags":["Meet","setupwowjs","setupcardglow","setupcarousel","setupcustomgallery"]},{"location":"meet/#openvidu-community","title":"OpenVidu COMMUNITY","text":"<p>It is completely open-source and free to use. It includes all the features you need for your video conferencing solution. Everything listed in the Features section is available in OpenVidu Meet COMMUNITY: HD video, HiFi audio, recording, screen sharing, advanced chat, virtual backgrounds, and more.</p> <p>OpenVidu Meet COMMUNITY is perfect for production deployments with moderate user load. It can be easily deployed on your own servers, and you can customize its branding to match your organization\u2019s identity. If necessary, upgrading to OpenVidu PRO is seamless and non-disruptive.</p>","tags":["Meet","setupwowjs","setupcardglow","setupcarousel","setupcustomgallery"]},{"location":"meet/#openvidu-pro","title":"OpenVidu PRO","text":"<p>It is OpenVidu's commercial edition and requires a license. It is meant for high demanding environments with significant user load. On top of every functional feature available in OpenVidu COMMUNITY, OpenVidu PRO brings 2x performance, advanced observability, scalability and fault tolerance features. As well as priority support from our team of experts.</p> <p>OpenVidu PRO follows a simple pricing model based on the size of your deployment (number of CPU cores). Check the OpenVidu pricing page for more details.</p>  You can choose the OpenVidu edition that best fits your needs when deploying OpenVidu Meet.","tags":["Meet","setupwowjs","setupcardglow","setupcarousel","setupcustomgallery"]},{"location":"meet/#what-does-it-mean-that-openvidu-meet-is-in-beta","title":"What does it mean that OpenVidu Meet is in BETA? Need total control and advanced SDKs to build your custom real-time application? Checkout OpenVidu Platform","text":"<p>OpenVidu Meet (v3.4.0) is considered in BETA. There may be bugs and its APIs are subject to change. We are actively working on adding new features, improving existing ones, and fixing any issues that arise. Your feedback is invaluable to us during this phase, so please don't hesitate to reach out with any comments or suggestions.</p>","tags":["Meet","setupwowjs","setupcardglow","setupcarousel","setupcustomgallery"]},{"location":"meet/releases/","title":"Releases","text":"","tags":["Meet"]},{"location":"meet/releases/#340","title":"3.4.0","text":"<p>For the Release Notes of OpenVidu Platform 3.4.0, please visit here: OpenVidu Platform 3.4.0 </p>","tags":["Meet"]},{"location":"meet/releases/#introducing-openvidu-meet","title":"Introducing OpenVidu Meet","text":"<p>We are excited to announce a new product in the OpenVidu family: OpenVidu Meet.</p>","tags":["Meet"]},{"location":"meet/releases/#what-is-openvidu-meet","title":"What is OpenVidu Meet?","text":"<p>OpenVidu Meet is a fully featured video calling service built on top of OpenVidu, designed to provide an easy-to-use, self-hosted solution for virtual meetings. Its design principles are:</p> <ul> <li>Simplicity: OpenVidu Meet is built on the same concepts as OpenVidu, but wraps them in a higher-level API, ideal for virtual meeting use cases. Simply manage rooms, meetings, and recordings.</li> <li>Feature-rich: OpenVidu Meet includes all the features you would expect from a modern video conferencing solution: HQ audio/video, screen sharing, chat, recording, and more. We will be continuously adding more features, taking advantage of all the advanced capabilities of OpenVidu: live-captions, AI integrations, streaming to large audiences, breakout rooms...</li> <li>Refined UI/UX: OpenVidu Meet user interface boasts a modern and intuitive design. Years of experience in the video conferencing space have been distilled into a polished user experience that feels familiar and gets out of the way. Perfect for all kinds of use cases, from e-learning to telehealth, collaboration and customer support.</li> <li>Self-hosted and secure by design: OpenVidu Meet is self-hosted, allowing you to retain full control over your data and compliance, and at the same time leverage your infrastructure. It can be easily deployed on-premises or in the cloud, with native integrations available for AWS, Azure, and GCP.</li> <li>Embed-first integration: OpenVidu Meet can act as a final application, but it is also designed to be embedded into your own web app with minimal effort. It provides a Web Component, REST API and Webhooks to integrate rooms, automate lifecycles, and connect to your business logic.</li> </ul>","tags":["Meet"]},{"location":"meet/releases/#why-a-separate-openvidu-product","title":"Why a separate OpenVidu product?","text":"<p>Visitors to the OpenVidu website will notice that there are now two distinct products: OpenVidu Meet and OpenVidu Platform, with very distinct color schemes. Both products serve complementary needs:</p> <ul> <li>OpenVidu Platform is just what OpenVidu has always been: a powerful platform for builders who want complete flexibility with SDKs and APIs to craft bespoke real-time experiences. For users of any previous version of OpenVidu, nothing changes: what was previously \"OpenVidu\" has now simply been renamed \"OpenVidu Platform\".</li> <li>OpenVidu Meet is a response to the growing demand for specialized video conferencing solutions that cater to the unique needs of virtual meetings. While OpenVidu Platform provides a powerful foundation for real-time communication, OpenVidu Meet builds on that foundation to deliver a more focused set of features and a simplified integration process.</li> </ul> <p>By separating the product lines, we keep the developer\u2011first power of OpenVidu Platform while offering a refined, ready\u2011to\u2011use solution for common videoconferencing use cases (e\u2011learning, telehealth, collaboration, customer support...). This clarity helps teams choose low\u2011level control with OpenVidu Platform, or the fastest path to value-off\u2011the\u2011shelf with OpenVidu Meet. In short, many use cases that fall under the category of \"video conferencing applications\" can be satisfied with OpenVidu Meet, saving development time and resources.</p> <p>You can read more about the differences between both OpenVidu products here: OpenVidu Meet vs OpenVidu Platform.</p>","tags":["Meet"]},{"location":"meet/releases/#am-i-the-right-fit-for-openvidu-meet","title":"Am I the right fit for OpenVidu Meet?","text":"<p>If you are new to OpenVidu, you may find that OpenVidu Meet is ideal for teams, businesses, and organizations that need a reliable and secure video conferencing solution running on their servers. It is perfect for any use case that falls under the category of \"video conferencing application\", without the need for extensive custom development. OpenVidu Meet is currently built for the web, with mobile support coming soon.</p> <p>If your use case requires a high degree of customization, or if you need to build a unique real-time experience that goes beyond the typical video conferencing features, OpenVidu Platform is likely a better fit. It also supports a wider range of platforms, including native mobile and desktop applications.</p> <p>If you come from a previous version of OpenVidu (&lt;= 3.3.0), the most likely scenario is that you will still want to keep using OpenVidu Platform. However, if your application primarily focuses on video conferencing features, you may find that OpenVidu Meet offers a more streamlined and more maintainable solution. We invite you to give OpenVidu Meet a try and see if it aligns with your requirements!</p>","tags":["Meet"]},{"location":"meet/releases/#future-roadmap-of-openvidu-meet","title":"Future roadmap of OpenVidu Meet","text":"<ul> <li>Mobile platforms embedding (iOS and Android).</li> <li>More branding and customization options.</li> <li>Locked rooms.</li> <li>E2E encryption.</li> <li>Live captions.</li> <li>AI meeting summaries.</li> <li>And much more...</li> </ul>","tags":["Meet"]},{"location":"meet/releases/#get-started-with-openvidu-meet","title":"Get started with OpenVidu Meet","text":"<p>If you want to learn more about OpenVidu Meet, check out the following resources:</p> <ul> <li>Compare OpenVidu Meet vs OpenVidu Platform: OpenVidu Meet vs OpenVidu Platform</li> <li>Launch OpenVidu Meet locally in a couple of minutes: Try OpenVidu Meet locally</li> <li>Embed OpenVidu Meet into your web app: OpenVidu Meet Embedded</li> </ul>","tags":["Meet"]},{"location":"meet/deployment/advanced/","title":"Advanced deployments","text":"<p>Warning</p> <p>OpenVidu Meet is currently considered in BETA. There may be bugs and its APIs are subject to change.</p> <p>Info</p> <p>OpenVidu Meet is under the hood an OpenVidu Platform deployment with a module on top of it. Therefore, all deployment documentation for OpenVidu Platform applies to OpenVidu Meet as well. The information in this page is a summary of the different deployment options and the links to their corresponding OpenVidu Platform documentation.</p>","tags":["Meet"]},{"location":"meet/deployment/advanced/#deployment-types","title":"Deployment types","text":"<p>OpenVidu Meet can be easily deployed in a single server (follow the basic deployment guide). However, a single server won't be enough for environments that require scalability and high-availability. For such cases, it is necessary a multi-node deployment.</p> Type of deployment OpenViduLocal (development) OpenViduSingle Node OpenViduElastic OpenViduHigh Availability OpenVidu Edition COMMUNITY COMMUNITY PRO PRO PRO Suitability For local development in your laptop For applications with medium user load For applications with dynamic user load that require scalability For applications where both scalability and fault tolerance are critical Features Friendly Docker Compose setup with Redis, Egress, Ingress, S3 storage and observability. With automatic certificate management to test across devices in your network COMMUNITY Custom LiveKit distribution with Redis, Egress, Ingress, S3 storage and observability.PRO Same features but adding 2x performance and advanced observability. Same benefits as OpenVidu Single Node plus 2x performance, advanced observability and scalability Same benefits as OpenVidu Elastic plus fault tolerance Number of servers Your laptop 1 Node 1 Master Node +N Media Nodes 4 Master Nodes +N Media Nodes Installation instructions Try Install Install Install <p>Info</p> <p>You can learn more about the OpenViduCOMMUNITY and OpenViduPRO editions here.</p> <p></p>","tags":["Meet"]},{"location":"meet/deployment/advanced/#openvidu-local-development","title":"OpenVidu Local (development)","text":"<p>Run the OpenVidu Local deployment in your machine by following this guide.</p> <p>To run OpenVidu in your local machine, this is the quickest option. It is a Docker Compose setup that includes all the necessary services to run OpenVidu in your LAN, including automated SSL certificates that will be valid across all devices in your network.</p> <p> </p> OpenVidu Local (development)","tags":["Meet"]},{"location":"meet/deployment/advanced/#openvidu-single-node","title":"OpenVidu Single Node","text":"<p>You can install OpenVidu Meet as a Single Node deployment by following the basic deployment guide. You can also check out the OpenVidu Platform documentation for more detailed installation options.</p> <p>This is the simplest production-ready OpenVidu deployment available. It provides all the features you need, but lacks scalability and fault tolerance. But make no mistake about it: it is perfectly suitable for medium-scale production deployments. For most projects OpenVidu Single Node will be enough, at least until your user load gets serious. You can host hundreds of simultaneous participants in your rooms by running OpenVidu Community on a sufficiently powerful server!</p> <p>It is composed of a single OpenVidu Node hosting all the necessary services in a monolithic setup. It comes in two flavors:</p> <ul> <li>OpenVidu Single Node COMMUNITY: all the features you need to build your real-time application.</li> <li>OpenVidu Single Node PRO: for those users that want the benefits of OpenVidu PRO in a single-node setup. It includes 2x performance and advanced observability features.</li> </ul> <p> </p> OpenVidu Single Node","tags":["Meet"]},{"location":"meet/deployment/advanced/#openvidu-elastic","title":"OpenVidu Elastic","text":"<p>Install OpenVidu Elastic by following the OpenVidu Platform guide.</p> <p>This is the intermediate OpenVidu deployment. It provides scalability for your video rooms. Suitable for applications with dynamic load in the media plane that require scalability.</p> <p>It is composed of two different types of nodes, one of them running on a cluster of multiple servers and the other running as a single monolithic server:</p> <ul> <li>A cluster of Media Nodes hosting all the media-related services. Your video rooms scale up and down thanks to this cluster.</li> <li>A single Master Node hosting all the support services in a monolithic setup.</li> </ul> <p> </p> OpenVidu Elastic","tags":["Meet"]},{"location":"meet/deployment/advanced/#openvidu-high-availability","title":"OpenVidu High Availability","text":"<p>Install OpenVidu High Availability by following the OpenVidu Platform guide.</p> <p>This is the most complete OpenVidu deployment. It provides scalability for your video rooms and fault tolerance in all its services. Suitable for applications where both scalability and availability are critical.</p> <p>It is composed of two different types of nodes running on two separate clusters:</p> <ul> <li>A cluster of Media Nodes hosting all the media-related services. Your video rooms scale up and down thanks to this cluster. The minimum number of nodes in this cluster is 1, and it is designed to scale up and down dynamically according to workload.</li> <li>A cluster of Master Nodes hosting all the support services in their high availability format. Your deployment is fault-tolerant thanks to this cluster. The minimum number of nodes in this cluster is 4, and it is designed to have a fixed number of nodes at all times.</li> </ul> <p> </p> OpenVidu High Availability cluster","tags":["Meet"]},{"location":"meet/deployment/basic/","title":"Basic deployment","text":"<p>Warning</p> <p>OpenVidu Meet is currently considered in BETA. There may be bugs and its APIs are subject to change.</p> <p>This section contains the instructions to deploy a production-ready deployment of OpenVidu Meet in a single server.</p> <p>Info</p> <p>This guide shows a single-node installation in a Linux machine. To see other deployment options, such as deploying in cloud providers like AWS, Azure, or GCP, or deploying in a multi-node architecture, check the Other deployment options section at the end of this page.</p>","tags":["Meet"]},{"location":"meet/deployment/basic/#prerequisites","title":"Prerequisites","text":"","tags":["Meet"]},{"location":"meet/deployment/basic/#os","title":"OS","text":"<ul> <li>Ubuntu 22.04 or newer.</li> <li>User with root permissions (via <code>sudo</code>).</li> </ul>","tags":["Meet"]},{"location":"meet/deployment/basic/#recommended-hardware","title":"Recommended hardware","text":"<ul> <li>At least 4 GB RAM and 4 CPU cores.</li> <li>Generous disk space (100 GB recommended), especially if you plan to record your meetings.</li> </ul>","tags":["Meet"]},{"location":"meet/deployment/basic/#networking","title":"Networking","text":"<ul> <li>A public IP, that doesn't change between restarts (a static IP).</li> <li>(Recommended) A domain name (FQDN) pointing to the public IP.</li> <li> <p>Port rules: these inbound ports must be open in your firewall and reachable from the internet.</p> Protocol Ports Source Requirement TCP 80 0.0.0.0/0, ::/0 Mandatory TCP 443 0.0.0.0/0, ::/0 Mandatory UDP 443 0.0.0.0/0, ::/0 Mandatory TCP 7881 0.0.0.0/0, ::/0 Optional, but recommended for optimal perfomance and media quality UDP 50000 - 60000 0.0.0.0/0, ::/0 Optional, but recommended for optimal perfomance and media quality </li> </ul>","tags":["Meet"]},{"location":"meet/deployment/basic/#installation","title":"Installation","text":"<p>Run this command in your server to start the installation wizard:</p> <pre><code>sh &lt;(curl -fsSL http://get.openvidu.io/community/singlenode/latest/install_meet.sh)\n</code></pre> <p>Follow the instructions of the installation wizard. They are self-explanatory, but here is a breakdown:</p> <ol> <li> <p>Select Yes to continue when prompted after the installation summary:</p> <p></p> </li> <li> <p>If you have a domain name, enter it when prompted. If you don't have one, just press Enter to continue:</p> <p></p> </li> <li> <p>The installer will ask you to confirm if you want to proceed with the installation. Select Yes to start the installation. </p> <p>The installation will begin, downloading the software and configuring your server. Once the installation is complete, you will see this message:</p> <p></p> <p>You can access OpenVidu Meet in your browser using the URL and credentials shown in the installation completion message.</p> </li> </ol>","tags":["Meet"]},{"location":"meet/deployment/basic/#administration","title":"Administration","text":"<p>You can manage the OpenVidu Meet installation running simple commands on your server:</p> <pre><code># Start OpenVidu Meet\nsudo systemctl start openvidu\n\n# Stop OpenVidu Meet\nsudo systemctl stop openvidu\n\n# Restart OpenVidu Meet\nsudo systemctl restart openvidu\n</code></pre> <p>OpenVidu Meet is under the hood an OpenVidu Platform deployment, so you can refer to the OpenVidu Platform Single Node administration guide for more advanced management tasks, including:</p> <ul> <li>Check the status of services</li> <li>Check logs</li> <li>Upgrade OpenVidu Meet to a newer version</li> <li>Uninstall OpenVidu Meet</li> </ul>","tags":["Meet"]},{"location":"meet/deployment/basic/#other-deployment-options","title":"Other deployment options","text":"<p>This guide has covered the manual installation of OpenVidu Meet as a single-node deployment in a Linux server. Under the hood OpenVidu Meet is an OpenVidu Platform deployment, so there are further deployment options available:</p> <ul> <li>Non-interactive installation: you can run the installation wizard in a non-interactive way, providing all the required parameters in a single command. Check the Non-interactive installation guide for OpenVidu Platform.</li> <li>Deploy OpenVidu Meet single-node in AWS: using our CloudFormation template, you can deploy OpenVidu Meet using native AWS resources. Follow the AWS deployment guide for OpenVidu Platform.</li> <li>Deploy OpenVidu Meet single-node in Azure: using our ARM template, you can deploy OpenVidu Meet using native Azure resources. Follow the Azure deployment guide for OpenVidu Platform.</li> </ul> <ul> <li>Deploy OpenVidu Meet single-node in GCP: using our Terraform template, you can deploy OpenVidu Meet using native GCP resources. Follow the GCP deployment guide for OpenVidu Platform.</li> </ul> <ul> <li>Deploy OpenVidu Meet in a multi-node architecture: there are multi-node deployment options available to make your OpenVidu Meet installation scalable and fault-tolerant. Check out the Advanced deployments section for more information.</li> </ul>","tags":["Meet"]},{"location":"meet/deployment/local/","title":"Try OpenVidu Meet locally","text":"","tags":["Meet"]},{"location":"meet/deployment/local/#try-openvidu-meet-locally","title":"Try OpenVidu Meet locally","text":"<p>You can easily deploy OpenVidu Meet on your local machine to explore its features right away.</p> <p>You can simulate several users joining to the same room using different tabs of your preferred browser.</p> <p>This local deployment is the ideal choice to develop the embedding of OpenVidu Meet into your own application.</p> <p>Warning</p> <p>Remember that this deployment is designed for demo and development purposes. For production follow the Basic deployment or Advanced deployments.</p>","tags":["Meet"]},{"location":"meet/deployment/local/#prerequisites","title":"Prerequisites","text":"<ul> <li>A computer with Windows, macOS, or Linux installed.</li> <li>4 CPU cores and 8 GB of RAM (16 GB recommended for better performance).</li> <li>At least 10 GB of free disk space.</li> <li>Docker Desktop (see installation instructions below).</li> </ul>","tags":["Meet"]},{"location":"meet/deployment/local/#installing-docker-desktop","title":"Installing Docker Desktop","text":"<p>Docker is a technology the simplifies the installation of applications on Windows, macOS, and Linux. </p> <p>In the Docker terminology, an application is downloaded as a one or several docker images. When the application is executed, it is composed of one or several docker containers.</p> <p>Instructions to install Docker Desktop (the software needed to execute Docker containers):</p>  Windows macOS Linux <ul> <li>Install Docker Desktop </li> </ul> <ul> <li>Install Docker Desktop </li> </ul> <ul> <li>Install Docker Desktop </li> </ul> <p>Info</p> <p>This guide is based on Docker Desktop, but the commands can also be used directly in a linux machine's terminal with Docker Engine  and Docker Compose  installed. Make sure they are recent versions: Docker Engine &gt;= 28.4.0 and Docker Compose &gt;= 2.39.4</p>","tags":["Meet"]},{"location":"meet/deployment/local/#running-openvidu-meet-locally","title":"Running OpenVidu Meet Locally","text":"<ol> <li> <p>Open Docker Desktop and click on the \"Terminal\" button in the bottom right corner.</p> <p></p> </li> <li> <p>Copy and paste the following command into the terminal:</p> <pre><code>docker compose -p openvidu-meet -f oci://openvidu/local-meet:latest up -y openvidu-meet-init\n</code></pre> <p>Info</p> <p>If you want to deploy a specific version, replace <code>latest</code> with the desired version tag. E.g., to deploy version <code>3.4.0</code> use:</p> <pre><code>docker compose -p openvidu-meet -f oci://openvidu/local-meet:3.4.0 up -y openvidu-meet-init\n</code></pre> <p></p> </li> <li> <p>After pasting the command, press Enter to execute the command.</p> <p>The terminal will show how OpenVidu Meet is downloaded and executed.</p> <p>Firstly, OpenVidu Meet components (docker images) are downloaded (only the first time). It will take ~5 minutes on a 100 Mbps Internet connection.</p> <p>Then, OpenVidu Meet components (docker containers) are executed.</p> <p>Finally, the terminal will show when OpenVidu Meet is ready to be used:</p> <pre><code>openvidu-meet-init-1  | Waiting for OpenVidu to start...    \nopenvidu-meet-init-1  | Starting OpenVidu... Please be patient...\nopenvidu-meet-init-1  | Starting OpenVidu... Please be patient...\nopenvidu-meet-init-1  | Starting OpenVidu... Please be patient...\nopenvidu-meet-init-1  | Starting OpenVidu... Please be patient...\nopenvidu-meet-init-1  | Starting OpenVidu... Please be patient...\nopenvidu-meet-init-1  | Starting OpenVidu... Please be patient...\n...\nopenvidu-meet-init-1  |\nopenvidu-meet-init-1  | ====================================================\nopenvidu-meet-init-1  | \ud83c\udf89 OpenVidu Meet main is ready! \ud83c\udf89\nopenvidu-meet-init-1  | ====================================================\nopenvidu-meet-init-1  |\nopenvidu-meet-init-1  | This version is only for local development purposes.\nopenvidu-meet-init-1  | DO NOT USE IT IN PRODUCTION!\nopenvidu-meet-init-1  |\nopenvidu-meet-init-1  | ------------------OpenVidu Meet---------------------\nopenvidu-meet-init-1  | &gt; NOTE: Below are the default initial login credentials\nopenvidu-meet-init-1  | &gt; for OpenVidu Meet. If you update them after deployment,\nopenvidu-meet-init-1  | &gt; this message will not reflect those changes.\nopenvidu-meet-init-1  | ----------------------------------------------------\nopenvidu-meet-init-1  |     - Access from this machine:\nopenvidu-meet-init-1  |         - http://localhost:9080\nopenvidu-meet-init-1  |     - Credentials:\nopenvidu-meet-init-1  |         - Username: admin\nopenvidu-meet-init-1  |         - Password: admin\nopenvidu-meet-init-1  |         - API Key: meet-api-key\nopenvidu-meet-init-1  | ----------------------------------------------------\n</code></pre> </li> </ol>","tags":["Meet"]},{"location":"meet/deployment/local/#accessing-openvidu-meet","title":"Accessing OpenVidu Meet","text":"<p>You can access OpenVidu Meet by opening http://localhost:9080 in your web browser with credentials:</p> <ul> <li>Username: <code>admin</code></li> <li>Password: <code>admin</code></li> </ul> <p>You can use the REST API to embed OpenVidu Meet using:</p> <ul> <li>API Key: <code>meet-api-key</code> </li> </ul> <p>You can change them later from the OpenVidu Meet Users And Permissions.</p>","tags":["Meet"]},{"location":"meet/deployment/local/#managing-the-deployment","title":"Managing the deployment","text":"<p>Once installed and executed, <code>openvidu-meet</code> will appear in Docker Desktop \u2192 Containers section.</p> <p></p> <p>You can manage OpenVidu Meet execution interactively:</p> StopStartRemoveView logs <ol> <li>Click the Stop button.</li> </ol> <p></p> <ol> <li>Click the Start button.</li> </ol> <p></p> <p>Warning</p> <p>It will remove rooms and recordings.</p> <ol> <li> <p>Click the Delete button.</p> <p></p> </li> <li> <p>Go to Docker Desktop \u2192 Images.</p> </li> <li> <p>Remove the images related to OpenVidu Meet.</p> <p></p> </li> <li> <p>Go to Docker Desktop \u2192 Volumes.</p> </li> <li> <p>Remove the volumes related to OpenVidu Meet.</p> <p></p> </li> </ol> <ol> <li>Click on the container group to open its details. The logs will be shown after clicking on the container group.</li> </ol> <p> </p>","tags":["Meet"]},{"location":"meet/deployment/local/#accessing-openvidu-meet-from-other-computers-or-phones","title":"Accessing OpenVidu Meet from other computers or phones","text":"<p>You can connect to OpenVidu Meet from other computers or phones. It is very useful to join several people to the same room and try the communication features.</p> <p>Follow these steps:</p> <ol> <li> <p>Be sure that other computers or phones are connected to the same Wi-Fi or local network (LAN) where OpenVidu Meet is installed.</p> </li> <li> <p>Stop OpenVidu Meet if it is already started.</p> </li> <li> <p>Start it again with a new command.</p>  Windows macOS Linux <ol> <li> <p>Obtain the local IP of the computer where OpenVidu is intalled following this guide . It typically is similar to <code>192.168.1.100</code>.</p> </li> <li> <p>Execute the following command in Docker Desktop (replacing <code>&lt;YOUR_PRIVATE_IP&gt;</code> with the IP obtained)</p> </li> </ol> <pre><code>$env:LAN_PRIVATE_IP='&lt;YOUR_PRIVATE_IP&gt;'; docker compose -p openvidu-meet -f oci://openvidu/local-meet:latest up -y openvidu-meet-init\n</code></pre> <ol> <li> <p>Obtain the local IP of the computer where OpenVidu is intalled following this guide . It typically is similar to <code>192.168.1.100</code>.</p> </li> <li> <p>Execute the following command in Docker Desktop (replacing <code>&lt;YOUR_PRIVATE_IP&gt;</code> with the IP obtained)</p> </li> </ol> <pre><code>LAN_PRIVATE_IP='&lt;YOUR_PRIVATE_IP&gt;' docker compose -p openvidu-meet -f oci://openvidu/local-meet:latest up -y openvidu-meet-init\n</code></pre> <ol> <li> <p>Obtain the local IP of the computer where OpenVidu is intalled following this guide . It typically is similar to <code>192.168.1.100</code>.</p> </li> <li> <p>Execute the following command in Docker Desktop (replacing <code>&lt;YOUR_PRIVATE_IP&gt;</code> with the IP obtained)</p> </li> </ol> <pre><code>LAN_PRIVATE_IP='&lt;YOUR_PRIVATE_IP&gt;' docker compose -p openvidu-meet -f oci://openvidu/local-meet:latest up -y openvidu-meet-init\n</code></pre> </li> <li> <p>Access to OpenVidu Meet with a different URL:</p> <p>When OpenVidu Meet is ready to be used the terminal will show the URL where it is accessible.</p> <p>For example, if your private IP is <code>192.168.1.100</code> you have to use the URL <code>https://192-168-1-100.openvidu-local.dev:9443</code>.</p> <p>You will see the following instructions in the terminal when OpenVidu Meet is ready:</p> <pre><code>openvidu-meet-init-1  |\nopenvidu-meet-init-1  | ====================================================\nopenvidu-meet-init-1  | \ud83c\udf89 OpenVidu Meet main is ready! \ud83c\udf89\nopenvidu-meet-init-1  | ====================================================\nopenvidu-meet-init-1  |\nopenvidu-meet-init-1  | This version is only for local development purposes.\nopenvidu-meet-init-1  | DO NOT USE IT IN PRODUCTION!\nopenvidu-meet-init-1  |\nopenvidu-meet-init-1  | ------------------OpenVidu Meet---------------------\nopenvidu-meet-init-1  | &gt; NOTE: Below are the default initial login credentials\nopenvidu-meet-init-1  | &gt; for OpenVidu Meet. If you update them after deployment,\nopenvidu-meet-init-1  | &gt; this message will not reflect those changes.\nopenvidu-meet-init-1  | ----------------------------------------------------\nopenvidu-meet-init-1  |     - Access from this machine:\nopenvidu-meet-init-1  |         - https://192-168-1-100.openvidu-local.dev:9443\nopenvidu-meet-init-1  |     - Credentials:\nopenvidu-meet-init-1  |         - Username: admin\nopenvidu-meet-init-1  |         - Password: admin\nopenvidu-meet-init-1  |         - API Key: meet-api-key\nopenvidu-meet-init-1  | ----------------------------------------------------\n</code></pre> </li> </ol>","tags":["Meet"]},{"location":"meet/deployment/local/#advanced-local-deployment","title":"Advanced Local Deployment","text":"<p>If you want to modify some configurations or have more control over the local deployment, you can deploy the OpenVidu Platform Local deployment which by default includes OpenVidu Meet as one of its services.</p>","tags":["Meet"]},{"location":"meet/deployment/overview/","title":"OpenVidu Meet deployment overview","text":"","tags":["Meet"]},{"location":"meet/deployment/overview/#openvidu-meet-deployment-overview","title":"OpenVidu Meet deployment overview","text":"","tags":["Meet"]},{"location":"meet/deployment/overview/#production-ready","title":"Production ready","text":"<p>OpenVidu Meet is designed to be self-hosted, whether it is on premises or in a cloud provider. It brings to your own managed service advanced capabilities usually reserved only for SaaS solutions. There are two main reasons why you may need to self-host the real-time solution yourself:</p> <ul> <li>Privacy: you can't afford to let your client's data get out of your reach. OpenVidu allows you to meet all your privacy and regulatory requirements: no data at all is sent to any third-party server. Everything is self-contained on your own servers.</li> <li>Leverage your resources: your organization has access to its own infrastructure that can be used to host these services. SaaS solutions generally offer complete freedom from infrastructure management, but this comes with generally high prices that cover both the provider's infrastructure and their service surcharge. OpenVidu allows taking full advantage of your own infrastructure, reducing costs and increasing performance.</li> </ul> <p>It is important to mention that when we talk about self-hosting OpenVidu, we don't just mean installing it in bare-metal servers or private VPCs. OpenVidu also supports deployments in the most popular cloud providers, using their native services when possible. AWS and Azure are currently supported, and others are coming soon. You can learn more about the different options to deploy OpenVidu in the deployment types section.</p> <p>One of OpenVidu's main goals is offering a self-hosted, production-ready live-video platform with all the advanced capabilities typically reserved for SaaS solutions. This includes outstanding performance, scalability, fault tolerance and observability:</p> <ul> <li> <p> Performance</p> <p>OpenVidu is built to be incredibly powerful. It is based on the best open source WebRTC stacks: LiveKit  and mediasoup . By combining the best of both worlds, OpenVidu provides outstanding performance.</p> <p> Learn more about performance</p> </li> <li> <p> Scalability</p> <p>OpenVidu has been designed from the outset with scalability in mind. Host videoconference rooms and large live streams with hundreds of participants. Autoscale your cluster to adapt to the demand and optimize your resources.</p> <p> Learn more about scalability</p> </li> <li> <p> Fault Tolerance</p> <p>OpenVidu offers fault tolerance in all its components. Deploy a reliable high-availability cluster knowing that if one of your node goes down, others will be able to continue working with no downtime.</p> <p> Learn more about fault tolerance</p> </li> <li> <p> Observability</p> <p>OpenVidu brings everything necessary to monitor the status, health, load and history of your deployment. It automatically collects events, metrics and logs, and provides OpenVidu Dashboard and a Grafana stack to navigate them.</p> <p> Learn more about observability</p> </li> </ul>","tags":["Meet"]},{"location":"meet/deployment/overview/#openvidu-meet-editions","title":"OpenVidu Meet editions","text":"<p>OpenVidu Meet is available in two editions:</p>","tags":["Meet"]},{"location":"meet/deployment/overview/#openvidu-community","title":"OpenVidu COMMUNITY","text":"<p>It is completely open-source and free to use. It includes all the features you need for your video conferencing solution. Everything listed in the Features section is available in OpenVidu Meet COMMUNITY: HD video, HiFi audio, recording, screen sharing, advanced chat, virtual backgrounds, and more.</p> <p>OpenVidu Meet COMMUNITY is perfect for production deployments with moderate user load. It can be easily deployed on your own servers, and you can customize its branding to match your organization\u2019s identity. If necessary, upgrading to OpenVidu PRO is seamless and non-disruptive.</p>","tags":["Meet"]},{"location":"meet/deployment/overview/#openvidu-pro","title":"OpenVidu PRO","text":"<p>It is OpenVidu's commercial edition and requires a license. It is meant for high demanding environments with significant user load. On top of every functional feature available in OpenVidu COMMUNITY, OpenVidu PRO brings 2x performance, advanced observability, scalability and fault tolerance features. As well as priority support from our team of experts.</p> <p>OpenVidu PRO follows a simple pricing model based on the size of your deployment (number of CPU cores). Check the OpenVidu pricing page for more details.</p> <p>Info</p> <p>Different OpenVidu deployment types support different editions.</p>","tags":["Meet"]},{"location":"meet/deployment/overview/#deployment-types","title":"Deployment types","text":"<p>OpenVidu Meet offers user-friendly installers that facilitate quick on-premises deployments, so you can self-host your real-time solution in your own infrastructure or any cloud provider.</p> <p>The following documentation pages focus on three different deployments:</p> <ul> <li>Local deployment, to test and develop in your machine.</li> <li>Basic deployment, a production installation requiring a single server.</li> <li>Advanced deployments, a production installation requiring multiple servers for scalability and high-availability.</li> </ul> <p>The table below summarizes the main characteristics of each deployment type.</p> Type of deployment OpenVidu Meet:Local deployment OpenVidu Meet:Basic deployment OpenVidu Meet:Advanced deployment OpenVidu Edition COMMUNITY COMMUNITY PRO Suitability Suitable to test and develop Suitable for production applications with medium user load Suitable for production applications with dynamic user load and need for high availability Features Try out all OpenVidu Meet features in your laptop All OpenVidu Meet features, ready for production All OpenVidu Meet features ready for production, plus 2x performance, advanced observability, scalability and fault tolerance Number of servers Your laptop 1 server Multiple servers Installation instructions Try Install Install","tags":["Meet"]},{"location":"meet/embedded/intro/","title":"OpenVidu Meet Embedded","text":"<p>With OpenVidu Meet Embedded, you can integrate the best video calling experience directly into your own application:</p> <ul> <li>Quick setup using a URL, an iframe or a Web Component.</li> <li>Integrate into your application's logic using REST API and Webhooks.</li> <li>Customizable user interface to match your app's branding and style.</li> </ul> <p>Add video calling capabilities to your app with a single line of HTML</p> <pre><code>&lt;openvidu-meet room-url=\"https://YOUR_DOMAIN/room/your-room?secret=1234567\"&gt;&lt;/openvidu-meet&gt;\n</code></pre> <ul> <li> <p>Create rooms through REST API</p> <pre><code>curl --request POST \\\n  --url https://YOUR_DOMAIN/api/v1/rooms \\\n  --header 'Accept: application/json' \\\n  --header 'Content-Type: application/json' \\\n  --header 'X-API-KEY: YOUR_API_KEY' \\\n  --data '{\"roomName\": \"my-room\"}'\n</code></pre> </li> <li> <p>Manage recordings through REST API</p> <pre><code>curl --request GET \\\n  --url https://YOUR_DOMAIN/api/v1/recordings \\\n  --header 'Accept: application/json' \\\n  --header 'X-API-KEY: YOUR_API_KEY'\n</code></pre> </li> </ul> <p>Integrate OpenVidu Meet into your own UI and business logic</p> <p></p> <p></p>  Where to start? We recommend following the step by step guide or exploring one of our tutorials.","tags":["Meet","setupcustomgallery"]},{"location":"meet/embedded/step-by-step-guide/","title":"Step by step guide","text":"","tags":["Meet","setupcustomgallery"]},{"location":"meet/embedded/step-by-step-guide/#1-run-openvidu-meet","title":"1. Run OpenVidu Meet","text":"<p>You need Docker Desktop. You can install it on Windows , Mac  or Linux .</p> <p>Run this command in Docker Desktop's terminal:</p> <pre><code>docker compose -p openvidu-meet -f oci://openvidu/local-meet:3.4.0 up -y openvidu-meet-init\n</code></pre> <p>Info</p> <p>For a detailed guide on how to run OpenVidu Meet locally, visit Try OpenVidu Meet locally .</p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/embedded/step-by-step-guide/#2-create-a-room","title":"2. Create a room","text":"<p>You can create a room from the \"Rooms\" page in OpenVidu Meet:</p> <p> </p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/embedded/step-by-step-guide/#automating-room-creation","title":"Automating room creation","text":"<p>You can automate the room creation process by using the OpenVidu Meet REST API. This allows you to create rooms programmatically from your application's backend, without manual intervention.</p> <p>Check out the API reference for creating rooms . Below you have copy-paste snippets for most common languages.</p> <p>Info</p> <p>Remember to replace <code>YOUR_OPENVIDU_DEPLOYMENT_DOMAIN</code> and <code>YOUR_API_KEY</code> in the snippets below.</p>  curl Node.js Go Ruby Java Python Rust PHP .NET <pre><code>curl --request POST \\\n    --url https://YOUR_OPENVIDU_DEPLOYMENT_DOMAIN/api/v1/rooms \\\n    --header 'Accept: application/json' \\\n    --header 'Content-Type: application/json' \\\n    --header 'X-API-KEY: YOUR_API_KEY' \\\n    --data '{\"roomName\": \"my-room\"}'\n    --data '{\"roomName\": \"my-room\"}'\n</code></pre> <pre><code>const https = require('https');\n\nconst options = {\n    method: 'POST',\n    hostname: 'YOUR_OPENVIDU_DEPLOYMENT_DOMAIN',\n    port: 443,\n    path: '/api/v1/rooms',\n    headers: {\n        'Content-Type': 'application/json',\n        Accept: 'application/json',\n        'X-API-KEY': 'YOUR_API_KEY'\n    }\n};\n\nconst req = https.request(options, function (res) {\n    const chunks = [];\n    res.on('data', function (chunk) {\n        chunks.push(chunk);\n    });\n    res.on('end', function () {\n        const body = Buffer.concat(chunks);\n        console.log(body.toString());\n    });\n});\n\nreq.write(JSON.stringify({\n    roomName: 'my-room',\n}));\n\nreq.end();\n</code></pre> <pre><code>package main\n\nimport (\n    \"fmt\"\n    \"strings\"\n    \"net/http\"\n    \"io\"\n)\n\nfunc main() {\n\n    url := \"https://YOUR_OPENVIDU_DEPLOYMENT_DOMAIN/api/v1/rooms\"\n\n    payload := strings.NewReader(\"{\\\"roomName\\\":\\\"my-room\\\"}\")\n\n    req, _ := http.NewRequest(\"POST\", url, payload)\n\n    req.Header.Add(\"Content-Type\", \"application/json\")\n    req.Header.Add(\"Accept\", \"application/json\")\n    req.Header.Add(\"X-API-KEY\", \"YOUR_API_KEY\")\n\n    res, _ := http.DefaultClient.Do(req)\n\n    defer res.Body.Close()\n    body, _ := io.ReadAll(res.Body)\n\n    fmt.Println(res)\n    fmt.Println(string(body))\n\n}\n</code></pre> <pre><code>require 'uri'\nrequire 'net/http'\nrequire 'openssl'\n\nurl = URI(\"https://YOUR_OPENVIDU_DEPLOYMENT_DOMAIN/api/v1/rooms\")\n\nhttp = Net::HTTP.new(url.host, url.port)\nhttp.use_ssl = true\n\nrequest = Net::HTTP::Post.new(url)\nrequest[\"Content-Type\"] = 'application/json'\nrequest[\"Accept\"] = 'application/json'\nrequest[\"X-API-KEY\"] = 'YOUR_API_KEY'\nrequest.body = \"{\\\"roomName\\\": \\\"my-room\\\"}\"\n\nresponse = http.request(request)\nputs response.read_body\n</code></pre> <pre><code>HttpRequest request = HttpRequest.newBuilder()\n    .uri(URI.create(\"https://YOUR_OPENVIDU_DEPLOYMENT_DOMAIN/api/v1/rooms\"))\n    .header(\"Content-Type\", \"application/json\")\n    .header(\"Accept\", \"application/json\")\n    .header(\"X-API-KEY\", \"YOUR_API_KEY\")\n    .method(\"POST\", HttpRequest.BodyPublishers.ofString(\"{\\\"roomName\\\": \\\"my-room\\\"}\"))\n    .build();\nHttpResponse&lt;String&gt; response = HttpClient.newHttpClient().send(request, HttpResponse.BodyHandlers.ofString());\nSystem.out.println(response.body());\n</code></pre> <pre><code>import http.client\n\nconn = http.client.HTTPSConnection(\"YOUR_OPENVIDU_DEPLOYMENT_DOMAIN\")\n\npayload = \"{\\\"roomName\\\": \\\"my-room\\\"}\"\n\nheaders = {\n    'Content-Type': \"application/json\",\n    'Accept': \"application/json\",\n    'X-API-KEY': \"YOUR_API_KEY\"\n}\n\nconn.request(\"POST\", \"/api/v1/rooms\", payload, headers)\n\nres = conn.getresponse()\ndata = res.read()\n\nprint(data.decode(\"utf-8\"))\n</code></pre> <pre><code>// Cargo.toml:\n// reqwest = { version = \"0.12\", features = [\"blocking\", \"rustls-tls\"] }\n\nuse reqwest::blocking::Client;\nuse reqwest::header::{ACCEPT, CONTENT_TYPE};\n\nfn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {\n    let client = Client::new();\n    let url = \"https://YOUR_OPENVIDU_DEPLOYMENT_DOMAIN/api/v1/rooms\";\n    let payload = r#\"{\"roomName\": \"my-room\"}\"#;\n\n    let resp = client\n        .post(url)\n        .header(ACCEPT, \"application/json\")\n        .header(CONTENT_TYPE, \"application/json\")\n        .header(\"X-API-KEY\", \"YOUR_API_KEY\")\n        .body(payload)\n        .send()?;\n\n    println!(\"Status: {}\", resp.status());\n    println!(\"{}\", resp.text()?);\n    Ok(())\n}\n</code></pre> <pre><code>&lt;?php\n\n$curl = curl_init();\n\ncurl_setopt_array($curl, [\n    CURLOPT_URL =&gt; \"https://YOUR_OPENVIDU_DEPLOYMENT_DOMAIN/api/v1/rooms\",\n    CURLOPT_RETURNTRANSFER =&gt; true,\n    CURLOPT_POST =&gt; true,\n    CURLOPT_POSTFIELDS =&gt; json_encode(['roomName' =&gt; 'my-room']),\n    CURLOPT_HTTPHEADER =&gt; [\n        \"Accept: application/json\",\n        \"Content-Type: application/json\",\n        \"X-API-KEY: YOUR_API_KEY\"\n    ],\n]);\n\n$response = curl_exec($curl);\n$err = curl_error($curl);\n\ncurl_close($curl);\n\nif ($err) {\n    echo \"cURL Error #:\" . $err;\n} else {\n    echo $response;\n}\n</code></pre> <pre><code>using System.Net.Http.Headers;\nvar client = new HttpClient();\nvar request = new HttpRequestMessage\n{\n    Method = HttpMethod.Post,\n    RequestUri = new Uri(\"https://YOUR_OPENVIDU_DEPLOYMENT_DOMAIN/api/v1/rooms\"),\n    Headers =\n    {\n        { \"Accept\", \"application/json\" },\n        { \"X-API-KEY\", \"YOUR_API_KEY\" },\n    },\n    Content = new StringContent(\"{\\\"roomName\\\": \\\"my-room\\\"}\")\n    {\n        Headers =\n        {\n            ContentType = new MediaTypeHeaderValue(\"application/json\")\n        }\n    }\n};\nusing (var response = await client.SendAsync(request))\n{\n    response.EnsureSuccessStatusCode();\n    var body = await response.Content.ReadAsStringAsync();\n    Console.WriteLine(body);\n}\n</code></pre> <p>The response to this request will be a JSON object as below. The required properties for the next step are <code>moderatorUrl</code> and <code>speakerUrl</code>, needed to embed the room into your application as explained in step 3.</p> <pre><code>{\n  \"roomId\": \"room-123\",\n  \"roomName\": \"My Room\",\n  \"creationDate\": 1620000000000,\n  \"autoDeletionDate\": 1900000000000,\n  \"autoDeletionPolicy\": {\n    \"withMeeting\": \"when_meeting_ends\",\n    \"withRecordings\": \"close\"\n  },\n  \"config\": {\n    \"chat\": {\n      \"enabled\": true\n    },\n    \"recording\": {\n      \"enabled\": true,\n      \"allowAccessTo\": \"admin_moderator_speaker\"\n    },\n    \"virtualBackground\": {\n      \"enabled\": true\n    }\n  },\n  \"moderatorUrl\": \"http://localhost:6080/room/room-123?secret=123456\",\n  \"speakerUrl\": \"http://localhost:6080/room/room-123?secret=654321\",\n  \"status\": \"open\",\n  \"meetingEndAction\": \"none\"\n}\n</code></pre>","tags":["Meet","setupcustomgallery"]},{"location":"meet/embedded/step-by-step-guide/#3-get-the-room-url","title":"3. Get the room URL","text":"<p>To embed a room into your application's frontend you need the room URL. You can copy the room URL for each participant role from the \"Rooms\" page in OpenVidu Meet console:</p> <p></p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/embedded/step-by-step-guide/#automating-room-url-retrieval","title":"Automating room URL retrieval","text":"<p>You can get the room URLs programmatically using the OpenVidu Meet REST API. They are available in properties <code>moderatorUrl</code> and <code>speakerUrl</code> of object MeetRoom . This object is returned as a JSON response from methods:</p> <ul> <li>Create a room </li> <li>Get a room </li> <li>Get all rooms </li> </ul>","tags":["Meet","setupcustomgallery"]},{"location":"meet/embedded/step-by-step-guide/#4-embed-the-room-into-your-application","title":"4. Embed the room into your application","text":"<p>Once you got the desired room URL, there are 3 alternatives to embed the OpenVidu Meet room into your application's interface:</p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/embedded/step-by-step-guide/#use-a-direct-link","title":"Use a direct link","text":"<p>This is the simplest and easiest way to embed an OpenVidu Meet room into your application. It's a perfect fit if your frontend is a web application, and you don't need any custom elements in the video meeting UI: the polished UI of OpenVidu Meet will be displayed in its own browser tab.</p> <p>Just link to the room URL from any element in your frontend. For example, with a simple <code>&lt;a&gt;</code> tag:</p> <pre><code>&lt;a href=\"{{ your-room-url }}\"&gt;Join Room&lt;/a&gt;\n</code></pre> <p>After clicking on the element, the user will be redirected to OpenVidu Meet, ready to join the room.</p> <p></p> <p>Info</p> <p>You can customize the room by simply appending query parameters to the room URL. For example, you can redirect back to your application after the user leaves the room by appending this query param: <code>https://{{ your-room-url }}&amp;leave-redirect-url=https://myapp.com</code></p> <p>See Passing attributes to a direct link for more information.</p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/embedded/step-by-step-guide/#use-the-web-component","title":"Use the Web Component","text":"<p>The OpenVidu Meet Web Component is the best option if you want to integrate the OpenVidu Meet UI along your own custom UI. OpenVidu Meet will simply become another component of your UI, blending seamlessly with your application's design and logic.</p> <p>Include a <code>&lt;script&gt;</code> tag to load the OpenVidu Meet Web Component definition from your OpenVidu deployment. Then, you can use the <code>&lt;openvidu-meet&gt;</code> custom element in your HTML, setting the <code>room-url</code> attribute.</p> <p>Info</p> <p>Check out the Web Component reference for the complete list of attributes, commands and events offered by it.</p> <pre><code>&lt;html&gt;\n    &lt;head&gt;\n        &lt;title&gt;My meeting&lt;/title&gt;\n        &lt;script src=\"https://{{ your-openvidu-deployment-domain }}/v1/openvidu-meet.js\"&gt;&lt;/script&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;div&gt;\n            &lt;openvidu-meet room-url=\"{{ your-room-url }}\"&gt;&lt;/openvidu-meet&gt;\n        &lt;/div&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p></p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/embedded/step-by-step-guide/#use-an-iframe","title":"Use an iframe","text":"<p>Some applications may not allow including a Web Component. For these cases OpenVidu Meet can be embedded using a traditional iframe.</p> <pre><code>&lt;html&gt;\n    &lt;head&gt;\n        &lt;title&gt;My meeting&lt;/title&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;div&gt;\n            &lt;iframe\n                src=\"{{ your-room-url }}\"\n                allow=\"camera; microphone; display-capture; fullscreen; autoplay; compute-pressure;\"\n                width=\"100%\" height=\"100%\"&gt;\n            &lt;/iframe&gt;\n        &lt;/div&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>The required iframe attributes are:</p> <ul> <li><code>src</code>: the room URL.</li> <li><code>allow</code>: the minimum permissions required by the iframe for the room to work fine. These are:<ul> <li><code>camera</code>: allow access to the camera.</li> <li><code>microphone</code>: allow access to the microphone.</li> <li><code>display-capture</code>: allow screen sharing.</li> <li><code>fullscreen</code>: allow full screen mode.</li> <li><code>autoplay</code>: allow autoplay of media.</li> <li><code>compute-pressure</code>: allow access to the device's compute pressure API.</li> </ul> </li> </ul> <p>Info</p> <p>The same attributes, commands and events available for the Web Component may also be used in an iframe. Check out these sections to learn how:</p> <ul> <li>Pass attributes to an OpenVidu Meet iframe</li> <li>Send commands to an OpenVidu Meet iframe</li> <li>Receive events from an OpenVidu Meet iframe</li> </ul>","tags":["Meet","setupcustomgallery"]},{"location":"meet/embedded/step-by-step-guide/#5-embed-recordings-into-your-application","title":"5. Embed recordings into your application","text":"<p>If your use case includes recording your rooms, you can also embed them right into your app. You can embed the list of recordings of a room or directly show the player for a specific recording.</p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/embedded/step-by-step-guide/#embed-the-list-of-recordings-of-a-room","title":"Embed the list of recordings of a room","text":"<p>To show the list of recordings of a room, declare attribute <code>show-only-recordings</code> in the embedding element:</p> <pre><code>&lt;openvidu-meet room-url=\"{{ your-room-url }}\" show-only-recordings=\"true\"&gt;&lt;/openvidu-meet&gt;\n</code></pre> <p>Info</p> <p>Checkout the Web Component's attributes section for more information.</p> <p>This will show the list of recordings for the specified room:</p> <p></p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/embedded/step-by-step-guide/#embed-the-player-for-a-specific-recording","title":"Embed the player for a specific recording","text":"<p>To show the player for a specific recording, replace attribute <code>room-url</code> with <code>recording-url</code> in the embedding element. The recording URL can be obtained from:</p> <ul> <li>OpenVidu Meet console</li> <li>Programmatically via REST API </li> </ul> <pre><code>&lt;openvidu-meet recording-url=\"{{ your-recording-url }}\"&gt;&lt;/openvidu-meet&gt;\n</code></pre> <p>Info</p> <p>Checkout the Web Component's attributes section for more information.</p> <p>This will show the player for the specified recording:</p> <p></p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/embedded/step-by-step-guide/#6-rest-api-and-webhooks","title":"6. REST API and Webhooks","text":"<p>Up to this point everything has been focused on the client-side integration of OpenVidu Meet. To integrate OpenVidu Meet into your application's backend you have available:</p> <ul> <li>REST API: manage rooms and recordings programmatically.</li> <li>Webhooks: listen to events happening in real time.</li> </ul>","tags":["Meet","setupcustomgallery"]},{"location":"meet/embedded/reference/direct-link/","title":"Direct Link","text":"","tags":["Meet"]},{"location":"meet/embedded/reference/direct-link/#direct-link","title":"Direct Link","text":"<p>Redirect users to OpenVidu Meet using simple HTML links. This is the simplest way to integrate OpenVidu Meet into your application - perfect when you want users to join meetings in a new browser tab or window with the polished OpenVidu Meet interface.</p>","tags":["Meet"]},{"location":"meet/embedded/reference/direct-link/#usage","title":"Usage","text":"<p>Create a direct link to an OpenVidu Meet room using a simple HTML anchor tag:</p> <pre><code>&lt;a href=\"https://your-meet-domain.com/room/MyRoom-abcdef?secret=12345\"&gt;Join Room&lt;/a&gt;\n</code></pre> <p>When users click the link, they'll be redirected to OpenVidu Meet in their browser, ready to join the room.</p> <p>Info</p> <p>You can get room URLs programmatically from your backend using the REST API properties <code>moderatorUrl</code> or <code>speakerUrl</code>.</p>","tags":["Meet"]},{"location":"meet/embedded/reference/direct-link/#api-reference","title":"API Reference","text":"","tags":["Meet"]},{"location":"meet/embedded/reference/direct-link/#attributes","title":"Attributes","text":"<p>Info</p> <p>Direct links accept the same attributes as the OpenVidu Meet Web Component. See Web Component Attributes for the full list and descriptions.</p> <p>Customize the meeting by passing attributes as query parameters in the room URL:</p> <pre><code>&lt;a href=\"https://your-meet-domain.com/room/MyRoom-abcdef?secret=12345&amp;participant-name=John&amp;leave-redirect-url=https://meeting.end.url/\"&gt;\n    Join Room as John\n&lt;/a&gt;\n</code></pre>","tags":["Meet"]},{"location":"meet/embedded/reference/direct-link/#commands","title":"Commands","text":"<p>Direct links do not support programmatic commands since the meeting opens in a separate browser tab/window. If you need to control the meeting programmatically, consider using the Web Component or Iframe approaches instead.</p>","tags":["Meet"]},{"location":"meet/embedded/reference/direct-link/#events","title":"Events","text":"<p>Direct links do not emit events to your application since the meeting runs in a separate browser context. If you need to listen to meeting events, consider using the Web Component or Iframe approaches instead.</p>","tags":["Meet"]},{"location":"meet/embedded/reference/iframe/","title":"Iframe","text":"","tags":["Meet"]},{"location":"meet/embedded/reference/iframe/#iframe","title":"Iframe","text":"<p>Embed OpenVidu Meet directly into your application using a traditional HTML iframe. This approach is perfect for applications that cannot use OpenVidu Meet Web Component or need a simple integration method.</p>","tags":["Meet"]},{"location":"meet/embedded/reference/iframe/#usage","title":"Usage","text":"<p>Embed OpenVidu Meet by adding an iframe to your HTML with the room URL and required permissions:</p> <pre><code>&lt;iframe\n    src=\"https://your-meet-domain.com/room/MyRoom-abcdef?secret=12345\"\n    allow=\"camera; microphone; display-capture; fullscreen; autoplay; compute-pressure;\"\n    width=\"100%\" height=\"100%\"&gt;\n&lt;/iframe&gt;\n</code></pre>","tags":["Meet"]},{"location":"meet/embedded/reference/iframe/#required-iframe-attributes","title":"Required iframe attributes","text":"<ul> <li><code>src</code>: The room URL to join</li> <li><code>allow</code>: Permissions required for the meeting to work properly:<ul> <li><code>camera</code>: Access to the camera</li> <li><code>microphone</code>: Access to the microphone</li> <li><code>display-capture</code>: Screen sharing capability</li> <li><code>fullscreen</code>: Full screen mode</li> <li><code>autoplay</code>: Media autoplay</li> <li><code>compute-pressure</code>: Device performance monitoring</li> </ul> </li> </ul> <p>Info</p> <p>You can get room URLs programmatically from your backend using the REST API properties <code>moderatorUrl</code> or <code>speakerUrl</code>.</p>","tags":["Meet"]},{"location":"meet/embedded/reference/iframe/#api-reference","title":"API Reference","text":"","tags":["Meet"]},{"location":"meet/embedded/reference/iframe/#attributes","title":"Attributes","text":"<p>Info</p> <p>The iframe accepts the same attributes as the OpenVidu Meet Web Component. See Web Component Attributes for the full list and descriptions.</p> <p>Customize the participant name and meeting redirect by adding attributes as query parameters in the iframe src URL.</p> <pre><code>&lt;iframe\n    src=\"https://your-meet-domain.com/room/MyRoom-abcdef?secret=12345&amp;participant-name=John&amp;leave-redirect-url=https://meeting.end.url/\"\n    allow=\"camera; microphone; display-capture; fullscreen; autoplay; compute-pressure;\"\n    width=\"100%\" height=\"100%\"&gt;\n&lt;/iframe&gt;\n</code></pre>","tags":["Meet"]},{"location":"meet/embedded/reference/iframe/#commands","title":"Commands","text":"<p>Info</p> <p>The iframe accepts the same commands as the OpenVidu Meet Web Component. See Web Component Commands for the full list and descriptions.</p> <p>Control the meeting programmatically by sending commands via <code>postMessage</code> to the iframe's content window:</p> <pre><code>const iframe = document.querySelector('iframe');\nconst targetOrigin = '*'; // Replace with your actual domain\niframe.contentWindow.postMessage({ command: 'leaveRoom' }, targetOrigin);\n</code></pre>","tags":["Meet"]},{"location":"meet/embedded/reference/iframe/#events","title":"Events","text":"<p>Info</p> <p>The iframe emits the same events as the OpenVidu Meet Web Component. See Web Component Events for the full list and descriptions.</p> <p>Listen to meeting events by monitoring messages from the iframe:</p> <pre><code>const iframe = document.querySelector('iframe');\n\nwindow.addEventListener('message', (event) =&gt; {\n    // Verify the event origin for security\n    if (event.origin !== 'https://your-meet-domain.com') return;\n\n    const message = event.data;\n\n    if (!message || !message.event) {\n        return;\n    }\n\n    console.log('Received event from iframe:', message.event, message.payload);\n});\n</code></pre>","tags":["Meet"]},{"location":"meet/embedded/reference/rest-api/","title":"REST API","text":"","tags":["Meet"]},{"location":"meet/embedded/reference/rest-api/#overview","title":"Overview","text":"<p>OpenVidu Meet provides a REST API for managing rooms and recordings programmatically from your application's backend. As a general rule, any action that is available in OpenVidu Meet UI for rooms and recordings can also be performed using the REST API.</p> <p>There are two endpoints:</p> <ul> <li><code>/api/v1/rooms</code>: manage rooms.</li> <li><code>/api/v1/recordings</code>: manage recordings.</li> </ul>","tags":["Meet"]},{"location":"meet/embedded/reference/rest-api/#authentication","title":"Authentication","text":"<p>Any request to the OpenVidu Meet REST API must include a valid API key in the <code>X-API-KEY</code> header:</p> <pre><code>X-API-KEY: your-openvidu-meet-api-key\n</code></pre>","tags":["Meet"]},{"location":"meet/embedded/reference/rest-api/#generate-an-api-key","title":"Generate an API key","text":"<ol> <li>Connect to OpenVidu Meet console at <code>https://YOUR_OPENVIDU_DEPLOYMENT_DOMAIN/</code>.</li> <li>Navigate to the \"Embedded\" page.</li> <li>Click on \" Generate API Key\" button.</li> </ol>","tags":["Meet"]},{"location":"meet/embedded/reference/rest-api/#reference","title":"Reference","text":"<p>You can access the REST API reference documentation at:</p> <ul> <li>OpenVidu Meet REST API Reference </li> <li>Your own OpenVidu Meet deployment serves the documentation at <code>https://{{ your-openvidu-deployment-domain }}/api/v1/docs/</code></li> </ul>","tags":["Meet"]},{"location":"meet/embedded/reference/rest-api/#code-snippets","title":"Code snippets","text":"<p>The reference documentation provides code snippets for each REST API method. You can choose from countless languages and frameworks and copy-paste directly to your code.</p> <p></p> <p></p>","tags":["Meet"]},{"location":"meet/embedded/reference/rest-api/#testing-api-endpoints","title":"Testing API Endpoints","text":"<p>When accessing the REST API documentation from your own OpenVidu Meet deployment at <code>https://{{ your-openvidu-deployment-domain }}/api/v1/docs/</code>, you can test every endpoint directly from the browser. This is a great way to explore the API's body requests and responses.</p> <p>Just configure a valid API key in the <code>X-API-KEY</code> header input.</p> <p></p>","tags":["Meet"]},{"location":"meet/embedded/reference/webcomponent/","title":"Webcomponent","text":"","tags":["Meet"]},{"location":"meet/embedded/reference/webcomponent/#web-component","title":"Web Component","text":"<p>OpenVidu Meet's Web Component allows embedding the refined, well-crafted OpenVidu Meet interface directly into your application. It offers attributes to customize the videoconferencing experience, exposes commands for programmatic control, and emits events for integration with your own application's logic.</p>","tags":["Meet"]},{"location":"meet/embedded/reference/webcomponent/#installation","title":"Installation","text":"<p>Include the following script in your HTML:</p> <pre><code>&lt;script src=\"https://{{ your-openvidu-deployment-domain }}/v1/openvidu-meet.js\"&gt;&lt;/script&gt;\n</code></pre>","tags":["Meet"]},{"location":"meet/embedded/reference/webcomponent/#usage","title":"Usage","text":"<p>Add the <code>&lt;openvidu-meet&gt;</code> tag to your HTML. This will embed OpenVidu Meet interface into your application:</p> <pre><code>&lt;openvidu-meet room-url=\"{{ my-room-url }}\"&gt;&lt;/openvidu-meet&gt;\n</code></pre> <p>The only required attribute is <code>room-url</code>, which determines the room to join. Different instances of the web component using the same room URL will access the same meeting.</p> <p>Info</p> <p>You can get a room's URL programmatically from your application's backend: properties <code>moderatorUrl</code> and <code>speakerUrl</code> of object MeetRoom .</p>","tags":["Meet"]},{"location":"meet/embedded/reference/webcomponent/#api-reference","title":"API Reference","text":"","tags":["Meet"]},{"location":"meet/embedded/reference/webcomponent/#attributes","title":"Attributes","text":"<p>Declare attributes in the component to customize the meeting for your user.</p> Attribute Description Required <code>room-url</code> The OpenVidu Meet room URL to connect to (moderator or speaker url) Yes (This attribute is required unless <code>recording-url</code> is provided.) <code>recording-url</code> The URL of a recording to view. Yes (This attribute is required unless <code>room-url</code> is provided.) <code>participant-name</code> Display name for the local participant. No <code>leave-redirect-url</code> URL to redirect to when leaving the meeting. Redirection occurs after the <code>CLOSED</code> event fires. No <code>show-only-recordings</code> Whether to show only recordings instead of live meetings. No <p>Example:</p> <pre><code>&lt;openvidu-meet\n    room-url=\"{{ my-room-url }}\"\n    participant-name=\"John Doe\"\n    leave-redirect-url=\"https://meeting.end.url/\"\n&gt;&lt;/openvidu-meet&gt;\n</code></pre>","tags":["Meet"]},{"location":"meet/embedded/reference/webcomponent/#commands","title":"Commands","text":"<p>The OpenVidu Meet component exposes a set of commands that allow you to control the room from your application's logic.</p> Method Command Description Parameters Access Level <code>endMeeting()</code> <code>endMeeting</code> Ends the current meeting for all participants. - Moderator <code>leaveRoom()</code> <code>leaveRoom</code> Disconnects the local participant from the current room. - All <code>kickParticipant(participantIdentity)</code> <code>kickParticipant</code> Kicks a participant from the meeting. \u2022 <code>participantIdentity</code>: string Moderator <p>Invoke commands using JavaScript:</p> <pre><code>const openviduMeet = document.querySelector('openvidu-meet');\nopenviduMeet.leaveRoom();\n</code></pre>","tags":["Meet"]},{"location":"meet/embedded/reference/webcomponent/#events","title":"Events","text":"<p>The OpenVidu Meet component emits events that you can listen to in your application.</p> Event Description Payload <code>joined</code> Event emitted when the local participant joins the room. <pre><code>{ \u00a0\u00a0\u00a0\u00a0\"roomId\": \"string\",\u00a0\u00a0\u00a0\u00a0\"participantIdentity\": \"string\"}</code></pre> <code>left</code> Event emitted when the local participant leaves the room. <pre><code>{ \u00a0\u00a0\u00a0\u00a0\"roomId\": \"string\",\u00a0\u00a0\u00a0\u00a0\"participantIdentity\": \"string\",\u00a0\u00a0\u00a0\u00a0\"reason\": \"LeftEventReason\"}</code></pre> <code>closed</code> Event emitted when the application is closed. - <p>Listen to events using JavaScript event listeners:</p> <pre><code>const openviduMeet = document.querySelector('openvidu-meet');\n\nopenviduMeet.addEventListener('JOINED', (event) =&gt; {\n    console.log('The local participant has joined the room!', event);\n});\n</code></pre> <p>You can also use the API <code>on</code> | <code>once</code> | <code>off</code>:</p> <pre><code>const openviduMeet = document.querySelector('openvidu-meet');\n\nopenviduMeet.on('JOINED', (event) =&gt; {\n    console.log('The local participant has joined the room!', event);\n});\n\nopenviduMeet.once('LEFT', (event) =&gt; {\n    console.log('The local participant has left the room!', event);\n});\n</code></pre>","tags":["Meet"]},{"location":"meet/embedded/reference/webhooks/","title":"Webhooks","text":"","tags":["Meet"]},{"location":"meet/embedded/reference/webhooks/#webhooks","title":"Webhooks","text":"<p>OpenVidu Meet sends webhooks to inform about important events happening in a room. You can receive them in your application's backend and react accordingly with your own business logic.</p>","tags":["Meet"]},{"location":"meet/embedded/reference/webhooks/#reference","title":"Reference","text":"<p>Visit OpenVidu Meet Webhooks  reference documentation for a complete list of all available webhook events. They include:</p> <ul> <li><code>meetingStarted</code> </li> <li><code>meetingEnded</code> </li> <li><code>recordingStarted</code> </li> <li><code>recordingUpdated</code> </li> <li><code>recordingEnded</code> </li> </ul>","tags":["Meet"]},{"location":"meet/embedded/reference/webhooks/#configuration","title":"Configuration","text":"<p>You can configure webhooks in OpenVidu Meet in the \"Embedded\" page. There you can:</p> <ul> <li>Enable/Disable sending webhooks</li> <li>Set up your webhook endpoint URL</li> <li>Test the current webhook configuration with a fake event</li> </ul> <p></p>","tags":["Meet"]},{"location":"meet/embedded/reference/webhooks/#validate-events","title":"Validate events","text":"<p>OpenVidu Meet signs all webhook events with your API key, so you can verify their authenticity. This way you can ensure that the events received by your application's backend are coming from your actual OpenVidu Meet deployment and have not been tampered with.</p> <p>Each webhook event includes two headers that you should use to validate the request:</p> <ul> <li><code>x-signature</code>: HMAC SHA256 signature of the request body, created by OpenVidu Meet using your API key.</li> <li><code>x-timestamp</code>: Unix timestamp (in milliseconds) when the webhook was sent.</li> </ul> <p>The steps to validate a webhook event in your backend are the following, given that you have access to the HTTP request body and headers:</p> <ol> <li>Get the <code>x-signature</code> and <code>x-timestamp</code> headers from the request.</li> <li>Compare the <code>x-timestamp</code> header value with the current Unix timestamp. If the difference is greater than a predefined threshold (e.g., 2 minutes), reject it to prevent replay attacks .</li> <li>Concatenate in a single string the <code>x-timestamp</code> header value + character <code>.</code> + the JSON request body.</li> <li>Create a HMAC SHA256 hash of the string of point 3) using your OpenVidu Meet API key as the key.</li> <li>Compare the computed hash of point 4) with the <code>x-signature</code> header value. Do a time safe comparison to avoid timing attacks . If they match, the request is valid.</li> </ol> <p>Below there are code snippets in different languages, showing the exact implementation of the above steps.</p>  Node.js Java Go Python PHP .NET Ruby Rust <p>Checkout working example </p> <pre><code>import crypto from \"crypto\";\n\nconst OPENVIDU_MEET_API_KEY = \"YOUR_API_KEY\";\nconst MAX_WEBHOOK_AGE = 120 * 1000; // 2 minutes in milliseconds\n\nfunction isWebhookEventValid(body, headers) {\n    const signature = headers[\"x-signature\"]; // (1)!\n    const timestamp = parseInt(headers[\"x-timestamp\"], 10);\n\n    if (!signature || !timestamp || isNaN(timestamp)) {\n        return false;\n    }\n\n    const current = Date.now();\n    const diffTime = current - timestamp;\n    if (diffTime &gt;= MAX_WEBHOOK_AGE) { // (2)!\n        // Webhook event too old\n        return false;\n    }\n\n    const signedPayload = `${timestamp}.${JSON.stringify(body)}`; // (3)!\n    const expectedSignature = crypto // (4)!\n        .createHmac(\"sha256\", OPENVIDU_MEET_API_KEY)\n        .update(signedPayload, \"utf8\")\n        .digest(\"hex\");\n\n    return crypto.timingSafeEqual( // (5)!\n        Buffer.from(expectedSignature, \"hex\"),\n        Buffer.from(signature, \"hex\")\n    );\n}\n</code></pre> <ol> <li>1) Get the <code>x-signature</code> and <code>x-timestamp</code> headers from the request.</li> <li>2) Compare the <code>x-timestamp</code> header value with the current Unix timestamp. If the difference is greater than a predefined threshold (e.g., 2 minutes), reject it to prevent replay attacks .</li> <li>3) Concatenate in a single string the <code>x-timestamp</code> header value + character <code>.</code> + the JSON request body.</li> <li>4) Create a HMAC SHA256 hash of the string of point 3) using your OpenVidu Meet API key as the key.</li> <li>5) Compare the computed hash of point 4) with the <code>x-signature</code> header value. Do a time safe comparisson to avoid timing attacks . If they match, the request is valid.</li> </ol> <p>Checkout working example </p> <pre><code>package com.example;\n\nimport javax.crypto.Mac;\nimport javax.crypto.spec.SecretKeySpec;\nimport java.nio.charset.StandardCharsets;\nimport java.util.Map;\n\npublic class WebhookValidator {\n    private static final long MAX_WEBHOOK_AGE = 120 * 1000; // 2 minutes in milliseconds\n    private static final String OPENVIDU_MEET_API_KEY = \"YOUR_API_KEY\";\n\n    public static boolean isWebhookEventValid(Object body, Map&lt;String, String&gt; headers) {\n        String signature = headers.get(\"x-signature\"); // (1)!\n        String ts = headers.get(\"x-timestamp\");\n        if (signature == null || ts == null) return false;\n\n        long timestamp;\n        try {\n            timestamp = Long.parseLong(ts);\n        } catch (NumberFormatException e) {\n            return false;\n        }\n\n        long current = System.currentTimeMillis();\n        long diffTime = current - timestamp;\n        if (diffTime &gt;= MAX_WEBHOOK_AGE) { // (2)!\n            // Webhook event too old\n            return false;\n        }\n\n        String signedPayload = timestamp + \".\" + body.toString(); // (3)!\n\n        try {\n            Mac mac = Mac.getInstance(\"HmacSHA256\");\n            mac.init(\n                new SecretKeySpec(\n                    OPENVIDU_MEET_API_KEY.getBytes(StandardCharsets.UTF_8), // (4)!\n                    \"HmacSHA256\"\n                )\n            );\n            byte[] expected = mac.doFinal(signedPayload.getBytes(StandardCharsets.UTF_8));\n            byte[] actual = hexToBytes(signature);\n\n            return timingSafeEqual(expected, actual); // (5)!\n        } catch (Exception e) {\n            return false;\n        }\n    }\n\n    // Helper method to convert hex string to byte array\n    private static byte[] hexToBytes(String hex) {\n        int len = hex.length();\n        byte[] data = new byte[len / 2];\n        for (int i = 0; i &lt; len; i += 2) {\n            data[i / 2] = (byte) ((Character.digit(hex.charAt(i), 16) &lt;&lt; 4)\n                                + Character.digit(hex.charAt(i + 1), 16));\n        }\n        return data;\n    }\n\n    // Time safe comparison to prevent timing attacks\n    private static boolean timingSafeEqual(byte[] a, byte[] b) {\n        if (a.length != b.length) return false;\n        int result = 0;\n        for (int i = 0; i &lt; a.length; i++) {\n            result |= a[i] ^ b[i];\n        }\n        return result == 0;\n    }\n}\n</code></pre> <ol> <li>1) Get the <code>x-signature</code> and <code>x-timestamp</code> headers from the request.</li> <li>2) Compare the <code>x-timestamp</code> header value with the current Unix timestamp. If the difference is greater than a predefined threshold (e.g., 2 minutes), reject it to prevent replay attacks .</li> <li>3) Concatenate in a single string the <code>x-timestamp</code> header value + character <code>.</code> + the JSON request body.</li> <li>4) Create a HMAC SHA256 hash of the string of point 3) using your OpenVidu Meet API key as the key.</li> <li>5) Compare the computed hash of point 4) with the <code>x-signature</code> header value. Do a time safe comparisson to avoid timing attacks . If they match, the request is valid.</li> </ol> <p>Checkout working example </p> <pre><code>package main\n\nimport (\n    \"crypto/hmac\"\n    \"crypto/sha256\"\n    \"crypto/subtle\"\n    \"encoding/hex\"\n    \"encoding/json\"\n    \"net/http\"\n    \"strconv\"\n    \"time\"\n)\n\nconst (\n    maxWebhookAge      = 120 * 1000 // 2 minutes in milliseconds\n    openviduMeetApiKey = \"YOUR_API_KEY\"\n)\n\nfunc isWebhookEventValid(bodyBytes []byte, headers http.Header) bool {\n    signature := headers.Get(\"x-signature\") // (1)!\n    tsStr := headers.Get(\"x-timestamp\")\n    if signature == \"\" || tsStr == \"\" {\n        return false\n    }\n\n    timestamp, err := strconv.ParseInt(tsStr, 10, 64)\n    if err != nil {\n        return false\n    }\n\n    current := time.Now().UnixMilli()\n    diffTime := current - timestamp\n    if diffTime &gt;= maxWebhookAge { // (2)!\n        // Webhook event too old\n        return false\n    }\n\n    signedPayload := tsStr + \".\" + string(bodyBytes) // (3)!\n\n    mac := hmac.New(sha256.New, []byte(openviduMeetApiKey)) // (4)!\n    mac.Write([]byte(signedPayload))\n    expected := mac.Sum(nil)\n\n    actual, err := hex.DecodeString(signature)\n    if err != nil {\n        return false\n    }\n\n    return subtle.ConstantTimeCompare(expected, actual) == 1 // (5)!\n}\n</code></pre> <ol> <li>1) Get the <code>x-signature</code> and <code>x-timestamp</code> headers from the request.</li> <li>2) Compare the <code>x-timestamp</code> header value with the current Unix timestamp. If the difference is greater than a predefined threshold (e.g., 2 minutes), reject it to prevent replay attacks .</li> <li>3) Concatenate in a single string the <code>x-timestamp</code> header value + character <code>.</code> + the JSON request body.</li> <li>4) Create a HMAC SHA256 hash of the string of point 3) using your OpenVidu Meet API key as the key.</li> <li>5) Compare the computed hash of point 4) with the <code>x-signature</code> header value. Do a time safe comparisson to avoid timing attacks . If they match, the request is valid.</li> </ol> <p>Checkout working example </p> <pre><code>import hmac\nimport hashlib\nimport json\nimport time\n\nMAX_WEBHOOK_AGE = 120 * 1000  # 2 minutes in milliseconds\nOPENVIDU_MEET_API_KEY = \"YOUR_API_KEY\"\n\ndef is_webhook_event_valid(body, headers):\n    signature = headers.get(\"x-signature\")  # (1)!\n    timestamp_str = headers.get(\"x-timestamp\")\n    if not signature or not timestamp_str:\n        return False\n\n    try:\n        timestamp = int(timestamp_str)\n    except ValueError:\n        return False\n\n    current = int(time.time() * 1000)\n    diff_time = current - timestamp\n    if diff_time &gt;= MAX_WEBHOOK_AGE:  # (2)!\n        return False\n\n    json_body = json.dumps(body, separators=(\",\", \":\"))\n    signed_payload = str(timestamp) + \".\" + json_body  # (3)!\n\n    expected = hmac.new(  # (4)!\n        OPENVIDU_MEET_API_KEY.encode('utf-8'),\n        signed_payload.encode('utf-8'),\n        hashlib.sha256\n    ).hexdigest()\n\n    return hmac.compare_digest(expected, signature)  # (5)!\n</code></pre> <ol> <li>1) Get the <code>x-signature</code> and <code>x-timestamp</code> headers from the request.</li> <li>2) Compare the <code>x-timestamp</code> header value with the current Unix timestamp. If the difference is greater than a predefined threshold (e.g., 2 minutes), reject it to prevent replay attacks .</li> <li>3) Concatenate in a single string the <code>x-timestamp</code> header value + character <code>.</code> + the JSON request body.</li> <li>4) Create a HMAC SHA256 hash of the string of point 3) using your OpenVidu Meet API key as the key.</li> <li>5) Compare the computed hash of point 4) with the <code>x-signature</code> header value. Do a time safe comparisson to avoid timing attacks . If they match, the request is valid.</li> </ol> <p>Checkout working example </p> <pre><code>&lt;?php\n\nconst MAX_WEBHOOK_AGE = 120 * 1000; // 2 minutes in milliseconds\nconst OPENVIDU_MEET_API_KEY = \"YOUR_API_KEY\";\n\nfunction isWebhookEventValid($body, $headers)\n{\n    $signature = $headers['x-signature'] ?? null; // (1)!\n    $timestampStr = $headers['x-timestamp'] ?? null;\n    if (!$signature || !$timestampStr) {\n        return false;\n    }\n\n    $timestamp = filter_var($timestampStr, FILTER_VALIDATE_INT);\n    if ($timestamp === false) {\n        return false;\n    }\n\n    $current = intval(microtime(true) * 1000);\n    $diffTime = $current - $timestamp;\n    if ($diffTime &gt;= MAX_WEBHOOK_AGE) { // (2)!\n        return false;\n    }\n\n    $signedPayload = $timestamp . '.' . json_encode($body, JSON_UNESCAPED_SLASHES); // (3)!\n\n    $expected = hash_hmac('sha256', $signedPayload, OPENVIDU_MEET_API_KEY); // (4)!\n\n    return hash_equals($expected, $signature); // (5)!\n}\n\n?&gt;\n</code></pre> <ol> <li>1) Get the <code>x-signature</code> and <code>x-timestamp</code> headers from the request.</li> <li>2) Compare the <code>x-timestamp</code> header value with the current Unix timestamp. If the difference is greater than a predefined threshold (e.g., 2 minutes), reject it to prevent replay attacks .</li> <li>3) Concatenate in a single string the <code>x-timestamp</code> header value + character <code>.</code> + the JSON request body.</li> <li>4) Create a HMAC SHA256 hash of the string of point 3) using your OpenVidu Meet API key as the key.</li> <li>5) Compare the computed hash of point 4) with the <code>x-signature</code> header value. Do a time safe comparisson to avoid timing attacks . If they match, the request is valid.</li> </ol> <p>Checkout working example </p> <pre><code>using System.Security.Cryptography;\nusing System.Text;\nusing System.Text.Json;\n\npublic class WebhookValidator\n{\n    private const long MAX_WEBHOOK_AGE = 120 * 1000; // 2 minutes in milliseconds\n    private const string OPENVIDU_MEET_API_KEY = \"YOUR_API_KEY\";\n\n    public static bool IsWebhookEventValid(string body, Dictionary&lt;string, string&gt; headers)\n    {\n        if (!headers.TryGetValue(\"x-signature\", out var signature) || // (1)!\n            !headers.TryGetValue(\"x-timestamp\", out var timestampStr))\n        {\n            return false;\n        }\n\n        if (!long.TryParse(timestampStr, out long timestamp))\n        {\n            return false;\n        }\n\n        long current = DateTimeOffset.UtcNow.ToUnixTimeMilliseconds();\n        long diffTime = current - timestamp;\n        if (diffTime &gt;= MAX_WEBHOOK_AGE) // (2)!\n        {\n            return false;\n        }\n\n        string signedPayload = $\"{timestamp}.{body}\"; // (3)!\n\n        using (var hmac = new HMACSHA256(Encoding.UTF8.GetBytes(OPENVIDU_MEET_API_KEY))) // (4)!\n        {\n            byte[] expected = hmac.ComputeHash(Encoding.UTF8.GetBytes(signedPayload));\n            byte[] actual = Convert.FromHexString(signature);\n\n            return CryptographicOperations.FixedTimeEquals(expected, actual); // (5)!\n        }\n    }\n}\n</code></pre> <ol> <li>1) Get the <code>x-signature</code> and <code>x-timestamp</code> headers from the request.</li> <li>2) Compare the <code>x-timestamp</code> header value with the current Unix timestamp. If the difference is greater than a predefined threshold (e.g., 2 minutes), reject it to prevent replay attacks .</li> <li>3) Concatenate in a single string the <code>x-timestamp</code> header value + character <code>.</code> + the JSON request body.</li> <li>4) Create a HMAC SHA256 hash of the string of point 3) using your OpenVidu Meet API key as the key.</li> <li>5) Compare the computed hash of point 4) with the <code>x-signature</code> header value. Do a time safe comparisson to avoid timing attacks . If they match, the request is valid.</li> </ol> <p>Checkout working example </p> <pre><code>require 'openssl'\nrequire 'json'\n\nMAX_WEBHOOK_AGE = 120 * 1000 # 2 minutes in milliseconds\nOPENVIDU_MEET_API_KEY = \"YOUR_API_KEY\"\n\ndef webhook_event_valid?(body, headers)\n    signature = headers['x-signature'] # (1)!\n    timestamp_str = headers['x-timestamp']\n    return false if signature.nil? || timestamp_str.nil?\n\n    begin\n        timestamp = Integer(timestamp_str)\n    rescue ArgumentError\n        return false\n    end\n\n    current = (Time.now.to_f * 1000).to_i\n    diff_time = current - timestamp\n    return false if diff_time &gt;= MAX_WEBHOOK_AGE # (2)!\n\n    signed_payload = \"#{timestamp}.#{body.to_json}\" # (3)!\n\n    expected = OpenSSL::HMAC.hexdigest('SHA256', OPENVIDU_MEET_API_KEY, signed_payload) # (4)!\n\n    OpenSSL.fixed_length_secure_compare(expected, signature) # (5)!\nend\n</code></pre> <ol> <li>1) Get the <code>x-signature</code> and <code>x-timestamp</code> headers from the request.</li> <li>2) Compare the <code>x-timestamp</code> header value with the current Unix timestamp. If the difference is greater than a predefined threshold (e.g., 2 minutes), reject it to prevent replay attacks .</li> <li>3) Concatenate in a single string the <code>x-timestamp</code> header value + character <code>.</code> + the JSON request body.</li> <li>4) Create a HMAC SHA256 hash of the string of point 3) using your OpenVidu Meet API key as the key.</li> <li>5) Compare the computed hash of point 4) with the <code>x-signature</code> header value. Do a time safe comparisson to avoid timing attacks . If they match, the request is valid.</li> </ol> <p>Checkout working example </p> <pre><code>use chrono::Utc;\nuse hmac::{Hmac, Mac};\nuse sha2::Sha256;\nuse std::collections::HashMap;\n\ntype HmacSha256 = Hmac&lt;Sha256&gt;;\n\nfn is_webhook_event_valid(body_str: &amp;str, headers: &amp;HashMap&lt;String, String&gt;) -&gt; bool {\n    let signature = match headers.get(\"x-signature\") { // (1)!\n        Some(sig) =&gt; sig,\n        None =&gt; return false,\n    };\n\n    let timestamp_str = match headers.get(\"x-timestamp\") {\n        Some(ts) =&gt; ts,\n        None =&gt; return false,\n    };\n\n    let timestamp: i64 = match timestamp_str.parse() {\n        Ok(ts) =&gt; ts,\n        Err(_) =&gt; return false,\n    };\n\n    // Check timestamp age\n    let current = Utc::now().timestamp_millis();\n    let diff_time = current - timestamp;\n    if diff_time &gt;= MAX_WEBHOOK_AGE { // (2)!\n        return false;\n    }\n\n    // Create signed payload using the raw body string\n    let signed_payload = format!(\"{}.{}\", timestamp, body_str); // (3)!\n\n    // Calculate HMAC\n    let mut mac = match HmacSha256::new_from_slice(OPENVIDU_MEET_API_KEY.as_bytes()) { // (4)!\n        Ok(mac) =&gt; mac,\n        Err(_) =&gt; return false,\n    };\n\n    mac.update(signed_payload.as_bytes());\n    let expected = mac.finalize().into_bytes();\n    let expected_hex = hex::encode(expected);\n\n    // Timing-safe comparison\n    if signature.len() != expected_hex.len() {\n        return false;\n    }\n\n    let mut result = 0u8;\n    for (a, b) in signature.bytes().zip(expected_hex.bytes()) { // (5)!\n        result |= a ^ b;\n    }\n    result == 0\n}\n</code></pre> <ol> <li>1) Get the <code>x-signature</code> and <code>x-timestamp</code> headers from the request.</li> <li>2) Compare the <code>x-timestamp</code> header value with the current Unix timestamp. If the difference is greater than a predefined threshold (e.g., 2 minutes), reject it to prevent replay attacks .</li> <li>3) Concatenate in a single string the <code>x-timestamp</code> header value + character <code>.</code> + the JSON request body.</li> <li>4) Create a HMAC SHA256 hash of the string of point 3) using your OpenVidu Meet API key as the key.</li> <li>5) Compare the computed hash of point 4) with the <code>x-signature</code> header value. Do a time safe comparisson to avoid timing attacks . If they match, the request is valid.</li> </ol>","tags":["Meet"]},{"location":"meet/embedded/reference/webhooks/#failures-and-retries","title":"Failures and retries","text":"<p>OpenVidu Meet will automatically retry sending webhooks in case of failures. For example, if your server is down or returns an error response.</p> <p>It will retry 5 times, with an exponential backoff (meaning it will wait longer between each retry).</p> <p>Info</p> <p>Your server must respond with a 2xx HTTP status code to acknowledge that you have received the webhook event. The timeout granted by OpenVidu Meet to do so is 5 seconds. If your server takes longer than that to respond, or if it sends any status code other than 2xx, OpenVidu Meet will consider it a failure and trigger a retry.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/","title":"OpenVidu Meet Tutorials","text":"","tags":["Meet"]},{"location":"meet/embedded/tutorials/#openvidu-meet-tutorials","title":"OpenVidu Meet Tutorials","text":"<p>OpenVidu Meet offers a robust and adaptable way to add video conferencing features to your projects. With minimal effort, you can integrate a complete video conferencing experience into your web application.</p> <p>The following tutorials will walk you through embedding OpenVidu Meet, either directly or via its Web Component, to quickly set up interactive video sessions.</p> <p>Every tutorial below shares the same core functionality:</p> <ul> <li>Users can create rooms.</li> <li>Users can delete rooms.</li> <li>Users can join a room as moderator or speaker.</li> <li>Users can chat with other users.</li> <li>Users may leave the room at any time.</li> <li>Users can view the recordings of the meeting.</li> <li>Moderators can record the meeting.</li> <li>Moderators may end the meeting at any time, disconnecting all users.</li> </ul> <p> Direct Link</p> <p> Web Component</p> <p> Web ComponentCommands &amp; Events</p> <p> Recordings</p> <p> Webhooks</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/direct-link/","title":"OpenVidu Meet Direct Link Tutorial","text":"","tags":["Meet"]},{"location":"meet/embedded/tutorials/direct-link/#openvidu-meet-direct-link-tutorial","title":"OpenVidu Meet Direct Link Tutorial","text":"<p>Source code </p> <p>This tutorial is a simple example of how to integrate OpenVidu Meet into a Node.js application by easily using a direct link. It is built using Node.js and Express for the backend and plain HTML/CSS/JavaScript for the frontend.</p> <p>At the end of this tutorial, you will have a fully functional simple video-call application with the following features:</p> <ul> <li>Users can create rooms.</li> <li>Users can delete rooms.</li> <li>Users can join a room as moderator or speaker.</li> <li>Users can chat with other users.</li> <li>Users may leave the room at any time.</li> <li>Users can view the recordings of the meeting.</li> <li>Moderators can record the meeting.</li> <li>Moderators may end the meeting at any time, disconnecting all users.</li> </ul> <p>The application uses the OpenVidu Meet API to create and delete rooms, and direct links to the OpenVidu Meet interface to access the video call functionality.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/direct-link/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Meet"]},{"location":"meet/embedded/tutorials/direct-link/#1-run-openvidu-meet","title":"1. Run OpenVidu Meet","text":"<p>You need Docker Desktop. You can install it on Windows , Mac  or Linux .</p> <p>Run this command in Docker Desktop's terminal:</p> <pre><code>docker compose -p openvidu-meet -f oci://openvidu/local-meet:3.4.0 up -y openvidu-meet-init\n</code></pre> <p>Info</p> <p>For a detailed guide on how to run OpenVidu Meet locally, visit Try OpenVidu Meet locally .</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/direct-link/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-meet-tutorials.git -b 3.4.0\n</code></pre>","tags":["Meet"]},{"location":"meet/embedded/tutorials/direct-link/#3-run-the-application","title":"3. Run the application","text":"<p>To run this application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the application directory</li> </ol> <pre><code>cd openvidu-meet-tutorials/meet-direct-link\n</code></pre> <ol> <li>Install dependencies</li> </ol> <pre><code>npm install\n</code></pre> <ol> <li>Run the application</li> </ol> <pre><code>npm start\n</code></pre> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:6080</code>. You should see a screen like this:</p> <p></p> <p></p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/direct-link/#understanding-the-code","title":"Understanding the code","text":"<p>This application is designed to be beginner-friendly and consists of one essential backend file under the <code>src</code> directory:</p> <ul> <li><code>index.js</code>: This file holds the server application and defines the REST API endpoints.</li> </ul> <p>And the following essential frontend files under the <code>public</code> directory:</p> <ul> <li><code>index.html</code>: This is the client application's main HTML file.</li> <li><code>app.js</code>: This is the main JavaScript file that interacts with the server application and handles the client application's logic and functionality.</li> <li><code>style.css</code>: This file contains the client application's styling.</li> </ul>","tags":["Meet"]},{"location":"meet/embedded/tutorials/direct-link/#backend","title":"Backend","text":"<p>The server application is a simple Express app with a single file <code>index.js</code> that exports three endpoints:</p> <ul> <li><code>POST /rooms</code>: Create a new room with the given room name.</li> <li><code>GET /rooms</code>: Get the list of rooms.</li> <li><code>DELETE /rooms/:roomId</code>: Delete a room with the given room ID.</li> </ul> <p>Let's see the code of the <code>index.js</code> file:</p> index.js<pre><code>import bodyParser from 'body-parser';\nimport cors from 'cors';\nimport dotenv from 'dotenv';\nimport express from 'express';\nimport path from 'path';\nimport { fileURLToPath } from 'url';\n\ndotenv.config(); // (1)!\n\n// Configuration\nconst SERVER_PORT = process.env.SERVER_PORT || 6080; // (2)!\nconst OV_MEET_SERVER_URL = process.env.OV_MEET_SERVER_URL || 'http://localhost:9080'; // (3)!\nconst OV_MEET_API_KEY = process.env.OV_MEET_API_KEY || 'meet-api-key'; // (4)!\n\nconst app = express(); // (5)!\n\napp.use(cors()); // (6)!\napp.use(express.json()); // (7)!\napp.use(bodyParser.urlencoded({ extended: true }));\n\nconst __filename = fileURLToPath(import.meta.url);\nconst __dirname = path.dirname(__filename);\napp.use(express.static(path.join(__dirname, '../public'))); // (8)!\n</code></pre> <ol> <li>Load environment variables from <code>.env</code> file.</li> <li>The port where the application will be listening.</li> <li>The OpenVidu Meet server URL.</li> <li>The OpenVidu Meet API key.</li> <li>Initialize the Express application.</li> <li>Enable CORS support.</li> <li>Enable JSON body parsing.</li> <li>Serve static files from the <code>public</code> directory.</li> </ol> <p>The <code>index.js</code> file imports the required dependencies and loads the necessary environment variables:</p> <ul> <li><code>SERVER_PORT</code>: The port where the application will be listening.</li> <li><code>OV_MEET_SERVER_URL</code>: The OpenVidu Meet server URL.</li> <li><code>OV_MEET_API_KEY</code>: The OpenVidu Meet API key.</li> </ul> <p>Then the <code>express</code> application is initialized. CORS is allowed, JSON body parsing is enabled, and static files are served from the <code>public</code> directory.</p> <p>Now let's see the code of each endpoint:</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/direct-link/#create-room","title":"Create room","text":"<p>The <code>POST /rooms</code> endpoint creates a new room. It receives the room name as a body parameter and returns the newly created room:</p> index.js<pre><code>// Create a new room\napp.post('/rooms', async (req, res) =&gt; {\n    const { roomName } = req.body; // (1)!\n\n    if (!roomName) {\n        res.status(400).json({ message: `'roomName' is required` }); // (2)!\n        return;\n    }\n\n    try {\n        // Create a new OpenVidu Meet room using the API\n        const room = await httpRequest('POST', 'rooms', {\n            roomName, // (3)!\n            config: {\n                // (4)!\n                // Default room configuration\n                chat: {\n                    enabled: true // Enable chat for this room\n                },\n                recording: {\n                    enabled: true, // Enable recording for this room\n                    allowAccessTo: 'admin_moderator_speaker' // Allow access to recordings for admin, moderator and speaker roles\n                },\n                virtualBackground: {\n                    enabled: true // Enable virtual background for this room\n                }\n            }\n        });\n\n        console.log('Room created:', room);\n        res.status(201).json({ message: `Room '${roomName}' created successfully`, room }); // (5)!\n    } catch (error) {\n        handleApiError(res, error, `Error creating room '${roomName}'`); // (6)!\n    }\n});\n</code></pre> <ol> <li>The <code>roomName</code> parameter is obtained from the request body.</li> <li>If the <code>roomName</code> is not provided, the server returns a <code>400 Bad Request</code> response.</li> <li>Specify the name of the room.</li> <li>Set the configuration for the room, enabling chat, recording and virtual background.</li> <li>The server returns a <code>201 Created</code> response with the room object.</li> <li>If an error occurs during room creation, it is handled by the <code>handleApiError</code> function.</li> </ol> <p>This endpoint does the following:</p> <ol> <li>The <code>roomName</code> parameter is obtained from the request body. If it is not provided, the server returns a <code>400 Bad Request</code> response.</li> <li> <p>A new room is created using the OpenVidu Meet API by sending a <code>POST</code> request to the <code>rooms</code> endpoint. The request includes the room name and additional configuration options (with default values):</p> <ul> <li>Chat Configuration: Enables chat functionality for the room.</li> <li>Recording Configuration: Enables recording for the room and allows access to recordings for the roles <code>admin</code>, <code>moderator</code> and <code>speaker</code>.</li> <li>Virtual Background Configuration: Enables virtual background functionality for the room.</li> </ul> <p>Info</p> <p>The reference for the room configuration options can be found in the OpenVidu Meet REST API reference .</p> <p>To send requests to the OpenVidu Meet API, we use the <code>httpRequest</code> function:</p> index.js<pre><code>// Function to make HTTP requests to OpenVidu Meet API\nconst httpRequest = async (method, path, body) =&gt; {\n    // (1)!\n    const response = await fetch(`${OV_MEET_SERVER_URL}/api/v1/${path}`, {\n        method,\n        headers: {\n            'Content-Type': 'application/json',\n            'X-API-KEY': OV_MEET_API_KEY // Include the API key in the header for authentication\n        },\n        body: body ? JSON.stringify(body) : undefined // (2)!\n    });\n\n    const responseBody = await response.json(); // (3)!\n\n    if (!response.ok) {\n        console.error('Error while performing request to OpenVidu Meet API:', responseBody);\n        // Create an error object that includes the HTTP status code from the API\n        const error = new Error(responseBody.message || 'Failed to perform request to OpenVidu Meet API');\n        error.statusCode = response.status;\n        throw error; // (4)!\n    }\n\n    return responseBody; // (5)!\n};\n</code></pre> <ol> <li>Perform an HTTP request to the OpenVidu Meet API in the specified method and path.</li> <li>Include the body in the request if provided.</li> <li>Parse the response body as JSON.</li> <li>If the response is not OK, throw an error with the message and status code from the response.</li> <li>Return the response body.</li> </ol> <p>This function makes HTTP requests to the OpenVidu Meet API using the <code>fetch</code> function. It receives the HTTP method, path and body as parameters. The API key is included in the request headers for authentication.</p> <p>It parses the response body as JSON and checks if the response is OK. If not, it throws an error with the message and status code from the response.</p> </li> <li> <p>If the room is successfully created, the server returns a <code>201 Created</code> response with the room object. Otherwise, the error is handled by the <code>handleApiError</code> function, which logs the error and returns an appropriate HTTP response:</p> index.js<pre><code>// Helper function to handle API errors consistently\nconst handleApiError = (res, error, message) =&gt; {\n    console.error(`${message}: ${error.message}`); // (1)!\n    const statusCode = error.statusCode || 500; // (2)!\n    const errorMessage = error.statusCode ? error.message : message; // (3)!\n    res.status(statusCode).json({ message: errorMessage }); // (4)!\n};\n</code></pre> <ol> <li>Log the error message to the console.</li> <li>Get the status code from the error object or default to <code>500 Internal Server Error</code>.</li> <li>Determine the error message to return based on whether the error has a status code.</li> <li>Return an HTTP response with the appropriate status code and error message.</li> </ol> </li> </ol>","tags":["Meet"]},{"location":"meet/embedded/tutorials/direct-link/#list-rooms","title":"List rooms","text":"<p>The <code>GET /rooms</code> endpoint retrieves the list of all rooms created in OpenVidu Meet:</p> index.js<pre><code>// List all rooms\napp.get('/rooms', (_req, res) =&gt; {\n    try {\n        // List all OpenVidu Meet rooms using the API (100 max)\n        const { rooms } = await httpRequest('GET', 'rooms?maxItems=100'); // (1)!\n        res.status(200).json({ rooms }); // (2)!\n    } catch (error) {\n        handleApiError(res, error, 'Error fetching rooms');\n    }\n});\n</code></pre> <ol> <li>Make a <code>GET</code> request to the <code>rooms</code> endpoint of the OpenVidu Meet API to retrieve the list of rooms (with a maximum of 100 rooms).</li> <li>The server returns a <code>200 OK</code> response with the list of rooms.</li> </ol> <p>This endpoint retrieves the list of rooms by making a <code>GET</code> request to the <code>rooms</code> endpoint (with a maximum of 100 rooms by setting the <code>maxItems</code> query parameter) of the OpenVidu Meet API using the <code>httpRequest</code> function. If the request is successful, the server returns a <code>200 OK</code> response with the list of rooms. Otherwise, the error is handled by the <code>handleApiError</code> function.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/direct-link/#delete-room","title":"Delete room","text":"<p>The <code>DELETE /room/:roomId</code> endpoint deletes the specified room:</p> index.js<pre><code>app.delete('/rooms/:roomId', async (req, res) =&gt; {\n    const { roomId } = req.params; // (1)!\n\n    try {\n        // Delete the OpenVidu Meet room using the API\n        await httpRequest('DELETE', `rooms/${roomId}`); // (2)!\n        res.status(200).json({ message: `Room '${roomId}' deleted successfully` }); // (3)!\n    } catch (error) {\n        handleApiError(res, error, `Error deleting room '${roomId}'`);\n    }\n});\n</code></pre> <ol> <li>The <code>roomId</code> parameter is obtained from the request parameters.</li> <li>The room is deleted using the OpenVidu Meet API by sending a <code>DELETE</code> request to the <code>rooms/:roomId</code> endpoint.</li> <li>The server returns a <code>200 OK</code> response with a success message.</li> </ol> <p>This endpoint does the following:</p> <ol> <li>The <code>roomId</code> parameter is obtained from the request parameters.</li> <li>The room is deleted using the OpenVidu Meet API by sending a <code>DELETE</code> request to the <code>rooms/:roomId</code> endpoint.</li> <li>If the room is successfully deleted, the server returns a <code>200 OK</code> response with a success message. Otherwise, the error is handled by the <code>handleApiError</code> function.</li> </ol>","tags":["Meet"]},{"location":"meet/embedded/tutorials/direct-link/#frontend","title":"Frontend","text":"<p>The client application consists of only three essential files that are located in the <code>public</code> directory:</p> <ul> <li><code>app.js</code>: This is the main JavaScript file for the sample application. It contains the logic for listing, creating, joining and deleting rooms.</li> <li><code>index.html</code>: This HTML file is responsible for creating the user interface. It contains the list of created rooms, and a form to create a new room.</li> <li><code>styles.css</code>: This file contains CSS classes that are used to style the <code>index.html</code> page.</li> </ul> <p>Now let's see the code of the <code>app.js</code> file grouped by sections:</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/direct-link/#listing-rooms","title":"Listing rooms","text":"<p>The list of rooms is displayed in the <code>index.html</code> file as soon as the page loads. This is done by calling the <code>fetchRooms()</code> function, which fetches the list of rooms from the server and updates the UI accordingly.</p> app.js<pre><code>const rooms = new Map(); // (1)!\n\ndocument.addEventListener('DOMContentLoaded', async () =&gt; {\n    await fetchRooms(); // (2)!\n});\n\nasync function fetchRooms() {\n    try {\n        const { rooms: roomsList } = await httpRequest('GET', '/rooms'); // (3)!\n\n        roomsList.forEach((room) =&gt; {\n            rooms.set(room.roomId, room); // (4)!\n        });\n        renderRooms(); // (5)!\n    } catch (error) {\n        console.error('Error fetching rooms:', error.message);\n\n        // Show error message\n        const roomsErrorElement = document.querySelector('#no-rooms-or-error');\n        roomsErrorElement.textContent = 'Error loading rooms';\n        roomsErrorElement.hidden = false;\n    }\n}\n</code></pre> <ol> <li>Create a map to store the rooms.</li> <li>When the DOM content is loaded, call the <code>fetchRooms()</code> function to fetch the list of rooms from the server.</li> <li>Make a <code>GET</code> request to the <code>/rooms</code> endpoint to fetch the list of rooms.</li> <li>For each room in the list, add it to the <code>rooms</code> map.</li> <li>Call the <code>renderRooms()</code> function to display the list of rooms.</li> </ol> <p>The <code>fetchRooms()</code> function performs the following actions:</p> <ol> <li> <p>Makes a <code>GET</code> request to the <code>/rooms</code> endpoint to fetch the list of rooms.</p> <p>To send requests to the backend, we use the <code>httpRequest</code> function:</p> app.js<pre><code>// Function to make HTTP requests to the backend\nasync function httpRequest(method, path, body) {\n    // (1)!\n    const response = await fetch(path, {\n        method,\n        headers: {\n            'Content-Type': 'application/json'\n        },\n        body: body ? JSON.stringify(body) : undefined // (2)!\n    });\n\n    const responseBody = await response.json(); // (3)!\n\n    if (!response.ok) {\n        throw new Error(responseBody.message || 'Failed to perform request to backend'); // (4)!\n    }\n\n    return responseBody; // (5)!\n}\n</code></pre> <ol> <li>Perform an HTTP request to the backend in the specified method and path.</li> <li>Include the body in the request if provided.</li> <li>Parse the response body as JSON.</li> <li>If the response is not OK, throw an error with the message from the response.</li> <li>Return the response body.</li> </ol> <p>This function makes HTTP requests to the server API using the <code>fetch</code> function. It receives the HTTP method, path and body as parameters. Then, it parses the response body as JSON and checks if the response is OK. If not, it throws an error with the message from the response.</p> </li> <li> <p>For each room in the list, it adds the room to the <code>rooms</code> map. This map is used to store the rooms indexed by their IDs to make it easier to access them later.</p> </li> <li>Calls the <code>renderRooms()</code> function to display the list of rooms.</li> <li>If an error occurs during the request, it logs the error and displays an appropriate error message.</li> </ol> <p>The <code>renderRooms()</code> function is responsible for updating the UI with the list of rooms:</p> app.js<pre><code>function renderRooms() {\n    // Clear the previous list of rooms\n    const roomsList = document.querySelector('#rooms-list ul'); // (1)!\n    roomsList.innerHTML = ''; // (2)!\n\n    // Show or remove the \"No rooms found\" message\n    const noRoomsElement = document.querySelector('#no-rooms-or-error');\n    if (rooms.size === 0) {\n        noRoomsElement.textContent = 'No rooms found. Please create a new room.';\n        noRoomsElement.hidden = false;\n        return;\n    } else {\n        noRoomsElement.textContent = '';\n        noRoomsElement.hidden = true;\n    }\n\n    // Add rooms to the list element\n    Array.from(rooms.values()).forEach((room) =&gt; {\n        const roomItem = getRoomListItemTemplate(room); // (3)!\n        roomsList.innerHTML += roomItem; // (4)!\n    });\n}\n\nfunction getRoomListItemTemplate(room) {\n    return `\n        &lt;li class=\"list-group-item\"&gt;\n            &lt;span&gt;${room.roomName}&lt;/span&gt;\n            &lt;div class=\"room-actions\"&gt;\n                &lt;a\n                    class=\"btn btn-primary btn-sm\"\n                    href=\"${room.moderatorUrl}\"\n                &gt;\n                    Join as Moderator\n                &lt;/a&gt;\n                &lt;a\n                    class=\"btn btn-secondary btn-sm\"\n                    href=\"${room.speakerUrl}\"\n                &gt;\n                    Join as Speaker\n                &lt;/a&gt;\n                &lt;button \n                    title=\"Delete room\"\n                    class=\"icon-button delete-button\"\n                    onclick=\"deleteRoom('${room.roomId}');\"\n                &gt;\n                    &lt;i class=\"fa-solid fa-trash\"&gt;&lt;/i&gt;\n                &lt;/button&gt;\n            &lt;/div&gt;\n        &lt;/li&gt;\n    `;\n}\n</code></pre> <ol> <li>Get the <code>ul</code> element where the list of rooms will be displayed.</li> <li>Clear the previous list of rooms.</li> <li>For each room, get the HTML template for the room list item.</li> <li>Append the room item to the list element.</li> </ol> <p>The <code>renderRooms()</code> function performs the following actions:</p> <ol> <li>Clears the previous list of rooms by getting the <code>ul</code> element and setting its inner HTML to an empty string.</li> <li>Checks if there are any rooms in the <code>rooms</code> map. If there are no rooms, it shows a message indicating that no rooms were found. Otherwise, it hides the message.</li> <li>For each room in the <code>rooms</code> map, it calls the <code>getRoomListItemTemplate()</code> function to get the HTML template for the room list item.</li> <li>Appends the room item to the list element.</li> </ol> <p>The <code>getRoomListItemTemplate()</code> function generates the HTML template for each room list item. It includes anchor links to join the room as a moderator or speaker using direct URLs, and a button to delete the room. The anchor links use the <code>moderatorUrl</code> and <code>speakerUrl</code> properties from the room object to redirect users directly to the OpenVidu Meet interface, while the delete button calls the <code>deleteRoom()</code> function passing the room ID to remove the room from the server.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/direct-link/#creating-a-room","title":"Creating a room","text":"<p>After the user specifies the room name and clicks the <code>Create Room</code> button, the <code>createRoom()</code> function is called:</p> app.js<pre><code>async function createRoom() {\n    // Clear previous error message\n    const errorDiv = document.querySelector('#create-room-error');\n    errorDiv.textContent = '';\n    errorDiv.hidden = true;\n\n    try {\n        const roomName = document.querySelector('#room-name').value; // (1)!\n\n        const { room } = await httpRequest('POST', '/rooms', {\n            roomName\n        }); // (2)!\n\n        // Add new room to the list\n        rooms.set(room.roomId, room); // (3)!\n        renderRooms(); // (4)!\n\n        // Reset the form\n        const createRoomForm = document.querySelector('#create-room form');\n        createRoomForm.reset(); // (5)!\n    } catch (error) {\n        console.error('Error creating room:', error.message);\n\n        // Show error message\n        errorDiv.textContent = 'Error creating room';\n        errorDiv.hidden = false;\n    }\n}\n</code></pre> <ol> <li>Get the room name from the input field.</li> <li>Make a <code>POST</code> request to the <code>/rooms</code> endpoint to create a new room with the specified name.</li> <li>Add the new room to the <code>rooms</code> map.</li> <li>Call the <code>renderRooms()</code> function to update the list of rooms.</li> <li>Reset the form to clear the input field.</li> </ol> <p>The <code>createRoom()</code> function performs the following actions:</p> <ol> <li>Clears any previous error messages.</li> <li>Gets the room name from the input field.</li> <li>Makes a <code>POST</code> request to the <code>/rooms</code> endpoint to create a new room with the specified name.</li> <li>If the room is successfully created, it adds the new room to the <code>rooms</code> map and calls the <code>renderRooms()</code> function to update the list of rooms.</li> <li>Resets the form to clear the input field.</li> <li>If an error occurs during room creation, it logs the error and displays an appropriate error message.</li> </ol>","tags":["Meet"]},{"location":"meet/embedded/tutorials/direct-link/#deleting-a-room","title":"Deleting a room","text":"<p>When the user clicks the delete room button, the <code>deleteRoom()</code> function is called:</p> app.js<pre><code>async function deleteRoom(roomId) {\n    try {\n        await httpRequest('DELETE', `/rooms/${roomId}`); // (1)!\n\n        // Remove the room from the list\n        rooms.delete(roomId); // (2)!\n        renderRooms(); // (3)!\n    } catch (error) {\n        console.error('Error deleting room:', error.message);\n    }\n}\n</code></pre> <ol> <li>Make a <code>DELETE</code> request to the <code>/rooms/:roomId</code> endpoint to delete the specified room.</li> <li>Remove the room from the <code>rooms</code> map.</li> <li>Call the <code>renderRooms()</code> function to update the list of rooms.</li> </ol> <p>The <code>deleteRoom()</code> function simply makes a <code>DELETE</code> request to the <code>/rooms/:roomId</code> endpoint to delete the specified room. If the room is successfully deleted, it removes the room from the <code>rooms</code> map and calls the <code>renderRooms()</code> function to update the list of rooms. If an error occurs during room deletion, it logs the error to the console.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/direct-link/#accessing-this-tutorial-from-other-computers-or-phones","title":"Accessing this tutorial from other computers or phones","text":"<p>To access this tutorial from other computers or phones, follow these steps:</p> <ol> <li> <p>Ensure network connectivity: Make sure your device (computer or phone) is connected to the same network as the machine running OpenVidu Meet and this tutorial.</p> </li> <li> <p>Configure OpenVidu Meet for network access: Start OpenVidu Meet by following the instructions in the Accessing OpenVidu Meet from other computers or phones  section.</p> </li> <li> <p>Update the OpenVidu Meet server URL: Modify the <code>OV_MEET_SERVER_URL</code> environment variable in your <code>.env</code> file to match the URL shown when OpenVidu Meet starts.</p> <pre><code># Example for IP address 192.168.1.100\nOV_MEET_SERVER_URL=https://192-168-1-100.openvidu-local.dev:9443\n</code></pre> </li> <li> <p>Restart the tutorial to apply the changes:</p> <pre><code>npm start\n</code></pre> </li> <li> <p>Access the tutorial: Open your browser and navigate to <code>https://192-168-1-100.openvidu-local.dev:6443</code> (replacing <code>192-168-1-100</code> with your actual private IP) on the computer where you started the tutorial or any device in the same network.</p> </li> </ol>","tags":["Meet"]},{"location":"meet/embedded/tutorials/direct-link/#connecting-this-tutorial-to-an-openvidu-meet-production-deployment","title":"Connecting this tutorial to an OpenVidu Meet production deployment","text":"<p>If you have a production deployment of OpenVidu Meet (installed in a server following deployment steps ), you can connect this tutorial to it by following these steps:</p> <ol> <li> <p>Update the server URL: Modify the <code>OV_MEET_SERVER_URL</code> environment variable in the <code>.env</code> file to point to your OpenVidu Meet production deployment URL.</p> <pre><code># Example for a production deployment\nOV_MEET_SERVER_URL=https://your-openvidu-meet-domain.com\n</code></pre> </li> <li> <p>Update the API key: Ensure the <code>OV_MEET_API_KEY</code> environment variable in the <code>.env</code> file matches the API key configured in your production deployment. See Generate an API Key  section to learn how to obtain it.</p> <pre><code>OV_MEET_API_KEY=your-production-api-key\n</code></pre> </li> <li> <p>Restart the tutorial to apply the changes:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Make this tutorial accessible from other computers or phones</p> <p>By default, this tutorial runs on <code>http://localhost:6080</code> and is only accessible from the local machine. If you want to access it from other computers or phones, you have the following options:</p> <ul> <li>Use tunneling tools: Configure tools like VS Code port forwarding , ngrok , localtunnel , or similar services to expose this tutorial to the internet. You can use http or https URLs.</li> <li>Deploy to a server: Upload this tutorial to a web server. You can use http or https URLs.</li> </ul>","tags":["Meet"]},{"location":"meet/embedded/tutorials/recordings/","title":"OpenVidu Meet Recordings Tutorial","text":"","tags":["Meet"]},{"location":"meet/embedded/tutorials/recordings/#openvidu-meet-recordings-tutorial","title":"OpenVidu Meet Recordings Tutorial","text":"<p>Source code </p> <p>This tutorial extends the advanced OpenVidu Meet WebComponent tutorial to add recording management capabilities. It demonstrates how to list, view, and delete recordings from your OpenVidu Meet meetings.</p> <p>The application includes all the features from the basic tutorial, plus:</p> <ul> <li>List recordings: View all available recordings from past meetings, with optional filtering by room.</li> <li>View recordings: Play recordings directly in the browser using the OpenVidu Meet WebComponent.</li> <li>Delete recordings: Remove recordings from the server.</li> </ul>","tags":["Meet"]},{"location":"meet/embedded/tutorials/recordings/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Meet"]},{"location":"meet/embedded/tutorials/recordings/#1-run-openvidu-meet","title":"1. Run OpenVidu Meet","text":"<p>You need Docker Desktop. You can install it on Windows , Mac  or Linux .</p> <p>Run this command in Docker Desktop's terminal:</p> <pre><code>docker compose -p openvidu-meet -f oci://openvidu/local-meet:3.4.0 up -y openvidu-meet-init\n</code></pre> <p>Info</p> <p>For a detailed guide on how to run OpenVidu Meet locally, visit Try OpenVidu Meet locally .</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/recordings/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-meet-tutorials.git -b 3.4.0\n</code></pre>","tags":["Meet"]},{"location":"meet/embedded/tutorials/recordings/#3-run-the-application","title":"3. Run the application","text":"<p>To run this application, you need Node.js  (\u2265 18) installed on your device.</p> <ol> <li>Navigate into the application directory</li> </ol> <pre><code>cd openvidu-meet-tutorials/meet-recordings\n</code></pre> <ol> <li>Install dependencies</li> </ol> <pre><code>npm install\n</code></pre> <ol> <li>Run the application</li> </ol> <pre><code>npm start\n</code></pre> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:6080</code>. You should see a screen like this:</p> <p></p> <p></p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/recordings/#understanding-the-code","title":"Understanding the code","text":"<p>This tutorial builds upon the advanced OpenVidu Meet WebComponent tutorial, adding recording management functionality. We'll focus on the new features and modifications related to recordings.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/recordings/#backend-modifications","title":"Backend modifications","text":"<p>The main changes to the backend involve adding new endpoints for recording management in the <code>src/index.js</code> file:</p> <ul> <li><code>GET /recordings</code>: List all recordings, with optional filtering by room.</li> <li><code>DELETE /recordings/:recordingId</code>: Delete a specific recording.</li> <li><code>GET /recordings/:recordingId/url</code>: Get the playback URL for a specific recording.</li> </ul> <p>Let's see the code of each new endpoint:</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/recordings/#list-recordings","title":"List recordings","text":"<p>The <code>GET /recordings</code> endpoint retrieves the list of recordings, with optional room filtering:</p> index.js<pre><code>// List all recordings\napp.get('/recordings', async (req, res) =&gt; {\n    // Create the base path for recordings, including maxItems parameter\n    let recordingsPath = `recordings?maxItems=100`; // (1)!\n\n    const { room: roomName } = req.query; // (2)!\n    if (roomName) {\n        // If a room is specified, filter recordings by room\n        recordingsPath += `&amp;roomId=${roomName}`; // (3)!\n    }\n\n    try {\n        const { recordings } = await httpRequest('GET', recordingsPath); // (4)!\n        res.status(200).json({ recordings }); // (5)!\n    } catch (error) {\n        handleApiError(res, error, 'Error fetching recordings');\n    }\n});\n</code></pre> <ol> <li>Create the base path for fetching recordings, including a <code>maxItems</code> parameter to limit the number of recordings returned to 100.</li> <li>Extract optional room name from query parameters for filtering.</li> <li>If a room name is provided, it appends the <code>roomId</code> parameter to the recordings path to filter recordings by that room.</li> <li>Fetch recordings using the OpenVidu Meet API by sending a <code>GET</code> request to the constructed <code>recordingsPath</code>.</li> <li>The server returns a <code>200 OK</code> response with the list of recordings in JSON format.</li> </ol> <p>This endpoint does the following:</p> <ol> <li>Creates the base path for fetching recordings, including a <code>maxItems</code> parameter to limit the number of recordings returned to 100.</li> <li>Extracts an optional room name from the query parameters for filtering. If a room name is provided, it appends the <code>roomId</code> parameter to the recordings path to filter recordings by that room.</li> <li>Fetches recordings using the OpenVidu Meet API by sending a <code>GET</code> request to the constructed <code>recordingsPath</code>.</li> <li>If successful, it returns a <code>200 OK</code> response with the list of recordings in JSON format. Otherwise, the error is handled by the <code>handleApiError</code> function.</li> </ol>","tags":["Meet"]},{"location":"meet/embedded/tutorials/recordings/#delete-recording","title":"Delete recording","text":"<p>The <code>DELETE /recordings/:recordingId</code> endpoint deletes the specified recording:</p> index.js<pre><code>// Delete a recording\napp.delete('/recordings/:recordingId', async (req, res) =&gt; {\n    const { recordingId } = req.params; // (1)!\n\n    try {\n        // Delete the recording using OpenVidu Meet API\n        await httpRequest('DELETE', `recordings/${recordingId}`); // (2)!\n        res.status(200).json({ message: `Recording '${recordingId}' deleted successfully` }); // (3)!\n    } catch (error) {\n        handleApiError(res, error, `Error deleting recording '${recordingId}'`);\n    }\n});\n</code></pre> <ol> <li>The <code>recordingId</code> parameter is obtained from the request parameters.</li> <li>The recording is deleted using the OpenVidu Meet API by sending a <code>DELETE</code> request to the <code>recordings/:recordingId</code> endpoint.</li> <li>The server returns a <code>200 OK</code> response with a success message.</li> </ol> <p>This endpoint simply deletes the specified recording using the OpenVidu Meet API by sending a <code>DELETE</code> request to the <code>recordings/:recordingId</code> endpoint. If the deletion is successful, it returns a <code>200 OK</code> response with a success message. Otherwise, the error is handled by the <code>handleApiError</code> function.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/recordings/#get-recording-url","title":"Get recording URL","text":"<p>A new <code>GET /recordings/:recordingId/url</code> endpoint retrieves the recording URL for playback:</p> index.js<pre><code>// Get recording URL\napp.get('/recordings/:recordingId/url', async (req, res) =&gt; {\n    const { recordingId } = req.params; // (1)!\n\n    try {\n        // Fetch the recording URL using OpenVidu Meet API\n        const { url } = await httpRequest('GET', `recordings/${recordingId}/url`); // (2)!\n        res.status(200).json({ url }); // (3)!\n    } catch (error) {\n        handleApiError(res, error, `Error fetching URL for recording '${recordingId}'`);\n    }\n});\n</code></pre> <ol> <li>The <code>recordingId</code> parameter is obtained from the request parameters.</li> <li>Fetch the recording URL from the OpenVidu Meet API by sending a <code>GET</code> request to the <code>recordings/:recordingId/url</code> endpoint.</li> <li>The server returns a <code>200 OK</code> response with the recording URL.</li> </ol> <p>This endpoint retrieves the playback URL for a specific recording by sending a <code>GET</code> request to the <code>recordings/:recordingId/url</code> endpoint. If successful, it returns a <code>200 OK</code> response with the recording URL. Otherwise, the error is handled by the <code>handleApiError</code> function.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/recordings/#frontend-modifications","title":"Frontend modifications","text":"<p>The frontend has been enhanced to include recording management functionality. The main changes are in the <code>public/js/app.js</code> file:</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/recordings/#additional-state-management","title":"Additional state management","text":"<p>A new <code>Map</code> is created to store recordings indexed by their recording ID:</p> app.js<pre><code>const rooms = new Map();\nconst recordings = new Map(); // (1)!\n</code></pre> <ol> <li>Added a recordings map to store recording data indexed by recording ID.</li> </ol>","tags":["Meet"]},{"location":"meet/embedded/tutorials/recordings/#enhanced-room-list-template","title":"Enhanced room list template","text":"<p>The room list template is updated to include a <code>View Recordings</code> button for each room:</p> app.js<pre><code>function getRoomListItemTemplate(room) {\n    return `\n        &lt;li class=\"list-group-item\"&gt;\n            &lt;span&gt;${room.roomName}&lt;/span&gt;\n            &lt;div class=\"room-actions\"&gt;\n                &lt;button\n                    class=\"btn btn-primary btn-sm\"\n                    onclick=\"joinRoom(\n                        '${room.roomName}', \n                        '${room.moderatorUrl}', \n                        'moderator'\n                    );\"\n                &gt;\n                    Join as Moderator\n                &lt;/button&gt;\n                &lt;button\n                    class=\"btn btn-secondary btn-sm\"\n                    onclick=\"joinRoom(\n                        '${room.roomName}', \n                        '${room.speakerUrl}', \n                        'speaker'\n                    );\"\n                &gt;\n                    Join as Speaker\n                &lt;/button&gt;\n                &lt;button \n                    class=\"btn btn-success btn-sm\" \n                    onclick=\"listRecordingsByRoom('${room.roomName}');\"\n                &gt;\n                    View Recordings\n                &lt;/button&gt;\n                &lt;button \n                    title=\"Delete room\"\n                    class=\"icon-button delete-button\"\n                    onclick=\"deleteRoom('${room.roomId}');\"\n                &gt;\n                    &lt;i class=\"fa-solid fa-trash\"&gt;&lt;/i&gt;\n                &lt;/button&gt;\n            &lt;/div&gt;\n        &lt;/li&gt;\n    `;\n}\n</code></pre> <p>This button calls the <code>listRecordingsByRoom()</code> function when clicked, passing the room name as an argument. This allows users to view recordings for that specific room.</p> app.js<pre><code>async function listRecordingsByRoom(roomName) {\n    // Hide the home screen and show the recordings screen\n    const homeScreen = document.querySelector('#home');\n    homeScreen.hidden = true; // (1)!\n    const recordingsScreen = document.querySelector('#recordings');\n    recordingsScreen.hidden = false; // (2)!\n\n    // Set the room name in the search input\n    const roomNameInput = document.querySelector('#recordings-room-search');\n    roomNameInput.value = roomName; // (3)!\n\n    await listRecordings(); // (4)!\n}\n</code></pre> <ol> <li>Hide the home screen</li> <li>Show the recordings screen.</li> <li>Pre-fill the room search input with the selected room name.</li> <li>Call the <code>listRecordings()</code> function to fetch and display recordings for the room.</li> </ol> <p>This function sets up the recordings view by hiding the home screen, showing the recordings screen, pre-filling the room search input with the selected room name, and calling the <code>listRecordings()</code> function to fetch and display recordings for that room.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/recordings/#listing-recordings","title":"Listing recordings","text":"<p>The <code>listRecordings()</code> function fetches and displays recordings, optionally filtering by room name:</p> app.js<pre><code>async function listRecordings() {\n    // Filter recordings by room name if provided\n    const roomName = document.querySelector('#recordings-room-search').value; // (1)!\n    const recordingsUrl = '/recordings' + (roomName ? `?room=${roomName}` : ''); // (2)!\n\n    try {\n        let { recordings: recordingsList } = await httpRequest('GET', recordingsUrl); // (3)!\n        // Filter completed recordings\n        recordingsList = filterCompletedRecordings(recordingsList); // (4)!\n\n        // Clear the previous recordings and populate the new ones\n        recordings.clear();\n        recordingsList.forEach((recording) =&gt; {\n            recordings.set(recording.recordingId, recording); // (5)!\n        });\n        renderRecordings(); // (6)!\n    } catch (error) {\n        console.error('Error listing recordings:', error.message);\n\n        // Show error message\n        const recordingsErrorElement = document.querySelector('#no-recordings-or-error');\n        recordingsErrorElement.textContent = 'Error loading recordings';\n        recordingsErrorElement.hidden = false;\n    }\n}\n\nfunction filterCompletedRecordings(recordingList) {\n    return recordingList.filter((recording) =&gt; recording.status === 'complete'); // (7)!\n}\n</code></pre> <ol> <li>Get the room name from the search input for filtering.</li> <li>Build the API URL with optional room filter parameter.</li> <li>Make a <code>GET</code> request to the <code>/recordings</code> endpoint to fetch the list of recordings.</li> <li>Call the <code>filterCompletedRecordings()</code> function to filter out recordings not completed.</li> <li>For each recording in the filtered list, add it to the <code>recordings</code> map indexed by recording ID.</li> <li>Call the <code>renderRecordings()</code> function to display the list of recordings in the UI.</li> <li>Filter recordings to include only those with 'complete' status.</li> </ol> <p>The listRecordings() function performs the following actions:</p> <ol> <li>Gets the room name from the search input field to optionally filter recordings by room.</li> <li>Makes a <code>GET</code> request to the <code>/recordings</code> endpoint to fetch the list of recordings, including the room filter parameter if specified.</li> <li>Filters the recordings to show only those with <code>complete</code> status using the <code>filterCompletedRecordings()</code> function.</li> <li>For each recording in the filtered list, it adds the recording to the <code>recordings</code> map. This map is used to store the recordings indexed by their recording IDs to make it easier to access them later.</li> <li>Calls the <code>renderRecordings()</code> function to display the list of recordings.</li> <li>If an error occurs during the request, it logs the error and displays an appropriate error message.</li> </ol> <p>The <code>renderRecordings()</code> function is responsible for updating the UI with the list of recordings:</p> app.js<pre><code>function renderRecordings() {\n    // Clear the previous list of recordings\n    const recordingsList = document.querySelector('#recordings-list ul'); // (1)!\n    recordingsList.innerHTML = ''; // (2)!\n\n    // Show or remove the \"No recordings found\" message\n    const noRecordingsElement = document.querySelector('#no-recordings-or-error');\n    if (recordings.size === 0) {\n        noRecordingsElement.textContent = 'No recordings found for the filters applied.';\n        noRecordingsElement.hidden = false;\n        return;\n    } else {\n        noRecordingsElement.textContent = '';\n        noRecordingsElement.hidden = true;\n    }\n\n    // Sort recordings by start date in ascending order\n    const recordingsArray = Array.from(recordings.values());\n    const sortedRecordings = sortRecordingsByDate(recordingsArray); // (3)!\n\n    // Add recordings to the list element\n    sortedRecordings.forEach((recording) =&gt; {\n        const recordingItem = getRecordingListItemTemplate(recording); // (4)!\n        recordingsList.innerHTML += recordingItem;\n    });\n}\n</code></pre> <ol> <li>Get the <code>ul</code> element where the list of recordings will be displayed.</li> <li>Clear the previous list of recordings.</li> <li>Sort recordings by start date in ascending order.</li> <li>For each recording, get the HTML template for the recording list item.</li> <li>Append the recording item to the list element.</li> </ol> <p>The <code>renderRecordings()</code> function performs the following actions:</p> <ol> <li>Clears the previous list of recordings by getting the <code>ul</code> element and setting its inner HTML to an empty string.</li> <li>Checks if there are any recordings in the <code>recordings</code> map. If there are no recordings, it shows a message indicating that no recordings were found for the filters applied. Otherwise, it hides the message.</li> <li>Sorts the recordings by start date in ascending order using the <code>sortRecordingsByDate()</code> function.</li> <li>For each recording in the sorted list, it calls the <code>getRecordingListItemTemplate()</code> function to get the HTML template for the recording list item.</li> <li>Appends the recording item to the list element.</li> </ol> <p>The <code>getRecordingListItemTemplate()</code> function generates the HTML template for each recording list item:</p> app.js<pre><code>function getRecordingListItemTemplate(recording) {\n    const recordingId = recording.recordingId; // (1)!\n    const roomName = recording.roomName; // (2)!\n    const startDate = recording.startDate ? new Date(recording.startDate).toLocaleString() : '-'; // (3)!\n    const duration = recording.duration ? secondsToHms(recording.duration) : '-'; // (4)!\n    const size = recording.size ? formatBytes(recording.size ?? 0) : '-'; // (5)!\n\n    return `\n        &lt;li class=\"recording-container\"&gt;\n            &lt;i class=\"fa-solid fa-file-video\"&gt;&lt;/i&gt;\n            &lt;div class=\"recording-info\"&gt;\n                &lt;p class=\"recording-name\"&gt;${roomName}&lt;/p&gt;\n                &lt;p&gt;&lt;span class=\"recording-info-tag\"&gt;Start date: &lt;/span&gt;&lt;span class=\"recording-info-value\"&gt;${startDate}&lt;/span&gt;&lt;/p&gt;\n                &lt;p&gt;&lt;span class=\"recording-info-tag\"&gt;Duration: &lt;/span&gt;&lt;span class=\"recording-info-value\"&gt;${duration}&lt;/span&gt;&lt;/p&gt;\n                &lt;p&gt;&lt;span class=\"recording-info-tag\"&gt;Size: &lt;/span&gt;&lt;span class=\"recording-info-value\"&gt;${size}&lt;/span&gt;&lt;/p&gt;\n            &lt;/div&gt;\n            &lt;div class=\"recording-actions\"&gt;\n                &lt;button title=\"Play\" class=\"icon-button\" onclick=\"displayRecording('${recordingId}')\"&gt;\n                    &lt;i class=\"fa-solid fa-play\"&gt;&lt;/i&gt;\n                &lt;/button&gt;\n                &lt;button title=\"Delete recording\" class=\"icon-button delete-button\" onclick=\"deleteRecording('${recordingId}')\"&gt;\n                    &lt;i class=\"fa-solid fa-trash\"&gt;&lt;/i&gt;\n                &lt;/button&gt;\n            &lt;/div&gt;\n        &lt;/li&gt;\n    `;\n}\n</code></pre> <ol> <li>Retrieve the recording ID.</li> <li>Retrieve the room name associated with the recording.</li> <li>Format the start date for display.</li> <li>Convert the duration from seconds to a human-readable format using the <code>secondsToHms()</code> helper function.</li> <li>Format the file size using the <code>formatBytes()</code> helper function.</li> </ol> <p>This function creates an HTML list item containing the recording's metadata, including the room name associated with the recording, start date, duration, and file size, along with buttons to play and delete the recording. The buttons call the <code>displayRecording()</code> and <code>deleteRecording()</code> functions respectively, passing the recording ID as an argument. The recording information is formatted using helper functions like <code>secondsToHms()</code> for duration and <code>formatBytes()</code> for file size to provide a user-friendly display.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/recordings/#playing-recording","title":"Playing recording","text":"<p>When the user clicks the play button for a recording, the <code>displayRecording()</code> function is called:</p> app.js<pre><code>async function displayRecording(recordingId) {\n    // Hide the recordings screen and show the display recording screen\n    const recordingsScreen = document.querySelector('#recordings');\n    recordingsScreen.hidden = true; // (1)!\n    const displayRecordingScreen = document.querySelector('#display-recording');\n    displayRecordingScreen.hidden = false; // (2)!\n\n    // Get the recording media URL and set it to the source of the video element\n    const recordingUrl = await getRecordingUrl(recordingId); // (3)!\n\n    // Inject the OpenVidu Meet component into the display recording container specifying the recording URL\n    displayRecordingScreen.innerHTML = `\n        &lt;openvidu-meet \n            recording-url=\"${recordingUrl}\"\n        &gt;\n        &lt;/openvidu-meet&gt;\n    `; // (4)!\n}\n\nasync function getRecordingUrl(recordingId) {\n    try {\n        const { url } = await httpRequest('GET', `/recordings/${recordingId}/url`); // (5)!\n        return url;\n    } catch (error) {\n        console.error('Error fetching recording URL:', error.message);\n        return null;\n    }\n}\n</code></pre> <ol> <li>Hide the recordings list screen.</li> <li>Show the recording playback screen.</li> <li>Fetch the recording URL from the backend using the <code>getRecordingUrl()</code> function.</li> <li>Inject the OpenVidu Meet WebComponent with the <code>recording-url</code> attribute for playback.</li> <li>Make a <code>GET</code> request to the <code>/recordings/:recordingId/url</code> endpoint to retrieve the recording URL.</li> </ol> <p>The <code>displayRecording()</code> function handles the playback of a specific recording by first hiding the recordings list screen and showing the display recording screen. It then fetches the recording URL from the backend using the <code>getRecordingUrl()</code> helper function, which makes a <code>GET</code> request to the <code>/recordings/:recordingId/url</code> endpoint. Finally, it injects the OpenVidu Meet WebComponent into the display container with the <code>recording-url</code> attribute set to the fetched URL, enabling the recording to be played directly in the browser. If an error occurs during URL fetching, it logs the error to the console and returns null.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/recordings/#deleting-recording","title":"Deleting recording","text":"<p>When the user clicks the delete recording button, the <code>deleteRecording()</code> function is called:</p> app.js<pre><code>async function deleteRecording(recordingId) {\n    try {\n        await httpRequest('DELETE', `/recordings/${recordingId}`); // (1)!\n\n        // Remove the recording from the list\n        recordings.delete(recordingId); // (2)!\n        renderRecordings(); // (3)!\n    } catch (error) {\n        console.error('Error deleting recording:', error.message);\n    }\n}\n</code></pre> <ol> <li>Make a <code>DELETE</code> request to the <code>/recordings/:recordingId</code> endpoint to delete the specified recording.</li> <li>Remove the recording from the <code>recordings</code> map.</li> <li>Call the <code>renderRecordings()</code> function to update the list of recordings.</li> </ol> <p>The <code>deleteRecording()</code> function simply makes a <code>DELETE</code> request to the <code>/recordings/:recordingId</code> endpoint to delete the specified recording. If the recording is successfully deleted, it removes the recording from the <code>recordings</code> map and calls the <code>renderRecordings()</code> function to update the list of recordings. If an error occurs during recording deletion, it logs the error to the console.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/recordings/#accessing-this-tutorial-from-other-computers-or-phones","title":"Accessing this tutorial from other computers or phones","text":"<p>To access this tutorial from other computers or phones, follow these steps:</p> <ol> <li> <p>Ensure network connectivity: Make sure your device (computer or phone) is connected to the same network as the machine running OpenVidu Meet and this tutorial.</p> </li> <li> <p>Configure OpenVidu Meet for network access: Start OpenVidu Meet by following the instructions in the Accessing OpenVidu Meet from other computers or phones  section.</p> </li> <li> <p>Update the OpenVidu Meet server URL: Modify the <code>OV_MEET_SERVER_URL</code> environment variable in your <code>.env</code> file to match the URL shown when OpenVidu Meet starts.</p> <pre><code># Example for IP address 192.168.1.100\nOV_MEET_SERVER_URL=https://192-168-1-100.openvidu-local.dev:9443\n</code></pre> </li> <li> <p>Update the OpenVidu Meet WebComponent script URL: In the <code>public/index.html</code> file, update the <code>&lt;script&gt;</code> tag that includes the OpenVidu Meet WebComponent to use the same base URL as above.</p> <pre><code>&lt;script src=\"http://192-168-1-100.openvidu-local.dev:9443/v1/openvidu-meet.js\"&gt;&lt;/script&gt;\n</code></pre> </li> <li> <p>Restart the tutorial to apply the changes:</p> <pre><code>npm start\n</code></pre> </li> <li> <p>Access the tutorial: Open your browser and navigate to <code>https://192-168-1-100.openvidu-local.dev:6443</code> (replacing <code>192-168-1-100</code> with your actual private IP) on the computer where you started the tutorial or any device in the same network.</p> </li> </ol>","tags":["Meet"]},{"location":"meet/embedded/tutorials/recordings/#connecting-this-tutorial-to-an-openvidu-meet-production-deployment","title":"Connecting this tutorial to an OpenVidu Meet production deployment","text":"<p>If you have a production deployment of OpenVidu Meet (installed in a server following deployment steps ), you can connect this tutorial to it by following these steps:</p> <ol> <li> <p>Update the server URL: Modify the <code>OV_MEET_SERVER_URL</code> environment variable in the <code>.env</code> file to point to your OpenVidu Meet production deployment URL.</p> <pre><code># Example for a production deployment\nOV_MEET_SERVER_URL=https://your-openvidu-meet-domain.com\n</code></pre> </li> <li> <p>Update the API key: Ensure the <code>OV_MEET_API_KEY</code> environment variable in the <code>.env</code> file matches the API key configured in your production deployment. See Generate an API Key  section to learn how to obtain it.</p> <pre><code>OV_MEET_API_KEY=your-production-api-key\n</code></pre> </li> <li> <p>Update the OpenVidu Meet WebComponent script URL: In the <code>public/index.html</code> file, update the <code>&lt;script&gt;</code> tag that includes the OpenVidu Meet WebComponent to use the same base URL as above.</p> <pre><code>&lt;script src=\"https://your-openvidu-meet-domain.com/v1/openvidu-meet.js\"&gt;&lt;/script&gt;\n</code></pre> </li> <li> <p>Restart the tutorial to apply the changes:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Make this tutorial accessible from other computers or phones</p> <p>By default, this tutorial runs on <code>http://localhost:6080</code> and is only accessible from the local machine. If you want to access it from other computers or phones, you have the following options:</p> <ul> <li>Use tunneling tools: Configure tools like VS Code port forwarding , ngrok , localtunnel , or similar services to expose this tutorial to the internet with a secure (HTTPS) public URL.</li> <li>Deploy to a server: Upload this tutorial to a web server and configure it to be accessible with a secure (HTTPS) public URL. This can be done by updating the source code to manage SSL certificates or configuring a reverse proxy (e.g., Nginx, Apache) to serve it.</li> </ul>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webcomponent-advanced/","title":"OpenVidu Meet WebComponent Commands & Events Tutorial","text":"","tags":["Meet"]},{"location":"meet/embedded/tutorials/webcomponent-advanced/#openvidu-meet-webcomponent-commands-events-tutorial","title":"OpenVidu Meet WebComponent Commands &amp; Events Tutorial","text":"<p>Source code </p> <p>This tutorial extends the basic WebComponent tutorial to add advanced WebComponent functionality through commands and event handling. It demonstrates how to interact with the OpenVidu Meet WebComponent programmatically and respond to meeting events.</p> <p>The application includes all the features from the basic WebComponent tutorial, plus:</p> <ul> <li>WebComponent commands: Control the meeting programmatically (e.g., end meeting for moderators).</li> <li>Event handling: Listen to and respond to WebComponent events (joined, left, closed).</li> <li>Role-based UI: Display different interface elements based on user role (moderator/speaker).</li> <li>Meeting header: Show room information and controls above the WebComponent.</li> <li>Enhanced room management: In-memory room tracking with unique names per room.</li> </ul>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webcomponent-advanced/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Meet"]},{"location":"meet/embedded/tutorials/webcomponent-advanced/#1-run-openvidu-meet","title":"1. Run OpenVidu Meet","text":"<p>You need Docker Desktop. You can install it on Windows , Mac  or Linux .</p> <p>Run this command in Docker Desktop's terminal:</p> <pre><code>docker compose -p openvidu-meet -f oci://openvidu/local-meet:3.4.0 up -y openvidu-meet-init\n</code></pre> <p>Info</p> <p>For a detailed guide on how to run OpenVidu Meet locally, visit Try OpenVidu Meet locally .</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webcomponent-advanced/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-meet-tutorials.git -b 3.4.0\n</code></pre>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webcomponent-advanced/#3-run-the-application","title":"3. Run the application","text":"<p>To run this application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the application directory</li> </ol> <pre><code>cd openvidu-meet-tutorials/meet-webcomponent-commands-events\n</code></pre> <ol> <li>Install dependencies</li> </ol> <pre><code>npm install\n</code></pre> <ol> <li>Run the application</li> </ol> <pre><code>npm start\n</code></pre> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:6080</code>. You should see a screen like this:</p> <p></p> <p></p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webcomponent-advanced/#understanding-the-code","title":"Understanding the code","text":"<p>This tutorial builds upon the basic WebComponent tutorial, adding advanced WebComponent interaction capabilities and enhanced room management. We'll focus on the key differences and new functionality.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webcomponent-advanced/#backend","title":"Backend","text":"<p>The backend is identical to previous tutorials. It provides the same three REST API endpoints:</p> <ul> <li><code>POST /rooms</code>: Create a new room with the given room name.</li> <li><code>GET /rooms</code>: Get the list of rooms.</li> <li><code>DELETE /rooms/:roomId</code>: Delete a room with the given room ID.</li> </ul> <p>For detailed backend documentation, please refer to the Direct Link tutorial backend section.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webcomponent-advanced/#frontend-modifications","title":"Frontend modifications","text":"<p>The frontend changes focus on enhanced room management, WebComponent event handling, and role-based UI features.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webcomponent-advanced/#enhanced-room-template","title":"Enhanced room template","text":"<p>The room template now passes additional parameters including role information:</p> app.js<pre><code>function getRoomListItemTemplate(room) {\n    return `\n        &lt;li class=\"list-group-item\"&gt;\n            &lt;span&gt;${room.roomName}&lt;/span&gt;\n            &lt;div class=\"room-actions\"&gt;\n                &lt;button\n                    class=\"btn btn-primary btn-sm\"\n                    onclick=\"joinRoom(\n                        '${room.roomName}', \n                        '${room.moderatorUrl}', \n                        'moderator'\n                    );\"\n                &gt;\n                    Join as Moderator\n                &lt;/button&gt;\n                &lt;button\n                    class=\"btn btn-secondary btn-sm\"\n                    onclick=\"joinRoom(\n                        '${room.roomName}', \n                        '${room.speakerUrl}', \n                        'speaker'\n                    );\"\n                &gt;\n                    Join as Speaker\n                &lt;/button&gt;\n                &lt;button \n                    title=\"Delete room\"\n                    class=\"icon-button delete-button\"\n                    onclick=\"deleteRoom('${room.roomId}');\"\n                &gt;\n                    &lt;i class=\"fa-solid fa-trash\"&gt;&lt;/i&gt;\n                &lt;/button&gt;\n            &lt;/div&gt;\n        &lt;/li&gt;\n    `;\n}\n</code></pre> <p>The template now provides the room name and user role to the <code>joinRoom()</code> function, enabling role-based functionality and proper room identification.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webcomponent-advanced/#advanced-room-joining-with-commands-and-events","title":"Advanced room joining with commands and events","text":"<p>The <code>joinRoom()</code> function has been significantly enhanced to handle WebComponent events and commands:</p> app.js<pre><code>function joinRoom(roomName, roomUrl, role) {\n    console.log(`Joining room as ${role}`);\n\n    // Hide the home screen and show the room screen\n    const homeScreen = document.querySelector('#home');\n    homeScreen.hidden = true; // (1)!\n    const roomScreen = document.querySelector('#room');\n    roomScreen.hidden = false; // (2)!\n\n    // Hide the room header until the local participant joins\n    const roomHeader = document.querySelector('#room-header');\n    roomHeader.hidden = true; // (3)!\n\n    // Inject the OpenVidu Meet component into the meeting container specifying the room URL\n    const meetingContainer = document.querySelector('#meeting-container');\n    meetingContainer.innerHTML = `\n        &lt;openvidu-meet \n            room-url=\"${roomUrl}\"\n        &gt;\n        &lt;/openvidu-meet&gt;\n    `; // (4)!\n\n    // Add event listeners for the OpenVidu Meet component\n    const meet = document.querySelector('openvidu-meet');\n\n    // Event listener for when the local participant joins the room\n    meet.once('joined', () =&gt; {\n        // (5)!\n        console.log('Local participant joined the room');\n\n        // Show the room header with the room name\n        roomHeader.hidden = false;\n        const roomNameHeader = document.querySelector('#room-name-header');\n        roomNameHeader.textContent = roomName; // (6)!\n\n        // Show end meeting button only for moderators\n        const endMeetingButton = document.querySelector('#end-meeting-btn');\n        if (role === 'moderator') {\n            endMeetingButton.hidden = false; // (7)!\n        } else {\n            endMeetingButton.hidden = true;\n        }\n\n        // Event listener for ending the meeting\n        if (role === 'moderator') {\n            endMeetingButton.addEventListener('click', () =&gt; {\n                console.log('Ending meeting');\n                meet.endMeeting(); // (8)!\n            });\n        }\n    });\n\n    // Event listener for when the local participant leaves the room\n    meet.once('left', (event) =&gt; {\n        // (9)!\n        console.log('Local participant left the room. Reason:', event.reason);\n\n        // Hide the room header\n        roomHeader.hidden = true;\n    });\n\n    // Event listener for when the OpenVidu Meet component is closed\n    meet.once('closed', () =&gt; {\n        // (10)!\n        console.log('OpenVidu Meet component closed');\n\n        // Hide the room screen and show the home screen\n        roomScreen.hidden = true;\n        homeScreen.hidden = false;\n    });\n}\n</code></pre> <ol> <li>Hide the home screen.</li> <li>Show the room screen.</li> <li>Hide the room header until the local participant joins.</li> <li>Inject the OpenVidu Meet WebComponent into the meeting container with the specified room URL.</li> <li>Add an event listener for the <code>joined</code> event, which is triggered when the local participant joins the room.</li> <li>Set the room name in the header.</li> <li>Show the end meeting button if the user is a moderator.</li> <li>Call the <code>endMeeting()</code> method of the OpenVidu Meet WebComponent to end the meeting when the moderator clicks the <code>End Meeting</code> button.</li> <li>Add an event listener for the <code>left</code> event, which is triggered when the local participant leaves the room.</li> <li>Add an event listener for the <code>closed</code> event, which is triggered when the OpenVidu Meet component is closed.</li> </ol> <p>The enhanced <code>joinRoom()</code> function now performs the following actions:</p> <ol> <li>Hides the home screen and shows the room screen.</li> <li>Hides the room header until the local participant joins.</li> <li>Injects the OpenVidu Meet WebComponent into the meeting container with the specified room URL.</li> <li> <p>Configures event listeners for the OpenVidu Meet WebComponent to handle different events:</p> <ul> <li><code>joined</code>: This event is triggered when the local participant joins the room. It shows the room header with the room name and displays the <code>End Meeting</code> button if the user is a moderator. It also adds an event listener for the <code>End Meeting</code> button to call the <code>endMeeting()</code> method of the OpenVidu Meet WebComponent to end the meeting. This method disconnects all participants and ends the meeting for everyone.</li> <li><code>left</code>: This event is triggered when the local participant leaves the room. It hides the room header.</li> <li><code>closed</code>: This event is triggered when the OpenVidu Meet component is closed. It hides the room screen and shows the home screen.</li> </ul> </li> </ol>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webcomponent-advanced/#accessing-this-tutorial-from-other-computers-or-phones","title":"Accessing this tutorial from other computers or phones","text":"<p>To access this tutorial from other computers or phones, follow these steps:</p> <ol> <li> <p>Ensure network connectivity: Make sure your device (computer or phone) is connected to the same network as the machine running OpenVidu Meet and this tutorial.</p> </li> <li> <p>Configure OpenVidu Meet for network access: Start OpenVidu Meet by following the instructions in the Accessing OpenVidu Meet from other computers or phones  section.</p> </li> <li> <p>Update the OpenVidu Meet server URL: Modify the <code>OV_MEET_SERVER_URL</code> environment variable in your <code>.env</code> file to match the URL shown when OpenVidu Meet starts.</p> <pre><code># Example for IP address 192.168.1.100\nOV_MEET_SERVER_URL=https://192-168-1-100.openvidu-local.dev:9443\n</code></pre> </li> <li> <p>Update the OpenVidu Meet WebComponent script URL: In the <code>public/index.html</code> file, update the <code>&lt;script&gt;</code> tag that includes the OpenVidu Meet WebComponent to use the same base URL as above.</p> <pre><code>&lt;script src=\"http://192-168-1-100.openvidu-local.dev:9443/v1/openvidu-meet.js\"&gt;&lt;/script&gt;\n</code></pre> </li> <li> <p>Restart the tutorial to apply the changes:</p> <pre><code>npm start\n</code></pre> </li> <li> <p>Access the tutorial: Open your browser and navigate to <code>https://192-168-1-100.openvidu-local.dev:6443</code> (replacing <code>192-168-1-100</code> with your actual private IP) on the computer where you started the tutorial or any device in the same network.</p> </li> </ol>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webcomponent-advanced/#connecting-this-tutorial-to-an-openvidu-meet-production-deployment","title":"Connecting this tutorial to an OpenVidu Meet production deployment","text":"<p>If you have a production deployment of OpenVidu Meet (installed in a server following deployment steps ), you can connect this tutorial to it by following these steps:</p> <ol> <li> <p>Update the server URL: Modify the <code>OV_MEET_SERVER_URL</code> environment variable in the <code>.env</code> file to point to your OpenVidu Meet production deployment URL.</p> <pre><code># Example for a production deployment\nOV_MEET_SERVER_URL=https://your-openvidu-meet-domain.com\n</code></pre> </li> <li> <p>Update the API key: Ensure the <code>OV_MEET_API_KEY</code> environment variable in the <code>.env</code> file matches the API key configured in your production deployment. See Generate an API Key  section to learn how to obtain it.</p> <pre><code>OV_MEET_API_KEY=your-production-api-key\n</code></pre> </li> <li> <p>Update the OpenVidu Meet WebComponent script URL: In the <code>public/index.html</code> file, update the <code>&lt;script&gt;</code> tag that includes the OpenVidu Meet WebComponent to use the same base URL as above.</p> <pre><code>&lt;script src=\"https://your-openvidu-meet-domain.com/v1/openvidu-meet.js\"&gt;&lt;/script&gt;\n</code></pre> </li> <li> <p>Restart the tutorial to apply the changes:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Make this tutorial accessible from other computers or phones</p> <p>By default, this tutorial runs on <code>http://localhost:6080</code> and is only accessible from the local machine. If you want to access it from other computers or phones, you have the following options:</p> <ul> <li>Use tunneling tools: Configure tools like VS Code port forwarding , ngrok , localtunnel , or similar services to expose this tutorial to the internet with a secure (HTTPS) public URL.</li> <li>Deploy to a server: Upload this tutorial to a web server and configure it to be accessible with a secure (HTTPS) public URL. This can be done by updating the source code to manage SSL certificates or configuring a reverse proxy (e.g., Nginx, Apache) to serve it.</li> </ul>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webcomponent/","title":"OpenVidu Meet WebComponent Tutorial","text":"","tags":["Meet"]},{"location":"meet/embedded/tutorials/webcomponent/#openvidu-meet-webcomponent-tutorial","title":"OpenVidu Meet WebComponent Tutorial","text":"<p>Source code </p> <p>This tutorial extends the Direct Link tutorial by integrating the OpenVidu Meet WebComponent directly into your application instead of using external links. It is built using Node.js and Express for the backend and plain HTML/CSS/JavaScript for the frontend.</p> <p>At the end of this tutorial, you will have a fully functional simple video-call application with the following features:</p> <ul> <li>Users can create rooms.</li> <li>Users can delete rooms.</li> <li>Users can join a room as moderator or speaker.</li> <li>Users can chat with other users.</li> <li>Users may leave the room at any time.</li> <li>Users can view the recordings of the meeting.</li> <li>Moderators can record the meeting.</li> <li>Moderators may end the meeting at any time, disconnecting all users.</li> </ul> <p>The application uses the OpenVidu Meet API to create and delete rooms, and the OpenVidu Meet WebComponent to embed the video call interface directly into the application.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webcomponent/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Meet"]},{"location":"meet/embedded/tutorials/webcomponent/#1-run-openvidu-meet","title":"1. Run OpenVidu Meet","text":"<p>You need Docker Desktop. You can install it on Windows , Mac  or Linux .</p> <p>Run this command in Docker Desktop's terminal:</p> <pre><code>docker compose -p openvidu-meet -f oci://openvidu/local-meet:3.4.0 up -y openvidu-meet-init\n</code></pre> <p>Info</p> <p>For a detailed guide on how to run OpenVidu Meet locally, visit Try OpenVidu Meet locally .</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webcomponent/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-meet-tutorials.git -b 3.4.0\n</code></pre>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webcomponent/#3-run-the-application","title":"3. Run the application","text":"<p>To run this application, you need Node.js  installed on your device.</p> <ol> <li>Navigate into the application directory</li> </ol> <pre><code>cd openvidu-meet-tutorials/meet-webcomponent-basic\n</code></pre> <ol> <li>Install dependencies</li> </ol> <pre><code>npm install\n</code></pre> <ol> <li>Run the application</li> </ol> <pre><code>npm start\n</code></pre> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:6080</code>. You should see a screen like this:</p> <p></p> <p></p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webcomponent/#understanding-the-code","title":"Understanding the code","text":"<p>This tutorial builds upon the Direct Link tutorial, replacing external redirect links with an embedded OpenVidu Meet WebComponent. The backend remains identical, so we'll focus on the frontend modifications that enable WebComponent integration.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webcomponent/#backend","title":"Backend","text":"<p>The backend is identical to the Direct Link tutorial. It provides the same three REST API endpoints:</p> <ul> <li><code>POST /rooms</code>: Create a new room with the given room name.</li> <li><code>GET /rooms</code>: Get the list of rooms.</li> <li><code>DELETE /rooms/:roomId</code>: Delete a room with the given room ID.</li> </ul> <p>For detailed backend documentation, please refer to the Direct Link tutorial backend section.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webcomponent/#frontend-modifications","title":"Frontend modifications","text":"<p>The main changes in the frontend involve replacing direct links with embedded WebComponent functionality. The key modifications are in the <code>public/js/app.js</code> and <code>public/index.html</code> files.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webcomponent/#including-the-openvidu-meet-webcomponent","title":"Including the OpenVidu Meet WebComponent","text":"<p>To use the OpenVidu Meet WebComponent in your application, you need to include it in your HTML file by adding a script tag to the end of the <code>&lt;body&gt;</code> section:</p> index.html<pre><code>&lt;!-- OpenVidu Meet WebComponent bundle --&gt;\n&lt;script src=\"http://localhost:9080/v1/openvidu-meet.js\"&gt;&lt;/script&gt;\n</code></pre>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webcomponent/#enhanced-room-list-template","title":"Enhanced room list template","text":"<p>The room list template has been modified to use buttons instead of direct links, enabling WebComponent integration:</p> app.js<pre><code>function getRoomListItemTemplate(room) {\n    return `\n        &lt;li class=\"list-group-item\"&gt;\n            &lt;span&gt;${room.roomName}&lt;/span&gt;\n            &lt;div class=\"room-actions\"&gt;\n                &lt;button\n                    class=\"btn btn-primary btn-sm\"\n                    onclick=\"joinRoom('${room.moderatorUrl}');\"\n                &gt;\n                    Join as Moderator\n                &lt;/button&gt;\n                &lt;button\n                    class=\"btn btn-secondary btn-sm\"\n                    onclick=\"joinRoom('${room.speakerUrl}');\"\n                &gt;\n                    Join as Speaker\n                &lt;/button&gt;\n                &lt;button \n                    title=\"Delete room\"\n                    class=\"icon-button delete-button\"\n                    onclick=\"deleteRoom('${room.roomId}');\"\n                &gt;\n                    &lt;i class=\"fa-solid fa-trash\"&gt;&lt;/i&gt;\n                &lt;/button&gt;\n            &lt;/div&gt;\n        &lt;/li&gt;\n    `;\n}\n</code></pre> <p>The key difference from the Direct Link tutorial is that instead of using anchor tags (<code>&lt;a&gt;</code>) with <code>href</code> attributes pointing to external URLs, this template uses buttons that call the <code>joinRoom()</code> function with the appropriate room URL.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webcomponent/#joining-a-room-with-webcomponent","title":"Joining a room with WebComponent","text":"<p>When the user clicks the <code>Join as Moderator</code> or <code>Join as Speaker</code> button, the <code>joinRoom()</code> function is called, which handles embedding the OpenVidu Meet WebComponent:</p> app.js<pre><code>function joinRoom(roomUrl) {\n    // Hide the home screen and show the room screen\n    const homeScreen = document.querySelector('#home');\n    homeScreen.hidden = true; // (1)!\n    const roomScreen = document.querySelector('#room');\n    roomScreen.hidden = false; // (2)!\n\n    // Inject the OpenVidu Meet component into the meeting container specifying the room URL\n    const meetingContainer = document.querySelector('#meeting-container');\n    meetingContainer.innerHTML = `\n        &lt;openvidu-meet \n            room-url=\"${roomUrl}\"\n            leave-redirect-url=\"/\"\n        &gt;\n        &lt;/openvidu-meet&gt;\n    `; // (3)!\n}\n</code></pre> <ol> <li>Hide the home screen to prepare for the meeting view.</li> <li>Show the room screen where the WebComponent will be embedded.</li> <li>Inject the OpenVidu Meet WebComponent into the meeting container with the specified room URL and a leave redirect URL.</li> </ol> <p>The <code>joinRoom()</code> function hides the home screen and shows the room screen to provide a dedicated space for the video meeting. Then, it dynamically creates and injects the <code>&lt;openvidu-meet&gt;</code> WebComponent into the meeting container, setting the <code>room-url</code> attribute with the URL provided by the OpenVidu Meet API and configuring the <code>leave-redirect-url</code> attribute to return users to the home screen when they leave the meeting.</p> <p>This approach provides a seamless user experience by keeping users within the same application while providing full video conferencing functionality through the embedded WebComponent.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webcomponent/#accessing-this-tutorial-from-other-computers-or-phones","title":"Accessing this tutorial from other computers or phones","text":"<p>To access this tutorial from other computers or phones, follow these steps:</p> <ol> <li> <p>Ensure network connectivity: Make sure your device (computer or phone) is connected to the same network as the machine running OpenVidu Meet and this tutorial.</p> </li> <li> <p>Configure OpenVidu Meet for network access: Start OpenVidu Meet by following the instructions in the Accessing OpenVidu Meet from other computers or phones  section.</p> </li> <li> <p>Update the OpenVidu Meet server URL: Modify the <code>OV_MEET_SERVER_URL</code> environment variable in your <code>.env</code> file to match the URL shown when OpenVidu Meet starts.</p> <pre><code># Example for IP address 192.168.1.100\nOV_MEET_SERVER_URL=https://192-168-1-100.openvidu-local.dev:9443\n</code></pre> </li> <li> <p>Update the OpenVidu Meet WebComponent script URL: In the <code>public/index.html</code> file, update the <code>&lt;script&gt;</code> tag that includes the OpenVidu Meet WebComponent to use the same base URL as above.</p> <pre><code>&lt;script src=\"http://192-168-1-100.openvidu-local.dev:9443/v1/openvidu-meet.js\"&gt;&lt;/script&gt;\n</code></pre> </li> <li> <p>Restart the tutorial to apply the changes:</p> <pre><code>npm start\n</code></pre> </li> <li> <p>Access the tutorial: Open your browser and navigate to <code>https://192-168-1-100.openvidu-local.dev:6443</code> (replacing <code>192-168-1-100</code> with your actual private IP) on the computer where you started the tutorial or any device in the same network.</p> </li> </ol>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webcomponent/#connecting-this-tutorial-to-an-openvidu-meet-production-deployment","title":"Connecting this tutorial to an OpenVidu Meet production deployment","text":"<p>If you have a production deployment of OpenVidu Meet (installed in a server following deployment steps ), you can connect this tutorial to it by following these steps:</p> <ol> <li> <p>Update the server URL: Modify the <code>OV_MEET_SERVER_URL</code> environment variable in the <code>.env</code> file to point to your OpenVidu Meet production deployment URL.</p> <pre><code># Example for a production deployment\nOV_MEET_SERVER_URL=https://your-openvidu-meet-domain.com\n</code></pre> </li> <li> <p>Update the API key: Ensure the <code>OV_MEET_API_KEY</code> environment variable in the <code>.env</code> file matches the API key configured in your production deployment. See Generate an API Key  section to learn how to obtain it.</p> <pre><code>OV_MEET_API_KEY=your-production-api-key\n</code></pre> </li> <li> <p>Update the OpenVidu Meet WebComponent script URL: In the <code>public/index.html</code> file, update the <code>&lt;script&gt;</code> tag that includes the OpenVidu Meet WebComponent to use the same base URL as above.</p> <pre><code>&lt;script src=\"https://your-openvidu-meet-domain.com/v1/openvidu-meet.js\"&gt;&lt;/script&gt;\n</code></pre> </li> <li> <p>Restart the tutorial to apply the changes:</p> <pre><code>npm start\n</code></pre> </li> </ol> <p>Make this tutorial accessible from other computers or phones</p> <p>By default, this tutorial runs on <code>http://localhost:6080</code> and is only accessible from the local machine. If you want to access it from other computers or phones, you have the following options:</p> <ul> <li>Use tunneling tools: Configure tools like VS Code port forwarding , ngrok , localtunnel , or similar services to expose this tutorial to the internet with a secure (HTTPS) public URL.</li> <li>Deploy to a server: Upload this tutorial to a web server and configure it to be accessible with a secure (HTTPS) public URL. This can be done by updating the source code to manage SSL certificates or configuring a reverse proxy (e.g., Nginx, Apache) to serve it.</li> </ul>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webhooks/","title":"OpenVidu Meet Webhooks Tutorial","text":"","tags":["Meet"]},{"location":"meet/embedded/tutorials/webhooks/#openvidu-meet-webhooks-tutorial","title":"OpenVidu Meet Webhooks Tutorial","text":"<p>Source code </p> <p>This tutorial extends the recordings tutorial to add real-time updates through webhooks and Server-Sent Events (SSE). It demonstrates how to receive and process OpenVidu Meet webhooks to provide live status updates for rooms and recordings.</p> <p>The application includes all the features from the recordings tutorial, plus:</p> <ul> <li>Real-time room status updates: Live updates when meetings start or end.</li> <li>Live recording updates: Instant updates when recordings are completed.</li> <li>Webhook validation: Secure webhook processing with signature verification.</li> <li>Room status badges: Visual indicators showing room status (open, active, closed).</li> <li>Server-Sent Events: Efficient real-time communication between server and client.</li> </ul>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webhooks/#running-this-tutorial","title":"Running this tutorial","text":"","tags":["Meet"]},{"location":"meet/embedded/tutorials/webhooks/#1-run-openvidu-meet","title":"1. Run OpenVidu Meet","text":"<p>You need Docker Desktop. You can install it on Windows , Mac  or Linux .</p> <p>Run this command in Docker Desktop's terminal:</p> <pre><code>docker compose -p openvidu-meet -f oci://openvidu/local-meet:3.4.0 up -y openvidu-meet-init\n</code></pre> <p>Info</p> <p>For a detailed guide on how to run OpenVidu Meet locally, visit Try OpenVidu Meet locally .</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webhooks/#2-download-the-tutorial-code","title":"2. Download the tutorial code","text":"<pre><code>git clone https://github.com/OpenVidu/openvidu-meet-tutorials.git -b 3.4.0\n</code></pre>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webhooks/#3-run-the-application","title":"3. Run the application","text":"<p>To run this application, you need Node.js  (\u2265 18) installed on your device.</p> <ol> <li>Navigate into the application directory</li> </ol> <pre><code>cd openvidu-meet-tutorials/meet-webhooks\n</code></pre> <ol> <li>Install dependencies</li> </ol> <pre><code>npm install\n</code></pre> <ol> <li>Run the application</li> </ol> <pre><code>npm start\n</code></pre> <p>Once the server is up and running, you can test the application by visiting <code>http://localhost:6080</code>. You should see a screen like this:</p> <p></p> <p></p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webhooks/#understanding-the-code","title":"Understanding the code","text":"<p>This tutorial builds upon the recordings tutorial, adding real-time functionality through webhooks and Server-Sent Events. We'll focus on the new webhook handling capabilities and live update features.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webhooks/#backend-modifications","title":"Backend modifications","text":"<p>The main backend changes involve implementing webhook processing, SSE communication, and security validation.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webhooks/#server-sent-events-setup","title":"Server-Sent Events setup","text":"<p>The backend now includes SSE support for real-time client notifications:</p> index.js<pre><code>import bodyParser from 'body-parser';\nimport cors from 'cors';\nimport crypto from 'crypto';\nimport dotenv from 'dotenv';\nimport express from 'express';\nimport SSE from 'express-sse'; // (1)!\nimport path from 'path';\nimport { fileURLToPath } from 'url';\n\ndotenv.config();\n\n// Configuration\nconst SERVER_PORT = process.env.SERVER_PORT || 6080;\nconst OV_MEET_SERVER_URL = process.env.OV_MEET_SERVER_URL || 'http://localhost:9080';\nconst OV_MEET_API_KEY = process.env.OV_MEET_API_KEY || 'meet-api-key';\nconst MAX_WEBHOOK_AGE = 120 * 1000; // 2 minutes in milliseconds\n\n// Create SSE instance for real-time notifications\nconst sse = new SSE(); // (2)!\n</code></pre> <ol> <li>Import the <code>express-sse</code> library for Server-Sent Events functionality.</li> <li>Create an SSE instance to manage real-time notifications to connected clients.</li> </ol> <p>This code sets up the backend to support Server-Sent Events (SSE), enabling the server to push real-time notifications to connected clients. It imports the <code>express-sse</code> library and initializes an SSE instance for managing live event streams.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webhooks/#sse-endpoint-for-client-subscriptions","title":"SSE endpoint for client subscriptions","text":"<p>A new endpoint allows clients to subscribe to real-time notifications:</p> index.js<pre><code>// SSE endpoint for real-time notifications\napp.get('/events', sse.init); // (1)!\n</code></pre> <ol> <li>Create an SSE endpoint that clients can connect to for receiving real-time webhook notifications.</li> </ol> <p>This endpoint enables clients to establish a persistent connection for receiving live updates about room status changes and recording completions.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webhooks/#webhook-processing-endpoint","title":"Webhook processing endpoint","text":"<p>A new endpoint handles incoming webhooks from OpenVidu Meet:</p> index.js<pre><code>// Webhook endpoint to receive events from OpenVidu Meet\napp.post('/webhook', (req, res) =&gt; {\n    const body = req.body;\n    const headers = req.headers;\n\n    if (!isWebhookEventValid(body, headers)) {\n        // (1)!\n        console.error('Invalid webhook signature');\n        return res.status(401).send('Invalid webhook signature');\n    }\n\n    console.log('Webhook received:', body);\n\n    // Broadcast the webhook event to all connected SSE clients\n    sse.send(body); // (2)!\n\n    res.status(200).send();\n});\n</code></pre> <ol> <li>Validate the webhook signature and timestamp to ensure authenticity and prevent replay attacks.</li> <li>Broadcast the validated webhook event to all connected SSE clients for real-time updates.</li> </ol> <p>This endpoint receives webhook events from OpenVidu Meet, validates their authenticity, and broadcasts them to all connected clients through Server-Sent Events.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webhooks/#webhook-signature-validation","title":"Webhook signature validation","text":"<p>A security function validates webhook authenticity:</p> index.js<pre><code>// Helper function to validate webhook event signature\nconst isWebhookEventValid = (body, headers) =&gt; {\n    const signature = headers['x-signature']; // (1)!\n    const timestamp = parseInt(headers['x-timestamp'], 10); // (2)!\n\n    if (!signature || !timestamp || isNaN(timestamp)) {\n        return false; // (3)!\n    }\n\n    const current = Date.now();\n    const diffTime = current - timestamp;\n    if (diffTime &gt;= MAX_WEBHOOK_AGE) {\n        // Webhook event too old\n        return false; // (4)!\n    }\n\n    const signedPayload = `${timestamp}.${JSON.stringify(body)}`; // (5)!\n    const expectedSignature = crypto.createHmac('sha256', OV_MEET_API_KEY).update(signedPayload, 'utf8').digest('hex'); // (6)!\n\n    return crypto.timingSafeEqual(Buffer.from(expectedSignature, 'hex'), Buffer.from(signature, 'hex')); // (7)!\n};\n</code></pre> <ol> <li>Extract the webhook signature from the <code>x-signature</code> header.</li> <li>Extract and parse the timestamp from the <code>x-timestamp</code> header.</li> <li>Return false if required headers are missing or invalid.</li> <li>Reject webhooks older than the maximum allowed age to prevent replay attacks.</li> <li>Create the signed payload by combining timestamp and JSON body.</li> <li>Generate the expected signature using HMAC-SHA256 with the API key.</li> <li>Use timing-safe comparison to validate the signature against the expected value.</li> </ol> <p>This function implements webhook security by validating both the cryptographic signature and the timestamp to ensure webhooks are authentic and recent.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webhooks/#frontend-modifications","title":"Frontend modifications","text":"<p>The frontend has been enhanced with real-time update capabilities and improved visual feedback for room status.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webhooks/#real-time-notifications-setup","title":"Real-time notifications setup","text":"<p>The application now establishes an SSE connection on page load:</p> app.js<pre><code>document.addEventListener('DOMContentLoaded', async () =&gt; {\n    await fetchRooms();\n    // Start listening for webhook notifications\n    startWebhookNotifications(); // (1)!\n});\n</code></pre> <ol> <li>Call <code>startWebhookNotifications()</code> to establish SSE connection for real-time updates.</li> </ol>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webhooks/#server-sent-events-connection","title":"Server-Sent Events connection","text":"<p>A new function establishes and manages the SSE connection:</p> app.js<pre><code>// Function to start listening for webhook events via Server-Sent Events\nfunction startWebhookNotifications() {\n    const eventSource = new EventSource('/events'); // (1)!\n\n    eventSource.onopen = (_event) =&gt; {\n        console.log('Connected to webhook notifications'); // (2)!\n    };\n\n    eventSource.onmessage = (event) =&gt; {\n        try {\n            const data = JSON.parse(event.data); // (3)!\n            handleWebhookNotification(data); // (4)!\n        } catch (error) {\n            console.error('Error parsing SSE message:', error);\n        }\n    };\n\n    eventSource.onerror = (event) =&gt; {\n        console.error('SSE connection error:', event); // (5)!\n        // The browser will automatically try to reconnect\n    };\n}\n</code></pre> <ol> <li>Create an <code>EventSource</code> connection to the <code>/events</code> SSE endpoint.</li> <li>Log successful connection establishment.</li> <li>Parse incoming SSE messages as JSON webhook data.</li> <li>Process webhook notifications through the <code>handleWebhookNotification()</code> function.</li> <li>Handle connection errors with automatic browser reconnection.</li> </ol> <p>This function creates a persistent connection to receive real-time webhook notifications from the server by creating an <code>EventSource</code> instance to the <code>/events</code> endpoint. When a message is received, it parses the JSON data and calls <code>handleWebhookNotification()</code> to process the event. The function also handles connection errors, allowing the browser to automatically attempt reconnection.</p>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webhooks/#webhook-notification-processing","title":"Webhook notification processing","text":"<p>A new function processes incoming webhook notifications and updates the UI accordingly:</p> app.js<pre><code>// Function to handle webhook notifications and update UI\nfunction handleWebhookNotification(webhookData) {\n    const { event, data } = webhookData; // (1)!\n    console.log(`Webhook '${event}' received for room '${data.roomName}':`, webhookData);\n\n    switch (event) {\n        case 'meetingStarted':\n            // Update rooms map with updated room info and re-render if on home screen\n            if (isOnHomeScreen()) {\n                // (2)!\n                rooms.set(data.roomId, data);\n                renderRooms(); // (3)!\n            }\n            break;\n        case 'meetingEnded':\n            // Update rooms map with updated room info and re-render if on home screen\n            if (isOnHomeScreen()) {\n                rooms.set(data.roomId, data);\n                renderRooms();\n            }\n            break;\n        case 'recordingEnded':\n            // Add recording to list and re-render if on recordings screen\n            if (isOnRecordingsScreen(data.roomName)) {\n                // (4)!\n                recordings.set(data.recordingId, data);\n                renderRecordings(); // (5)!\n            }\n            break;\n    }\n}\n</code></pre> <ol> <li>Extract the event type and data from the webhook payload.</li> <li>Check if the user is currently on the home screen before updating room status.</li> <li>Update the rooms map and re-render the room list with new status information.</li> <li>Check if the user is viewing recordings for the relevant room before adding new recordings.</li> <li>Update the recordings map and re-render the recordings list with new recording data.</li> </ol> <p>This function processes different webhook event types and updates the appropriate UI elements only when the user is viewing the relevant screen:</p> <ul> <li>For <code>meetingStarted</code> and <code>meetingEnded</code> events, it updates the room status and re-renders the room list if the user is on the home screen.</li> <li>For <code>recordingEnded</code> events, it adds the new recording to the list and re-renders the recordings list if the user is viewing recordings for the relevant room.</li> </ul> <p>In order to determine the current screen context, new utility functions have been introduced:</p> app.js<pre><code>// Helper functions to detect current screen\nfunction isOnHomeScreen() {\n    const homeScreen = document.querySelector('#home');\n    return homeScreen &amp;&amp; !homeScreen.hidden; // (1)!\n}\n\nfunction isOnRecordingsScreen(roomName) {\n    const recordingsScreen = document.querySelector('#recordings');\n    if (!recordingsScreen || recordingsScreen.hidden) {\n        return false; // (2)!\n    }\n\n    // Check if the room filter matches room name\n    const roomSearchInput = document.querySelector('#recordings-room-search');\n    const roomFilter = roomSearchInput ? roomSearchInput.value.trim() : '';\n    return !roomFilter || roomName.startsWith(roomFilter); // (3)!\n}\n</code></pre> <ol> <li>Check if the home screen is currently visible to determine if room updates should be applied.</li> <li>Return false if the recordings screen is not visible.</li> <li>Check if the room name matches the current filter to determine if recording updates are relevant.</li> </ol> <p>These helper functions ensure that UI updates are only applied when users are viewing the relevant sections, optimizing performance and preventing unnecessary re-renders:</p> <ul> <li><code>isOnHomeScreen()</code>: Checks if the home screen is currently visible.</li> <li><code>isOnRecordingsScreen(roomName)</code>: Checks if the recordings screen is visible and if the room name matches the current filter.</li> </ul>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webhooks/#enhanced-room-status-display","title":"Enhanced room status display","text":"<p>The room template has been updated to include visual status indicators:</p> app.js<pre><code>function getRoomListItemTemplate(room) {\n    const roomStatus = room.status === 'active_meeting' ? 'ACTIVE' : room.status === 'open' ? 'OPEN' : 'CLOSED'; // (1)!\n    const roomStatusBadgeClass =\n        room.status === 'active_meeting' ? 'bg-primary' : room.status === 'open' ? 'bg-success' : 'bg-warning'; // (2)!\n\n    return `\n        &lt;li class=\"list-group-item\"&gt;\n            &lt;div class=\"room-info\"&gt;\n                &lt;span&gt;${room.roomName}&lt;/span&gt;\n                &lt;span class=\"badge ${roomStatusBadgeClass}\"&gt;${roomStatus}&lt;/span&gt;\n            &lt;/div&gt;\n            &lt;div class=\"room-actions\"&gt;\n                &lt;!-- buttons remain the same --&gt;\n            &lt;/div&gt;\n        &lt;/li&gt;\n    `;\n}\n</code></pre> <ol> <li>Map room status values to user-friendly display text.</li> <li>Assign appropriate CSS classes for visual styling based on room status.</li> </ol> <p>The room template now includes status badges that provide immediate visual feedback about room state:</p> <ul> <li>ACTIVE (blue badge): Meeting is currently in progress</li> <li>OPEN (green badge): Room is available for joining</li> <li>CLOSED (yellow badge): Room is closed and cannot be joined</li> </ul>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webhooks/#accessing-this-tutorial-from-other-computers-or-phones","title":"Accessing this tutorial from other computers or phones","text":"<p>To access this tutorial from other computers or phones, follow these steps:</p> <ol> <li> <p>Ensure network connectivity: Make sure your device (computer or phone) is connected to the same network as the machine running OpenVidu Meet and this tutorial.</p> </li> <li> <p>Configure OpenVidu Meet for network access: Start OpenVidu Meet by following the instructions in the Accessing OpenVidu Meet from other computers or phones  section.</p> </li> <li> <p>Update the OpenVidu Meet server URL: Modify the <code>OV_MEET_SERVER_URL</code> environment variable in your <code>.env</code> file to match the URL shown when OpenVidu Meet starts.</p> <pre><code># Example for IP address 192.168.1.100\nOV_MEET_SERVER_URL=https://192-168-1-100.openvidu-local.dev:9443\n</code></pre> </li> <li> <p>Update the OpenVidu Meet WebComponent script URL: In the <code>public/index.html</code> file, update the <code>&lt;script&gt;</code> tag that includes the OpenVidu Meet WebComponent to use the same base URL as above.</p> <pre><code>&lt;script src=\"http://192-168-1-100.openvidu-local.dev:9443/v1/openvidu-meet.js\"&gt;&lt;/script&gt;\n</code></pre> </li> <li> <p>Restart the tutorial to apply the changes:</p> <pre><code>npm start\n</code></pre> </li> <li> <p>Access the tutorial: Open your browser and navigate to <code>https://192-168-1-100.openvidu-local.dev:6443</code> (replacing <code>192-168-1-100</code> with your actual private IP) on the computer where you started the tutorial or any device in the same network.</p> </li> </ol>","tags":["Meet"]},{"location":"meet/embedded/tutorials/webhooks/#connecting-this-tutorial-to-an-openvidu-meet-production-deployment","title":"Connecting this tutorial to an OpenVidu Meet production deployment","text":"<p>If you have a production deployment of OpenVidu Meet (installed in a server following deployment steps ), you can connect this tutorial to it by following these steps:</p> <ol> <li> <p>Update the server URL: Modify the <code>OV_MEET_SERVER_URL</code> environment variable in the <code>.env</code> file to point to your OpenVidu Meet production deployment URL.</p> <pre><code># Example for a production deployment\nOV_MEET_SERVER_URL=https://your-openvidu-meet-domain.com\n</code></pre> </li> <li> <p>Update the API key: Ensure the <code>OV_MEET_API_KEY</code> environment variable in the <code>.env</code> file matches the API key configured in your production deployment. See Generate an API Key  section to learn how to obtain it.</p> <pre><code>OV_MEET_API_KEY=your-production-api-key\n</code></pre> </li> <li> <p>Update the OpenVidu Meet WebComponent script URL: In the <code>public/index.html</code> file, update the <code>&lt;script&gt;</code> tag that includes the OpenVidu Meet WebComponent to use the same base URL as above.</p> <pre><code>&lt;script src=\"https://your-openvidu-meet-domain.com/v1/openvidu-meet.js\"&gt;&lt;/script&gt;\n</code></pre> </li> <li> <p>Restart the application to apply the changes:</p> <pre><code>npm start\n</code></pre> </li> <li> <p>Make the tutorial accessible to OpenVidu Meet deployment: As OpenVidu Meet needs to send webhooks to this tutorial, it must be accessible from the internet. To achieve this, you have the following options:</p> <ul> <li>Using tunneling tools: Configure tools like VS Code port forwarding , ngrok , localtunnel , or similar services to expose this tutorial to the internet with a secure (HTTPS) public URL.</li> <li>Deploying to a public server: Upload this tutorial to a web server and configure it to be accessible with a secure (HTTPS) public URL. This can be done by updating the source code to manage SSL certificates or configuring a reverse proxy (e.g., Nginx, Apache) to serve it.</li> </ul> <p>A the end, you should have a public URL (e.g., <code>https://your-tutorial-domain.com:XXXX</code>) that points to this tutorial.</p> </li> <li> <p>Configure webhooks in OpenVidu Meet: Set up webhooks in your OpenVidu Meet production deployment to point to this tutorial. Follow the instructions in the Webhooks configuration  section to learn how to configure a webhook URL. Use the public URL of this tutorial followed by <code>/webhook</code> (e.g., <code>https://your-tutorial-domain.com:XXXX/webhook</code>).</p> </li> <li> <p>Access the tutorial: Access the tutorial in your web browser using its public URL (e.g., <code>https://your-tutorial-domain.com:XXXX</code>).</p> </li> </ol>","tags":["Meet"]},{"location":"meet/features/live-captions/","title":"Live captions","text":"","tags":["Meet"]},{"location":"meet/features/recordings/","title":"Recordings","text":"","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/recordings/#recordings","title":"Recordings","text":"","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/recordings/#recording-a-meeting","title":"Recording a meeting","text":"<p>Recordings must be started by a participant with role \"Moderator\" in the meeting view (see Participant roles in a room).</p> <p></p> <p>While the recording is active, all participants in the meeting will see an indicator in the bottom left corner.</p> <p></p> <p>To stop the recording, a participant with role \"Moderator\" must simply click the \"Stop recording\" button. The recording will be automatically saved in the OpenVidu Meet server.</p> <p></p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/recordings/#viewing-recordings","title":"Viewing recordings","text":"<p>By default, recordings share the same access permissions as their rooms. Whenever a user uses a room link to join a meeting, they will also have the possibility of accessing the list of its previous recordings (if any):</p> <p> </p> <p>The recording list shows every recording of that particular room:</p> <p> </p> <p>Participants can also open the list of recordings for that room directly from the meeting view:</p> <p></p> <p>The recording view allows playing the video, downloading it or creating a shareable link:</p> <p></p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/recordings/#access-permissions-for-recordings","title":"Access permissions for recordings","text":"<p>When creating a new room you can configure who may access its recordings:</p> <p></p> <p>Available options are:</p> <ul> <li>Only admin: only administrators of OpenVidu Meet will have access to the recordings of this room. Administrators can always access recordings of any room.</li> <li>Admin and moderators: administrators and any participant of the meeting with \"Moderator\" role will have access to the recordings of this room.</li> <li>Admin, moderators and speakers: this is the default value. Administrators and any participant of the meeting with \"Moderator\" or \"Speaker\" role will have access to the recordings of this room.</li> </ul> <p>Info</p> <p>Participants with role \"Speaker\" may only play recordings. Administrators and participants with role \"Moderator\" can also delete them.</p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/recordings/#sharing-recordings-via-link","title":"Sharing recordings via link","text":"<p>Specific recordings can be shared through a link:</p> <ul> <li> <p>Users can generate a shareable link from the recording list.</p> <p></p> </li> <li> <p>Users can generate a shareable link from the recording view.</p> <p></p> </li> <li> <p>From OpenVidu Meet console it is possible to generate shareable links for any recording.</p> <p></p> </li> </ul>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/recordings/#room-recording-settings","title":"Room recording settings","text":"<p>Rooms can be configured with different recording settings. You can set up these settings when creating a new room or editing an existing room.</p> <ul> <li>Allow Recording / No recording: whether to allow recording the room or not.</li> <li>Recording Access Control: who can access the recordings of the room. See Access permissions for viewing recordings.</li> </ul> <p></p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/recordings/#managing-recordings","title":"Managing recordings","text":"<p>OpenVidu Meet console can be used to manage all recordings from the \"Recordings\" page. It is possible to see all recordings, play them, download them, delete them, and share them via a link:</p> <p></p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/recordings/#recording-rest-api","title":"Recording REST API","text":"<p>Recordings can be managed via the OpenVidu Meet REST API:</p> Operation HTTP Method Reference Get recording GET Reference  Get all recordings GET Reference  Delete recording DELETE Reference  Bulk delete recordings DELETE Reference  Download recordings GET Reference  Get recording media GET Reference  Get recording URL GET Reference","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/rooms-and-meetings/","title":"Rooms and meetings","text":"","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/rooms-and-meetings/#room-vs-meeting","title":"Room vs meeting","text":"<p>It is important to understand these core concepts of OpenVidu Meet:</p> <ul> <li>A room is a persistent virtual space used to host one or more meetings. Its real-world counterpart is a physical conference room in a building: you can name it, lock it, change its appearance, etc.</li> <li>A meeting is a temporary session that occurs within a room, where participants can join and interact in real-time. Its real-world counterpart is a scheduled event that takes place in a specific room, where authorized people meet, talk and share information.</li> </ul> <p>Rooms host meetings following these principles:</p> <ul> <li>First you create a room. Then you can host a meeting in the room.</li> <li>One room can host just one meeting at a time, but it can be reused for multiple meetings over time.</li> <li>Every room has a room link. A user connecting to a room link will either start a new meeting (if no meeting is currently active in the room) or join the existing meeting (if there is one).</li> </ul>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/rooms-and-meetings/#rooms","title":"Rooms","text":"","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/rooms-and-meetings/#creating-a-room","title":"Creating a room","text":"<p>As an administrator, you can create a new room directly from the \"Rooms\" page in OpenVidu Meet.</p> <p>Rooms require a name. Additionally, they can be customized with the following options by clicking on \"Advanced Setup\":</p> <ul> <li>Set up an auto-deletion date.</li> <li>Set up recording and access control to them.</li> <li>Enable/disable features like chat or virtual backgrounds.</li> </ul> <p> </p> <p>Available rooms are all listed in the \"Rooms\" page. From there administrators can:</p> <ul> <li>Start a meeting in a room.</li> <li>Edit the room settings.</li> <li>Delete the room.</li> <li>Access the room's recordings.</li> <li>Share room links with different permissions (see Users and permissions).</li> </ul> <p> </p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/rooms-and-meetings/#editing-a-room","title":"Editing a room","text":"<p>You can edit the settings of an existing room at any time in the \"Rooms\" page. The same options available when creating a room are also available when editing it:</p> <ol> <li>Name them.</li> <li>Set up an auto-deletion date.</li> <li>Set up recording and access control to them.</li> <li>Enable/disable features like chat or virtual backgrounds.</li> </ol> <p></p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/rooms-and-meetings/#deleting-a-room","title":"Deleting a room","text":"<p>Rooms can be deleted at any time from the \"Rooms\" page. This will remove the room and all its associated data.</p> <p></p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/rooms-and-meetings/#room-auto-deletion","title":"Room auto-deletion","text":"<p>Rooms can be configured with an auto-deletion date. You can set this date when creating or editing a room. This helps keeping OpenVidu Meet clean and organized, avoiding clutter from old rooms that are no longer needed.</p> <p> </p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/rooms-and-meetings/#room-auto-deletion-policies","title":"Room auto-deletion policies","text":"<p>When the auto-deletion date is reached, the room will be deleted. The Auto-deletion policies determine how to handle active meetings and stored recordings when attempting to delete the room:</p> <ul> <li>Active meetings policy<ul> <li><code>Force</code>: the meeting will be immediately ended without waiting for participants to leave, and the room will be deleted.</li> <li><code>When meeting ends</code>: the room will be deleted after the active meeting ends.</li> </ul> </li> <li>Recordings policy<ul> <li><code>Force</code>: the room and all its recordings will be deleted.</li> <li><code>Close</code>: the room will be closed instead of deleted, maintaining its recordings.</li> </ul> </li> </ul> <p> </p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/rooms-and-meetings/#bulk-deleting-rooms","title":"Bulk deleting rooms","text":"<p>Use the multi-select checkbox to delete multiple rooms at once.</p> <p></p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/rooms-and-meetings/#room-links","title":"Room links","text":"<p>Rooms have predefined room links that grant access to them. Users connecting to a room link will start a new meeting (if no meeting is currently active in the room) or join the existing meeting (if there is one).</p> <p>Each room has different room links, each one granting access to the room with a specific participant role. See Participant roles in a meeting for more information.</p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/rooms-and-meetings/#get-a-room-link-from-the-rooms-page","title":"Get a room link from the \"Rooms\" page","text":"<p>Every room item allows sharing the room link for every participant role.</p> <p></p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/rooms-and-meetings/#get-a-room-link-from-an-active-meeting","title":"Get a room link from an active meeting","text":"<p>Participants with the <code>Moderator</code> role can share room links from the active meeting view.</p> <p></p> <p>Info</p> <p>Links copied from the meeting view will always grant access to the room with <code>Speaker</code> role. If necessary, users with role <code>Moderator</code> can upgrade other user's roles during the meeting. See Changing participant roles during a meeting for more information.</p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/rooms-and-meetings/#get-a-room-link-from-the-rest-api","title":"Get a room link from the REST API","text":"<p>Available in properties <code>moderatorUrl</code> and <code>speakerUrl</code> of object MeetRoom .</p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/rooms-and-meetings/#room-visual-customization","title":"Room visual customization","text":"<p>Rooms can be customized to fit your branding needs. As for now, you can setup the color scheme of your rooms from the \"Configuration\" page.</p> <p> </p> <p>You can set separately the color of:</p> <ul> <li>Main background: background color of the meeting view.</li> <li>Main controls: colors for the main control buttons (mic, camera, etc.)</li> <li>Secondary elements: colors for logos, icons, borders and subtle details.</li> <li>Highlights &amp; accents: colors for active states and highlighted items.</li> <li>Panels &amp; dialogs: background color for side panels and dialog boxes.</li> </ul> <p>You can also choose between a light and a dark background style, to ensure the displayed text is always readable after applying your color scheme.</p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/rooms-and-meetings/#room-rest-api","title":"Room REST API","text":"<p>Every possible action against a room can be done through OpenVidu Meet REST API:</p> Operation HTTP Method Reference Create a room POST Reference  Get a room GET Reference  Get all rooms GET Reference  Delete a room DELETE Reference  Bulk delete rooms DELETE Reference  Get room config GET Reference  Update room config PUT Reference","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/rooms-and-meetings/#meetings","title":"Meetings","text":"","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/rooms-and-meetings/#starting-a-meeting","title":"Starting a meeting","text":"<p>A meeting will start as soon as a participant enters an empty room using a valid room link. You can learn everything about room links here.</p> <p>Users with access to OpenVidu Meet can join a meeting directly from the \"Rooms\" page:</p> <p></p> <p>Info</p> <p>Doing this simply opens a new tab with a <code>Moderator</code> room link.</p> <p>Users with access to OpenVidu Meet can also copy a room link and share it with external participants:</p> <p></p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/rooms-and-meetings/#lifecycle-of-a-meeting","title":"Lifecycle of a meeting","text":"<p>Meetings consist of different views:</p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/rooms-and-meetings/#join-view","title":"Join view","text":"<p>This is the first view participants see when accessing a room link. It allows setting a nickname before joining the meeting. If the participant has the required permissions, they can also access the Recording view of this room from here.</p> <p> </p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/rooms-and-meetings/#device-view","title":"Device view","text":"<p>This view allows participants tuning their microphone and camera before joining the meeting, as well as setting a virtual background.</p> <p> </p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/rooms-and-meetings/#meeting-view","title":"Meeting view","text":"<p>This is the main view of the meeting, where participants can interact with each other.</p> <p></p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/rooms-and-meetings/#recording-view","title":"Recording view","text":"<p>This view allows to manage the recording of the meeting while it is active. Participants with the required permissions can review, play, download, delete, and share the recording via a link.</p> <p> </p> <p>Info</p> <p>Recordings can also be accessed from the \"Recordings\" page in OpenVidu Meet, even after the meeting has ended. See Managing recordings.</p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/rooms-and-meetings/#end-view","title":"End view","text":"<p>This view is shown to a participant when the meeting ends, at least for that participant. It informs about the specific reason why the meeting ended (an administrator ended it, the participant was evicted from the meeting, etc.).</p> <p> </p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/users-and-permissions/","title":"Users and permissions","text":"","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/users-and-permissions/#users-and-permissions","title":"Users and permissions","text":"","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/users-and-permissions/#participant-roles-in-a-room","title":"Participant roles in a room","text":"<p>Participants in a room can have different roles, which grant different permissions. The role of a participant is determined by the room link used to join. See Room links for more information.</p> <p>Available roles are:</p> <ul> <li>Moderator: grants permissions to end the meeting, start/stop recordings, share room links and manage participants. Also grants permissions of <code>Speaker</code> role.</li> <li>Speaker: grants permissions to share their camera, microphone and screen.</li> </ul>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/users-and-permissions/#changing-participant-roles-during-a-meeting","title":"Changing participant roles during a meeting","text":"<p>Participants with <code>Moderator</code> role can upgrade or downgrade other participants' roles during the meeting from the \"Participants\" side panel:</p> <p></p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/users-and-permissions/#openvidu-meet-authentication","title":"OpenVidu Meet authentication","text":"<p>OpenVidu Meet is by default protected with an administrator username and password. These credentials will be required when accessing OpenVidu Meet console:</p> <p> </p> <p>The initial administrator credentials are:</p> <ul> <li>Username: <code>admin</code></li> <li>Password: specified on installation time</li> </ul> <p>The value of the password will be asked on installation. If left empty, a random password will be generated. The location of the administration password depends on the environment of the deployment:</p> Local (Demo)On PremisesAWSAzure <p>Credentials are always username <code>admin</code> and password <code>admin</code>.</p> <p>Credentials will be logged at the end of the installation process:</p> <pre><code>OpenVidu Meet is available at:\n\n    URL: https://&lt;YOUR_DOMAIN&gt;\n    Credentials:\n      - User: admin\n      - Password: XXXXXXX\n</code></pre> <p>Warning</p> <p>If you modify the initial administrator password, this value will no longer be valid.</p> <p>In the Secrets Manager of the CloudFormation stack, in secret <code>MEET_INITIAL_ADMIN_PASSWORD</code></p> <p>Warning</p> <p>If you modify the initial administrator password, this value will no longer be valid.</p> <p>In the Azure Key Vault, in secret <code>MEET_INITIAL_ADMIN_PASSWORD</code></p> <p>Warning</p> <p>If you modify the initial administrator password, this value will no longer be valid.</p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/features/users-and-permissions/#modify-openvidu-meet-authentication","title":"Modify OpenVidu Meet authentication","text":"<p>Administrator credentials can be modified from the \"User &amp; Permissions\" view:</p> <p></p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/getting-started/","title":"Getting started with OpenVidu Meet","text":"<p>OpenVidu Meet is a fully fledged video call solution built on top of OpenVidu. You can use it out of the box, or you can embed it in your own application. Either way, OpenVidu Meet provides a rich set of features and a great degree of customization, so you can tailor it to your needs and match your branding.</p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/getting-started/#run-openvidu-meet","title":"Run OpenVidu Meet","text":"<p>Follow these instructions to quickly run OpenVidu Meet in your local machine:</p> <p>Run OpenVidu Meet locally</p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/getting-started/#a-quick-tour","title":"A quick tour","text":"<p>Let's go through the basics of a typical video call workflow with OpenVidu Meet:</p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/getting-started/#1-login-into-openvidu-meet","title":"1. Login into OpenVidu Meet","text":"<p>Using your administrator credentials (find out where to get them here).</p> <p> </p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/getting-started/#2-create-your-first-room","title":"2. Create your first room","text":"","tags":["Meet","setupcustomgallery"]},{"location":"meet/getting-started/#3-join-a-meeting-and-invite-someone","title":"3. Join a meeting and invite someone","text":"","tags":["Meet","setupcustomgallery"]},{"location":"meet/getting-started/#4-record-your-meeting","title":"4. Record your meeting","text":"","tags":["Meet","setupcustomgallery"]},{"location":"meet/getting-started/#5-view-and-share-the-recording","title":"5. View and share the recording","text":"","tags":["Meet","setupcustomgallery"]},{"location":"meet/getting-started/#embed-openvidu-meet-into-your-app","title":"Embed OpenVidu Meet into your app","text":"<p>You can integrate a complete video call solution into your application with just a few lines of code using OpenVidu Meet Embedded. You can also customize its look and feel to match your application's design, branding colors and styles.</p> <p>Embed OpenVidu Meet into your app</p>","tags":["Meet","setupcustomgallery"]},{"location":"meet/getting-started/#should-i-use-openvidu-platform-instead","title":"Should I use OpenVidu Platform instead?","text":"<p>If your use case requires other features or a more specific integration, you may want to consider using OpenVidu Platform. It supports low-level SDKs to build any type of real-time experience. You can find a comparison between both OpenVidu solutions here: OpenVidu Meet vs OpenVidu Platform.</p>","tags":["Meet","setupcustomgallery"]}]}