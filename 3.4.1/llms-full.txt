# OpenVidu

> From ready-to-use video conferencing apps<br>to custom-made WebRTC solutions.<br>Self-hosted. Performant. Scalable. Fault tolerant. Observable.

Self-hosted videoconference solution and SDK

# OpenVidu

# Home

## Choose the ideal OpenVidu solution for your real-time needs

### 

Ready-to-use videoconferencing solution

For teams, businesses and organizations that need a reliable and secure video conferencing solution running on their servers.

- Multi-party HQ video conferencing
- Customize with your branding and corporate colors
- Feature rich: screen sharing, chat, virtual background, recording...
- Ready to use AI integrations
- Embed right into your app with pre-built components

[Get Started](meet/)

### 

Developer-oriented SDKs for custom apps

For developers that need complete freedom to build their real-time application using SDKs and self-host a production-ready solution.

- Programmable client and server SDKs for all languages compatible with [LiveKit](https://docs.livekit.io/reference/)
- Build your custom UI from scratch with total freedom
- Low level control of real time media: codecs, protocols, bitrates...
- Precise control of recording and streaming with custom layouts
- Advanced telephony and AI integrations

[Get Started](docs/)

|                                                   |                        |                             |
| ------------------------------------------------- | ---------------------- | --------------------------- |
| Self-hosted                                       |                        |                             |
| AWS & Azure templates                             |                        |                             |
| HQ real-time video                                |                        |                             |
| Performant, Scalable, Fault-Tolerant & Observable |                        |                             |
| Tutorials available                               |                        |                             |
| Customer support                                  |                        |                             |
| Ready-to-use application                          |                        |                             |
| No-code & Low-code options available              |                        |                             |
| Low-level SDKs                                    |                        |                             |
| High control over real-time features              |                        |                             |
| AI agents                                         |                        |                             |
| Models                                            | Rooms & Meetings       | Audio tracks & Video tracks |
| Links                                             | [OpenVidu Meet](meet/) | [OpenVidu Platform](docs/)  |

*[Learn more about OpenVidu Meet vs OpenVidu Platform](openvidu-meet-vs-openvidu-platform/)*

______________________________________________________________________

## Self-host a production-ready live-video platform with advanced capabilities typically reserved for pricy SaaS solutions

- **Self-hosted**

  ______________________________________________________________________

  OpenVidu is designed from the ground up to be [**self-hosted**](docs/self-hosting/production-ready/) in your own servers. With OpenVidu you can easily deploy and manage a production-ready live-video solution in your own infrastructure, whether it is on premises or in your favorite cloud provider. Leverage your hardware and regain control of your users' data!

- **Professional support**

  ______________________________________________________________________

  We are experts in WebRTC. We have been developing real time tools and supporting customers building their solutions for over a decade. Let's work together to make your project a success! [**Contact us**](support/) now.

- **Easy to deploy**

  ______________________________________________________________________

  What could take a whole DevOps team days of work, with OpenVidu you can have it ready in minutes: an easy installation, configuration and administration experience to your self-hosted, production grade, real-time solution. [**Install now**](docs/self-hosting/deployment-types/).

- **Cost effective**

  ______________________________________________________________________

  OpenVidu COMMUNITY is open source, free and can handle a significant user load. With OpenVidu PRO you can handle more simultaneous Rooms in the same hardware thanks to mediasoup integration. This allows reducing the cost of each Room, making OpenVidu PRO truly cost-effective as a self-hosted solution. See [**Pricing**](/pricing/).

- **Performant**

  ______________________________________________________________________

  OpenVidu is built to be incredibly powerful. It is based on the best open source WebRTC stacks: [**LiveKit**](https://livekit.io/) and [**mediasoup**](https://mediasoup.org/) . By combining the best of both worlds, OpenVidu provides outstanding [**performance**](docs/self-hosting/production-ready/performance/).

- **Scalable**

  ______________________________________________________________________

  OpenVidu has been designed from the outset with [**scalability**](docs/self-hosting/production-ready/scalability/) in mind. Host videoconference rooms and large live streams with hundreds of participants. Autoscale your cluster to adapt to the demand and optimize your resources.

- **Fault tolerant**

  ______________________________________________________________________

  OpenVidu offers [**fault tolerance**](docs/self-hosting/production-ready/fault-tolerance/) in all its components. Deploy a reliable cluster knowing that if one of your node goes down, others will be able to continue working with no downtime.

- **Observable**

  ______________________________________________________________________

  OpenVidu brings everything necessary to monitor the status, health, load and history of your deployment. It automatically collects events, metrics and logs and provides [**OpenVidu Dashboard**](docs/self-hosting/production-ready/observability/openvidu-dashboard/) and a [**Grafana stack**](docs/self-hosting/production-ready/observability/grafana-stack/) to navigate them.

______________________________________________________________________

## All the features you need to quickly build your perfect real-time application

- **WebRTC**

  ______________________________________________________________________

  Achieve ultra-low latency in your videoconference or live-streaming app thanks to [WebRTC](https://webrtc.org/) .

- **Security at all levels**

  ______________________________________________________________________

  Fine-grained access control and highly secure deployments for the most demanding security requirements. **E2E encryption coming soon!**

- **Multiplatform**

  ______________________________________________________________________

  Chrome, Firefox, Safari, Android, iOS, Unity, Windows, macOS, Linux... OpenVidu is compatible with all of them.

- **Up to 4K video and HQ audio**

  ______________________________________________________________________

  HD up to 4K video resolution, and crisp audio quality with noise cancellation and echo suppression.

- **Recording**

  ______________________________________________________________________

  Record your video calls with complete freedom. You can use predefined layouts or easily build your own.

- **Broadcast to YouTube/Twitch**

  ______________________________________________________________________

  OpenVidu allows you to easily broadcast your sessions to live-streaming platforms such as YouTube or Twitch.

- **Screen sharing**

  ______________________________________________________________________

  Screen share from browsers or native applications with ease, always with the best quality.

- **Virtual Backgrounds**

  ______________________________________________________________________

  Apply effects to your videos, blurring the background or replacing it with an image.

- **Server side processing**

  ______________________________________________________________________

  For the most advanced use cases: you can add pipelines to process video and audio streams in real time in your servers.

______________________________________________________________________

## Build, deploy on-premises and scale your videoconferencing or live streaming app with ease. Contact us if you need it : we are here to help!

[Talk to an expert](/support/)

# Pricing

|                           | **OpenVidu COMMUNITY**                                                                           | **OpenVidu PRO**                                                                                       |                                                                                 |                                                                                                     |
| ------------------------- | ------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------- |
| Price                     | Free                                                                                             | 0.0006$ core/minute                                                                                    |                                                                                 |                                                                                                     |
| Type of deployment        | [**OpenVidu Single NodeCOMMUNITY**](../docs/self-hosting/deployment-types/#openvidu-single-node) | [**OpenVidu Single Node PRO**](../docs/self-hosting/deployment-types/#openvidu-single-node)            | [**OpenVidu Elastic**](../docs/self-hosting/deployment-types/#openvidu-elastic) | [**OpenVidu High Availability**](../docs/self-hosting/deployment-types/#openvidu-high-availability) |
| Suitability               | For applications with medium user load                                                           | Enjoy the benefits of OpenVidu PRO in a single-node installation                                       | For applications with dynamic user load that require scalability                | For applications where both scalability and fault tolerance are critical                            |
| Features                  | Custom LiveKit distribution with Redis, Egress, Ingress, S3 storage and observability            | Same features as OpenVidu Single Node COMMUNITY plus **2x performance** and **advanced observability** | Same benefits as OpenVidu Single Node PRO plus **scalability**                  | Same benefits as OpenVidu Elastic plus **fault tolerance**                                          |
| Number of servers         | 1 Node                                                                                           | 1 Node                                                                                                 | 1 Master Node + N Media Nodes                                                   | 4 Master Nodes + N Media Nodes                                                                      |
| Installation instructions | [Install](../docs/self-hosting/single-node)                                                      | [Install](../docs/self-hosting/single-node-pro)                                                        | [Install](../docs/self-hosting/elastic/)                                        | [Install](../docs/self-hosting/ha/)                                                                 |

OpenVidu offers two editions:

- **OpenVidu COMMUNITY**, completely open-source and free to use. Offers a single node deployment suitable for medium user load.
- **OpenVidu PRO**, which is proprietary and with a simple pay-per-use pricing model. Offers advanced multi-node deployments suitable for applications that require improved performance, scalability, fault tolerance, and observability.

OpenVidu offers two solutions: **OpenVidu Meet** and **OpenVidu Platform**. They target different use cases (see [OpenVidu Meet vs OpenVidu Platform](../openvidu-meet-vs-openvidu-platform/)), but they **do not affect pricing**: you can have either solution in an **OpenVidu COMMUNITY** or **OpenVidu PRO** deployment.

## How is OpenVidu Pro priced?

OpenVidu Pro follows a simple pricing model based on the number of cores used by the OpenVidu Pro cluster:

$0.0006

per core per minute available\
for your OpenVidu PRO cluster

Taking into account the following points:

- You only pay for your OpenVidu Pro cluster(s) for the time they are running. Usage will be registered the moment you start your cluster and will stop as soon as you shut your cluster down. When turned on, your cluster will be charged even in idle state (without active Rooms).
- You pay for every available core at any given time: if you cluster grows for one hour, that hour you will pay more. If your cluster decreases the next hour, next hour will be cheaper. Master Nodes and Media Nodes have the same core per minute price.
- Your OpenVidu Pro cluster(s) need to allow outbound traffic to domain **`accounts.openvidu.io`** port **`443`**. If you are behind a very restrictive corporate firewall that doesn't allow this, please contact us through [commercial@openvidu.io](mailto:commercial@openvidu.io).

## There is a 15-day free trial period waiting for you!

[Get an OpenVidu License](/account/)

______________________________________________________________________

## Why is OpenVidu Pro priced like this?

There are deliberate reasons for this pricing model in OpenVidu Pro:

- We believe that a platform specifically designed to be self-hosted should have a pricing model that is as close to hardware as possible: that is the total number of cores available to the cluster over time.
- This pricing model is simple, transparent and easy to predict: you pay only for the time the cluster is running and always according to its size.
- The cost is directly proportional to the size of your cluster: larger clusters pay more, smaller clusters pay less.
- Elasticity is encouraged: adjust the size of your cluster according to the load at any given time to minimize costs.

## When and how are you charged?

Users must create an [OpenVidu account](/account/) and get an OpenVidu License. This license will be required to deploy an OpenVidu Pro cluster ([OpenVidu Elastic](../docs/self-hosting/elastic/) or [OpenVidu High Availability](../docs/self-hosting/ha/)).

When purchasing an OpenVidu License, you will have to indicate your billing address and a credit card. You will receive a **15-day free trial period** during which you will not be charged at all.

After the free trial period, a **monthly billing cycle** will charge all your expenses to your credit card. Therefore, you will receive an invoice each month. You can review your upcoming expenses and your past invoices in your [OpenVidu account](/account/) page. And don't worry: we don't store any credit card data. The entire billing process is securely done via [Stripe](https://stripe.com/) .

OpenVidu Pro clusters will automatically report their usage on a recurring basis. That's why they need outbound access to domain **`accounts.openvidu.io`** port **`443`**. If you are behind a very restrictive corporate firewall that doesn't allow this, please contact us through [commercial@openvidu.io](mailto:commercial@openvidu.io).

## Pricing examples

As explained above, every minute of an OpenVidu Pro cluster is charged according to the number of cores available for the cluster. So let's see some actual examples, first noting the following points:

- The examples represent a **continuous usage of the cluster**, but remember that you can shut it down whenever you are not using it and that you can drop nodes to save resources.
- Each example shows in a table the price for **8 hours, 1 day and 1 month** of continuous usage, as well as the approximated amount of video Tracks and Rooms of 8 participants the cluster would support. This is done to provide a basic insight into the capacity of each cluster. These **8-to-8 Rooms** assume 64 video Tracks (640x480) and 64 audio Tracks in them (2 tracks published and 14 tracks subscribed per Participant), with no Egress, Ingress or other additional features.

### OpenVidu Elastic with 12 cores in total

This OpenVidu Pro Elastic cluster has 1 Master Node of 4 cores and 2 Media Nodes of 4 cores each.

|                                              |         |
| -------------------------------------------- | ------- |
| **Number of video Tracks**                   | 2000    |
| **Number of Rooms with 8 Participants**      | 30      |
| **8 hours**                                  | $3.46   |
| **24 hours** (1 day of uninterrupted use)    | $10.37  |
| **720 hours** (1 month of uninterrupted use) | $311.04 |

______________________________________________________________________

### OpenVidu Elastic with 20 cores in total

This OpenVidu Pro Elastic cluster has 1 Master Node of 4 cores and 4 Media Nodes of 4 cores each.

|                                              |         |
| -------------------------------------------- | ------- |
| **Number of video Tracks**                   | 4000    |
| **Number of Rooms with 8 Participants**      | 60      |
| **8 hours**                                  | $5.76   |
| **24 hours** (1 day of uninterrupted use)    | $17.28  |
| **720 hours** (1 month of uninterrupted use) | $518.40 |

______________________________________________________________________

### OpenVidu High Availability with 32 cores in total

This OpenVidu Pro HA cluster has 4 Master Nodes of 4 cores each and 4 Media Nodes of 4 cores each. The number of simultaneous Rooms and Tracks will be the same as in the previous example, but this cluster will provide fault tolerance thanks to the replication of the Master Nodes.

|                                              |         |
| -------------------------------------------- | ------- |
| **Number of video Tracks**                   | 4000    |
| **Number of Rooms with 8 Participants**      | 60      |
| **8 hours**                                  | $9.21   |
| **24 hours** (1 day of uninterrupted use)    | $27.65  |
| **720 hours** (1 month of uninterrupted use) | $829.44 |

______________________________________________________________________

### OpenVidu Elastic with a variable number of cores

This OpenVidu Pro Elastic cluster takes advantage of the elasticity of the platform. It has a fixed Master Node of 4 cores, but a variable number of Media Nodes. Let's imagine a scenario where our days are divided in three phases according to the user load:

- First 8 hours of the day the demand is low. 1 Media Node of 4 cores is enough to handle it.
- The next 8 hours of the day the user load increases significantly (this is very typical if our application is used more during working hours). We add another Media Node of 8 cores to handle this new demand.
- The last 8 hours of the day the demand decreases, and we are able to remove the Media Node of 8 cores and keep only the Media Node of 4 cores.

|                                                                  |         |
| ---------------------------------------------------------------- | ------- |
| **First 8 hours of the day with low demand** (8 cores in total)  |         |
| **Next 8 hours of the day with high demand** (16 cores in total) |         |
| **Last 8 hours of the day with low demand** (8 cores in total)   |         |
| **Total for 1 day**                                              | $9.21   |
| **Total for 1 month**                                            | $276.30 |

______________________________________________________________________

## There is a 15-day free trial period waiting for you!

[Get an OpenVidu License](/account/)

# OpenVidu Meet vs OpenVidu Platform

OpenVidu offers two different products:

- **OpenVidu Meet**: a complete, high-quality video calling service designed to be self-hosted. Ideal for teams, businesses and organizations that need a reliable, secure and customizable video conferencing solution running on their servers.
- **OpenVidu Platform**: a solution comprised of a self-hosted deployment and a set of SDKs and APIs that greatly simplifies the development of any type of real-time application.

Both OpenVidu Meet and OpenVidu Platform provide **production-grade performance, scalability, fault-tolerance and observability**. What product should you choose?

- Give [**OpenVidu Meet**](../meet/) a try if your use case falls under the category of "video conferencing application": e-learning, telehealth, team collaboration, customer support, etc. Don't mistake the simplicity for a lack of possibilities: OpenVidu Meet offers branding customizations and many features out-of-the-box, such as screen-sharing, recording, advanced chat, virtual backgrounds, and more coming soon: broadcasting, E2E encryption, AI agents...
- Choose [**OpenVidu Platform**](../docs/) if you really need total control and flexibility to build your own custom real-time app, either from scratch or integrating OpenVidu Platform into your existing app. OpenVidu Platform provides low-level WebRTC SDKs for any language, and full control over features like audio/video/data streaming, media ingestion, telephony and AI integrations.

|                                                   |                           |                               |
| ------------------------------------------------- | ------------------------- | ----------------------------- |
| Self-hosted                                       |                           |                               |
| AWS & Azure templates                             |                           |                               |
| HQ real-time video                                |                           |                               |
| Performant, Scalable, Fault-Tolerant & Observable |                           |                               |
| Tutorials available                               |                           |                               |
| Customer support                                  |                           |                               |
| Ready-to-use application                          |                           |                               |
| No-code & Low-code options available              |                           |                               |
| Low-level SDKs                                    |                           |                               |
| High control over real-time features              |                           |                               |
| AI agents                                         |                           |                               |
| Models                                            | Rooms & Meetings          | Audio tracks & Video tracks   |
| Links                                             | [OpenVidu Meet](../meet/) | [OpenVidu Platform](../docs/) |
# OpenVidu Meet [BETA]

## Intro

# 

## Host and customize your own high-quality video calling service in minutes

\[[](../assets/videos/meet/meet-demo.mp4)\](../assets/videos/meet/meet-demo.mp4)

- **Feature-rich for videoconferencing**

  ______________________________________________________________________

  OpenVidu Meet brings all the **features** you expect from a professional video calling solution: HD video, HiFi audio, recording, broadcasting, screen sharing, chat, virtual backgrounds, and more.

- **Integrate right into your app**

  ______________________________________________________________________

  OpenVidu Meet can be used out-of-the-box via web, but it also offers everything you need to **embed it into your existing application**: a web component, a REST API and webhooks.

- **Secure, self-hosted deployments**

  ______________________________________________________________________

  OpenVidu Meet is designed from the ground up to be **self-hosted** on your own servers (AWS and Azure templates also available). It provides the highest level of **privacy and security** for your video calls.

- **Designed for most common use cases**

  ______________________________________________________________________

  OpenVidu Meet perfectly fits most common videoconferencing use cases: **e-learning, telehealth, remote collaboration, customer support**... And you can customize its **branding** to match your organization’s identity.

## Built for all purposes. Customizable for your particular use case.

[Try OpenVidu Meet Demo](https://meet-demo-app.openvidu.io)

## Features

**Multi-Party smart layout**

Connect dozens of participants in a room. OpenVidu Meet automatically adapts to provide the best experience.

- **Pre-join view**

  Your users can set up their video/audio devices, virtual background and language before entering the room.

- **Background filters**

  Allow your users to easily replace their video background with a blur effect or an image.

  \[[](../assets/videos/ov-call-vb.mp4)\](../assets/videos/ov-call-vb.mp4)

**Record and share**

OpenVidu Meet offers high-quality recordings and greatly simplifies their storage and access control.

\[[](../assets/videos/meet/share-recording.mp4)\](../assets/videos/meet/share-recording.mp4)

- **Pre-configure your rooms**

  Create and customize the behavior of your rooms in a few clicks: look-and-feel, user permissions, recording, chat and more.

  \[[](../assets/videos/meet/preconfigure-room.mp4)\](../assets/videos/meet/preconfigure-room.mp4)

- **Share room links**

  Unique secure links give access to your rooms with different permission levels.

  \[[](../assets/videos/meet/meet-share-link.mp4)\](../assets/videos/meet/meet-share-link.mp4)

______________________________________________________________________

## With all the features you need to fine-tune your perfect video calling service.

- **One-click video calls**

  ______________________________________________________________________

  Share links to allow users to join video calls. Compatible with any web browser. No installations required.

- **Your own branding**

  ______________________________________________________________________

  Deliver a professional experience by customizing OpenVidu Meet with your own domain, branding colors and logo.

- **Up to 4K video and HiFi audio**

  ______________________________________________________________________

  Up to 4K video resolution, and crisp audio quality with noise cancellation and echo suppression.

- **Recording**

  ______________________________________________________________________

  Record your video calls with different layouts. Manage recording permissions and access with ease.

- **Screen Sharing**

  ______________________________________________________________________

  Screen sharing with the best quality.

- **Background effects**

  ______________________________________________________________________

  Apply effects to your videos, blurring the background or replacing it with an image.

- **Advanced chat**

  ______________________________________________________________________

  OpenVidu Meet integrates an advanced chat with support of rich messages, emojis, reactions and more.

- **Broadcasting**

  ______________________________________________________________________

  OpenVidu Meet allows you to broadcast your video calls to platforms such as YouTube or Twitch.

- **Live Captions**

  ______________________________________________________________________

  Support for a vast number of speech-to-text providers.

- **E2E Encryption**

  ______________________________________________________________________

  Avoid man-in-the-middle attacks: only your final users can decrypt the audio, video and chat messages.

- **Locked rooms**

  ______________________________________________________________________

  Prevent unwanted guests and require administrator approval to join.

- **File sharing**

  ______________________________________________________________________

  Allow participants to share files during calls with a simple drag and drop.

______________________________________________________________________

## Integrations

OpenVidu Meet can be easily integrated with your existing applications and workflows:

**Pre-built web component**

Embed the OpenVidu Meet UI right into your app.

\[[](../assets/videos/meet/embed-html.mp4)\](../assets/videos/meet/embed-html.mp4)

**REST API and webhooks**

Control your meetings from your backend.

```bash
curl --request POST \
    --url https://YOUR_DOMAIN/api/v1/rooms \
    --header 'Accept: application/json' \
    --header 'Content-Type: application/json' \
    --header 'X-API-KEY: YOUR_API_KEY' \
    --data '{"roomName": "my-room"}'
```

______________________________________________________________________

## Deployments

Self-host OpenVidu Meet on your own infrastructure for maximum security and cost-effectiveness. It is easy to deploy, protect, maintain, and scale. No advanced DevOps skills are required to run it in production.

- **On Premises**

  ______________________________________________________________________

  Deploy on your own bare-metal servers

- **AWS**

  ______________________________________________________________________

  Deploy with AWS CloudFormation

- **Azure**

  ______________________________________________________________________

  Deploy with Azure Resource Manager

- **GCP**

  ______________________________________________________________________

  Deploy in GCP with Terraform

## Check out the [**deployment documentation**](./deployment/overview).

______________________________________________________________________

## Use cases

Team meetings

Empower collaboration across your organization with customizable, secure, high-quality video meetings.

- OpenVidu Meet is the perfect tool for **collaborative work**. With its user-friendly interface and powerful features, teams can easily connect, share ideas, and make decisions in real-time.

- **Collaboration tools**

  ______________________________________________________________________

  Screen sharing with top-tier quality, advanced chat with rich features, file sharing and more.

- **Quick access and flexibility**

  ______________________________________________________________________

  One-click join via secure room links. No installation required, full support for any web browser.

- **Custom branding**

  ______________________________________________________________________

  Achieve a professional look and feel with customizable domain, colors and logo.

e-Learning

Deliver a seamless learning experience by embedding OpenVidu Meet in your LMS or e-learning portal using **OpenVidu Meet Embedded**.

- With OpenVidu Meet **instructors** can engage with **students** through high quality video & audio, as well as advanced interactive tools. Locked rooms, breakout groups and many more features to enhance the learning experience.

- **High quality media**

  ______________________________________________________________________

  Up to **4K** video and **HiFi** audio for crystal-clear lessons. Stable experience across all kind of network thanks to **simulcast**, **SVC**, **dynacast** and **adaptive streaming**.

- **Accessibility**

  ______________________________________________________________________

  Live captions and real-time transcriptions. OpenVidu Meet is localized in multiple languages.

- **Persistence and continuity**

  ______________________________________________________________________

  Record and share lessons with multiple layouts. Manage recordings and share via secure links.

Telehealth

The most secure videoconference platform is the one you host on your own servers.

- OpenVidu Meet is the ideal solution for telehealth services. **Practitioners** can conduct remote consultations, share medical documents, and ensure **patient** privacy with end-to-end encryption.

- **Security and privacy**

  ______________________________________________________________________

  End-to-end encryption for audio, video, and chat. Locked rooms and administrator-controlled access. No third-party data routing.

- **Accessibility and trust**

  ______________________________________________________________________

  Browser-based with no installation needed. Live Captions and real-time transcriptions with specific support for medical language models.

- **Communication and clarity**

  ______________________________________________________________________

  Up to 4K and HiFi audio for clear communication between practitioners and patients. File sharing for medical documents and images.

Customer support

Build trust with instant, reliable support through embedded video calls that persist. Right where your clients need it.

- Connecting your **remote assistance** team with your **customers** has never been so easy. OpenVidu Meet provides all the necessary tools for effective communication and collaboration, ensuring a seamless support experience.

- **Ease of access**

  ______________________________________________________________________

  Simple, one-click access via web: embed support rooms directly into your platform.

- **Record assistance**

  ______________________________________________________________________

  Record your customer support meetings and generate transcriptions for future reference.

- **Custom branding**

  ______________________________________________________________________

  Customize the look and feel of your support rooms to match your brand identity.

______________________________________________________________________

## Free open-source edition vs Commercial edition

OpenVidu Meet is available in two editions:

### OpenVidu COMMUNITY

It is completely **open-source and free to use**. It includes all the features you need for your video conferencing solution. Everything listed in the [Features](#features) section is available in OpenVidu Meet COMMUNITY: HD video, HiFi audio, recording, screen sharing, advanced chat, virtual backgrounds, and more.

OpenVidu Meet COMMUNITY is perfect for production deployments with moderate user load. It can be easily deployed on your own servers, and you can customize its branding to match your organization’s identity. If necessary, upgrading to OpenVidu PRO is seamless and non-disruptive.

### OpenVidu PRO

It is OpenVidu's **commercial edition** and requires a license. It is meant for high demanding environments with significant user load. On top of every functional feature available in OpenVidu COMMUNITY, OpenVidu PRO brings **2x performance**, **advanced observability**, **scalability** and **fault tolerance** features. As well as **priority support** from our team of experts.

OpenVidu PRO follows a simple pricing model based on the size of your deployment (number of CPU cores). Check the [OpenVidu pricing page](https://openvidu.io/pricing) for more details.

## You can choose the OpenVidu edition that best fits your needs when [deploying OpenVidu Meet](./deployment/overview).

______________________________________________________________________

## What does it mean that OpenVidu Meet is in BETA?

OpenVidu Meet (v3.4.1) is considered in **BETA**. There may be bugs and its APIs are subject to change. We are actively working on adding new features, improving existing ones, and fixing any issues that arise. Your feedback is invaluable to us during this phase, so please don't hesitate to [reach out](../support/) with any comments or suggestions.

______________________________________________________________________

## Need total control and advanced SDKs to build your custom real-time application? Checkout [**OpenVidu Platform**](../docs)

OpenVidu Meet is a fully fledged video call solution built on top of OpenVidu. You can use it out of the box, or you can embed it in your own application. Either way, OpenVidu Meet provides a rich set of features and a great degree of customization, so you can tailor it to your needs and match your branding.

## Run OpenVidu Meet

Follow these instructions to quickly run OpenVidu Meet in your local machine:

[Run OpenVidu Meet locally](../deployment/local/)

## A quick tour

Let's go through the basics of a typical video call workflow with OpenVidu Meet:

### 1. Login into OpenVidu Meet

Using your administrator credentials (find out where to get them [here](../features/users-and-permissions/#openvidu-meet-authentication)).

### 2. Create your first room

\[[](../../../assets/videos/meet/create-room-dark.mp4#only-dark)\](../../../assets/videos/meet/create-room-dark.mp4) \[[](../../../assets/videos/meet/create-room-light.mp4#only-light)\](../../../assets/videos/meet/create-room-light.mp4)

### 3. Join a meeting and invite someone

\[[](../../../assets/videos/meet/start-meeting-dark.mp4#only-dark)\](../../../assets/videos/meet/start-meeting-dark.mp4) \[[](../../../assets/videos/meet/start-meeting-light.mp4#only-light)\](../../../assets/videos/meet/start-meeting-light.mp4)

### 4. Record your meeting

\[[](../../../assets/videos/meet/start-recording-2-dark.mp4#only-dark)\](../../../assets/videos/meet/start-recording-2-dark.mp4) \[[](../../../assets/videos/meet/start-recording-2-light.mp4#only-light)\](../../../assets/videos/meet/start-recording-2-light.mp4)

### 5. View and share the recording

\[[](../../../assets/videos/meet/view-recording-dark.mp4#only-dark)\](../../../assets/videos/meet/view-recording-dark.mp4) \[[](../../../assets/videos/meet/view-recording-light.mp4#only-light)\](../../../assets/videos/meet/view-recording-light.mp4)

## Embed OpenVidu Meet into your app

You can integrate a complete video call solution into your application with just a few lines of code using **OpenVidu Meet Embedded**. You can also customize its look and feel to match your application's design, branding colors and styles.

[Embed OpenVidu Meet into your app](../embedded/intro/)

## Should I use OpenVidu Platform instead?

If your use case requires other features or a more specific integration, you may want to consider using **OpenVidu Platform**. It supports low-level SDKs to build any type of real-time experience. You can find a comparison between both OpenVidu solutions here: [OpenVidu Meet vs OpenVidu Platform](../../openvidu-meet-vs-openvidu-platform/).

## Room vs meeting

It is important to understand these core concepts of OpenVidu Meet:

- A **room** is a persistent virtual space used to host one or more meetings. Its real-world counterpart is a physical conference room in a building: you can name it, lock it, change its appearance, etc.
- A **meeting** is a temporary session that occurs within a room, where participants can join and interact in real-time. Its real-world counterpart is a scheduled event that takes place in a specific room, where authorized people meet, talk and share information.

Rooms host meetings following these principles:

- First you create a room. Then you can host a meeting in the room.
- One room can host just one meeting at a time, but it can be reused for multiple meetings over time.
- Every room has a **room link**. A user connecting to a room link will either start a new meeting (if no meeting is currently active in the room) or join the existing meeting (if there is one).

## Rooms

### Creating a room

As an administrator, you can create a new room directly from the "Rooms" page in OpenVidu Meet.

Rooms require a name. Additionally, they can be customized with the following options by clicking on "Advanced Setup":

- Set up an [auto-deletion date](#room-auto-deletion).
- Set up recording and access control to them.
- Enable/disable features like chat or virtual backgrounds.

\[[](../../../assets/videos/meet/meet-rooms-dark.mp4#only-dark)\](../../../assets/videos/meet/meet-rooms-dark.mp4) \[[](../../../assets/videos/meet/meet-rooms-light.mp4#only-light)\](../../../assets/videos/meet/meet-rooms-light.mp4)

Available rooms are all listed in the "Rooms" page. From there administrators can:

- Start a meeting in a room.
- Edit the room settings.
- Delete the room.
- Access the room's recordings.
- Share room links with different permissions (see [Users and permissions](../users-and-permissions/)).

\[[](../../../assets/videos/meet/room-actions-dark.mp4#only-dark)\](../../../assets/videos/meet/room-actions-dark.mp4) \[[](../../../assets/videos/meet/room-actions-light.mp4#only-light)\](../../../assets/videos/meet/room-actions-light.mp4)

### Editing a room

You can edit the settings of an existing room at any time in the "Rooms" page. The same options available when creating a room are also available when editing it:

1. Name them.
1. Set up an [auto-deletion date](#room-auto-deletion).
1. Set up recording and access control to them.
1. Enable/disable features like chat or virtual backgrounds.

### Deleting a room

Rooms can be deleted at any time from the "Rooms" page. This will remove the room and all its associated data.

#### Room auto-deletion

Rooms can be configured with an **auto-deletion date**. You can set this date when [creating](#creating-a-room) or [editing a room](#editing-a-room). This helps keeping OpenVidu Meet clean and organized, avoiding clutter from old rooms that are no longer needed.

#### Room auto-deletion policies

When the auto-deletion date is reached, the room will be deleted. The **Auto-deletion policies** determine how to handle active meetings and stored recordings when attempting to delete the room:

- **Active meetings policy**
  - `Force`: the meeting will be immediately ended without waiting for participants to leave, and the room will be deleted.
  - `When meeting ends`: the room will be deleted after the active meeting ends.
- **Recordings policy**
  - `Force`: the room and all its recordings will be deleted.
  - `Close`: the room will be closed instead of deleted, maintaining its recordings.

### Bulk deleting rooms

Use the multi-select checkbox to delete multiple rooms at once.

\[[](../../../assets/videos/meet/bulk-delete-rooms.mp4)\](../../../assets/videos/meet/bulk-delete-rooms.mp4)

### Room links

Rooms have predefined **room links** that grant access to them. Users connecting to a room link will start a new meeting (if no meeting is currently active in the room) or join the existing meeting (if there is one).

Each room has different room links, each one granting access to the room with a specific participant role. See [Participant roles in a meeting](../users-and-permissions/#participant-roles-in-a-meeting) for more information.

#### Get a room link from the "Rooms" page

Every room item allows sharing the room link for every participant role.

\[[](../../../assets/videos/meet/share-room-link.mp4)\](../../../assets/videos/meet/share-room-link.mp4)

#### Get a room link from an active meeting

Participants with the `Moderator` role can share room links from the active meeting view.

Info

Links copied from the meeting view will always grant access to the room with `Speaker` role. If necessary, users with role `Moderator` can upgrade other user's roles during the meeting. See [Changing participant roles during a meeting](../users-and-permissions/#changing-participant-roles-during-a-meeting) for more information.

#### Get a room link from the REST API

Available in properties `moderatorUrl` and `speakerUrl` of object [MeetRoom](../../embedded/reference/api.html#/schemas/MeetRoom) .

### Room visual customization

Rooms can be customized to fit your branding needs. As for now, you can setup the color scheme of your rooms from the "Configuration" page.

You can set separately the color of:

- **Main background**: background color of the meeting view.
- **Main controls**: colors for the main control buttons (mic, camera, etc.)
- **Secondary elements**: colors for logos, icons, borders and subtle details.
- **Highlights & accents**: colors for active states and highlighted items.
- **Panels & dialogs**: background color for side panels and dialog boxes.

You can also choose between a light and a dark background style, to ensure the displayed text is always readable after applying your color scheme.

### Room REST API

Every possible action against a room can be done through [OpenVidu Meet REST API](../../embedded/reference/rest-api/):

| Operation          | HTTP Method | Reference                                                                   |
| ------------------ | ----------- | --------------------------------------------------------------------------- |
| Create a room      | POST        | [Reference](../../embedded/reference/api.html#/operations/createRoom)       |
| Get a room         | GET         | [Reference](../../embedded/reference/api.html#/operations/getRoom)          |
| Get all rooms      | GET         | [Reference](../../embedded/reference/api.html#/operations/getRooms)         |
| Delete a room      | DELETE      | [Reference](../../embedded/reference/api.html#/operations/deleteRoom)       |
| Bulk delete rooms  | DELETE      | [Reference](../../embedded/reference/api.html#/operations/bulkDeleteRooms)  |
| Get room config    | GET         | [Reference](../../embedded/reference/api.html#/operations/getRoomConfig)    |
| Update room config | PUT         | [Reference](../../embedded/reference/api.html#/operations/updateRoomConfig) |

## Meetings

### Starting a meeting

A meeting will start as soon as a participant enters an empty room using a valid **room link**. You can learn everything about room links [here](#room-links).

Users with access to OpenVidu Meet can join a meeting directly from the "Rooms" page:

\[[](../../../assets/videos/meet/join-meeting.mp4)\](../../../assets/videos/meet/join-meeting.mp4)

Info

Doing this simply opens a new tab with a `Moderator` room link.

Users with access to OpenVidu Meet can also copy a room link and share it with external participants:

\[[](../../../assets/videos/meet/share-room-link.mp4)\](../../../assets/videos/meet/share-room-link.mp4)

### Lifecycle of a meeting

Meetings consist of different views:

#### Join view

This is the first view participants see when accessing a room link. It allows setting a nickname before joining the meeting. If the participant has the required permissions, they can also access the [Recording view](#recording-view) of this room from here.

#### Device view

This view allows participants tuning their microphone and camera before joining the meeting, as well as setting a virtual background.

\[[](../../../assets/videos/meet/device-view-dark.mp4#only-dark)\](../../../assets/videos/meet/device-view-dark.mp4) \[[](../../../assets/videos/meet/device-view-light.mp4#only-light)\](../../../assets/videos/meet/device-view-light.mp4)

#### Meeting view

This is the main view of the meeting, where participants can interact with each other.

#### Recording view

This view allows to manage the recording of the meeting while it is active. Participants with the required permissions can review, play, download, delete, and share the recording via a link.

Info

Recordings can also be accessed from the "Recordings" page in OpenVidu Meet, even after the meeting has ended. See [Managing recordings](../recordings/#managing-recordings).

#### End view

This view is shown to a participant when the meeting ends, at least for that participant. It informs about the specific reason why the meeting ended (an administrator ended it, the participant was evicted from the meeting, etc.).

# Recordings

## Recording a meeting

Recordings must be started by a participant with role "Moderator" in the meeting view (see [Participant roles in a room](../users-and-permissions/#participant-roles-in-a-room)).

\[[](../../../assets/videos/meet/start-recording.mp4)\](../../../assets/videos/meet/start-recording.mp4)

While the recording is active, all participants in the meeting will see an indicator in the bottom left corner.

To stop the recording, a participant with role "Moderator" must simply click the "Stop recording" button. The recording will be automatically saved in the OpenVidu Meet server.

## Viewing recordings

By default, recordings share the same access permissions as their rooms. Whenever a user uses a room link to join a meeting, they will also have the possibility of accessing the list of its previous recordings (if any):

The recording list shows every recording of that particular room:

Participants can also open the list of recordings for that room directly from the meeting view:

\[[](../../../assets/videos/meet/recording-while-meeting.mp4)\](../../../assets/videos/meet/recording-while-meeting.mp4)

The recording view allows playing the video, downloading it or creating a [shareable link](#sharing-recordings-via-link):

### Access permissions for recordings

When [creating a new room](../rooms-and-meetings/#creating-a-room) you can configure who may access its recordings:

Available options are:

- **Only admin**: only administrators of OpenVidu Meet will have access to the recordings of this room. Administrators can always access recordings of any room.
- **Admin and moderators**: administrators and any participant of the meeting with "Moderator" role will have access to the recordings of this room.
- **Admin, moderators and speakers**: this is the default value. Administrators and any participant of the meeting with "Moderator" or "Speaker" role will have access to the recordings of this room.

Info

Participants with role "Speaker" may only **play** recordings. Administrators and participants with role "Moderator" can also **delete** them.

### Sharing recordings via link

Specific recordings can be shared through a link:

- Users can generate a shareable link from the recording list.

  \[[](../../../assets/videos/meet/share-recording-from-recording-list.mp4)\](../../../assets/videos/meet/share-recording-from-recording-list.mp4)

- Users can generate a shareable link from the recording view.

  \[[](../../../assets/videos/meet/share-recording.mp4)\](../../../assets/videos/meet/share-recording.mp4)

- From OpenVidu Meet console it is possible to generate shareable links for any recording.

  \[[](../../../assets/videos/meet/meet-recording-share-dark.mp4)\](../../../assets/videos/meet/meet-recording-share-dark.mp4)

## Room recording settings

Rooms can be configured with different recording settings. You can set up these settings when [creating a new room](../rooms-and-meetings/#creating-a-room) or [editing an existing room](../rooms-and-meetings/#editing-a-room).

- **Allow Recording / No recording**: whether to allow recording the room or not.
- **Recording Access Control**: who can access the recordings of the room. See [Access permissions for viewing recordings](#access-permissions-for-viewing-recordings).

## Managing recordings

OpenVidu Meet console can be used to manage all recordings from the "Recordings" page. It is possible to see all recordings, play them, download them, delete them, and share them via a link:

## Recording REST API

Recordings can be managed via the [OpenVidu Meet REST API](../../embedded/reference/rest-api/):

| Operation              | HTTP Method | Reference                                                                       |
| ---------------------- | ----------- | ------------------------------------------------------------------------------- |
| Get recording          | GET         | [Reference](../../embedded/reference/api.html#/operations/getRecording)         |
| Get all recordings     | GET         | [Reference](../../embedded/reference/api.html#/operations/getRecordings)        |
| Delete recording       | DELETE      | [Reference](../../embedded/reference/api.html#/operations/deleteRecording)      |
| Bulk delete recordings | DELETE      | [Reference](../../embedded/reference/api.html#/operations/bulkDeleteRecordings) |
| Download recordings    | GET         | [Reference](../../embedded/reference/api.html#/operations/downloadRecordings)   |
| Get recording media    | GET         | [Reference](../../embedded/reference/api.html#/operations/getRecordingMedia)    |
| Get recording URL      | GET         | [Reference](../../embedded/reference/api.html#/operations/getRecordingUrl)      |

# Users and permissions

## Participant roles in a room

Participants in a room can have different roles, which grant different permissions. The role of a participant is determined by the room link used to join. See [Room links](../rooms-and-meetings/#room-links) for more information.

Available roles are:

- **Moderator**: grants permissions to end the meeting, start/stop recordings, share room links and manage participants. Also grants permissions of `Speaker` role.
- **Speaker**: grants permissions to share their camera, microphone and screen.

### Changing participant roles during a meeting

Participants with `Moderator` role can upgrade or downgrade other participants' roles during the meeting from the "Participants" side panel:

## OpenVidu Meet authentication

OpenVidu Meet is by default protected with an administrator **username and password**. These credentials will be required when accessing OpenVidu Meet console:

The initial administrator credentials are:

- **Username**: **`admin`**
- **Password**: specified on installation time

The value of the password will be asked on installation. If left empty, a random password will be generated. The location of the administration password depends on the environment of the deployment:

Credentials are always username **`admin`** and password **`admin`**.

Credentials will be logged at the end of the installation process:

```text
OpenVidu Meet is available at:

    URL: https://<YOUR_DOMAIN>
    Credentials:
      - User: admin
      - Password: XXXXXXX
```

Warning

If you [modify the initial administrator password](#modify-openvidu-meet-authentication), this value will no longer be valid.

In the Secrets Manager of the CloudFormation stack, in secret **`MEET_INITIAL_ADMIN_PASSWORD`**

Warning

If you [modify the initial administrator password](#modify-openvidu-meet-authentication), this value will no longer be valid.

In the Azure Key Vault, in secret **`MEET_INITIAL_ADMIN_PASSWORD`**

Warning

If you [modify the initial administrator password](#modify-openvidu-meet-authentication), this value will no longer be valid.

### Modify OpenVidu Meet authentication

Administrator credentials can be modified from the **"User & Permissions"** view:

# OpenVidu Meet deployment overview

## Production ready

OpenVidu Meet is designed to be **self-hosted**, whether it is on premises or in a cloud provider. It brings to your own managed service advanced capabilities usually reserved only for SaaS solutions. There are two main reasons why you may need to self-host the real-time solution yourself:

- **Privacy**: you can't afford to let your client's data get out of your reach. OpenVidu allows you to meet all your privacy and regulatory requirements: no data at all is sent to any third-party server. Everything is self-contained on your own servers.
- **Leverage your resources**: your organization has access to its own infrastructure that can be used to host these services. SaaS solutions generally offer complete freedom from infrastructure management, but this comes with generally high prices that cover both the provider's infrastructure and their service surcharge. OpenVidu allows taking full advantage of your own infrastructure, reducing costs and increasing performance.

It is important to mention that when we talk about self-hosting OpenVidu, we don't just mean installing it in bare-metal servers or private VPCs. OpenVidu also supports deployments in the most popular cloud providers, using their native services when possible. **AWS** and **Azure** are currently supported, and others are coming soon. You can learn more about the different options to deploy OpenVidu in the [deployment types](../../../docs/self-hosting/deployment-types/) section.

One of OpenVidu's main goals is offering a self-hosted, production-ready live-video platform with all the advanced capabilities typically reserved for SaaS solutions. This includes outstanding **performance**, **scalability**, **fault tolerance** and **observability**:

- **Performance**

  ______________________________________________________________________

  OpenVidu is built to be incredibly powerful. It is based on the best open source WebRTC stacks: [LiveKit](https://livekit.io/) and [mediasoup](https://mediasoup.org/) . By combining the best of both worlds, OpenVidu provides outstanding performance.

  [Learn more about performance](../../../docs/self-hosting/production-ready/performance/)

- **Scalability**

  ______________________________________________________________________

  OpenVidu has been designed from the outset with scalability in mind. Host videoconference rooms and large live streams with hundreds of participants. Autoscale your cluster to adapt to the demand and optimize your resources.

  [Learn more about scalability](../../../docs/self-hosting/production-ready/scalability/)

- **Fault Tolerance**

  ______________________________________________________________________

  OpenVidu offers fault tolerance in all its components. Deploy a reliable high-availability cluster knowing that if one of your node goes down, others will be able to continue working with no downtime.

  [Learn more about fault tolerance](../../../docs/self-hosting/production-ready/fault-tolerance/)

- **Observability**

  ______________________________________________________________________

  OpenVidu brings everything necessary to monitor the status, health, load and history of your deployment. It automatically collects events, metrics and logs, and provides [OpenVidu Dashboard](../../../docs/self-hosting/production-ready/observability/openvidu-dashboard/) and a [Grafana stack](../../../docs/self-hosting/production-ready/observability/grafana-stack/) to navigate them.

  [Learn more about observability](../../../docs/self-hosting/production-ready/observability/)

## OpenVidu Meet editions

OpenVidu Meet is available in two editions:

### OpenVidu COMMUNITY

It is completely **open-source and free to use**. It includes all the features you need for your video conferencing solution. Everything listed in the [Features](../../#features) section is available in OpenVidu Meet COMMUNITY: HD video, HiFi audio, recording, screen sharing, advanced chat, virtual backgrounds, and more.

OpenVidu Meet COMMUNITY is perfect for production deployments with moderate user load. It can be easily deployed on your own servers, and you can customize its branding to match your organization’s identity. If necessary, upgrading to OpenVidu PRO is seamless and non-disruptive.

### OpenVidu PRO

It is OpenVidu's **commercial edition** and requires a license. It is meant for high demanding environments with significant user load. On top of every functional feature available in OpenVidu COMMUNITY, OpenVidu PRO brings **2x performance**, **advanced observability**, **scalability** and **fault tolerance** features. As well as **priority support** from our team of experts.

OpenVidu PRO follows a simple pricing model based on the size of your deployment (number of CPU cores). Check the [OpenVidu pricing page](https://openvidu.io/pricing) for more details.

Info

Different OpenVidu [deployment types](#deployment-types) support different editions.

## Deployment types

OpenVidu Meet offers **user-friendly installers** that facilitate quick **on-premises deployments**, so you can self-host your real-time solution in your own infrastructure or any cloud provider.

The following documentation pages focus on three different deployments:

- [Local deployment](../local/), to test and develop in your machine.
- [Basic deployment](../basic/), a production installation requiring a single server.
- [Advanced deployments](../advanced/), a production installation requiring multiple servers for scalability and high-availability.

The table below summarizes the main characteristics of each deployment type.

| Type of deployment            | **OpenVidu Meet: Local deployment**               | **OpenVidu Meet: Basic deployment**                        | **OpenVidu Meet: Advanced deployment**                                                                                                        |
| ----------------------------- | ------------------------------------------------- | ---------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------- |
| **OpenVidu Edition**          | COMMUNITY                                         | COMMUNITY                                                  | PRO                                                                                                                                           |
| **Suitability**               | Suitable to test and develop                      | Suitable for production applications with medium user load | Suitable for production applications with dynamic user load and need for high availability                                                    |
| **Features**                  | Try out all OpenVidu Meet features in your laptop | All OpenVidu Meet features, ready for production           | All OpenVidu Meet features ready for production, plus **2x performance**, **advanced observability**, **scalability** and **fault tolerance** |
| **Number of servers**         | Your laptop                                       | 1 server                                                   | Multiple servers                                                                                                                              |
| **Installation instructions** | [Try](../local/)                                  | [Install](../basic/)                                       | [Install](../advanced/)                                                                                                                       |

# Try OpenVidu Meet locally

You can easily deploy **OpenVidu Meet** on your local machine to explore its features right away.

You can simulate **several users** joining to the **same room** using different tabs of your preferred browser.

This local deployment is the ideal choice to develop the [embedding of OpenVidu Meet into your own application](../../embedded/intro/).

Warning

Remember that this deployment is designed for **demo** and **development** purposes. For production follow the [Basic deployment](../basic/) or [Advanced deployments](../advanced/).

## Prerequisites

- A computer with **Windows**, **macOS**, or **Linux** installed.
- 4 CPU cores and 8 GB of RAM (16 GB recommended for better performance).
- At least 10 GB of free disk space.
- [Docker Desktop](https://docs.docker.com/desktop/) (see installation instructions below).

## Installing Docker Desktop

[Docker](https://docs.docker.com/get-started/docker-overview/) is a technology the simplifies the installation of applications on **Windows**, **macOS**, and **Linux**.

In the Docker terminology, an application is downloaded as a one or several **docker images**. When the application is executed, it is composed of one or several **docker containers**.

Instructions to install [Docker Desktop](https://docs.docker.com/desktop/) (the software needed to execute Docker containers):

- Install [Docker Desktop](https://docs.docker.com/desktop/install/windows-install/)

- Install [Docker Desktop](https://docs.docker.com/desktop/install/mac-install/)

- Install [Docker Desktop](https://docs.docker.com/desktop/install/linux-install/)

Info

This guide is based on Docker Desktop, but the commands can also be used directly in a linux machine's terminal with [Docker Engine](https://docs.docker.com/engine/install/#supported-platforms) and [Docker Compose](https://docs.docker.com/compose/install/linux/) installed. Make sure they are recent versions: Docker Engine >= **28.4.0** and Docker Compose >= **2.39.4**

## Running OpenVidu Meet Locally

1. Open **Docker Desktop** and click on the **"Terminal"** button in the bottom right corner.

1. Copy and paste the following command into the terminal:

   ```bash
   docker compose -p openvidu-meet -f oci://openvidu/local-meet:latest up -y openvidu-meet-init
   ```

   Info

   If you want to deploy a specific version, replace `latest` with the desired version tag. E.g., to deploy version `3.4.1` use:

   ```text
   docker compose -p openvidu-meet -f oci://openvidu/local-meet:3.4.1 up -y openvidu-meet-init
   ```

1. After pasting the command, press **Enter** to execute the command.

   The terminal will show how OpenVidu Meet is downloaded and executed.

   Firstly, OpenVidu Meet components (docker images) are downloaded (only the first time). It will take ~5 minutes on a 100 Mbps Internet connection.

   Then, OpenVidu Meet components (docker containers) are executed.

   Finally, the terminal will show when OpenVidu Meet is ready to be used:

   ```text
   openvidu-meet-init-1  | Waiting for OpenVidu to start...    
   openvidu-meet-init-1  | Starting OpenVidu... Please be patient...
   openvidu-meet-init-1  | Starting OpenVidu... Please be patient...
   openvidu-meet-init-1  | Starting OpenVidu... Please be patient...
   openvidu-meet-init-1  | Starting OpenVidu... Please be patient...
   openvidu-meet-init-1  | Starting OpenVidu... Please be patient...
   openvidu-meet-init-1  | Starting OpenVidu... Please be patient...
   ...
   openvidu-meet-init-1  |
   openvidu-meet-init-1  | ====================================================
   openvidu-meet-init-1  | 🎉 OpenVidu Meet main is ready! 🎉
   openvidu-meet-init-1  | ====================================================
   openvidu-meet-init-1  |
   openvidu-meet-init-1  | This version is only for local development purposes.
   openvidu-meet-init-1  | DO NOT USE IT IN PRODUCTION!
   openvidu-meet-init-1  |
   openvidu-meet-init-1  | ------------------OpenVidu Meet---------------------
   openvidu-meet-init-1  | > NOTE: Below are the default initial login credentials
   openvidu-meet-init-1  | > for OpenVidu Meet. If you update them after deployment,
   openvidu-meet-init-1  | > this message will not reflect those changes.
   openvidu-meet-init-1  | ----------------------------------------------------
   openvidu-meet-init-1  |     - Access from this machine:
   openvidu-meet-init-1  |         - http://localhost:9080
   openvidu-meet-init-1  |     - Credentials:
   openvidu-meet-init-1  |         - Username: admin
   openvidu-meet-init-1  |         - Password: admin
   openvidu-meet-init-1  |         - API Key: meet-api-key
   openvidu-meet-init-1  | ----------------------------------------------------
   ```

## Accessing OpenVidu Meet

You can access **OpenVidu Meet** by opening <http://localhost:9080> in your web browser with credentials:

- Username: `admin`
- Password: `admin`

You can use the [REST API](../../embedded/reference/rest-api/) to [embed OpenVidu Meet](../../embedded/intro) using:

- API Key: `meet-api-key`

You can change them later from the [OpenVidu Meet Users And Permissions](../../features/users-and-permissions/#modify-openvidu-meet-authentication).

## Managing the deployment

Once installed and executed, **`openvidu-meet`** will appear in **Docker Desktop → Containers** section.

You can manage OpenVidu Meet execution interactively:

1. Click the **Stop** button.

1. Click the **Start** button.

Warning

It will remove rooms and recordings.

1. Click the **Delete** button.

1. Go to **Docker Desktop → Images**.

1. Remove the images related to **OpenVidu Meet**.

1. Go to **Docker Desktop → Volumes**.

1. Remove the volumes related to **OpenVidu Meet**.

1. Click on the container group to open its details. The logs will be shown after clicking on the container group.

## Accessing OpenVidu Meet from other computers or phones

You can connect to OpenVidu Meet from other computers or phones. It is very useful to join several people to the same room and try the communication features.

Follow these steps:

1. Be sure that other computers or phones are connected to the same Wi-Fi or local network (LAN) where OpenVidu Meet is installed.

1. Stop OpenVidu Meet if it is already started.

1. Start it again with a new command.

   1. Obtain the local IP of the computer where OpenVidu is intalled following [this guide](https://www.avast.com/c-how-to-find-ip-address) . It typically is similar to `192.168.1.100`.
   1. Execute the following command in Docker Desktop (replacing `<YOUR_PRIVATE_IP>` with the IP obtained)

   ```powershell
   $env:LAN_PRIVATE_IP='<YOUR_PRIVATE_IP>'; docker compose -p openvidu-meet -f oci://openvidu/local-meet:latest up -y openvidu-meet-init
   ```

   1. Obtain the local IP of the computer where OpenVidu is intalled following [this guide](https://www.avast.com/c-how-to-find-ip-address) . It typically is similar to `192.168.1.100`.
   1. Execute the following command in Docker Desktop (replacing `<YOUR_PRIVATE_IP>` with the IP obtained)

   ```bash
   LAN_PRIVATE_IP='<YOUR_PRIVATE_IP>' docker compose -p openvidu-meet -f oci://openvidu/local-meet:latest up -y openvidu-meet-init
   ```

   1. Obtain the local IP of the computer where OpenVidu is intalled following [this guide](https://www.ionos.com/digitalguide/hosting/technical-matters/get-linux-ip-address/) . It typically is similar to `192.168.1.100`.
   1. Execute the following command in Docker Desktop (replacing `<YOUR_PRIVATE_IP>` with the IP obtained)

   ```bash
   LAN_PRIVATE_IP='<YOUR_PRIVATE_IP>' docker compose -p openvidu-meet -f oci://openvidu/local-meet:latest up -y openvidu-meet-init
   ```

1. Access to OpenVidu Meet with a different URL:

   When OpenVidu Meet is ready to be used the terminal will show the URL where it is accessible.

   For example, if your private IP is `192.168.1.100` you have to use the URL `https://192-168-1-100.openvidu-local.dev:9443`.

   You will see the following instructions in the terminal when OpenVidu Meet is ready:

   ```text
   openvidu-meet-init-1  |
   openvidu-meet-init-1  | ====================================================
   openvidu-meet-init-1  | 🎉 OpenVidu Meet main is ready! 🎉
   openvidu-meet-init-1  | ====================================================
   openvidu-meet-init-1  |
   openvidu-meet-init-1  | This version is only for local development purposes.
   openvidu-meet-init-1  | DO NOT USE IT IN PRODUCTION!
   openvidu-meet-init-1  |
   openvidu-meet-init-1  | ------------------OpenVidu Meet---------------------
   openvidu-meet-init-1  | > NOTE: Below are the default initial login credentials
   openvidu-meet-init-1  | > for OpenVidu Meet. If you update them after deployment,
   openvidu-meet-init-1  | > this message will not reflect those changes.
   openvidu-meet-init-1  | ----------------------------------------------------
   openvidu-meet-init-1  |     - Access from this machine:
   openvidu-meet-init-1  |         - https://192-168-1-100.openvidu-local.dev:9443
   openvidu-meet-init-1  |     - Credentials:
   openvidu-meet-init-1  |         - Username: admin
   openvidu-meet-init-1  |         - Password: admin
   openvidu-meet-init-1  |         - API Key: meet-api-key
   openvidu-meet-init-1  | ----------------------------------------------------
   ```

## Advanced Local Deployment

If you want to modify some configurations or have more control over the local deployment, you can deploy the [OpenVidu Platform Local deployment](../../../docs/self-hosting/local/) which by default includes **OpenVidu Meet** as one of its services.

Warning

OpenVidu Meet is currently considered in **BETA**. There may be bugs and its APIs are subject to change.

This section contains the instructions to deploy a production-ready deployment of OpenVidu Meet in a single server.

Info

This guide shows a single-node installation in a Linux machine. To see other deployment options, such as deploying in cloud providers like AWS, Azure, or GCP, or deploying in a multi-node architecture, check the [Other deployment options](#other-deployment-options) section at the end of this page.

## Prerequisites

### OS

- **Ubuntu** 22.04 or newer.
- User with **root** permissions (via `sudo`).

### Recommended hardware

- At least 4 GB RAM and 4 CPU cores.
- Generous disk space (100 GB recommended), especially if you plan to record your meetings.

### Networking

- A public IP, that doesn't change between restarts (a static IP).

- (Recommended) A domain name (FQDN) pointing to the public IP.

- Port rules: these inbound ports must be open in your firewall and reachable from the internet.

  | Protocol | Ports         | Source          | Requirement                                                        |
  | -------- | ------------- | --------------- | ------------------------------------------------------------------ |
  | TCP      | 80            | 0.0.0.0/0, ::/0 | Mandatory                                                          |
  | TCP      | 443           | 0.0.0.0/0, ::/0 | Mandatory                                                          |
  | UDP      | 443           | 0.0.0.0/0, ::/0 | Mandatory                                                          |
  | TCP      | 7881          | 0.0.0.0/0, ::/0 | Optional, but recommended for optimal perfomance and media quality |
  | UDP      | 50000 - 60000 | 0.0.0.0/0, ::/0 | Optional, but recommended for optimal perfomance and media quality |

## Installation

Run this command in your server to start the installation wizard:

```bash
sh <(curl -fsSL http://get.openvidu.io/community/singlenode/latest/install_meet.sh)
```

Follow the instructions of the installation wizard. They are self-explanatory, but here is a breakdown:

1. Select **Yes** to continue when prompted after the installation summary:

1. If you have a domain name, enter it when prompted. If you don't have one, just press **Enter** to continue:

1. The installer will ask you to confirm if you want to proceed with the installation. Select **Yes** to start the installation.

   The installation will begin, downloading the software and configuring your server. Once the installation is complete, you will see this message:

   You can access OpenVidu Meet in your browser using the URL and credentials shown in the installation completion message.

## Administration

You can manage the OpenVidu Meet installation running simple commands on your server:

```bash
# Start OpenVidu Meet
sudo systemctl start openvidu

# Stop OpenVidu Meet
sudo systemctl stop openvidu

# Restart OpenVidu Meet
sudo systemctl restart openvidu
```

OpenVidu Meet is under the hood an OpenVidu Platform deployment, so you can refer to the [OpenVidu Platform Single Node administration guide](../../../docs/self-hosting/single-node/on-premises/admin/) for more advanced management tasks, including:

- [Check the status of services](../../../docs/self-hosting/single-node/on-premises/admin/#checking-the-status-of-services)
- [Check logs](../../../docs/self-hosting/single-node/on-premises/admin/#checking-logs)
- [Upgrade OpenVidu Meet to a newer version](../../../docs/self-hosting/single-node/on-premises/upgrade/)
- [Uninstall OpenVidu Meet](../../../docs/self-hosting/single-node/on-premises/admin/#uninstalling-openvidu)

## Other deployment options

This guide has covered the manual installation of OpenVidu Meet as a single-node deployment in a Linux server. Under the hood OpenVidu Meet is an OpenVidu Platform deployment, so there are further deployment options available:

- **Non-interactive installation**: you can run the installation wizard in a non-interactive way, providing all the required parameters in a single command. Check the [Non-interactive installation](../../../docs/self-hosting/single-node/on-premises/install/#non-interactive-installation) guide for OpenVidu Platform.

- **Deploy OpenVidu Meet single-node in AWS**: using our CloudFormation template, you can deploy OpenVidu Meet using native AWS resources. Follow the [AWS deployment](../../../docs/self-hosting/single-node/aws/install/) guide for OpenVidu Platform.

- **Deploy OpenVidu Meet single-node in Azure**: using our ARM template, you can deploy OpenVidu Meet using native Azure resources. Follow the [Azure deployment](../../../docs/self-hosting/single-node/azure/install/) guide for OpenVidu Platform.

- **Deploy OpenVidu Meet single-node in GCP**: using our Terraform template, you can deploy OpenVidu Meet using native GCP resources. Follow the [GCP deployment](../../../docs/self-hosting/single-node/gcp/install/) guide for OpenVidu Platform.

- **Deploy OpenVidu Meet in a multi-node architecture**: there are multi-node deployment options available to make your OpenVidu Meet installation scalable and fault-tolerant. Check out the [Advanced deployments](../advanced/) section for more information.

Warning

OpenVidu Meet is currently considered in **BETA**. There may be bugs and its APIs are subject to change.

Info

**OpenVidu Meet** is under the hood an **OpenVidu Platform** deployment with a module on top of it. Therefore, all deployment documentation for OpenVidu Platform applies to OpenVidu Meet as well. The information in this page is a summary of the different deployment options and the links to their corresponding OpenVidu Platform documentation.

## Deployment types

OpenVidu Meet can be easily deployed in a single server (follow the [basic deployment guide](../basic/)). However, a single server won't be enough for environments that require scalability and high-availability. For such cases, it is necessary a multi-node deployment.

| Type of deployment            | [**OpenVidu Local (development)**](#openvidu-local-development)                                                                                                       | [**OpenVidu Single Node**](#openvidu-single-node)                                                                                                                                | [**OpenVidu Elastic**](#openvidu-elastic)                                                                     | [**OpenVidu High Availability**](#openvidu-high-availability)            |
| ----------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------ |
| **OpenVidu Edition**          | COMMUNITY                                                                                                                                                             | COMMUNITY PRO                                                                                                                                                                    | PRO                                                                                                           | PRO                                                                      |
| **Suitability**               | For local development in your laptop                                                                                                                                  | For applications with medium user load                                                                                                                                           | For applications with dynamic user load that require scalability                                              | For applications where both scalability and fault tolerance are critical |
| **Features**                  | Friendly Docker Compose setup with Redis, Egress, Ingress, S3 storage and observability. With automatic certificate management to test across devices in your network | COMMUNITY Custom LiveKit distribution with Redis, Egress, Ingress, S3 storage and observability. PRO Same features but adding **2x performance** and **advanced observability**. | Same benefits as OpenVidu Single Node plus **2x performance**, **advanced observability** and **scalability** | Same benefits as OpenVidu Elastic plus **fault tolerance**               |
| **Number of servers**         | Your laptop                                                                                                                                                           | 1 Node                                                                                                                                                                           | 1 Master Node + N Media Nodes                                                                                 | 4 Master Nodes + N Media Nodes                                           |
| **Installation instructions** | [Try](../local/)                                                                                                                                                      | [Install](../basic/)                                                                                                                                                             | [Install](../../../docs/self-hosting/elastic/)                                                                | [Install](../../../docs/self-hosting/ha/)                                |

Info

You can learn more about the **OpenVidu**COMMUNITY and **OpenVidu**PRO editions [here](../overview/#openvidu-meet-editions).

### OpenVidu Local (development)

Run the OpenVidu Local deployment in your machine by following [this guide](../local/).

To run OpenVidu in your local machine, this is the quickest option. It is a Docker Compose setup that includes all the necessary services to run OpenVidu in your LAN, including automated SSL certificates that will be valid across all devices in your network.

OpenVidu Local (development)

### OpenVidu Single Node

You can install OpenVidu Meet as a Single Node deployment by following the [basic deployment guide](../basic/). You can also check out the [OpenVidu Platform documentation](../../../docs/self-hosting/single-node/) for more detailed installation options.

This is the simplest production-ready OpenVidu deployment available. It provides all the features you need, but lacks scalability and fault tolerance. But make no mistake about it: it is perfectly suitable for medium-scale production deployments. For most projects OpenVidu Single Node will be enough, at least until your user load gets serious. You can host hundreds of simultaneous participants in your rooms by running OpenVidu Community on a sufficiently powerful server!

It is composed of a single OpenVidu Node hosting all the necessary services in a monolithic setup. It comes in two flavors:

- **OpenVidu Single Node COMMUNITY**: all the features you need to build your real-time application.
- **OpenVidu Single Node PRO**: for those users that want the benefits of OpenVidu PRO in a single-node setup. It includes **2x performance** and **advanced observability** features.

OpenVidu Single Node

### OpenVidu Elastic

Install OpenVidu Elastic by following the [OpenVidu Platform guide](../../../docs/self-hosting/elastic/).

This is the intermediate OpenVidu deployment. It provides **scalability** for your video rooms. Suitable for applications with dynamic load in the media plane that require scalability.

It is composed of two different types of nodes, one of them running on a cluster of multiple servers and the other running as a single monolithic server:

- **A cluster of Media Nodes** hosting all the media-related services. Your video rooms scale up and down thanks to this cluster.
- **A single Master Node** hosting all the support services in a monolithic setup.

OpenVidu Elastic

### OpenVidu High Availability

Install OpenVidu High Availability by following the [OpenVidu Platform guide](../../../docs/self-hosting/ha/).

This is the most complete OpenVidu deployment. It provides **scalability** for your video rooms and **fault tolerance** in all its services. Suitable for applications where both scalability and availability are critical.

It is composed of two different types of nodes running on two separate clusters:

- **A cluster of Media Nodes** hosting all the media-related services. Your video rooms scale up and down thanks to this cluster. The minimum number of nodes in this cluster is **1**, and it is designed to scale up and down dynamically according to workload.
- **A cluster of Master Nodes** hosting all the support services in their high availability format. Your deployment is fault-tolerant thanks to this cluster. The minimum number of nodes in this cluster is **4**, and it is designed to have a fixed number of nodes at all times.

OpenVidu High Availability cluster

With **OpenVidu Meet Embedded**, you can integrate the best video calling experience directly into your own application:

- Quick setup using a **URL**, an **iframe** or a **Web Component**.
- Integrate into your application's logic using **REST API** and **Webhooks**.
- Customizable user interface to match your app's **branding and style**.

**Add video calling capabilities to your app with a single line of HTML**

```html
<openvidu-meet room-url="https://YOUR_DOMAIN/room/your-room?secret=1234567"></openvidu-meet>
```

- **Create rooms through REST API**

  ```bash
  curl --request POST \
    --url https://YOUR_DOMAIN/api/v1/rooms \
    --header 'Accept: application/json' \
    --header 'Content-Type: application/json' \
    --header 'X-API-KEY: YOUR_API_KEY' \
    --data '{"roomName": "my-room"}'
  ```

- **Manage recordings through REST API**

  ```bash
  curl --request GET \
    --url https://YOUR_DOMAIN/api/v1/recordings \
    --header 'Accept: application/json' \
    --header 'X-API-KEY: YOUR_API_KEY'
  ```

**Integrate OpenVidu Meet into your own UI and business logic**

______________________________________________________________________

## Where to start? We recommend following the [**step by step guide**](../step-by-step-guide) or exploring one of our [**tutorials**](../tutorials).

## 1. Run OpenVidu Meet

You need **Docker Desktop**. You can install it on [Windows](https://docs.docker.com/desktop/setup/install/windows-install/) , [Mac](https://docs.docker.com/desktop/setup/install/mac-install/) or [Linux](http://docs.docker.com/desktop/setup/install/linux/) .

Run this command in Docker Desktop's terminal:

```bash
docker compose -p openvidu-meet -f oci://openvidu/local-meet:3.4.1 up -y openvidu-meet-init
```

Info

For a detailed guide on how to run OpenVidu Meet locally, visit [Try OpenVidu Meet locally](../../deployment/local/) .

## 2. Create a room

You can create a room from the **"Rooms"** page in OpenVidu Meet:

\[[](../../../assets/videos/meet/meet-rooms-dark.mp4#only-dark)\](../../../assets/videos/meet/meet-rooms-dark.mp4) \[[](../../../assets/videos/meet/meet-rooms-light.mp4#only-light)\](../../../assets/videos/meet/meet-rooms-light.mp4)

### Automating room creation

You can automate the room creation process by using the [OpenVidu Meet REST API](../reference/rest-api/). This allows you to create rooms programmatically from your application's backend, without manual intervention.

Check out the [API reference for creating rooms](../../embedded/reference/api.html#/operations/createRoom) . Below you have copy-paste snippets for most common languages.

Info

Remember to replace **`YOUR_OPENVIDU_DEPLOYMENT_DOMAIN`** and **`YOUR_API_KEY`** in the snippets below.

```bash
curl --request POST \
    --url https://YOUR_OPENVIDU_DEPLOYMENT_DOMAIN/api/v1/rooms \
    --header 'Accept: application/json' \
    --header 'Content-Type: application/json' \
    --header 'X-API-KEY: YOUR_API_KEY' \
    --data '{"roomName": "my-room"}'
    --data '{"roomName": "my-room"}'
```

```javascript
const https = require('https');

const options = {
    method: 'POST',
    hostname: 'YOUR_OPENVIDU_DEPLOYMENT_DOMAIN',
    port: 443,
    path: '/api/v1/rooms',
    headers: {
        'Content-Type': 'application/json',
        Accept: 'application/json',
        'X-API-KEY': 'YOUR_API_KEY'
    }
};

const req = https.request(options, function (res) {
    const chunks = [];
    res.on('data', function (chunk) {
        chunks.push(chunk);
    });
    res.on('end', function () {
        const body = Buffer.concat(chunks);
        console.log(body.toString());
    });
});

req.write(JSON.stringify({
    roomName: 'my-room',
}));

req.end();
```

```go
package main

import (
    "fmt"
    "strings"
    "net/http"
    "io"
)

func main() {

    url := "https://YOUR_OPENVIDU_DEPLOYMENT_DOMAIN/api/v1/rooms"

    payload := strings.NewReader("{\"roomName\":\"my-room\"}")

    req, _ := http.NewRequest("POST", url, payload)

    req.Header.Add("Content-Type", "application/json")
    req.Header.Add("Accept", "application/json")
    req.Header.Add("X-API-KEY", "YOUR_API_KEY")

    res, _ := http.DefaultClient.Do(req)

    defer res.Body.Close()
    body, _ := io.ReadAll(res.Body)

    fmt.Println(res)
    fmt.Println(string(body))

}
```

```ruby
require 'uri'
require 'net/http'
require 'openssl'

url = URI("https://YOUR_OPENVIDU_DEPLOYMENT_DOMAIN/api/v1/rooms")

http = Net::HTTP.new(url.host, url.port)
http.use_ssl = true

request = Net::HTTP::Post.new(url)
request["Content-Type"] = 'application/json'
request["Accept"] = 'application/json'
request["X-API-KEY"] = 'YOUR_API_KEY'
request.body = "{\"roomName\": \"my-room\"}"

response = http.request(request)
puts response.read_body
```

```java
HttpRequest request = HttpRequest.newBuilder()
    .uri(URI.create("https://YOUR_OPENVIDU_DEPLOYMENT_DOMAIN/api/v1/rooms"))
    .header("Content-Type", "application/json")
    .header("Accept", "application/json")
    .header("X-API-KEY", "YOUR_API_KEY")
    .method("POST", HttpRequest.BodyPublishers.ofString("{\"roomName\": \"my-room\"}"))
    .build();
HttpResponse<String> response = HttpClient.newHttpClient().send(request, HttpResponse.BodyHandlers.ofString());
System.out.println(response.body());
```

```python
import http.client

conn = http.client.HTTPSConnection("YOUR_OPENVIDU_DEPLOYMENT_DOMAIN")

payload = "{\"roomName\": \"my-room\"}"

headers = {
    'Content-Type': "application/json",
    'Accept': "application/json",
    'X-API-KEY': "YOUR_API_KEY"
}

conn.request("POST", "/api/v1/rooms", payload, headers)

res = conn.getresponse()
data = res.read()

print(data.decode("utf-8"))
```

```rust
// Cargo.toml:
// reqwest = { version = "0.12", features = ["blocking", "rustls-tls"] }

use reqwest::blocking::Client;
use reqwest::header::{ACCEPT, CONTENT_TYPE};

fn main() -> Result<(), Box<dyn std::error::Error>> {
    let client = Client::new();
    let url = "https://YOUR_OPENVIDU_DEPLOYMENT_DOMAIN/api/v1/rooms";
    let payload = r#"{"roomName": "my-room"}"#;

    let resp = client
        .post(url)
        .header(ACCEPT, "application/json")
        .header(CONTENT_TYPE, "application/json")
        .header("X-API-KEY", "YOUR_API_KEY")
        .body(payload)
        .send()?;

    println!("Status: {}", resp.status());
    println!("{}", resp.text()?);
    Ok(())
}
```

```php
<?php

$curl = curl_init();

curl_setopt_array($curl, [
    CURLOPT_URL => "https://YOUR_OPENVIDU_DEPLOYMENT_DOMAIN/api/v1/rooms",
    CURLOPT_RETURNTRANSFER => true,
    CURLOPT_POST => true,
    CURLOPT_POSTFIELDS => json_encode(['roomName' => 'my-room']),
    CURLOPT_HTTPHEADER => [
        "Accept: application/json",
        "Content-Type: application/json",
        "X-API-KEY: YOUR_API_KEY"
    ],
]);

$response = curl_exec($curl);
$err = curl_error($curl);

curl_close($curl);

if ($err) {
    echo "cURL Error #:" . $err;
} else {
    echo $response;
}
```

```csharp
using System.Net.Http.Headers;
var client = new HttpClient();
var request = new HttpRequestMessage
{
    Method = HttpMethod.Post,
    RequestUri = new Uri("https://YOUR_OPENVIDU_DEPLOYMENT_DOMAIN/api/v1/rooms"),
    Headers =
    {
        { "Accept", "application/json" },
        { "X-API-KEY", "YOUR_API_KEY" },
    },
    Content = new StringContent("{\"roomName\": \"my-room\"}")
    {
        Headers =
        {
            ContentType = new MediaTypeHeaderValue("application/json")
        }
    }
};
using (var response = await client.SendAsync(request))
{
    response.EnsureSuccessStatusCode();
    var body = await response.Content.ReadAsStringAsync();
    Console.WriteLine(body);
}
```

The response to this request will be a JSON object as below. The required properties for the next step are `moderatorUrl` and `speakerUrl`, needed to embed the room into your application as explained in step 3.

```json
{
  "roomId": "room-123",
  "roomName": "My Room",
  "creationDate": 1620000000000,
  "autoDeletionDate": 1900000000000,
  "autoDeletionPolicy": {
    "withMeeting": "when_meeting_ends",
    "withRecordings": "close"
  },
  "config": {
    "chat": {
      "enabled": true
    },
    "recording": {
      "enabled": true,
      "allowAccessTo": "admin_moderator_speaker"
    },
    "virtualBackground": {
      "enabled": true
    }
  },
  "moderatorUrl": "http://localhost:6080/room/room-123?secret=123456",
  "speakerUrl": "http://localhost:6080/room/room-123?secret=654321",
  "status": "open",
  "meetingEndAction": "none"
}
```

## 3. Get the room URL

To embed a room into your application's frontend you need the **room URL**. You can copy the room URL for each participant role from the "Rooms" page in OpenVidu Meet console:

### Automating room URL retrieval

You can get the room URLs programmatically using the [OpenVidu Meet REST API](../reference/rest-api/). They are available in properties `moderatorUrl` and `speakerUrl` of object [MeetRoom](../../embedded/reference/api.html#/schemas/MeetRoom) . This object is returned as a JSON response from methods:

- [Create a room](../../embedded/reference/api.html#/operations/createRoom)
- [Get a room](../../embedded/reference/api.html#/operations/getRoom)
- [Get all rooms](../../embedded/reference/api.html#/operations/getRooms)

## 4. Embed the room into your application

Once you got the desired room URL, there are 3 alternatives to embed the OpenVidu Meet room into your application's interface:

### Use a direct link

This is the simplest and easiest way to embed an OpenVidu Meet room into your application. It's a perfect fit if your frontend is a web application, and you don't need any custom elements in the video meeting UI: the polished UI of OpenVidu Meet will be displayed in its own browser tab.

Just link to the room URL from any element in your frontend. For example, with a simple `<a>` tag:

```html
<a href="{{ your-room-url }}">Join Room</a>
```

After clicking on the element, the user will be redirected to OpenVidu Meet, ready to join the room.

\[[](../../../assets/videos/meet/embed-url.mp4)\](../../../assets/videos/meet/embed-url.mp4)

Info

You can customize the room by simply appending query parameters to the room URL. For example, you can redirect back to your application after the user leaves the room by appending this query param: `https://{{ your-room-url }}&leave-redirect-url=https://myapp.com`

See [Passing attributes to a direct link](../reference/direct-link/#attributes) for more information.

### Use the Web Component

The OpenVidu Meet Web Component is the best option if you want to integrate the OpenVidu Meet UI along your own custom UI. OpenVidu Meet will simply become another component of your UI, blending seamlessly with your application's design and logic.

Include a `<script>` tag to load the OpenVidu Meet Web Component definition from your OpenVidu deployment. Then, you can use the `<openvidu-meet>` custom element in your HTML, setting the `room-url` attribute.

Info

Check out the [Web Component reference](../reference/webcomponent/) for the complete list of attributes, commands and events offered by it.

```html
<html>
    <head>
        <title>My meeting</title>
        <script src="https://{{ your-openvidu-deployment-domain }}/v1/openvidu-meet.js"></script>
    </head>
    <body>
        <div>
            <openvidu-meet room-url="{{ your-room-url }}"></openvidu-meet>
        </div>
    </body>
</html>
```

### Use an iframe

Some applications may not allow including a Web Component. For these cases OpenVidu Meet can be embedded using a traditional iframe.

```html
<html>
    <head>
        <title>My meeting</title>
    </head>
    <body>
        <div>
            <iframe
                src="{{ your-room-url }}"
                allow="camera; microphone; display-capture; fullscreen; autoplay; compute-pressure;"
                width="100%" height="100%">
            </iframe>
        </div>
    </body>
</html>
```

The required iframe attributes are:

- `src`: the room URL.
- `allow`: the minimum permissions required by the iframe for the room to work fine. These are:
  - `camera`: allow access to the camera.
  - `microphone`: allow access to the microphone.
  - `display-capture`: allow screen sharing.
  - `fullscreen`: allow full screen mode.
  - `autoplay`: allow autoplay of media.
  - `compute-pressure`: allow access to the device's compute pressure API.

Info

The same **attributes**, **commands** and **events** available for the Web Component may also be used in an iframe. Check out these sections to learn how:

- [Pass attributes to an OpenVidu Meet iframe](../reference/iframe/#attributes)
- [Send commands to an OpenVidu Meet iframe](../reference/iframe/#commands)
- [Receive events from an OpenVidu Meet iframe](../reference/iframe/#events)

## 5. Embed recordings into your application

If your use case includes recording your rooms, you can also embed them right into your app. You can embed the list of recordings of a room or directly show the player for a specific recording.

### Embed the list of recordings of a room

To show the list of recordings of a room, declare attribute **`show-only-recordings`** in the embedding element:

```html
<openvidu-meet room-url="{{ your-room-url }}" show-only-recordings="true"></openvidu-meet>
```

Info

Checkout the Web Component's [attributes](../reference/webcomponent/#attributes) section for more information.

This will show the list of recordings for the specified room:

### Embed the player for a specific recording

To show the player for a specific recording, replace attribute `room-url` with **`recording-url`** in the embedding element. The recording URL can be obtained from:

- [OpenVidu Meet console](../../features/recordings/#sharing-recordings-via-link)
- [Programmatically via REST API](../../embedded/reference/api.html#/operations/getRecordingUrl)

```html
<openvidu-meet recording-url="{{ your-recording-url }}"></openvidu-meet>
```

Info

Checkout the Web Component's [attributes](../reference/webcomponent/#attributes) section for more information.

This will show the player for the specified recording:

## 6. REST API and Webhooks

Up to this point everything has been focused on the client-side integration of OpenVidu Meet. To integrate OpenVidu Meet into your application's backend you have available:

- [REST API](../reference/rest-api/): manage rooms and recordings programmatically.
- [Webhooks](../reference/webhooks/): listen to events happening in real time.

# OpenVidu Meet Direct Link Tutorial

[Source code](https://github.com/OpenVidu/openvidu-meet-tutorials/tree/3.4.1/meet-direct-link)

This tutorial is a simple example of how to integrate **OpenVidu Meet** into a **Node.js** application by easily using a direct link. It is built using **Node.js and Express** for the backend and plain **HTML/CSS/JavaScript** for the frontend.

At the end of this tutorial, you will have a fully functional simple video-call application with the following features:

- Users can create rooms.
- Users can delete rooms.
- Users can join a room as moderator or speaker.
- Users can chat with other users.
- Users may leave the room at any time.
- Users can view the recordings of the meeting.
- Moderators can record the meeting.
- Moderators may end the meeting at any time, disconnecting all users.

The application uses the [OpenVidu Meet API](../../reference/rest-api/) to create and delete rooms, and direct links to the **OpenVidu Meet interface** to access the video call functionality.

## Running this tutorial

#### 1. Run OpenVidu Meet

You need **Docker Desktop**. You can install it on [Windows](https://docs.docker.com/desktop/setup/install/windows-install/) , [Mac](https://docs.docker.com/desktop/setup/install/mac-install/) or [Linux](http://docs.docker.com/desktop/setup/install/linux/) .

Run this command in Docker Desktop's terminal:

```bash
docker compose -p openvidu-meet -f oci://openvidu/local-meet:3.4.1 up -y openvidu-meet-init
```

Info

For a detailed guide on how to run OpenVidu Meet locally, visit [Try OpenVidu Meet locally](../../../deployment/local/) .

### 2. Download the tutorial code

```bash
git clone https://github.com/OpenVidu/openvidu-meet-tutorials.git -b 3.4.1
```

### 3. Run the application

To run this application, you need [Node.js](https://nodejs.org/en/download) installed on your device.

1. Navigate into the application directory

```bash
cd openvidu-meet-tutorials/meet-direct-link
```

1. Install dependencies

```bash
npm install
```

1. Run the application

```bash
npm start
```

Once the server is up and running, you can test the application by visiting [`http://localhost:6080`](http://localhost:6080). You should see a screen like this:

## Understanding the code

This application is designed to be beginner-friendly and consists of one essential backend file under the `src` directory:

- `index.js`: This file holds the server application and defines the REST API endpoints.

And the following essential frontend files under the `public` directory:

- `index.html`: This is the client application's main HTML file.
- `app.js`: This is the main JavaScript file that interacts with the server application and handles the client application's logic and functionality.
- `style.css`: This file contains the client application's styling.

______________________________________________________________________

### Backend

The server application is a simple Express app with a single file `index.js` that exports three endpoints:

- **`POST /rooms`**: Create a new room with the given room name.
- **`GET /rooms`**: Get the list of rooms.
- **`DELETE /rooms/:roomId`**: Delete a room with the given room ID.

Let's see the code of the `index.js` file:

```javascript
import bodyParser from 'body-parser';
import cors from 'cors';
import dotenv from 'dotenv';
import express from 'express';
import path from 'path';
import { fileURLToPath } from 'url';

dotenv.config(); // (1)!

// Configuration
const SERVER_PORT = process.env.SERVER_PORT || 6080; // (2)!
const OV_MEET_SERVER_URL = process.env.OV_MEET_SERVER_URL || 'http://localhost:9080'; // (3)!
const OV_MEET_API_KEY = process.env.OV_MEET_API_KEY || 'meet-api-key'; // (4)!

const app = express(); // (5)!

app.use(cors()); // (6)!
app.use(express.json()); // (7)!
app.use(bodyParser.urlencoded({ extended: true }));

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
app.use(express.static(path.join(__dirname, '../public'))); // (8)!
```

1. Load environment variables from `.env` file.
1. The port where the application will be listening.
1. The OpenVidu Meet server URL.
1. The OpenVidu Meet API key.
1. Initialize the Express application.
1. Enable CORS support.
1. Enable JSON body parsing.
1. Serve static files from the `public` directory.

The `index.js` file imports the required dependencies and loads the necessary environment variables:

- `SERVER_PORT`: The port where the application will be listening.
- `OV_MEET_SERVER_URL`: The OpenVidu Meet server URL.
- `OV_MEET_API_KEY`: The OpenVidu Meet API key.

Then the `express` application is initialized. CORS is allowed, JSON body parsing is enabled, and static files are served from the `public` directory.

Now let's see the code of each endpoint:

______________________________________________________________________

#### Create room

The `POST /rooms` endpoint creates a new room. It receives the room name as a body parameter and returns the newly created room:

```javascript
// Create a new room
app.post('/rooms', async (req, res) => {
    const { roomName } = req.body; // (1)!

    if (!roomName) {
        res.status(400).json({ message: `'roomName' is required` }); // (2)!
        return;
    }

    try {
        // Create a new OpenVidu Meet room using the API
        const room = await httpRequest('POST', 'rooms', {
            roomName, // (3)!
            config: {
                // (4)!
                // Default room configuration
                chat: {
                    enabled: true // Enable chat for this room
                },
                recording: {
                    enabled: true, // Enable recording for this room
                    allowAccessTo: 'admin_moderator_speaker' // Allow access to recordings for admin, moderator and speaker roles
                },
                virtualBackground: {
                    enabled: true // Enable virtual background for this room
                }
            }
        });

        console.log('Room created:', room);
        res.status(201).json({ message: `Room '${roomName}' created successfully`, room }); // (5)!
    } catch (error) {
        handleApiError(res, error, `Error creating room '${roomName}'`); // (6)!
    }
});
```

1. The `roomName` parameter is obtained from the request body.
1. If the `roomName` is not provided, the server returns a `400 Bad Request` response.
1. Specify the name of the room.
1. Set the configuration for the room, enabling chat, recording and virtual background.
1. The server returns a `201 Created` response with the room object.
1. If an error occurs during room creation, it is handled by the `handleApiError` function.

This endpoint does the following:

1. The `roomName` parameter is obtained from the request body. If it is not provided, the server returns a `400 Bad Request` response.

1. A new room is created using the OpenVidu Meet API by sending a `POST` request to the `rooms` endpoint. The request includes the room name and additional configuration options (with default values):

   - **Chat Configuration**: Enables chat functionality for the room.
   - **Recording Configuration**: Enables recording for the room and allows access to recordings for the roles `admin`, `moderator` and `speaker`.
   - **Virtual Background Configuration**: Enables virtual background functionality for the room.

   Info

   The reference for the room configuration options can be found in the [OpenVidu Meet REST API reference](../../../assets/htmls/rest-api.html#/operations/createRoom) .

   To send requests to the OpenVidu Meet API, we use the `httpRequest` function:

   ```javascript
   // Function to make HTTP requests to OpenVidu Meet API
   const httpRequest = async (method, path, body) => {
       // (1)!
       const response = await fetch(`${OV_MEET_SERVER_URL}/api/v1/${path}`, {
           method,
           headers: {
               'Content-Type': 'application/json',
               'X-API-KEY': OV_MEET_API_KEY // Include the API key in the header for authentication
           },
           body: body ? JSON.stringify(body) : undefined // (2)!
       });

       const responseBody = await response.json(); // (3)!

       if (!response.ok) {
           console.error('Error while performing request to OpenVidu Meet API:', responseBody);
           // Create an error object that includes the HTTP status code from the API
           const error = new Error(responseBody.message || 'Failed to perform request to OpenVidu Meet API');
           error.statusCode = response.status;
           throw error; // (4)!
       }

       return responseBody; // (5)!
   };
   ```

   1. Perform an HTTP request to the OpenVidu Meet API in the specified method and path.
   1. Include the body in the request if provided.
   1. Parse the response body as JSON.
   1. If the response is not OK, throw an error with the message and status code from the response.
   1. Return the response body.

   This function makes HTTP requests to the OpenVidu Meet API using the `fetch` function. It receives the HTTP method, path and body as parameters. The API key is included in the request headers for authentication.

   It parses the response body as JSON and checks if the response is OK. If not, it throws an error with the message and status code from the response.

1. If the room is successfully created, the server returns a `201 Created` response with the room object. Otherwise, the error is handled by the `handleApiError` function, which logs the error and returns an appropriate HTTP response:

   ```javascript
   // Helper function to handle API errors consistently
   const handleApiError = (res, error, message) => {
       console.error(`${message}: ${error.message}`); // (1)!
       const statusCode = error.statusCode || 500; // (2)!
       const errorMessage = error.statusCode ? error.message : message; // (3)!
       res.status(statusCode).json({ message: errorMessage }); // (4)!
   };
   ```

   1. Log the error message to the console.
   1. Get the status code from the error object or default to `500 Internal Server Error`.
   1. Determine the error message to return based on whether the error has a status code.
   1. Return an HTTP response with the appropriate status code and error message.

______________________________________________________________________

#### List rooms

The `GET /rooms` endpoint retrieves the list of all rooms created in OpenVidu Meet:

```javascript
// List all rooms
app.get('/rooms', (_req, res) => {
    try {
        // List all OpenVidu Meet rooms using the API (100 max)
        const { rooms } = await httpRequest('GET', 'rooms?maxItems=100'); // (1)!
        res.status(200).json({ rooms }); // (2)!
    } catch (error) {
        handleApiError(res, error, 'Error fetching rooms');
    }
});
```

1. Make a `GET` request to the `rooms` endpoint of the OpenVidu Meet API to retrieve the list of rooms (with a maximum of 100 rooms).
1. The server returns a `200 OK` response with the list of rooms.

This endpoint retrieves the list of rooms by making a `GET` request to the `rooms` endpoint (with a maximum of 100 rooms by setting the `maxItems` query parameter) of the OpenVidu Meet API using the `httpRequest` function. If the request is successful, the server returns a `200 OK` response with the list of rooms. Otherwise, the error is handled by the `handleApiError` function.

______________________________________________________________________

#### Delete room

The `DELETE /room/:roomId` endpoint deletes the specified room:

```javascript
app.delete('/rooms/:roomId', async (req, res) => {
    const { roomId } = req.params; // (1)!

    try {
        // Delete the OpenVidu Meet room using the API
        await httpRequest('DELETE', `rooms/${roomId}`); // (2)!
        res.status(200).json({ message: `Room '${roomId}' deleted successfully` }); // (3)!
    } catch (error) {
        handleApiError(res, error, `Error deleting room '${roomId}'`);
    }
});
```

1. The `roomId` parameter is obtained from the request parameters.
1. The room is deleted using the OpenVidu Meet API by sending a `DELETE` request to the `rooms/:roomId` endpoint.
1. The server returns a `200 OK` response with a success message.

This endpoint does the following:

1. The `roomId` parameter is obtained from the request parameters.
1. The room is deleted using the OpenVidu Meet API by sending a `DELETE` request to the `rooms/:roomId` endpoint.
1. If the room is successfully deleted, the server returns a `200 OK` response with a success message. Otherwise, the error is handled by the `handleApiError` function.

______________________________________________________________________

### Frontend

The client application consists of only three essential files that are located in the `public` directory:

- `app.js`: This is the main JavaScript file for the sample application. It contains the logic for listing, creating, joining and deleting rooms.
- `index.html`: This HTML file is responsible for creating the user interface. It contains the list of created rooms, and a form to create a new room.
- `styles.css`: This file contains CSS classes that are used to style the `index.html` page.

Now let's see the code of the `app.js` file grouped by sections:

______________________________________________________________________

#### Listing rooms

The list of rooms is displayed in the `index.html` file as soon as the page loads. This is done by calling the `fetchRooms()` function, which fetches the list of rooms from the server and updates the UI accordingly.

```javascript
const rooms = new Map(); // (1)!

document.addEventListener('DOMContentLoaded', async () => {
    await fetchRooms(); // (2)!
});

async function fetchRooms() {
    try {
        const { rooms: roomsList } = await httpRequest('GET', '/rooms'); // (3)!

        roomsList.forEach((room) => {
            rooms.set(room.roomId, room); // (4)!
        });
        renderRooms(); // (5)!
    } catch (error) {
        console.error('Error fetching rooms:', error.message);

        // Show error message
        const roomsErrorElement = document.querySelector('#no-rooms-or-error');
        roomsErrorElement.textContent = 'Error loading rooms';
        roomsErrorElement.hidden = false;
    }
}
```

1. Create a map to store the rooms.
1. When the DOM content is loaded, call the `fetchRooms()` function to fetch the list of rooms from the server.
1. Make a `GET` request to the `/rooms` endpoint to fetch the list of rooms.
1. For each room in the list, add it to the `rooms` map.
1. Call the `renderRooms()` function to display the list of rooms.

The `fetchRooms()` function performs the following actions:

1. Makes a `GET` request to the `/rooms` endpoint to fetch the list of rooms.

   To send requests to the backend, we use the `httpRequest` function:

   ```javascript
   // Function to make HTTP requests to the backend
   async function httpRequest(method, path, body) {
       // (1)!
       const response = await fetch(path, {
           method,
           headers: {
               'Content-Type': 'application/json'
           },
           body: body ? JSON.stringify(body) : undefined // (2)!
       });

       const responseBody = await response.json(); // (3)!

       if (!response.ok) {
           throw new Error(responseBody.message || 'Failed to perform request to backend'); // (4)!
       }

       return responseBody; // (5)!
   }
   ```

   1. Perform an HTTP request to the backend in the specified method and path.
   1. Include the body in the request if provided.
   1. Parse the response body as JSON.
   1. If the response is not OK, throw an error with the message from the response.
   1. Return the response body.

   This function makes HTTP requests to the server API using the `fetch` function. It receives the HTTP method, path and body as parameters. Then, it parses the response body as JSON and checks if the response is OK. If not, it throws an error with the message from the response.

1. For each room in the list, it adds the room to the `rooms` map. This map is used to store the rooms indexed by their IDs to make it easier to access them later.

1. Calls the `renderRooms()` function to display the list of rooms.

1. If an error occurs during the request, it logs the error and displays an appropriate error message.

The `renderRooms()` function is responsible for updating the UI with the list of rooms:

```javascript
function renderRooms() {
    // Clear the previous list of rooms
    const roomsList = document.querySelector('#rooms-list ul'); // (1)!
    roomsList.innerHTML = ''; // (2)!

    // Show or remove the "No rooms found" message
    const noRoomsElement = document.querySelector('#no-rooms-or-error');
    if (rooms.size === 0) {
        noRoomsElement.textContent = 'No rooms found. Please create a new room.';
        noRoomsElement.hidden = false;
        return;
    } else {
        noRoomsElement.textContent = '';
        noRoomsElement.hidden = true;
    }

    // Add rooms to the list element
    Array.from(rooms.values()).forEach((room) => {
        const roomItem = getRoomListItemTemplate(room); // (3)!
        roomsList.innerHTML += roomItem; // (4)!
    });
}

function getRoomListItemTemplate(room) {
    return `
        <li class="list-group-item">
            <span>${room.roomName}</span>
            <div class="room-actions">
                <a
                    class="btn btn-primary btn-sm"
                    href="${room.moderatorUrl}"
                >
                    Join as Moderator
                </a>
                <a
                    class="btn btn-secondary btn-sm"
                    href="${room.speakerUrl}"
                >
                    Join as Speaker
                </a>
                <button 
                    title="Delete room"
                    class="icon-button delete-button"
                    onclick="deleteRoom('${room.roomId}');"
                >
                    <i class="fa-solid fa-trash"></i>
                </button>
            </div>
        </li>
    `;
}
```

1. Get the `ul` element where the list of rooms will be displayed.
1. Clear the previous list of rooms.
1. For each room, get the HTML template for the room list item.
1. Append the room item to the list element.

The `renderRooms()` function performs the following actions:

1. Clears the previous list of rooms by getting the `ul` element and setting its inner HTML to an empty string.
1. Checks if there are any rooms in the `rooms` map. If there are no rooms, it shows a message indicating that no rooms were found. Otherwise, it hides the message.
1. For each room in the `rooms` map, it calls the `getRoomListItemTemplate()` function to get the HTML template for the room list item.
1. Appends the room item to the list element.

The `getRoomListItemTemplate()` function generates the HTML template for each room list item. It includes anchor links to join the room as a moderator or speaker using direct URLs, and a button to delete the room. The anchor links use the `moderatorUrl` and `speakerUrl` properties from the room object to redirect users directly to the OpenVidu Meet interface, while the delete button calls the `deleteRoom()` function passing the room ID to remove the room from the server.

______________________________________________________________________

#### Creating a room

After the user specifies the room name and clicks the `Create Room` button, the `createRoom()` function is called:

```javascript
async function createRoom() {
    // Clear previous error message
    const errorDiv = document.querySelector('#create-room-error');
    errorDiv.textContent = '';
    errorDiv.hidden = true;

    try {
        const roomName = document.querySelector('#room-name').value; // (1)!

        const { room } = await httpRequest('POST', '/rooms', {
            roomName
        }); // (2)!

        // Add new room to the list
        rooms.set(room.roomId, room); // (3)!
        renderRooms(); // (4)!

        // Reset the form
        const createRoomForm = document.querySelector('#create-room form');
        createRoomForm.reset(); // (5)!
    } catch (error) {
        console.error('Error creating room:', error.message);

        // Show error message
        errorDiv.textContent = 'Error creating room';
        errorDiv.hidden = false;
    }
}
```

1. Get the room name from the input field.
1. Make a `POST` request to the `/rooms` endpoint to create a new room with the specified name.
1. Add the new room to the `rooms` map.
1. Call the `renderRooms()` function to update the list of rooms.
1. Reset the form to clear the input field.

The `createRoom()` function performs the following actions:

1. Clears any previous error messages.
1. Gets the room name from the input field.
1. Makes a `POST` request to the `/rooms` endpoint to create a new room with the specified name.
1. If the room is successfully created, it adds the new room to the `rooms` map and calls the `renderRooms()` function to update the list of rooms.
1. Resets the form to clear the input field.
1. If an error occurs during room creation, it logs the error and displays an appropriate error message.

______________________________________________________________________

#### Deleting a room

When the user clicks the delete room button, the `deleteRoom()` function is called:

```javascript
async function deleteRoom(roomId) {
    try {
        await httpRequest('DELETE', `/rooms/${roomId}`); // (1)!

        // Remove the room from the list
        rooms.delete(roomId); // (2)!
        renderRooms(); // (3)!
    } catch (error) {
        console.error('Error deleting room:', error.message);
    }
}
```

1. Make a `DELETE` request to the `/rooms/:roomId` endpoint to delete the specified room.
1. Remove the room from the `rooms` map.
1. Call the `renderRooms()` function to update the list of rooms.

The `deleteRoom()` function simply makes a `DELETE` request to the `/rooms/:roomId` endpoint to delete the specified room. If the room is successfully deleted, it removes the room from the `rooms` map and calls the `renderRooms()` function to update the list of rooms. If an error occurs during room deletion, it logs the error to the console.

## Accessing this tutorial from other computers or phones

To access this tutorial from other computers or phones, follow these steps:

1. **Ensure network connectivity**: Make sure your device (computer or phone) is connected to the same network as the machine running OpenVidu Meet and this tutorial.

1. **Configure OpenVidu Meet for network access**: Start OpenVidu Meet by following the instructions in the [Accessing OpenVidu Meet from other computers or phones](../../../deployment/local/#accessing-openvidu-meet-from-other-computers-or-phones) section.

1. **Update the OpenVidu Meet server URL**: Modify the `OV_MEET_SERVER_URL` environment variable in your `.env` file to match the URL shown when OpenVidu Meet starts.

   ```text
   # Example for IP address 192.168.1.100
   OV_MEET_SERVER_URL=https://192-168-1-100.openvidu-local.dev:9443
   ```

1. **Restart the tutorial** to apply the changes:

   ```bash
   npm start
   ```

1. **Access the tutorial**: Open your browser and navigate to `https://192-168-1-100.openvidu-local.dev:6443` (replacing `192-168-1-100` with your actual private IP) on the computer where you started the tutorial or any device in the same network.

## Connecting this tutorial to an OpenVidu Meet production deployment

If you have a production deployment of OpenVidu Meet (installed in a server following [deployment steps](../../../deployment/basic/) ), you can connect this tutorial to it by following these steps:

1. **Update the server URL**: Modify the `OV_MEET_SERVER_URL` environment variable in the `.env` file to point to your OpenVidu Meet production deployment URL.

   ```text
   # Example for a production deployment
   OV_MEET_SERVER_URL=https://your-openvidu-meet-domain.com
   ```

1. **Update the API key**: Ensure the `OV_MEET_API_KEY` environment variable in the `.env` file matches the API key configured in your production deployment. See [Generate an API Key](../../reference/rest-api/#generate-an-api-key) section to learn how to obtain it.

   ```text
   OV_MEET_API_KEY=your-production-api-key
   ```

1. **Restart the tutorial** to apply the changes:

   ```bash
   npm start
   ```

Make this tutorial accessible from other computers or phones

By default, this tutorial runs on `http://localhost:6080` and is only accessible from the local machine. If you want to access it from other computers or phones, you have the following options:

- **Use tunneling tools**: Configure tools like [VS Code port forwarding](https://code.visualstudio.com/docs/debugtest/port-forwarding) , [ngrok](https://ngrok.com/) , [localtunnel](https://localtunnel.github.io/www/) , or similar services to expose this tutorial to the internet. You can use HTTP or HTTPS URLs.
- **Deploy to a server**: Upload this tutorial to a web server. You can use HTTP or HTTPS URLs.

# OpenVidu Meet WebComponent Tutorial

[Source code](https://github.com/OpenVidu/openvidu-meet-tutorials/tree/3.4.1/meet-webcomponent-basic)

This tutorial extends the [Direct Link tutorial](../direct-link/) by integrating the **OpenVidu Meet WebComponent** directly into your application instead of using external links. It is built using **Node.js and Express** for the backend and plain **HTML/CSS/JavaScript** for the frontend.

At the end of this tutorial, you will have a fully functional simple video-call application with the following features:

- Users can create rooms.
- Users can delete rooms.
- Users can join a room as moderator or speaker.
- Users can chat with other users.
- Users may leave the room at any time.
- Users can view the recordings of the meeting.
- Moderators can record the meeting.
- Moderators may end the meeting at any time, disconnecting all users.

The application uses the [OpenVidu Meet API](../../reference/rest-api/) to create and delete rooms, and the [OpenVidu Meet WebComponent](../../reference/webcomponent/) to embed the video call interface directly into the application.

## Running this tutorial

#### 1. Run OpenVidu Meet

You need **Docker Desktop**. You can install it on [Windows](https://docs.docker.com/desktop/setup/install/windows-install/) , [Mac](https://docs.docker.com/desktop/setup/install/mac-install/) or [Linux](http://docs.docker.com/desktop/setup/install/linux/) .

Run this command in Docker Desktop's terminal:

```bash
docker compose -p openvidu-meet -f oci://openvidu/local-meet:3.4.1 up -y openvidu-meet-init
```

Info

For a detailed guide on how to run OpenVidu Meet locally, visit [Try OpenVidu Meet locally](../../../deployment/local/) .

### 2. Download the tutorial code

```bash
git clone https://github.com/OpenVidu/openvidu-meet-tutorials.git -b 3.4.1
```

### 3. Run the application

To run this application, you need [Node.js](https://nodejs.org/en/download) installed on your device.

1. Navigate into the application directory

```bash
cd openvidu-meet-tutorials/meet-webcomponent-basic
```

1. Install dependencies

```bash
npm install
```

1. Run the application

```bash
npm start
```

Once the server is up and running, you can test the application by visiting [`http://localhost:6080`](http://localhost:6080). You should see a screen like this:

## Understanding the code

This tutorial builds upon the [Direct Link tutorial](../direct-link/), replacing external redirect links with an embedded OpenVidu Meet WebComponent. The backend remains identical, so we'll focus on the frontend modifications that enable WebComponent integration.

______________________________________________________________________

### Backend

The backend is identical to the [Direct Link tutorial](../direct-link/). It provides the same three REST API endpoints:

- **`POST /rooms`**: Create a new room with the given room name.
- **`GET /rooms`**: Get the list of rooms.
- **`DELETE /rooms/:roomId`**: Delete a room with the given room ID.

For detailed backend documentation, please refer to the [Direct Link tutorial backend section](../direct-link/#backend).

______________________________________________________________________

### Frontend modifications

The main changes in the frontend involve replacing direct links with embedded WebComponent functionality. The key modifications are in the `public/js/app.js` and `public/index.html` files.

#### Including the OpenVidu Meet WebComponent

To use the OpenVidu Meet WebComponent in your application, you need to include it in your HTML file by adding a script tag to the end of the `<body>` section:

```html
<!-- OpenVidu Meet WebComponent bundle -->
<script src="http://localhost:9080/v1/openvidu-meet.js"></script>
```

______________________________________________________________________

#### Enhanced room list template

The room list template has been modified to use buttons instead of direct links, enabling WebComponent integration:

```javascript
function getRoomListItemTemplate(room) {
    return `
        <li class="list-group-item">
            <span>${room.roomName}</span>
            <div class="room-actions">
                <button
                    class="btn btn-primary btn-sm"
                    onclick="joinRoom('${room.moderatorUrl}');"
                >
                    Join as Moderator
                </button>
                <button
                    class="btn btn-secondary btn-sm"
                    onclick="joinRoom('${room.speakerUrl}');"
                >
                    Join as Speaker
                </button>
                <button 
                    title="Delete room"
                    class="icon-button delete-button"
                    onclick="deleteRoom('${room.roomId}');"
                >
                    <i class="fa-solid fa-trash"></i>
                </button>
            </div>
        </li>
    `;
}
```

The key difference from the Direct Link tutorial is that instead of using anchor tags (`<a>`) with `href` attributes pointing to external URLs, this template uses buttons that call the `joinRoom()` function with the appropriate room URL.

______________________________________________________________________

#### Joining a room with WebComponent

When the user clicks the `Join as Moderator` or `Join as Speaker` button, the `joinRoom()` function is called, which handles embedding the OpenVidu Meet WebComponent:

```javascript
function joinRoom(roomUrl) {
    // Hide the home screen and show the room screen
    const homeScreen = document.querySelector('#home');
    homeScreen.hidden = true; // (1)!
    const roomScreen = document.querySelector('#room');
    roomScreen.hidden = false; // (2)!

    // Inject the OpenVidu Meet component into the meeting container specifying the room URL
    const meetingContainer = document.querySelector('#meeting-container');
    meetingContainer.innerHTML = `
        <openvidu-meet 
            room-url="${roomUrl}"
            leave-redirect-url="/"
        >
        </openvidu-meet>
    `; // (3)!
}
```

1. Hide the home screen to prepare for the meeting view.
1. Show the room screen where the WebComponent will be embedded.
1. Inject the OpenVidu Meet WebComponent into the meeting container with the specified room URL and a leave redirect URL.

The `joinRoom()` function hides the home screen and shows the room screen to provide a dedicated space for the video meeting. Then, it dynamically creates and injects the `<openvidu-meet>` WebComponent into the meeting container, setting the `room-url` attribute with the URL provided by the OpenVidu Meet API and configuring the `leave-redirect-url` attribute to return users to the home screen when they leave the meeting.

This approach provides a seamless user experience by keeping users within the same application while providing full video conferencing functionality through the embedded WebComponent.

## Accessing this tutorial from other computers or phones

To access this tutorial from other computers or phones, follow these steps:

1. **Ensure network connectivity**: Make sure your device (computer or phone) is connected to the same network as the machine running OpenVidu Meet and this tutorial.

1. **Configure OpenVidu Meet for network access**: Start OpenVidu Meet by following the instructions in the [Accessing OpenVidu Meet from other computers or phones](../../../deployment/local/#accessing-openvidu-meet-from-other-computers-or-phones) section.

1. **Update the OpenVidu Meet server URL**: Modify the `OV_MEET_SERVER_URL` environment variable in your `.env` file to match the URL shown when OpenVidu Meet starts.

   ```text
   # Example for IP address 192.168.1.100
   OV_MEET_SERVER_URL=https://192-168-1-100.openvidu-local.dev:9443
   ```

1. **Update the OpenVidu Meet WebComponent script URL**: In the `public/index.html` file, update the `<script>` tag that includes the OpenVidu Meet WebComponent to use the same base URL as above.

   ```html
   <script src="http://192-168-1-100.openvidu-local.dev:9443/v1/openvidu-meet.js"></script>
   ```

1. **Restart the tutorial** to apply the changes:

   ```bash
   npm start
   ```

1. **Access the tutorial**: Open your browser and navigate to `https://192-168-1-100.openvidu-local.dev:6443` (replacing `192-168-1-100` with your actual private IP) on the computer where you started the tutorial or any device in the same network.

## Connecting this tutorial to an OpenVidu Meet production deployment

If you have a production deployment of OpenVidu Meet (installed in a server following [deployment steps](../../../deployment/basic/) ), you can connect this tutorial to it by following these steps:

1. **Update the server URL**: Modify the `OV_MEET_SERVER_URL` environment variable in the `.env` file to point to your OpenVidu Meet production deployment URL.

   ```text
   # Example for a production deployment
   OV_MEET_SERVER_URL=https://your-openvidu-meet-domain.com
   ```

1. **Update the API key**: Ensure the `OV_MEET_API_KEY` environment variable in the `.env` file matches the API key configured in your production deployment. See [Generate an API Key](../../reference/rest-api/#generate-an-api-key) section to learn how to obtain it.

   ```text
   OV_MEET_API_KEY=your-production-api-key
   ```

1. **Update the OpenVidu Meet WebComponent script URL**: In the `public/index.html` file, update the `<script>` tag that includes the OpenVidu Meet WebComponent to use the same base URL as above.

   ```html
   <script src="https://your-openvidu-meet-domain.com/v1/openvidu-meet.js"></script>
   ```

1. **Restart the tutorial** to apply the changes:

   ```bash
   npm start
   ```

Make this tutorial accessible from other computers or phones

By default, this tutorial runs on `http://localhost:6080` and is only accessible from the local machine. If you want to access it from other computers or phones, you have the following options:

- **Use tunneling tools**: Configure tools like [VS Code port forwarding](https://code.visualstudio.com/docs/debugtest/port-forwarding) , [ngrok](https://ngrok.com/) , [localtunnel](https://localtunnel.github.io/www/) , or similar services to expose this tutorial to the internet with a secure (HTTPS) public URL.
- **Deploy to a server**: Upload this tutorial to a web server and configure it to be accessible with a secure (HTTPS) public URL. This can be done by updating the source code to manage SSL certificates or configuring a reverse proxy (e.g., Nginx, Apache) to serve it.

# OpenVidu Meet WebComponent Commands & Events Tutorial

[Source code](https://github.com/OpenVidu/openvidu-meet-tutorials/tree/3.4.1/meet-webcomponent-commands-events)

This tutorial extends the [basic WebComponent tutorial](../webcomponent/) to add **advanced WebComponent functionality** through commands and event handling. It demonstrates how to interact with the OpenVidu Meet WebComponent programmatically and respond to meeting events.

The application includes all the features from the basic WebComponent tutorial, plus:

- **WebComponent commands**: Control the meeting programmatically (e.g., end meeting for moderators).
- **Event handling**: Listen to and respond to WebComponent events (joined, left, closed).
- **Role-based UI**: Display different interface elements based on user role (moderator/speaker).
- **Meeting header**: Show room information and controls above the WebComponent.
- **Enhanced room management**: In-memory room tracking with unique names per room.

## Running this tutorial

#### 1. Run OpenVidu Meet

You need **Docker Desktop**. You can install it on [Windows](https://docs.docker.com/desktop/setup/install/windows-install/) , [Mac](https://docs.docker.com/desktop/setup/install/mac-install/) or [Linux](http://docs.docker.com/desktop/setup/install/linux/) .

Run this command in Docker Desktop's terminal:

```bash
docker compose -p openvidu-meet -f oci://openvidu/local-meet:3.4.1 up -y openvidu-meet-init
```

Info

For a detailed guide on how to run OpenVidu Meet locally, visit [Try OpenVidu Meet locally](../../../deployment/local/) .

### 2. Download the tutorial code

```bash
git clone https://github.com/OpenVidu/openvidu-meet-tutorials.git -b 3.4.1
```

### 3. Run the application

To run this application, you need [Node.js](https://nodejs.org/en/download) installed on your device.

1. Navigate into the application directory

```bash
cd openvidu-meet-tutorials/meet-webcomponent-commands-events
```

1. Install dependencies

```bash
npm install
```

1. Run the application

```bash
npm start
```

Once the server is up and running, you can test the application by visiting [`http://localhost:6080`](http://localhost:6080). You should see a screen like this:

## Understanding the code

This tutorial builds upon the [basic WebComponent tutorial](../webcomponent/), adding advanced WebComponent interaction capabilities and enhanced room management. We'll focus on the key differences and new functionality.

______________________________________________________________________

### Backend

The backend is identical to previous tutorials. It provides the same three REST API endpoints:

- **`POST /rooms`**: Create a new room with the given room name.
- **`GET /rooms`**: Get the list of rooms.
- **`DELETE /rooms/:roomId`**: Delete a room with the given room ID.

For detailed backend documentation, please refer to the [Direct Link tutorial backend section](../direct-link/#backend).

______________________________________________________________________

### Frontend modifications

The frontend changes focus on enhanced room management, WebComponent event handling, and role-based UI features.

#### Enhanced room template

The room template now passes additional parameters including role information:

```javascript
function getRoomListItemTemplate(room) {
    return `
        <li class="list-group-item">
            <span>${room.roomName}</span>
            <div class="room-actions">
                <button
                    class="btn btn-primary btn-sm"
                    onclick="joinRoom(
                        '${room.roomName}', 
                        '${room.moderatorUrl}', 
                        'moderator'
                    );"
                >
                    Join as Moderator
                </button>
                <button
                    class="btn btn-secondary btn-sm"
                    onclick="joinRoom(
                        '${room.roomName}', 
                        '${room.speakerUrl}', 
                        'speaker'
                    );"
                >
                    Join as Speaker
                </button>
                <button 
                    title="Delete room"
                    class="icon-button delete-button"
                    onclick="deleteRoom('${room.roomId}');"
                >
                    <i class="fa-solid fa-trash"></i>
                </button>
            </div>
        </li>
    `;
}
```

The template now provides the room name and user role to the `joinRoom()` function, enabling role-based functionality and proper room identification.

______________________________________________________________________

#### Advanced room joining with commands and events

The `joinRoom()` function has been significantly enhanced to handle WebComponent events and commands:

```javascript
function joinRoom(roomName, roomUrl, role) {
    console.log(`Joining room as ${role}`);

    // Hide the home screen and show the room screen
    const homeScreen = document.querySelector('#home');
    homeScreen.hidden = true; // (1)!
    const roomScreen = document.querySelector('#room');
    roomScreen.hidden = false; // (2)!

    // Hide the room header until the local participant joins
    const roomHeader = document.querySelector('#room-header');
    roomHeader.hidden = true; // (3)!

    // Inject the OpenVidu Meet component into the meeting container specifying the room URL
    const meetingContainer = document.querySelector('#meeting-container');
    meetingContainer.innerHTML = `
        <openvidu-meet 
            room-url="${roomUrl}"
        >
        </openvidu-meet>
    `; // (4)!

    // Add event listeners for the OpenVidu Meet component
    const meet = document.querySelector('openvidu-meet');

    // Event listener for when the local participant joins the room
    meet.once('joined', () => {
        // (5)!
        console.log('Local participant joined the room');

        // Show the room header with the room name
        roomHeader.hidden = false;
        const roomNameHeader = document.querySelector('#room-name-header');
        roomNameHeader.textContent = roomName; // (6)!

        // Show end meeting button only for moderators
        const endMeetingButton = document.querySelector('#end-meeting-btn');
        if (role === 'moderator') {
            endMeetingButton.hidden = false; // (7)!
        } else {
            endMeetingButton.hidden = true;
        }

        // Event listener for ending the meeting
        if (role === 'moderator') {
            endMeetingButton.addEventListener('click', () => {
                console.log('Ending meeting');
                meet.endMeeting(); // (8)!
            });
        }
    });

    // Event listener for when the local participant leaves the room
    meet.once('left', (event) => {
        // (9)!
        console.log('Local participant left the room. Reason:', event.reason);

        // Hide the room header
        roomHeader.hidden = true;
    });

    // Event listener for when the OpenVidu Meet component is closed
    meet.once('closed', () => {
        // (10)!
        console.log('OpenVidu Meet component closed');

        // Hide the room screen and show the home screen
        roomScreen.hidden = true;
        homeScreen.hidden = false;
    });
}
```

1. Hide the home screen.
1. Show the room screen.
1. Hide the room header until the local participant joins.
1. Inject the OpenVidu Meet WebComponent into the meeting container with the specified room URL.
1. Add an event listener for the `joined` event, which is triggered when the local participant joins the room.
1. Set the room name in the header.
1. Show the end meeting button if the user is a moderator.
1. Call the `endMeeting()` method of the OpenVidu Meet WebComponent to end the meeting when the moderator clicks the `End Meeting` button.
1. Add an event listener for the `left` event, which is triggered when the local participant leaves the room.
1. Add an event listener for the `closed` event, which is triggered when the OpenVidu Meet component is closed.

The enhanced `joinRoom()` function now performs the following actions:

1. Hides the home screen and shows the room screen.

1. Hides the room header until the local participant joins.

1. Injects the OpenVidu Meet WebComponent into the meeting container with the specified room URL.

1. Configures event listeners for the OpenVidu Meet WebComponent to handle different events:

   - **`joined`**: This event is triggered when the local participant joins the room. It shows the room header with the room name and displays the `End Meeting` button if the user is a moderator. It also adds an event listener for the `End Meeting` button to call the `endMeeting()` method of the OpenVidu Meet WebComponent to end the meeting. This method disconnects all participants and ends the meeting for everyone.
   - **`left`**: This event is triggered when the local participant leaves the room. It hides the room header.
   - **`closed`**: This event is triggered when the OpenVidu Meet component is closed. It hides the room screen and shows the home screen.

## Accessing this tutorial from other computers or phones

To access this tutorial from other computers or phones, follow these steps:

1. **Ensure network connectivity**: Make sure your device (computer or phone) is connected to the same network as the machine running OpenVidu Meet and this tutorial.

1. **Configure OpenVidu Meet for network access**: Start OpenVidu Meet by following the instructions in the [Accessing OpenVidu Meet from other computers or phones](../../../deployment/local/#accessing-openvidu-meet-from-other-computers-or-phones) section.

1. **Update the OpenVidu Meet server URL**: Modify the `OV_MEET_SERVER_URL` environment variable in your `.env` file to match the URL shown when OpenVidu Meet starts.

   ```text
   # Example for IP address 192.168.1.100
   OV_MEET_SERVER_URL=https://192-168-1-100.openvidu-local.dev:9443
   ```

1. **Update the OpenVidu Meet WebComponent script URL**: In the `public/index.html` file, update the `<script>` tag that includes the OpenVidu Meet WebComponent to use the same base URL as above.

   ```html
   <script src="http://192-168-1-100.openvidu-local.dev:9443/v1/openvidu-meet.js"></script>
   ```

1. **Restart the tutorial** to apply the changes:

   ```bash
   npm start
   ```

1. **Access the tutorial**: Open your browser and navigate to `https://192-168-1-100.openvidu-local.dev:6443` (replacing `192-168-1-100` with your actual private IP) on the computer where you started the tutorial or any device in the same network.

## Connecting this tutorial to an OpenVidu Meet production deployment

If you have a production deployment of OpenVidu Meet (installed in a server following [deployment steps](../../../deployment/basic/) ), you can connect this tutorial to it by following these steps:

1. **Update the server URL**: Modify the `OV_MEET_SERVER_URL` environment variable in the `.env` file to point to your OpenVidu Meet production deployment URL.

   ```text
   # Example for a production deployment
   OV_MEET_SERVER_URL=https://your-openvidu-meet-domain.com
   ```

1. **Update the API key**: Ensure the `OV_MEET_API_KEY` environment variable in the `.env` file matches the API key configured in your production deployment. See [Generate an API Key](../../reference/rest-api/#generate-an-api-key) section to learn how to obtain it.

   ```text
   OV_MEET_API_KEY=your-production-api-key
   ```

1. **Update the OpenVidu Meet WebComponent script URL**: In the `public/index.html` file, update the `<script>` tag that includes the OpenVidu Meet WebComponent to use the same base URL as above.

   ```html
   <script src="https://your-openvidu-meet-domain.com/v1/openvidu-meet.js"></script>
   ```

1. **Restart the tutorial** to apply the changes:

   ```bash
   npm start
   ```

Make this tutorial accessible from other computers or phones

By default, this tutorial runs on `http://localhost:6080` and is only accessible from the local machine. If you want to access it from other computers or phones, you have the following options:

- **Use tunneling tools**: Configure tools like [VS Code port forwarding](https://code.visualstudio.com/docs/debugtest/port-forwarding) , [ngrok](https://ngrok.com/) , [localtunnel](https://localtunnel.github.io/www/) , or similar services to expose this tutorial to the internet with a secure (HTTPS) public URL.
- **Deploy to a server**: Upload this tutorial to a web server and configure it to be accessible with a secure (HTTPS) public URL. This can be done by updating the source code to manage SSL certificates or configuring a reverse proxy (e.g., Nginx, Apache) to serve it.

# OpenVidu Meet Recordings Tutorial

[Source code](https://github.com/OpenVidu/openvidu-meet-tutorials/tree/3.4.1/meet-recordings)

This tutorial extends the [advanced OpenVidu Meet WebComponent tutorial](../webcomponent-advanced/) to add **recording management capabilities**. It demonstrates how to list, view, and delete recordings from your OpenVidu Meet meetings.

The application includes all the features from the basic tutorial, plus:

- **List recordings**: View all available recordings from past meetings, with optional filtering by room.
- **View recordings**: Play recordings directly in the browser using the OpenVidu Meet WebComponent.
- **Delete recordings**: Remove recordings from the server.

## Running this tutorial

#### 1. Run OpenVidu Meet

You need **Docker Desktop**. You can install it on [Windows](https://docs.docker.com/desktop/setup/install/windows-install/) , [Mac](https://docs.docker.com/desktop/setup/install/mac-install/) or [Linux](http://docs.docker.com/desktop/setup/install/linux/) .

Run this command in Docker Desktop's terminal:

```bash
docker compose -p openvidu-meet -f oci://openvidu/local-meet:3.4.1 up -y openvidu-meet-init
```

Info

For a detailed guide on how to run OpenVidu Meet locally, visit [Try OpenVidu Meet locally](../../../deployment/local/) .

### 2. Download the tutorial code

```bash
git clone https://github.com/OpenVidu/openvidu-meet-tutorials.git -b 3.4.1
```

### 3. Run the application

To run this application, you need [Node.js](https://nodejs.org/en/download) (≥ 18) installed on your device.

1. Navigate into the application directory

```bash
cd openvidu-meet-tutorials/meet-recordings
```

1. Install dependencies

```bash
npm install
```

1. Run the application

```bash
npm start
```

Once the server is up and running, you can test the application by visiting [`http://localhost:6080`](http://localhost:6080). You should see a screen like this:

## Understanding the code

This tutorial builds upon the [advanced OpenVidu Meet WebComponent tutorial](../webcomponent-advanced/), adding recording management functionality. We'll focus on the new features and modifications related to recordings.

______________________________________________________________________

### Backend modifications

The main changes to the backend involve adding new endpoints for recording management in the `src/index.js` file:

- **`GET /recordings`**: List all recordings, with optional filtering by room.
- **`DELETE /recordings/:recordingId`**: Delete a specific recording.
- **`GET /recordings/:recordingId/url`**: Get the playback URL for a specific recording.

Let's see the code of each new endpoint:

______________________________________________________________________

#### List recordings

The `GET /recordings` endpoint retrieves the list of recordings, with optional room filtering:

```javascript
// List all recordings
app.get('/recordings', async (req, res) => {
    // Create the base path for recordings, including maxItems parameter
    let recordingsPath = `recordings?maxItems=100`; // (1)!

    const { room: roomName } = req.query; // (2)!
    if (roomName) {
        // If a room is specified, filter recordings by room
        recordingsPath += `&roomId=${roomName}`; // (3)!
    }

    try {
        const { recordings } = await httpRequest('GET', recordingsPath); // (4)!
        res.status(200).json({ recordings }); // (5)!
    } catch (error) {
        handleApiError(res, error, 'Error fetching recordings');
    }
});
```

1. Create the base path for fetching recordings, including a `maxItems` parameter to limit the number of recordings returned to 100.
1. Extract optional room name from query parameters for filtering.
1. If a room name is provided, it appends the `roomId` parameter to the recordings path to filter recordings by that room.
1. Fetch recordings using the OpenVidu Meet API by sending a `GET` request to the constructed `recordingsPath`.
1. The server returns a `200 OK` response with the list of recordings in JSON format.

This endpoint does the following:

1. Creates the base path for fetching recordings, including a `maxItems` parameter to limit the number of recordings returned to 100.
1. Extracts an optional room name from the query parameters for filtering. If a room name is provided, it appends the `roomId` parameter to the recordings path to filter recordings by that room.
1. Fetches recordings using the OpenVidu Meet API by sending a `GET` request to the constructed `recordingsPath`.
1. If successful, it returns a `200 OK` response with the list of recordings in JSON format. Otherwise, the error is handled by the `handleApiError` function.

______________________________________________________________________

#### Delete recording

The `DELETE /recordings/:recordingId` endpoint deletes the specified recording:

```javascript
// Delete a recording
app.delete('/recordings/:recordingId', async (req, res) => {
    const { recordingId } = req.params; // (1)!

    try {
        // Delete the recording using OpenVidu Meet API
        await httpRequest('DELETE', `recordings/${recordingId}`); // (2)!
        res.status(200).json({ message: `Recording '${recordingId}' deleted successfully` }); // (3)!
    } catch (error) {
        handleApiError(res, error, `Error deleting recording '${recordingId}'`);
    }
});
```

1. The `recordingId` parameter is obtained from the request parameters.
1. The recording is deleted using the OpenVidu Meet API by sending a `DELETE` request to the `recordings/:recordingId` endpoint.
1. The server returns a `200 OK` response with a success message.

This endpoint simply deletes the specified recording using the OpenVidu Meet API by sending a `DELETE` request to the `recordings/:recordingId` endpoint. If the deletion is successful, it returns a `200 OK` response with a success message. Otherwise, the error is handled by the `handleApiError` function.

______________________________________________________________________

#### Get recording URL

A new `GET /recordings/:recordingId/url` endpoint retrieves the recording URL for playback:

```javascript
// Get recording URL
app.get('/recordings/:recordingId/url', async (req, res) => {
    const { recordingId } = req.params; // (1)!

    try {
        // Fetch the recording URL using OpenVidu Meet API
        const { url } = await httpRequest('GET', `recordings/${recordingId}/url`); // (2)!
        res.status(200).json({ url }); // (3)!
    } catch (error) {
        handleApiError(res, error, `Error fetching URL for recording '${recordingId}'`);
    }
});
```

1. The `recordingId` parameter is obtained from the request parameters.
1. Fetch the recording URL from the OpenVidu Meet API by sending a `GET` request to the `recordings/:recordingId/url` endpoint.
1. The server returns a `200 OK` response with the recording URL.

This endpoint retrieves the playback URL for a specific recording by sending a `GET` request to the `recordings/:recordingId/url` endpoint. If successful, it returns a `200 OK` response with the recording URL. Otherwise, the error is handled by the `handleApiError` function.

______________________________________________________________________

### Frontend modifications

The frontend has been enhanced to include recording management functionality. The main changes are in the `public/js/app.js` file:

#### Additional state management

A new `Map` is created to store recordings indexed by their recording ID:

```javascript
const rooms = new Map();
const recordings = new Map(); // (1)!
```

1. Added a recordings map to store recording data indexed by recording ID.

______________________________________________________________________

#### Enhanced room list template

The room list template is updated to include a `View Recordings` button for each room:

```javascript
function getRoomListItemTemplate(room) {
    return `
        <li class="list-group-item">
            <span>${room.roomName}</span>
            <div class="room-actions">
                <button
                    class="btn btn-primary btn-sm"
                    onclick="joinRoom(
                        '${room.roomName}', 
                        '${room.moderatorUrl}', 
                        'moderator'
                    );"
                >
                    Join as Moderator
                </button>
                <button
                    class="btn btn-secondary btn-sm"
                    onclick="joinRoom(
                        '${room.roomName}', 
                        '${room.speakerUrl}', 
                        'speaker'
                    );"
                >
                    Join as Speaker
                </button>
                <button 
                    class="btn btn-success btn-sm" 
                    onclick="listRecordingsByRoom('${room.roomName}');"
                >
                    View Recordings
                </button>
                <button 
                    title="Delete room"
                    class="icon-button delete-button"
                    onclick="deleteRoom('${room.roomId}');"
                >
                    <i class="fa-solid fa-trash"></i>
                </button>
            </div>
        </li>
    `;
}
```

This button calls the `listRecordingsByRoom()` function when clicked, passing the room name as an argument. This allows users to view recordings for that specific room.

```javascript
async function listRecordingsByRoom(roomName) {
    // Hide the home screen and show the recordings screen
    const homeScreen = document.querySelector('#home');
    homeScreen.hidden = true; // (1)!
    const recordingsScreen = document.querySelector('#recordings');
    recordingsScreen.hidden = false; // (2)!

    // Set the room name in the search input
    const roomNameInput = document.querySelector('#recordings-room-search');
    roomNameInput.value = roomName; // (3)!

    await listRecordings(); // (4)!
}
```

1. Hide the home screen
1. Show the recordings screen.
1. Pre-fill the room search input with the selected room name.
1. Call the `listRecordings()` function to fetch and display recordings for the room.

This function sets up the recordings view by hiding the home screen, showing the recordings screen, pre-filling the room search input with the selected room name, and calling the `listRecordings()` function to fetch and display recordings for that room.

______________________________________________________________________

#### Listing recordings

The `listRecordings()` function fetches and displays recordings, optionally filtering by room name:

```javascript
async function listRecordings() {
    // Filter recordings by room name if provided
    const roomName = document.querySelector('#recordings-room-search').value; // (1)!
    const recordingsUrl = '/recordings' + (roomName ? `?room=${roomName}` : ''); // (2)!

    try {
        let { recordings: recordingsList } = await httpRequest('GET', recordingsUrl); // (3)!
        // Filter completed recordings
        recordingsList = filterCompletedRecordings(recordingsList); // (4)!

        // Clear the previous recordings and populate the new ones
        recordings.clear();
        recordingsList.forEach((recording) => {
            recordings.set(recording.recordingId, recording); // (5)!
        });
        renderRecordings(); // (6)!
    } catch (error) {
        console.error('Error listing recordings:', error.message);

        // Show error message
        const recordingsErrorElement = document.querySelector('#no-recordings-or-error');
        recordingsErrorElement.textContent = 'Error loading recordings';
        recordingsErrorElement.hidden = false;
    }
}

function filterCompletedRecordings(recordingList) {
    return recordingList.filter((recording) => recording.status === 'complete'); // (7)!
}
```

1. Get the room name from the search input for filtering.
1. Build the API URL with optional room filter parameter.
1. Make a `GET` request to the `/recordings` endpoint to fetch the list of recordings.
1. Call the `filterCompletedRecordings()` function to filter out recordings not completed.
1. For each recording in the filtered list, add it to the `recordings` map indexed by recording ID.
1. Call the `renderRecordings()` function to display the list of recordings in the UI.
1. Filter recordings to include only those with 'complete' status.

The listRecordings() function performs the following actions:

1. Gets the room name from the search input field to optionally filter recordings by room.
1. Makes a `GET` request to the `/recordings` endpoint to fetch the list of recordings, including the room filter parameter if specified.
1. Filters the recordings to show only those with `complete` status using the `filterCompletedRecordings()` function.
1. For each recording in the filtered list, it adds the recording to the `recordings` map. This map is used to store the recordings indexed by their recording IDs to make it easier to access them later.
1. Calls the `renderRecordings()` function to display the list of recordings.
1. If an error occurs during the request, it logs the error and displays an appropriate error message.

The `renderRecordings()` function is responsible for updating the UI with the list of recordings:

```javascript
function renderRecordings() {
    // Clear the previous list of recordings
    const recordingsList = document.querySelector('#recordings-list ul'); // (1)!
    recordingsList.innerHTML = ''; // (2)!

    // Show or remove the "No recordings found" message
    const noRecordingsElement = document.querySelector('#no-recordings-or-error');
    if (recordings.size === 0) {
        noRecordingsElement.textContent = 'No recordings found for the filters applied.';
        noRecordingsElement.hidden = false;
        return;
    } else {
        noRecordingsElement.textContent = '';
        noRecordingsElement.hidden = true;
    }

    // Sort recordings by start date in ascending order
    const recordingsArray = Array.from(recordings.values());
    const sortedRecordings = sortRecordingsByDate(recordingsArray); // (3)!

    // Add recordings to the list element
    sortedRecordings.forEach((recording) => {
        const recordingItem = getRecordingListItemTemplate(recording); // (4)!
        recordingsList.innerHTML += recordingItem;
    });
}
```

1. Get the `ul` element where the list of recordings will be displayed.
1. Clear the previous list of recordings.
1. Sort recordings by start date in ascending order.
1. For each recording, get the HTML template for the recording list item.
1. Append the recording item to the list element.

The `renderRecordings()` function performs the following actions:

1. Clears the previous list of recordings by getting the `ul` element and setting its inner HTML to an empty string.
1. Checks if there are any recordings in the `recordings` map. If there are no recordings, it shows a message indicating that no recordings were found for the filters applied. Otherwise, it hides the message.
1. Sorts the recordings by start date in ascending order using the `sortRecordingsByDate()` function.
1. For each recording in the sorted list, it calls the `getRecordingListItemTemplate()` function to get the HTML template for the recording list item.
1. Appends the recording item to the list element.

The `getRecordingListItemTemplate()` function generates the HTML template for each recording list item:

```javascript
function getRecordingListItemTemplate(recording) {
    const recordingId = recording.recordingId; // (1)!
    const roomName = recording.roomName; // (2)!
    const startDate = recording.startDate ? new Date(recording.startDate).toLocaleString() : '-'; // (3)!
    const duration = recording.duration ? secondsToHms(recording.duration) : '-'; // (4)!
    const size = recording.size ? formatBytes(recording.size ?? 0) : '-'; // (5)!

    return `
        <li class="recording-container">
            <i class="fa-solid fa-file-video"></i>
            <div class="recording-info">
                <p class="recording-name">${roomName}</p>
                <p><span class="recording-info-tag">Start date: </span><span class="recording-info-value">${startDate}</span></p>
                <p><span class="recording-info-tag">Duration: </span><span class="recording-info-value">${duration}</span></p>
                <p><span class="recording-info-tag">Size: </span><span class="recording-info-value">${size}</span></p>
            </div>
            <div class="recording-actions">
                <button title="Play" class="icon-button" onclick="displayRecording('${recordingId}')">
                    <i class="fa-solid fa-play"></i>
                </button>
                <button title="Delete recording" class="icon-button delete-button" onclick="deleteRecording('${recordingId}')">
                    <i class="fa-solid fa-trash"></i>
                </button>
            </div>
        </li>
    `;
}
```

1. Retrieve the recording ID.
1. Retrieve the room name associated with the recording.
1. Format the start date for display.
1. Convert the duration from seconds to a human-readable format using the `secondsToHms()` helper function.
1. Format the file size using the `formatBytes()` helper function.

This function creates an HTML list item containing the recording's metadata, including the room name associated with the recording, start date, duration, and file size, along with buttons to play and delete the recording. The buttons call the `displayRecording()` and `deleteRecording()` functions respectively, passing the recording ID as an argument. The recording information is formatted using helper functions like `secondsToHms()` for duration and `formatBytes()` for file size to provide a user-friendly display.

______________________________________________________________________

#### Playing recording

When the user clicks the play button for a recording, the `displayRecording()` function is called:

```javascript
async function displayRecording(recordingId) {
    // Hide the recordings screen and show the display recording screen
    const recordingsScreen = document.querySelector('#recordings');
    recordingsScreen.hidden = true; // (1)!
    const displayRecordingScreen = document.querySelector('#display-recording');
    displayRecordingScreen.hidden = false; // (2)!

    // Get the recording media URL and set it to the source of the video element
    const recordingUrl = await getRecordingUrl(recordingId); // (3)!

    // Inject the OpenVidu Meet component into the display recording container specifying the recording URL
    displayRecordingScreen.innerHTML = `
        <openvidu-meet 
            recording-url="${recordingUrl}"
        >
        </openvidu-meet>
    `; // (4)!
}

async function getRecordingUrl(recordingId) {
    try {
        const { url } = await httpRequest('GET', `/recordings/${recordingId}/url`); // (5)!
        return url;
    } catch (error) {
        console.error('Error fetching recording URL:', error.message);
        return null;
    }
}
```

1. Hide the recordings list screen.
1. Show the recording playback screen.
1. Fetch the recording URL from the backend using the `getRecordingUrl()` function.
1. Inject the OpenVidu Meet WebComponent with the `recording-url` attribute for playback.
1. Make a `GET` request to the `/recordings/:recordingId/url` endpoint to retrieve the recording URL.

The `displayRecording()` function handles the playback of a specific recording by first hiding the recordings list screen and showing the display recording screen. It then fetches the recording URL from the backend using the `getRecordingUrl()` helper function, which makes a `GET` request to the `/recordings/:recordingId/url` endpoint. Finally, it injects the OpenVidu Meet WebComponent into the display container with the `recording-url` attribute set to the fetched URL, enabling the recording to be played directly in the browser. If an error occurs during URL fetching, it logs the error to the console and returns null.

______________________________________________________________________

#### Deleting recording

When the user clicks the delete recording button, the `deleteRecording()` function is called:

```javascript
async function deleteRecording(recordingId) {
    try {
        await httpRequest('DELETE', `/recordings/${recordingId}`); // (1)!

        // Remove the recording from the list
        recordings.delete(recordingId); // (2)!
        renderRecordings(); // (3)!
    } catch (error) {
        console.error('Error deleting recording:', error.message);
    }
}
```

1. Make a `DELETE` request to the `/recordings/:recordingId` endpoint to delete the specified recording.
1. Remove the recording from the `recordings` map.
1. Call the `renderRecordings()` function to update the list of recordings.

The `deleteRecording()` function simply makes a `DELETE` request to the `/recordings/:recordingId` endpoint to delete the specified recording. If the recording is successfully deleted, it removes the recording from the `recordings` map and calls the `renderRecordings()` function to update the list of recordings. If an error occurs during recording deletion, it logs the error to the console.

## Accessing this tutorial from other computers or phones

To access this tutorial from other computers or phones, follow these steps:

1. **Ensure network connectivity**: Make sure your device (computer or phone) is connected to the same network as the machine running OpenVidu Meet and this tutorial.

1. **Configure OpenVidu Meet for network access**: Start OpenVidu Meet by following the instructions in the [Accessing OpenVidu Meet from other computers or phones](../../../deployment/local/#accessing-openvidu-meet-from-other-computers-or-phones) section.

1. **Update the OpenVidu Meet server URL**: Modify the `OV_MEET_SERVER_URL` environment variable in your `.env` file to match the URL shown when OpenVidu Meet starts.

   ```text
   # Example for IP address 192.168.1.100
   OV_MEET_SERVER_URL=https://192-168-1-100.openvidu-local.dev:9443
   ```

1. **Update the OpenVidu Meet WebComponent script URL**: In the `public/index.html` file, update the `<script>` tag that includes the OpenVidu Meet WebComponent to use the same base URL as above.

   ```html
   <script src="http://192-168-1-100.openvidu-local.dev:9443/v1/openvidu-meet.js"></script>
   ```

1. **Restart the tutorial** to apply the changes:

   ```bash
   npm start
   ```

1. **Access the tutorial**: Open your browser and navigate to `https://192-168-1-100.openvidu-local.dev:6443` (replacing `192-168-1-100` with your actual private IP) on the computer where you started the tutorial or any device in the same network.

## Connecting this tutorial to an OpenVidu Meet production deployment

If you have a production deployment of OpenVidu Meet (installed in a server following [deployment steps](../../../deployment/basic/) ), you can connect this tutorial to it by following these steps:

1. **Update the server URL**: Modify the `OV_MEET_SERVER_URL` environment variable in the `.env` file to point to your OpenVidu Meet production deployment URL.

   ```text
   # Example for a production deployment
   OV_MEET_SERVER_URL=https://your-openvidu-meet-domain.com
   ```

1. **Update the API key**: Ensure the `OV_MEET_API_KEY` environment variable in the `.env` file matches the API key configured in your production deployment. See [Generate an API Key](../../reference/rest-api/#generate-an-api-key) section to learn how to obtain it.

   ```text
   OV_MEET_API_KEY=your-production-api-key
   ```

1. **Update the OpenVidu Meet WebComponent script URL**: In the `public/index.html` file, update the `<script>` tag that includes the OpenVidu Meet WebComponent to use the same base URL as above.

   ```html
   <script src="https://your-openvidu-meet-domain.com/v1/openvidu-meet.js"></script>
   ```

1. **Restart the tutorial** to apply the changes:

   ```bash
   npm start
   ```

Make this tutorial accessible from other computers or phones

By default, this tutorial runs on `http://localhost:6080` and is only accessible from the local machine. If you want to access it from other computers or phones, you have the following options:

- **Use tunneling tools**: Configure tools like [VS Code port forwarding](https://code.visualstudio.com/docs/debugtest/port-forwarding) , [ngrok](https://ngrok.com/) , [localtunnel](https://localtunnel.github.io/www/) , or similar services to expose this tutorial to the internet with a secure (HTTPS) public URL.
- **Deploy to a server**: Upload this tutorial to a web server and configure it to be accessible with a secure (HTTPS) public URL. This can be done by updating the source code to manage SSL certificates or configuring a reverse proxy (e.g., Nginx, Apache) to serve it.

# OpenVidu Meet Webhooks Tutorial

[Source code](https://github.com/OpenVidu/openvidu-meet-tutorials/tree/3.4.1/meet-webhooks)

This tutorial extends the [recordings tutorial](../recordings/) to add **real-time updates** through webhooks and Server-Sent Events (SSE). It demonstrates how to receive and process OpenVidu Meet webhooks to provide live status updates for rooms and recordings.

The application includes all the features from the recordings tutorial, plus:

- **Real-time room status updates**: Live updates when meetings start or end.
- **Live recording updates**: Instant updates when recordings are completed.
- **Webhook validation**: Secure webhook processing with signature verification.
- **Room status badges**: Visual indicators showing room status (open, active, closed).
- **Server-Sent Events**: Efficient real-time communication between server and client.

## Running this tutorial

#### 1. Run OpenVidu Meet

You need **Docker Desktop**. You can install it on [Windows](https://docs.docker.com/desktop/setup/install/windows-install/) , [Mac](https://docs.docker.com/desktop/setup/install/mac-install/) or [Linux](http://docs.docker.com/desktop/setup/install/linux/) .

Run this command in Docker Desktop's terminal:

```bash
docker compose -p openvidu-meet -f oci://openvidu/local-meet:3.4.1 up -y openvidu-meet-init
```

Info

For a detailed guide on how to run OpenVidu Meet locally, visit [Try OpenVidu Meet locally](../../../deployment/local/) .

### 2. Download the tutorial code

```bash
git clone https://github.com/OpenVidu/openvidu-meet-tutorials.git -b 3.4.1
```

### 3. Run the application

To run this application, you need [Node.js](https://nodejs.org/en/download) (≥ 18) installed on your device.

1. Navigate into the application directory

```bash
cd openvidu-meet-tutorials/meet-webhooks
```

1. Install dependencies

```bash
npm install
```

1. Run the application

```bash
npm start
```

Once the server is up and running, you can test the application by visiting [`http://localhost:6080`](http://localhost:6080). You should see a screen like this:

## Understanding the code

This tutorial builds upon the [recordings tutorial](../recordings/), adding real-time functionality through webhooks and Server-Sent Events. We'll focus on the new webhook handling capabilities and live update features.

______________________________________________________________________

### Backend modifications

The main backend changes involve implementing webhook processing, SSE communication, and security validation.

#### Server-Sent Events setup

The backend now includes SSE support for real-time client notifications:

```javascript
import bodyParser from 'body-parser';
import cors from 'cors';
import crypto from 'crypto';
import dotenv from 'dotenv';
import express from 'express';
import SSE from 'express-sse'; // (1)!
import path from 'path';
import { fileURLToPath } from 'url';

dotenv.config();

// Configuration
const SERVER_PORT = process.env.SERVER_PORT || 6080;
const OV_MEET_SERVER_URL = process.env.OV_MEET_SERVER_URL || 'http://localhost:9080';
const OV_MEET_API_KEY = process.env.OV_MEET_API_KEY || 'meet-api-key';
const MAX_WEBHOOK_AGE = 120 * 1000; // 2 minutes in milliseconds

// Create SSE instance for real-time notifications
const sse = new SSE(); // (2)!
```

1. Import the `express-sse` library for Server-Sent Events functionality.
1. Create an SSE instance to manage real-time notifications to connected clients.

This code sets up the backend to support Server-Sent Events (SSE), enabling the server to push real-time notifications to connected clients. It imports the `express-sse` library and initializes an SSE instance for managing live event streams.

______________________________________________________________________

#### SSE endpoint for client subscriptions

A new endpoint allows clients to subscribe to real-time notifications:

```javascript
// SSE endpoint for real-time notifications
app.get('/events', sse.init); // (1)!
```

1. Create an SSE endpoint that clients can connect to for receiving real-time webhook notifications.

This endpoint enables clients to establish a persistent connection for receiving live updates about room status changes and recording completions.

______________________________________________________________________

#### Webhook processing endpoint

A new endpoint handles incoming webhooks from OpenVidu Meet:

```javascript
// Webhook endpoint to receive events from OpenVidu Meet
app.post('/webhook', (req, res) => {
    const body = req.body;
    const headers = req.headers;

    if (!isWebhookEventValid(body, headers)) {
        // (1)!
        console.error('Invalid webhook signature');
        return res.status(401).send('Invalid webhook signature');
    }

    console.log('Webhook received:', body);

    // Broadcast the webhook event to all connected SSE clients
    sse.send(body); // (2)!

    res.status(200).send();
});
```

1. Validate the webhook signature and timestamp to ensure authenticity and prevent replay attacks.
1. Broadcast the validated webhook event to all connected SSE clients for real-time updates.

This endpoint receives webhook events from OpenVidu Meet, validates their authenticity, and broadcasts them to all connected clients through Server-Sent Events.

______________________________________________________________________

#### Webhook signature validation

A security function validates webhook authenticity:

```javascript
// Helper function to validate webhook event signature
const isWebhookEventValid = (body, headers) => {
    const signature = headers['x-signature']; // (1)!
    const timestamp = parseInt(headers['x-timestamp'], 10); // (2)!

    if (!signature || !timestamp || isNaN(timestamp)) {
        return false; // (3)!
    }

    const current = Date.now();
    const diffTime = current - timestamp;
    if (diffTime >= MAX_WEBHOOK_AGE) {
        // Webhook event too old
        return false; // (4)!
    }

    const signedPayload = `${timestamp}.${JSON.stringify(body)}`; // (5)!
    const expectedSignature = crypto.createHmac('sha256', OV_MEET_API_KEY).update(signedPayload, 'utf8').digest('hex'); // (6)!

    return crypto.timingSafeEqual(Buffer.from(expectedSignature, 'hex'), Buffer.from(signature, 'hex')); // (7)!
};
```

1. Extract the webhook signature from the `x-signature` header.
1. Extract and parse the timestamp from the `x-timestamp` header.
1. Return false if required headers are missing or invalid.
1. Reject webhooks older than the maximum allowed age to prevent replay attacks.
1. Create the signed payload by combining timestamp and JSON body.
1. Generate the expected signature using HMAC-SHA256 with the API key.
1. Use timing-safe comparison to validate the signature against the expected value.

This function implements webhook security by validating both the cryptographic signature and the timestamp to ensure webhooks are authentic and recent.

Verifying webhooks in other languages

You can find examples of how to verify OpenVidu Meet webhooks in other programming languages in the [Validate events](../../reference/webhooks/#validate-events) section of the Webhooks reference.

______________________________________________________________________

### Frontend modifications

The frontend has been enhanced with real-time update capabilities and improved visual feedback for room status.

#### Real-time notifications setup

The application now establishes an SSE connection on page load:

```javascript
document.addEventListener('DOMContentLoaded', async () => {
    await fetchRooms();
    // Start listening for webhook notifications
    startWebhookNotifications(); // (1)!
});
```

1. Call `startWebhookNotifications()` to establish SSE connection for real-time updates.

______________________________________________________________________

#### Server-Sent Events connection

A new function establishes and manages the SSE connection:

```javascript
// Function to start listening for webhook events via Server-Sent Events
function startWebhookNotifications() {
    const eventSource = new EventSource('/events'); // (1)!

    eventSource.onopen = (_event) => {
        console.log('Connected to webhook notifications'); // (2)!
    };

    eventSource.onmessage = (event) => {
        try {
            const data = JSON.parse(event.data); // (3)!
            handleWebhookNotification(data); // (4)!
        } catch (error) {
            console.error('Error parsing SSE message:', error);
        }
    };

    eventSource.onerror = (event) => {
        console.error('SSE connection error:', event); // (5)!
        // The browser will automatically try to reconnect
    };
}
```

1. Create an `EventSource` connection to the `/events` SSE endpoint.
1. Log successful connection establishment.
1. Parse incoming SSE messages as JSON webhook data.
1. Process webhook notifications through the `handleWebhookNotification()` function.
1. Handle connection errors with automatic browser reconnection.

This function creates a persistent connection to receive real-time webhook notifications from the server by creating an `EventSource` instance to the `/events` endpoint. When a message is received, it parses the JSON data and calls `handleWebhookNotification()` to process the event. The function also handles connection errors, allowing the browser to automatically attempt reconnection.

______________________________________________________________________

#### Webhook notification processing

A new function processes incoming webhook notifications and updates the UI accordingly:

```javascript
// Function to handle webhook notifications and update UI
function handleWebhookNotification(webhookData) {
    const { event, data } = webhookData; // (1)!
    console.log(`Webhook '${event}' received for room '${data.roomName}':`, webhookData);

    switch (event) {
        case 'meetingStarted':
            // Update rooms map with updated room info and re-render if on home screen
            if (isOnHomeScreen()) {
                // (2)!
                rooms.set(data.roomId, data);
                renderRooms(); // (3)!
            }
            break;
        case 'meetingEnded':
            // Update rooms map with updated room info and re-render if on home screen
            if (isOnHomeScreen()) {
                rooms.set(data.roomId, data);
                renderRooms();
            }
            break;
        case 'recordingEnded':
            // Add recording to list and re-render if on recordings screen
            if (isOnRecordingsScreen(data.roomName)) {
                // (4)!
                recordings.set(data.recordingId, data);
                renderRecordings(); // (5)!
            }
            break;
    }
}
```

1. Extract the event type and data from the webhook payload.
1. Check if the user is currently on the home screen before updating room status.
1. Update the rooms map and re-render the room list with new status information.
1. Check if the user is viewing recordings for the relevant room before adding new recordings.
1. Update the recordings map and re-render the recordings list with new recording data.

This function processes different webhook event types and updates the appropriate UI elements only when the user is viewing the relevant screen:

- For `meetingStarted` and `meetingEnded` events, it updates the room status and re-renders the room list if the user is on the home screen.
- For `recordingEnded` events, it adds the new recording to the list and re-renders the recordings list if the user is viewing recordings for the relevant room.

In order to determine the current screen context, new utility functions have been introduced:

```javascript
// Helper functions to detect current screen
function isOnHomeScreen() {
    const homeScreen = document.querySelector('#home');
    return homeScreen && !homeScreen.hidden; // (1)!
}

function isOnRecordingsScreen(roomName) {
    const recordingsScreen = document.querySelector('#recordings');
    if (!recordingsScreen || recordingsScreen.hidden) {
        return false; // (2)!
    }

    // Check if the room filter matches room name
    const roomSearchInput = document.querySelector('#recordings-room-search');
    const roomFilter = roomSearchInput ? roomSearchInput.value.trim() : '';
    return !roomFilter || roomName.startsWith(roomFilter); // (3)!
}
```

1. Check if the home screen is currently visible to determine if room updates should be applied.
1. Return false if the recordings screen is not visible.
1. Check if the room name matches the current filter to determine if recording updates are relevant.

These helper functions ensure that UI updates are only applied when users are viewing the relevant sections, optimizing performance and preventing unnecessary re-renders:

- `isOnHomeScreen()`: Checks if the home screen is currently visible.
- `isOnRecordingsScreen(roomName)`: Checks if the recordings screen is visible and if the room name matches the current filter.

______________________________________________________________________

#### Enhanced room status display

The room template has been updated to include visual status indicators:

```javascript
function getRoomListItemTemplate(room) {
    const roomStatus = room.status === 'active_meeting' ? 'ACTIVE' : room.status === 'open' ? 'OPEN' : 'CLOSED'; // (1)!
    const roomStatusBadgeClass =
        room.status === 'active_meeting' ? 'bg-primary' : room.status === 'open' ? 'bg-success' : 'bg-warning'; // (2)!

    return `
        <li class="list-group-item">
            <div class="room-info">
                <span>${room.roomName}</span>
                <span class="badge ${roomStatusBadgeClass}">${roomStatus}</span>
            </div>
            <div class="room-actions">
                <!-- buttons remain the same -->
            </div>
        </li>
    `;
}
```

1. Map room status values to user-friendly display text.
1. Assign appropriate CSS classes for visual styling based on room status.

The room template now includes status badges that provide immediate visual feedback about room state:

- **ACTIVE** (blue badge): Meeting is currently in progress
- **OPEN** (green badge): Room is available for joining
- **CLOSED** (yellow badge): Room is closed and cannot be joined

## Accessing this tutorial from other computers or phones

To access this tutorial from other computers or phones, follow these steps:

1. **Ensure network connectivity**: Make sure your device (computer or phone) is connected to the same network as the machine running OpenVidu Meet and this tutorial.

1. **Configure OpenVidu Meet for network access**: Start OpenVidu Meet by following the instructions in the [Accessing OpenVidu Meet from other computers or phones](../../../deployment/local/#accessing-openvidu-meet-from-other-computers-or-phones) section.

1. **Update the OpenVidu Meet server URL**: Modify the `OV_MEET_SERVER_URL` environment variable in your `.env` file to match the URL shown when OpenVidu Meet starts.

   ```text
   # Example for IP address 192.168.1.100
   OV_MEET_SERVER_URL=https://192-168-1-100.openvidu-local.dev:9443
   ```

1. **Update the OpenVidu Meet WebComponent script URL**: In the `public/index.html` file, update the `<script>` tag that includes the OpenVidu Meet WebComponent to use the same base URL as above.

   ```html
   <script src="http://192-168-1-100.openvidu-local.dev:9443/v1/openvidu-meet.js"></script>
   ```

1. **Restart the tutorial** to apply the changes:

   ```bash
   npm start
   ```

1. **Access the tutorial**: Open your browser and navigate to `https://192-168-1-100.openvidu-local.dev:6443` (replacing `192-168-1-100` with your actual private IP) on the computer where you started the tutorial or any device in the same network.

## Connecting this tutorial to an OpenVidu Meet production deployment

If you have a production deployment of OpenVidu Meet (installed in a server following [deployment steps](../../../deployment/basic/) ), you can connect this tutorial to it by following these steps:

1. **Update the server URL**: Modify the `OV_MEET_SERVER_URL` environment variable in the `.env` file to point to your OpenVidu Meet production deployment URL.

   ```text
   # Example for a production deployment
   OV_MEET_SERVER_URL=https://your-openvidu-meet-domain.com
   ```

1. **Update the API key**: Ensure the `OV_MEET_API_KEY` environment variable in the `.env` file matches the API key configured in your production deployment. See [Generate an API Key](../../reference/rest-api/#generate-an-api-key) section to learn how to obtain it.

   ```text
   OV_MEET_API_KEY=your-production-api-key
   ```

1. **Update the OpenVidu Meet WebComponent script URL**: In the `public/index.html` file, update the `<script>` tag that includes the OpenVidu Meet WebComponent to use the same base URL as above.

   ```html
   <script src="https://your-openvidu-meet-domain.com/v1/openvidu-meet.js"></script>
   ```

1. **Restart the application** to apply the changes:

   ```bash
   npm start
   ```

1. **Make the tutorial accessible to OpenVidu Meet deployment**: As OpenVidu Meet needs to send webhooks to this tutorial, it must be accessible from the internet. To achieve this, you have the following options:

   - **Using tunneling tools**: Configure tools like [VS Code port forwarding](https://code.visualstudio.com/docs/debugtest/port-forwarding) , [ngrok](https://ngrok.com/) , [localtunnel](https://localtunnel.github.io/www/) , or similar services to expose this tutorial to the internet with a secure (HTTPS) public URL.
   - **Deploying to a public server**: Upload this tutorial to a web server and configure it to be accessible with a secure (HTTPS) public URL. This can be done by updating the source code to manage SSL certificates or configuring a reverse proxy (e.g., Nginx, Apache) to serve it.

   A the end, you should have a public URL (e.g., `https://your-tutorial-domain.com:XXXX`) that points to this tutorial.

1. **Configure webhooks in OpenVidu Meet**: Set up webhooks in your OpenVidu Meet production deployment to point to this tutorial. Follow the instructions in the [Webhooks configuration](../../reference/webhooks/#configuration) section to learn how to configure a webhook URL. Use the public URL of this tutorial followed by `/webhook` (e.g., `https://your-tutorial-domain.com:XXXX/webhook`).

1. **Access the tutorial**: Access the tutorial from any device connected to the internet using its public URL (e.g., `https://your-tutorial-domain.com:XXXX`).

# Direct Link

Redirect users to OpenVidu Meet using simple HTML links. This is the simplest way to integrate OpenVidu Meet into your application - perfect when you want users to join meetings in a new browser tab or window with the polished OpenVidu Meet interface.

## Usage

Create a direct link to an OpenVidu Meet room using a simple HTML anchor tag:

```html
<a href="https://your-meet-domain.com/room/MyRoom-abcdef?secret=12345">Join Room</a>
```

When users click the link, they'll be redirected to OpenVidu Meet in their browser, ready to join the room.

Info

You can get room URLs programmatically from your backend using the [REST API](../api.html#/schemas/MeetRoom) properties `moderatorUrl` or `speakerUrl`.

## API Reference

### Attributes

Info

Direct links accept the same **attributes** as the OpenVidu Meet Web Component. See [Web Component Attributes](../webcomponent/#attributes) for the full list and descriptions.

Customize the meeting by passing attributes as query parameters in the room URL:

```html
<a href="https://your-meet-domain.com/room/MyRoom-abcdef?secret=12345&participant-name=John&leave-redirect-url=https://meeting.end.url/">
    Join Room as John
</a>
```

### Commands

Direct links do not support programmatic commands since the meeting opens in a separate browser tab/window. If you need to control the meeting programmatically, consider using the [Web Component](../webcomponent/) or [Iframe](../iframe/) approaches instead.

### Events

Direct links do not emit events to your application since the meeting runs in a separate browser context. If you need to listen to meeting events, consider using the [Web Component](../webcomponent/) or [Iframe](../iframe/) approaches instead.

# Iframe

Embed OpenVidu Meet directly into your application using a traditional HTML iframe. This approach is perfect for applications that cannot use [OpenVidu Meet Web Component](../webcomponent/) or need a simple integration method.

## Usage

Embed OpenVidu Meet by adding an iframe to your HTML with the room URL and required permissions:

```html
<iframe
    src="https://your-meet-domain.com/room/MyRoom-abcdef?secret=12345"
    allow="camera; microphone; display-capture; fullscreen; autoplay; compute-pressure;"
    width="100%" height="100%">
</iframe>
```

### Required iframe attributes

- **`src`**: The room URL to join
- **`allow`**: Permissions required for the meeting to work properly:
  - `camera`: Access to the camera
  - `microphone`: Access to the microphone
  - `display-capture`: Screen sharing capability
  - `fullscreen`: Full screen mode
  - `autoplay`: Media autoplay
  - `compute-pressure`: Device performance monitoring

Info

You can get room URLs programmatically from your backend using the [REST API](../api.html#/schemas/MeetRoom) properties `moderatorUrl` or `speakerUrl`.

## API Reference

### Attributes

Info

The iframe accepts the same **attributes** as the OpenVidu Meet Web Component. See [Web Component Attributes](../webcomponent/#attributes) for the full list and descriptions.

Customize the **participant name** and meeting redirect by adding attributes as query parameters in the iframe src URL.

```html
<iframe
    src="https://your-meet-domain.com/room/MyRoom-abcdef?secret=12345&participant-name=John&leave-redirect-url=https://meeting.end.url/"
    allow="camera; microphone; display-capture; fullscreen; autoplay; compute-pressure;"
    width="100%" height="100%">
</iframe>
```

### Commands

Info

The iframe accepts the same **commands** as the OpenVidu Meet Web Component. See [Web Component Commands](../webcomponent/#commands) for the full list and descriptions.

Control the meeting programmatically by sending commands via `postMessage` to the iframe's content window:

```javascript
const iframe = document.querySelector('iframe');
const targetOrigin = '*'; // Replace with your actual domain
iframe.contentWindow.postMessage({ command: 'leaveRoom' }, targetOrigin);
```

### Events

Info

The iframe emits the same **events** as the OpenVidu Meet Web Component. See [Web Component Events](../webcomponent/#events) for the full list and descriptions.

Listen to meeting events by monitoring messages from the iframe:

```javascript
const iframe = document.querySelector('iframe');

window.addEventListener('message', (event) => {
    // Verify the event origin for security
    if (event.origin !== 'https://your-meet-domain.com') return;

    const message = event.data;

    if (!message || !message.event) {
        return;
    }

    console.log('Received event from iframe:', message.event, message.payload);
});
```

## Overview

OpenVidu Meet provides a REST API for managing **rooms** and **recordings** programmatically from your application's backend. As a general rule, any action that is available in OpenVidu Meet UI for rooms and recordings can also be performed using the REST API.

There are two endpoints:

- `/api/v1/rooms`: manage [rooms](../../../features/rooms-and-meetings/).
- `/api/v1/recordings`: manage [recordings](../../../features/recordings/).

## Authentication

Any request to the OpenVidu Meet REST API must include a valid API key in the `X-API-KEY` header:

```text
X-API-KEY: your-openvidu-meet-api-key
```

### Generate an API key

1. Connect to OpenVidu Meet console at `https://YOUR_OPENVIDU_DEPLOYMENT_DOMAIN/`.
1. Navigate to the **"Embedded"** page.
1. Click on **" Generate API Key"** button.

\[[](../../../../assets/videos/meet/generate-api-key.mp4)\](../../../../assets/videos/meet/generate-api-key.mp4)

## Reference

You can access the REST API reference documentation at:

- [**OpenVidu Meet REST API Reference**](../api.html)
- **Your own OpenVidu Meet deployment** serves the documentation at **`https://{{ your-openvidu-deployment-domain }}/api/v1/docs/`**

### Code snippets

The reference documentation provides code snippets for each REST API method. You can choose from countless languages and frameworks and copy-paste directly to your code.

### Testing API Endpoints

When accessing the REST API documentation from your own OpenVidu Meet deployment at **`https://{{ your-openvidu-deployment-domain }}/api/v1/docs/`**, you can test every endpoint directly from the browser. This is a great way to explore the API's body requests and responses.

Just configure a valid API key in the `X-API-KEY` header input.

\[[](../../../../assets/videos/meet/rest-api-test.mp4)\](../../../../assets/videos/meet/rest-api-test.mp4)

# Web Component

OpenVidu Meet's Web Component allows embedding the refined, well-crafted OpenVidu Meet interface directly into your application. It offers **attributes** to customize the videoconferencing experience, exposes **commands** for programmatic control, and emits **events** for integration with your own application's logic.

## Installation

Include the following script in your HTML:

```html
<script src="https://{{ your-openvidu-deployment-domain }}/v1/openvidu-meet.js"></script>
```

## Usage

Add the `<openvidu-meet>` tag to your HTML. This will embed OpenVidu Meet interface into your application:

```html
<openvidu-meet room-url="{{ my-room-url }}"></openvidu-meet>
```

The only required attribute is **`room-url`**, which determines the room to join. Different instances of the web component using the same room URL will access the same meeting.

Info

You can get a room's URL programmatically from your application's backend: properties `moderatorUrl` and `speakerUrl` of object [MeetRoom](../api.html#/schemas/MeetRoom) .

## API Reference

### Attributes

Declare attributes in the component to customize the meeting for your user.

| Attribute              | Description                                                                                         | Required                                                             |
| ---------------------- | --------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------- |
| `room-url`             | The OpenVidu Meet room URL to connect to (moderator or speaker url)                                 | Yes (This attribute is required unless `recording-url` is provided.) |
| `recording-url`        | The URL of a recording to view.                                                                     | Yes (This attribute is required unless `room-url` is provided.)      |
| `participant-name`     | Display name for the local participant.                                                             | No                                                                   |
| `leave-redirect-url`   | URL to redirect to when leaving the meeting. Redirection occurs after the **`CLOSED` event** fires. | No                                                                   |
| `show-only-recordings` | Whether to show only recordings instead of live meetings.                                           | No                                                                   |

Example:

```html
<openvidu-meet
    room-url="{{ my-room-url }}"
    participant-name="John Doe"
    leave-redirect-url="https://meeting.end.url/"
></openvidu-meet>
```

### Commands

The OpenVidu Meet component exposes a set of commands that allow you to control the room from your application's logic.

| Method                                 | Command           | Description                                              | Parameters                      | Access Level |
| -------------------------------------- | ----------------- | -------------------------------------------------------- | ------------------------------- | ------------ |
| `endMeeting()`                         | `endMeeting`      | Ends the current meeting for all participants.           | -                               | Moderator    |
| `leaveRoom()`                          | `leaveRoom`       | Disconnects the local participant from the current room. | -                               | All          |
| `kickParticipant(participantIdentity)` | `kickParticipant` | Kicks a participant from the meeting.                    | • `participantIdentity`: string | Moderator    |

Invoke commands using JavaScript:

```javascript
const openviduMeet = document.querySelector('openvidu-meet');
openviduMeet.leaveRoom();
```

### Events

The OpenVidu Meet component emits events that you can listen to in your application.

| Event    | Description                                               | Payload                                                                                             |
| -------- | --------------------------------------------------------- | --------------------------------------------------------------------------------------------------- |
| `joined` | Event emitted when the local participant joins the room.  | `{      "roomId": "string",     "participantIdentity": "string" }`                                  |
| `left`   | Event emitted when the local participant leaves the room. | `{      "roomId": "string",     "participantIdentity": "string",     "reason": "LeftEventReason" }` |
| `closed` | Event emitted when the application is closed.             | -                                                                                                   |

Listen to events using JavaScript event listeners:

```javascript
const openviduMeet = document.querySelector('openvidu-meet');

openviduMeet.addEventListener('JOINED', (event) => {
    console.log('The local participant has joined the room!', event);
});
```

You can also use the API `on` | `once` | `off`:

```javascript
const openviduMeet = document.querySelector('openvidu-meet');

openviduMeet.on('JOINED', (event) => {
    console.log('The local participant has joined the room!', event);
});

openviduMeet.once('LEFT', (event) => {
    console.log('The local participant has left the room!', event);
});
```

# Webhooks

OpenVidu Meet sends webhooks to inform about important events happening in a room. You can receive them in your application's backend and react accordingly with your own business logic.

## Reference

Visit [OpenVidu Meet Webhooks](../api.html#/webhooks/recordingStartedWebhook) reference documentation for a complete list of all available webhook events. They include:

- [`meetingStarted`](../api.html#/webhooks/meetingStartedWebhook)
- [`meetingEnded`](../api.html#/webhooks/meetingEndedWebhook)
- [`recordingStarted`](../api.html#/webhooks/recordingStartedWebhook)
- [`recordingUpdated`](../api.html#/webhooks/recordingUpdatedWebhook)
- [`recordingEnded`](../api.html#/webhooks/recordingEndedWebhook)

## Configuration

You can configure webhooks in OpenVidu Meet in the **"Embedded"** page. There you can:

- Enable/Disable sending webhooks
- Set up your webhook endpoint URL
- Test the current webhook configuration with a fake event

## Validate events

OpenVidu Meet signs all webhook events with [your API key](../rest-api/#generate-an-api-key), so you can verify their authenticity. This way you can ensure that the events received by your application's backend are coming from your actual OpenVidu Meet deployment and have not been tampered with.

Each webhook event includes two headers that you should use to validate the request:

- `x-signature`: HMAC SHA256 signature of the request body, created by OpenVidu Meet using your API key.
- `x-timestamp`: Unix timestamp (in milliseconds) when the webhook was sent.

The steps to validate a webhook event in your backend are the following, given that you have access to the HTTP request **body** and **headers**:

1. Get the `x-signature` and `x-timestamp` headers from the request.
1. Compare the `x-timestamp` header value with the current Unix timestamp. If the difference is greater than a predefined threshold (e.g., 2 minutes), reject it to prevent [replay attacks](https://en.wikipedia.org/wiki/Replay_attack) .
1. Concatenate in a single string the `x-timestamp` header value + character `.` + the JSON request body.
1. Create a HMAC SHA256 hash of the string of point 3) using your OpenVidu Meet API key as the key.
1. Compare the computed hash of point 4) with the `x-signature` header value. Do a time safe comparison to avoid [timing attacks](https://en.wikipedia.org/wiki/Timing_attack) . If they match, the request is valid.

Below there are code snippets in different languages, showing the exact implementation of the above steps.

Checkout [working example](https://github.com/OpenVidu/openvidu-meet/tree/main/webhooks-snippets/node)

```javascript
import crypto from "crypto";

const OPENVIDU_MEET_API_KEY = "YOUR_API_KEY";
const MAX_WEBHOOK_AGE = 120 * 1000; // 2 minutes in milliseconds

function isWebhookEventValid(body, headers) {
    const signature = headers["x-signature"]; // (1)!
    const timestamp = parseInt(headers["x-timestamp"], 10);

    if (!signature || !timestamp || isNaN(timestamp)) {
        return false;
    }

    const current = Date.now();
    const diffTime = current - timestamp;
    if (diffTime >= MAX_WEBHOOK_AGE) { // (2)!
        // Webhook event too old
        return false;
    }

    const signedPayload = `${timestamp}.${JSON.stringify(body)}`; // (3)!
    const expectedSignature = crypto // (4)!
        .createHmac("sha256", OPENVIDU_MEET_API_KEY)
        .update(signedPayload, "utf8")
        .digest("hex");

    return crypto.timingSafeEqual( // (5)!
        Buffer.from(expectedSignature, "hex"),
        Buffer.from(signature, "hex")
    );
}
```

1. 1. Get the `x-signature` and `x-timestamp` headers from the request.
1. 2. Compare the `x-timestamp` header value with the current Unix timestamp. If the difference is greater than a predefined threshold (e.g., 2 minutes), reject it to prevent [replay attacks](https://en.wikipedia.org/wiki/Replay_attack) .
1. 3. Concatenate in a single string the `x-timestamp` header value + character `.` + the JSON request body.
1. 4. Create a HMAC SHA256 hash of the string of point 3) using your OpenVidu Meet API key as the key.
1. 5. Compare the computed hash of point 4) with the `x-signature` header value. Do a time safe comparisson to avoid [timing attacks](https://en.wikipedia.org/wiki/Timing_attack) . If they match, the request is valid.

Checkout [working example](https://github.com/OpenVidu/openvidu-meet/tree/main/webhooks-snippets/java)

```java
package com.example;

import javax.crypto.Mac;
import javax.crypto.spec.SecretKeySpec;
import java.nio.charset.StandardCharsets;
import java.util.Map;

public class WebhookValidator {
    private static final long MAX_WEBHOOK_AGE = 120 * 1000; // 2 minutes in milliseconds
    private static final String OPENVIDU_MEET_API_KEY = "YOUR_API_KEY";

    public static boolean isWebhookEventValid(Object body, Map<String, String> headers) {
        String signature = headers.get("x-signature"); // (1)!
        String ts = headers.get("x-timestamp");
        if (signature == null || ts == null) return false;

        long timestamp;
        try {
            timestamp = Long.parseLong(ts);
        } catch (NumberFormatException e) {
            return false;
        }

        long current = System.currentTimeMillis();
        long diffTime = current - timestamp;
        if (diffTime >= MAX_WEBHOOK_AGE) { // (2)!
            // Webhook event too old
            return false;
        }

        String signedPayload = timestamp + "." + body.toString(); // (3)!

        try {
            Mac mac = Mac.getInstance("HmacSHA256");
            mac.init(
                new SecretKeySpec(
                    OPENVIDU_MEET_API_KEY.getBytes(StandardCharsets.UTF_8), // (4)!
                    "HmacSHA256"
                )
            );
            byte[] expected = mac.doFinal(signedPayload.getBytes(StandardCharsets.UTF_8));
            byte[] actual = hexToBytes(signature);

            return timingSafeEqual(expected, actual); // (5)!
        } catch (Exception e) {
            return false;
        }
    }

    // Helper method to convert hex string to byte array
    private static byte[] hexToBytes(String hex) {
        int len = hex.length();
        byte[] data = new byte[len / 2];
        for (int i = 0; i < len; i += 2) {
            data[i / 2] = (byte) ((Character.digit(hex.charAt(i), 16) << 4)
                                + Character.digit(hex.charAt(i + 1), 16));
        }
        return data;
    }

    // Time safe comparison to prevent timing attacks
    private static boolean timingSafeEqual(byte[] a, byte[] b) {
        if (a.length != b.length) return false;
        int result = 0;
        for (int i = 0; i < a.length; i++) {
            result |= a[i] ^ b[i];
        }
        return result == 0;
    }
}
```

1. 1. Get the `x-signature` and `x-timestamp` headers from the request.
1. 2. Compare the `x-timestamp` header value with the current Unix timestamp. If the difference is greater than a predefined threshold (e.g., 2 minutes), reject it to prevent [replay attacks](https://en.wikipedia.org/wiki/Replay_attack) .
1. 3. Concatenate in a single string the `x-timestamp` header value + character `.` + the JSON request body.
1. 4. Create a HMAC SHA256 hash of the string of point 3) using your OpenVidu Meet API key as the key.
1. 5. Compare the computed hash of point 4) with the `x-signature` header value. Do a time safe comparisson to avoid [timing attacks](https://en.wikipedia.org/wiki/Timing_attack) . If they match, the request is valid.

Checkout [working example](https://github.com/OpenVidu/openvidu-meet/tree/main/webhooks-snippets/go)

```go
package main

import (
    "crypto/hmac"
    "crypto/sha256"
    "crypto/subtle"
    "encoding/hex"
    "encoding/json"
    "net/http"
    "strconv"
    "time"
)

const (
    maxWebhookAge      = 120 * 1000 // 2 minutes in milliseconds
    openviduMeetApiKey = "YOUR_API_KEY"
)

func isWebhookEventValid(bodyBytes []byte, headers http.Header) bool {
    signature := headers.Get("x-signature") // (1)!
    tsStr := headers.Get("x-timestamp")
    if signature == "" || tsStr == "" {
        return false
    }

    timestamp, err := strconv.ParseInt(tsStr, 10, 64)
    if err != nil {
        return false
    }

    current := time.Now().UnixMilli()
    diffTime := current - timestamp
    if diffTime >= maxWebhookAge { // (2)!
        // Webhook event too old
        return false
    }

    signedPayload := tsStr + "." + string(bodyBytes) // (3)!

    mac := hmac.New(sha256.New, []byte(openviduMeetApiKey)) // (4)!
    mac.Write([]byte(signedPayload))
    expected := mac.Sum(nil)

    actual, err := hex.DecodeString(signature)
    if err != nil {
        return false
    }

    return subtle.ConstantTimeCompare(expected, actual) == 1 // (5)!
}
```

1. 1. Get the `x-signature` and `x-timestamp` headers from the request.
1. 2. Compare the `x-timestamp` header value with the current Unix timestamp. If the difference is greater than a predefined threshold (e.g., 2 minutes), reject it to prevent [replay attacks](https://en.wikipedia.org/wiki/Replay_attack) .
1. 3. Concatenate in a single string the `x-timestamp` header value + character `.` + the JSON request body.
1. 4. Create a HMAC SHA256 hash of the string of point 3) using your OpenVidu Meet API key as the key.
1. 5. Compare the computed hash of point 4) with the `x-signature` header value. Do a time safe comparisson to avoid [timing attacks](https://en.wikipedia.org/wiki/Timing_attack) . If they match, the request is valid.

Checkout [working example](https://github.com/OpenVidu/openvidu-meet/tree/main/webhooks-snippets/python)

```python
import hmac
import hashlib
import json
import time

MAX_WEBHOOK_AGE = 120 * 1000  # 2 minutes in milliseconds
OPENVIDU_MEET_API_KEY = "YOUR_API_KEY"

def is_webhook_event_valid(body, headers):
    signature = headers.get("x-signature")  # (1)!
    timestamp_str = headers.get("x-timestamp")
    if not signature or not timestamp_str:
        return False

    try:
        timestamp = int(timestamp_str)
    except ValueError:
        return False

    current = int(time.time() * 1000)
    diff_time = current - timestamp
    if diff_time >= MAX_WEBHOOK_AGE:  # (2)!
        return False

    json_body = json.dumps(body, separators=(",", ":"))
    signed_payload = str(timestamp) + "." + json_body  # (3)!

    expected = hmac.new(  # (4)!
        OPENVIDU_MEET_API_KEY.encode('utf-8'),
        signed_payload.encode('utf-8'),
        hashlib.sha256
    ).hexdigest()

    return hmac.compare_digest(expected, signature)  # (5)!
```

1. 1. Get the `x-signature` and `x-timestamp` headers from the request.
1. 2. Compare the `x-timestamp` header value with the current Unix timestamp. If the difference is greater than a predefined threshold (e.g., 2 minutes), reject it to prevent [replay attacks](https://en.wikipedia.org/wiki/Replay_attack) .
1. 3. Concatenate in a single string the `x-timestamp` header value + character `.` + the JSON request body.
1. 4. Create a HMAC SHA256 hash of the string of point 3) using your OpenVidu Meet API key as the key.
1. 5. Compare the computed hash of point 4) with the `x-signature` header value. Do a time safe comparisson to avoid [timing attacks](https://en.wikipedia.org/wiki/Timing_attack) . If they match, the request is valid.

Checkout [working example](https://github.com/OpenVidu/openvidu-meet/tree/main/webhooks-snippets/php)

```php
<?php

const MAX_WEBHOOK_AGE = 120 * 1000; // 2 minutes in milliseconds
const OPENVIDU_MEET_API_KEY = "YOUR_API_KEY";

function isWebhookEventValid($body, $headers)
{
    $signature = $headers['x-signature'] ?? null; // (1)!
    $timestampStr = $headers['x-timestamp'] ?? null;
    if (!$signature || !$timestampStr) {
        return false;
    }

    $timestamp = filter_var($timestampStr, FILTER_VALIDATE_INT);
    if ($timestamp === false) {
        return false;
    }

    $current = intval(microtime(true) * 1000);
    $diffTime = $current - $timestamp;
    if ($diffTime >= MAX_WEBHOOK_AGE) { // (2)!
        return false;
    }

    $signedPayload = $timestamp . '.' . json_encode($body, JSON_UNESCAPED_SLASHES); // (3)!

    $expected = hash_hmac('sha256', $signedPayload, OPENVIDU_MEET_API_KEY); // (4)!

    return hash_equals($expected, $signature); // (5)!
}

?>
```

1. 1. Get the `x-signature` and `x-timestamp` headers from the request.
1. 2. Compare the `x-timestamp` header value with the current Unix timestamp. If the difference is greater than a predefined threshold (e.g., 2 minutes), reject it to prevent [replay attacks](https://en.wikipedia.org/wiki/Replay_attack) .
1. 3. Concatenate in a single string the `x-timestamp` header value + character `.` + the JSON request body.
1. 4. Create a HMAC SHA256 hash of the string of point 3) using your OpenVidu Meet API key as the key.
1. 5. Compare the computed hash of point 4) with the `x-signature` header value. Do a time safe comparisson to avoid [timing attacks](https://en.wikipedia.org/wiki/Timing_attack) . If they match, the request is valid.

Checkout [working example](https://github.com/OpenVidu/openvidu-meet/tree/main/webhooks-snippets/dotnet)

```csharp
using System.Security.Cryptography;
using System.Text;
using System.Text.Json;

public class WebhookValidator
{
    private const long MAX_WEBHOOK_AGE = 120 * 1000; // 2 minutes in milliseconds
    private const string OPENVIDU_MEET_API_KEY = "YOUR_API_KEY";

    public static bool IsWebhookEventValid(string body, Dictionary<string, string> headers)
    {
        if (!headers.TryGetValue("x-signature", out var signature) || // (1)!
            !headers.TryGetValue("x-timestamp", out var timestampStr))
        {
            return false;
        }

        if (!long.TryParse(timestampStr, out long timestamp))
        {
            return false;
        }

        long current = DateTimeOffset.UtcNow.ToUnixTimeMilliseconds();
        long diffTime = current - timestamp;
        if (diffTime >= MAX_WEBHOOK_AGE) // (2)!
        {
            return false;
        }

        string signedPayload = $"{timestamp}.{body}"; // (3)!

        using (var hmac = new HMACSHA256(Encoding.UTF8.GetBytes(OPENVIDU_MEET_API_KEY))) // (4)!
        {
            byte[] expected = hmac.ComputeHash(Encoding.UTF8.GetBytes(signedPayload));
            byte[] actual = Convert.FromHexString(signature);

            return CryptographicOperations.FixedTimeEquals(expected, actual); // (5)!
        }
    }
}
```

1. 1. Get the `x-signature` and `x-timestamp` headers from the request.
1. 2. Compare the `x-timestamp` header value with the current Unix timestamp. If the difference is greater than a predefined threshold (e.g., 2 minutes), reject it to prevent [replay attacks](https://en.wikipedia.org/wiki/Replay_attack) .
1. 3. Concatenate in a single string the `x-timestamp` header value + character `.` + the JSON request body.
1. 4. Create a HMAC SHA256 hash of the string of point 3) using your OpenVidu Meet API key as the key.
1. 5. Compare the computed hash of point 4) with the `x-signature` header value. Do a time safe comparisson to avoid [timing attacks](https://en.wikipedia.org/wiki/Timing_attack) . If they match, the request is valid.

Checkout [working example](https://github.com/OpenVidu/openvidu-meet/tree/main/webhooks-snippets/ruby)

```ruby
require 'openssl'
require 'json'

MAX_WEBHOOK_AGE = 120 * 1000 # 2 minutes in milliseconds
OPENVIDU_MEET_API_KEY = "YOUR_API_KEY"

def webhook_event_valid?(body, headers)
    signature = headers['x-signature'] # (1)!
    timestamp_str = headers['x-timestamp']
    return false if signature.nil? || timestamp_str.nil?

    begin
        timestamp = Integer(timestamp_str)
    rescue ArgumentError
        return false
    end

    current = (Time.now.to_f * 1000).to_i
    diff_time = current - timestamp
    return false if diff_time >= MAX_WEBHOOK_AGE # (2)!

    signed_payload = "#{timestamp}.#{body.to_json}" # (3)!

    expected = OpenSSL::HMAC.hexdigest('SHA256', OPENVIDU_MEET_API_KEY, signed_payload) # (4)!

    OpenSSL.fixed_length_secure_compare(expected, signature) # (5)!
end
```

1. 1. Get the `x-signature` and `x-timestamp` headers from the request.
1. 2. Compare the `x-timestamp` header value with the current Unix timestamp. If the difference is greater than a predefined threshold (e.g., 2 minutes), reject it to prevent [replay attacks](https://en.wikipedia.org/wiki/Replay_attack) .
1. 3. Concatenate in a single string the `x-timestamp` header value + character `.` + the JSON request body.
1. 4. Create a HMAC SHA256 hash of the string of point 3) using your OpenVidu Meet API key as the key.
1. 5. Compare the computed hash of point 4) with the `x-signature` header value. Do a time safe comparisson to avoid [timing attacks](https://en.wikipedia.org/wiki/Timing_attack) . If they match, the request is valid.

Checkout [working example](https://github.com/OpenVidu/openvidu-meet/tree/main/webhooks-snippets/rust)

```rust
use chrono::Utc;
use hmac::{Hmac, Mac};
use sha2::Sha256;
use std::collections::HashMap;

type HmacSha256 = Hmac<Sha256>;

fn is_webhook_event_valid(body_str: &str, headers: &HashMap<String, String>) -> bool {
    let signature = match headers.get("x-signature") { // (1)!
        Some(sig) => sig,
        None => return false,
    };

    let timestamp_str = match headers.get("x-timestamp") {
        Some(ts) => ts,
        None => return false,
    };

    let timestamp: i64 = match timestamp_str.parse() {
        Ok(ts) => ts,
        Err(_) => return false,
    };

    // Check timestamp age
    let current = Utc::now().timestamp_millis();
    let diff_time = current - timestamp;
    if diff_time >= MAX_WEBHOOK_AGE { // (2)!
        return false;
    }

    // Create signed payload using the raw body string
    let signed_payload = format!("{}.{}", timestamp, body_str); // (3)!

    // Calculate HMAC
    let mut mac = match HmacSha256::new_from_slice(OPENVIDU_MEET_API_KEY.as_bytes()) { // (4)!
        Ok(mac) => mac,
        Err(_) => return false,
    };

    mac.update(signed_payload.as_bytes());
    let expected = mac.finalize().into_bytes();
    let expected_hex = hex::encode(expected);

    // Timing-safe comparison
    if signature.len() != expected_hex.len() {
        return false;
    }

    let mut result = 0u8;
    for (a, b) in signature.bytes().zip(expected_hex.bytes()) { // (5)!
        result |= a ^ b;
    }
    result == 0
}
```

1. 1. Get the `x-signature` and `x-timestamp` headers from the request.
1. 2. Compare the `x-timestamp` header value with the current Unix timestamp. If the difference is greater than a predefined threshold (e.g., 2 minutes), reject it to prevent [replay attacks](https://en.wikipedia.org/wiki/Replay_attack) .
1. 3. Concatenate in a single string the `x-timestamp` header value + character `.` + the JSON request body.
1. 4. Create a HMAC SHA256 hash of the string of point 3) using your OpenVidu Meet API key as the key.
1. 5. Compare the computed hash of point 4) with the `x-signature` header value. Do a time safe comparisson to avoid [timing attacks](https://en.wikipedia.org/wiki/Timing_attack) . If they match, the request is valid.

## Failures and retries

OpenVidu Meet will automatically retry sending webhooks in case of failures. For example, if your server is down or returns an error response.

It will retry **5 times**, with an **exponential backoff** (meaning it will wait longer between each retry).

Info

Your server must respond with a **2xx HTTP status code** to acknowledge that you have received the webhook event. The timeout granted by OpenVidu Meet to do so is **5 seconds**. If your server takes longer than that to respond, or if it sends any status code other than 2xx, OpenVidu Meet will consider it a failure and trigger a retry.
# OpenVidu Platform

# 

## Build your real-time application with complete freedom using SDKs

## What is OpenVidu Platform?

OpenVidu Platform enables you to build real-time applications. You can build your new OpenVidu application from scratch, but it is also very easy to integrate OpenVidu in your already existing application.

OpenVidu is based on WebRTC technology and allows developing any kind of use case you can imagine: one-to-one calls, video conference rooms, massive live-streaming events, management and processing of drones and camera feeds...

OpenVidu is built on the best open source technologies: [LiveKit](https://livekit.io) , from which it inherits all its amazing SDKs to integrate it into your front-end and back-end applications, and [mediasoup](https://mediasoup.org) , from which it inherits the best performance and optimization for media routing.

OpenVidu is a custom fork of LiveKit, 100% compatible in terms of its API and SDKs, with the power of mediasoup at its core. This and other integrations provide improved performance, new features and facilitate the deployment and management of your self-hosted, production-grade cluster.

## Use cases

OpenVidu is a super versatile platform that can be used to build just about any kind of real-time application you can think of. Most common use cases can be classified into one of the following categories:

### Video conferencing

Video conferencing rooms are virtual spaces where two or more users can send video and audio and interact with each other in real-time. They can scale in size, from a simple 1-to-1 call to a massive video conference with thousands of participants. For example:

- A 1-to-1 **video-call center** to attend your customers face to face.
- An **e-health application** where doctors can treat their patients directly from it, in a private and secure manner using end-to-end encryption.
- A **banking application** where customers may sign a contract, live and recording the call as proof of it.
- A **webinar platform** where speakers can give their talks to large audiences, with the possibility of viewers temporarily turning their cameras to ask questions.

Info

If your use case actually fits into the video conferencing category, [**OpenVidu Meet**](../meet/) may be the perfect solution for you. Give it a try!

### Live-streaming

Live streaming applications allow one publisher to broadcast video to many viewers. It can be a single video feed, multiple video feeds (webcam and screen share) or there could be even multiple publishers. The general rule is that the ratio of viewers to publishers is very high, in the order of thousands.

Ultra-low latency live-streaming (below 300ms) allows for actual real-time interaction between the viewers and the publishers. This differs from traditional live-streaming platforms where the latency is usually in the order of seconds. In this way you can build applications like:

- A **TEDx-like application**, where a speaker can give a talk to a massive audience of thousands of viewers, who may communicate through a chat. Real time subtitles and translations can be added to the stream.
- An application to **stream sport events**, where viewers can switch between different cameras to watch the game from different angles to increase fan engagement.
- A **global live auction platform** where the auctioneer can be seen by the bidders in real-time with sub-second latency all around the world.

### AI Agents

AI has changed the world, forever. OpenVidu can be used to integrate any kind of AI agent in your in application, using real-time audio/video/data tracks as inputs for LLMs or any other kind of AI model. With these capabilities, you can expand your application to new horizons:

- Implement **real-time subtitles, translations, word-detection, sentiment analysis, profanity filter**, etc. in your video conferences.
- Add a **summary generator** to your video conference app, that can extract the most important parts of the conversation to be shared with the participants.
- Build a 1-to-1 **virtual assistant** that can speak naturally with your users, using the latest Text-To-Speech AI models.
- Implement **object detection** in your live-streaming app, to detect and track objects in real-time in the video feed.

### Robotics and embedded systems

The future lies in the integration of cameras and sensors in all kinds of devices, everywhere: industry, homes, public spaces, emergency services... OpenVidu can be used to receive and process video and audio streams from these devices, and doing so in real-time. For example:

- A **security system** to receive the feed of IP cameras and sending an alert when detecting a person.
- A **drone control system** to receive the video feed from each drone camera and securely record it. Any other sensor reading could also be sent to be synchronized later with the recorded video feed.
- A **real-time translation app** that uses the latest AI models to provide high-quality translations of spoken language in real time.

## OpenVidu application architecture

Every OpenVidu application consists of 3 main components:

- **Your OpenVidu deployment**: provides all the necessary infrastructure for streaming real-time audio and video. It is built upon **LiveKit server** and **mediasoup server**, but it can usually be treated as a black box where its internal aspects are not important: you just deploy it and connect your application to it. It can be a single server or a cluster, deployed on premises or in your cloud provider.
- **Your Application client**: runs in your user devices and interacts with the OpenVidu server through any **LiveKit client SDK**. As OpenVidu server is 100% compatible with LiveKit protocol, you can integrate any LiveKit client SDK in your Application client. Your users will join rooms as participants to send and receive real-time audio and video tracks. It needs a token generated by the Application server to join a room.
- **Your Application server**: interacts with the OpenVidu deployment through any **LiveKit server SDK**. As OpenVidu server is 100% compatible with LiveKit protocol, you can integrate any LiveKit server SDK in your application server. At a minimum, it is responsible for the generation of tokens for the Application client to join a room. But you can implement your own business logic managing rooms, participants and tracks from the safety of your Application server.

## Basic concepts

### Room

A Room is a virtual space where Participants can connect to send and receive media Tracks. Two Participants can only communicate if they are connected to the same Room.

### Participant

A Participant is a user connected to a specific Room. Each Participant can publish as many video and audio Tracks as needed, and subscribe to any other Participant's Tracks, as long as they are connected to the same Room.

### Track

A Track is a data flow of audio or video. Participants create them from a local media source (a webcam, a microphone, a screen share) and publish them into a Room. Other Participants of the same Room can subscribe to them.

With these three concepts you can build any kind of real-time application you can think of. The figure below shows two simple examples.

Room "Daily meeting" has 2 Participants: "Alice" is publishing Track "Webcam" and "Mic" and is receiving Track "Screen" from "Bob". "Bob" is publishing Track "Screen" and receiving Tracks "Webcam" and "Mic" from "Alice".

Room "Remote support" has 3 Participants: Participant "Dan" is not publishing any Track, but receiving all Tracks in the Room. Participant "Erin" is only receiving Track "Mic" from Participant "Carol", but not Track "Screen".

### Other concepts

Apart from these basic building blocks, there are other concepts that will be tipically used in your OpenVidu application. All of them are just special types of [Participants](#participant) that connect to Rooms to perform specific tasks:

- **Egress**: a process that exports media out of a Room. It is a special type of Participant that only subscribes to Tracks. It allows recording tracks to a file or streaming them to an external destination (via HLS or RTMP).
- **Ingress**: a process that imports media into a Room. It is a special type of Participant that only publishes Tracks. It allows bringing external media sources into a Room, such as an MP4 file, an IP camera or a RTMP stream.
- **Agents**: a process that performs AI-driven operations to the media of a Room. It is a special type of Participant that can both subscribe and publish Tracks, analyzing and/or modifying them in between. It allows implementing any AI task you can imagine: real-time subtitles, translations, object detection, AI voice bots, etc.

## OpenVidu Editions

OpenVidu is available in two editions:

- **OpenVidu** [COMMUNITY](/pricing/#openvidu-community): free to use. It is a single-server deployment and provides a custom LiveKit distribution with Egress, Ingress, S3 storage and monitoring. Ideal for development and testing, but also for medium-scale production deployments. You can host hundreds of simultaneous participants in your rooms by running OpenVidu Community in a sufficiently powerful server!
- **OpenVidu** [PRO](/pricing/#openvidu-pro): OpenVidu commercial edition. It is a multi-server deployment with all the features of OpenVidu Community plus 2x performance, scalability, fault tolerance and improved monitoring and observability. Ideal for large-scale production deployments with heavy traffic that require the highest standards. You can start with OpenVidu Community and upgrade to OpenVidu Pro when needed.

| Type of deployment            | [**OpenVidu Local (development)**](#openvidu-local-development)                                                                                                       | [**OpenVidu Single Node**](#openvidu-single-node)                                                                                                                                | [**OpenVidu Elastic**](#openvidu-elastic)                                                                     | [**OpenVidu High Availability**](#openvidu-high-availability)            |
| ----------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------ |
| **OpenVidu Edition**          | COMMUNITY PRO                                                                                                                                                         | COMMUNITY PRO                                                                                                                                                                    | PRO                                                                                                           | PRO                                                                      |
| **Suitability**               | For local development in your laptop                                                                                                                                  | For applications with medium user load                                                                                                                                           | For applications with dynamic user load that require scalability                                              | For applications where both scalability and fault tolerance are critical |
| **Features**                  | Friendly Docker Compose setup with Redis, Egress, Ingress, S3 storage and observability. With automatic certificate management to test across devices in your network | COMMUNITY Custom LiveKit distribution with Redis, Egress, Ingress, S3 storage and observability. PRO Same features but adding **2x performance** and **advanced observability**. | Same benefits as OpenVidu Single Node plus **2x performance**, **advanced observability** and **scalability** | Same benefits as OpenVidu Elastic plus **fault tolerance**               |
| **Number of servers**         | Your laptop                                                                                                                                                           | 1 Node                                                                                                                                                                           | 1 Master Node + N Media Nodes                                                                                 | 4 Master Nodes + N Media Nodes                                           |
| **Installation instructions** | [Install](self-hosting/local/)                                                                                                                                        | [Install](self-hosting/single-node/)                                                                                                                                             | [Install](self-hosting/elastic/)                                                                              | [Install](self-hosting/ha/)                                              |


This section compares OpenVidu to other videoconference/streaming solutions, to better understand what it is, what it is not, and what advantages and disadvantages it may have over them.

## OpenVidu Meet vs OpenVidu Platform

OpenVidu offers two different solutions suitable for different use cases. Find out which is the best for you here: [OpenVidu Meet vs OpenVidu Platform](../../openvidu-meet-vs-openvidu-platform/).

## OpenVidu vs LiveKit

First of all, and perhaps the most obvious question, how does OpenVidu differ from LiveKit, and what kind of relationship is there between them? This can be answered with four simple points:

- OpenVidu is a **fork of LiveKit**. It is 100% compatible with LiveKit: any application built for LiveKit is compatible with OpenVidu.
- OpenVidu is a **superset of LiveKit**. It provides all the open source features of LiveKit and supports all of its SDKs, but it also extends LiveKit with extra features, APIs and internal enhancements, most notably integration with [mediasoup](https://mediasoup.org/) .
- OpenVidu is a **production-ready self-hosted solution**. It offers an easy deployment process to self-host a high performance, fault-tolerant, scalable and observable cluster. OpenVidu provides an interactive installer that manages all the complexities, so you can quickly host a production deployment that would otherwise require advanced DevOps/SRE expertise.
- OpenVidu is a **support team** for self-hosted deployments. The OpenVidu team is made up of real-time experts with over a decade of experience in the field. We specialize in customer support and are always ready to help you bring your ideas to life.

OpenVidu is a custom fork of LiveKit, 100% compatible in terms of its API and SDKs, with the power of mediasoup at its core. This and other integrations provide improved performance, new features and facilitate the deployment and management of your cluster.

LiveKit comes in two flavors: [LiveKit Open Source](https://github.com/livekit/livekit) and [LiveKit Cloud](https://docs.livekit.io/home/cloud/) .

### OpenVidu COMMUNITY vs LiveKit Open Source

LiveKit Open Source is probably the most advanced and feature-rich open source WebRTC stack available today. It has a simple but very versatile API design, and has a large collection of SDKs to integrate into your application on both the frontend and backend. Regardless of your technology stack, there is sure to be a LiveKit Open Source SDK available for you! This is why OpenVidu is fully compatible with LiveKit protocols. You can use any LiveKit SDK to build your application, and it will work seamlessly with an OpenVidu deployment.

What does OpenVidu Community bring over LiveKit Open Source?

With OpenVidu Community you get a handful of features on top of LiveKit Open Source that will help with the development of your application:

- **Egress and Ingress services already integrated with a Redis instance**: LiveKit allows you to export media from a Room (for example recording it) or import media into a Room (for example ingesting a video file), using [Egress](https://docs.livekit.io/home/egress/overview/) and [Ingress](https://docs.livekit.io/home/ingress/overview/) services respectively. These modules are independent of LiveKit Server and must be correctly configured and connected via a shared Redis. When running OpenVidu Community you will have all these services properly integrated, so you can focus on developing your app without worrying about anything else.
- **S3 compatible storage for Egress recordings**: OpenVidu Community comes with an S3 compatible storage already configured to store [Egress](https://docs.livekit.io/home/egress/overview/) recordings ([Minio](https://min.io/) ).
- **Administration dashboard to monitor your Rooms**: OpenVidu comes with an administration dashboard that allows you to monitor the status of your Rooms. Not only in real time, but also historically: the number of participants, the number of published tracks, Egress and Ingress processes... This is a great tool to have when developing your app, as it can help to spot issues and debugging your application's logic. [See more](../self-hosting/production-ready/observability/openvidu-dashboard/).
- **OpenVidu Meet**: a fully-fledged, ready to use videoconference application. [See more](../../meet/).
- **Powerful and easy to use local development environment**: OpenVidu provides a Docker Compose based deployment designed for development and testing devices on your local network. It comes with automatic certificate management that makes it easy to test mobile devices in your LAN. [See more](../self-hosting/local/#accessing-your-local-deployment-from-other-devices-on-your-network).

### OpenVidu PRO vs LiveKit Open Source

Deploying LiveKit Open Source in production requires DevOps/SRE experience to operate your own network of media servers, load balance between them, maintain high uptime and monitor the health of your deployment. OpenVidu Pro makes this an easy process, hiding most of the complexities of such an advanced deployment. With OpenVidu Pro you can self-host a fault-tolerant, scalable and observable cluster, while doubling the original LiveKit Open Source performance to handle twice as many media streams with the same hardware.

### OpenVidu PRO vs LiveKit Cloud

LiveKit Cloud is the official SaaS solution for LiveKit. They manage the infrastructure, with a pricing model based on the total bandwidth consumed by your application. It offers certain advantages over LiveKit Open Source:

- Analytics and telemetry dashboard. LiveKit Open Source does not export any metrics or logs out-of-the-box.
- Massive Rooms for livestreams, where a theoretically unlimited number of viewers can be established for published tracks. In LiveKit Open Source one Room must fit in a single server. LiveKit Cloud overcomes this limitation with a mesh architecture where one media server can connect to other media servers to distribute the load.

Where does OpenVidu Pro stand in relation to LiveKit Cloud? **OpenVidu Pro aims to deliver the same advanced benefits as LiveKit Cloud, but as a self-hosted solution**. We intend to provide a performant, fault-tolerant, scalable and observable cluster that is easy to deploy, configure and administrate in your own infrastructure. For now, OpenVidu Pro brings:

- OpenVidu Pro provides a complete observability stack with Grafana, Loki, Promtail and Mimir, as well as OpenVidu Dashboard to visualize the data. [See more](../self-hosting/production-ready/observability/).
- We are currently working on supporting the same scalability as LiveKit Cloud to support big videoconferences and massive live streams. [See more](../self-hosting/production-ready/scalability/#big-videoconferences-and-massive-live-streams-working-on-it).

## OpenVidu vs SaaS solutions

This includes many services like [Agora](https://www.agora.io/) , [GetStream](https://getstream.io/) , [Daily](https://www.daily.co/) , [Vonage](https://www.vonage.com/communications-apis/video/) , [Jitsi as a Service](https://jaas.8x8.vc/#/) , [Whereby](https://whereby.com/) , [Zoom SDK](https://developers.zoom.us/docs/video-sdk/) , [Dolby Millicast](https://dolby.io/) , [Amazon Chime SDK](https://aws.amazon.com/chime/chime-sdk/) .

The main difference between OpenVidu and these services is who owns the infrastructure, and where your users' data flows. All these SaaS solutions provide:

- A public endpoint that your application connects to, so all media is routed through their servers.
- Different sets of SDKs to integrate with your application. Some more complete than others, and maybe some low-code options.
- A pricing model usually based on one of these two options: minutes-per-participant or total GBs of bandwidth consumed.

Using a SaaS provider is a great option for some use cases, but not all. **OpenVidu is designed to be self-hosted**. This allows you to have full control over your infrastructure and data, taking the most out of your own resources and complying with the most strict regulations. While having the best features provided by SaaS: scalability, fault tolerance, observability. See [Production ready](../self-hosting/production-ready/) for more information.

## OpenVidu vs SFUs

This includes projects such as [Kurento](https://doc-kurento.readthedocs.io/) , [mediasoup](https://mediasoup.org/) , [Pion](https://pion.ly/) , [Janus](https://janus.conf.meetecho.com/) , [Jitsi Videobridge](https://jitsi.org/jitsi-videobridge/) or [Medooze](https://github.com/medooze/sfu) .

These are all media servers. More specifically, they fall under the umbrella of the so-called **SFUs** (Selective Forwarding Units): they are able to receive media streams from different clients and *selectively forward* them to other clients, usually without transcoding or mixing the media.

SFUs are generally low-level tools. Using them directly to implement real-time applications requires a deep understanding of signaling protocols, codecs, networking and other low-level concepts. **OpenVidu is a higher-level abstraction compared to SFUs**. It internally uses SFUs to rely the media streams (more specifically [Pion](https://pion.ly/) and [mediasoup](https://mediasoup.org/) ), but hides all complexities to offer a simpler way to develop videoconferencing and live-streaming applications.

## OpenVidu vs mediasoup

[mediasoup](https://mediasoup.org/) is a [WebRTC SFU](#openvidu-vs-sfus). It is a minimalist media server with a super low level API that allows building custom real-time applications. Compared to other SFUs, mediasoup is well known for its outstanding performance.

OpenVidu uses mediasoup internally to transmit media streams. We have embedded mediasoup as the WebRTC engine right at the core of LiveKit Open Source, which allows OpenVidu to offer the fantastic APIs and SDKs of LiveKit while providing the cutting-edge performance of mediasoup. Learn more about mediasoup integration in section [Performance](../self-hosting/production-ready/performance/).

## OpenVidu vs Microsoft Teams, Google Meet, Zoom

All these well-known video conferencing tools are final applications that provide little to no customization at all. They are proprietary, closed-source apps designed to be used as-is, and they are not intended to be integrated into other systems.

OpenVidu is inherently different, as it provides a set of APIs and SDKs to integrate real-time video capabilities into your own application. In other words: **with OpenVidu you can easily build your own custom Microsoft Teams, Google Meet or Zoom-like application.** See [Use cases](../getting-started/#use-cases) for some examples of what you can build with OpenVidu.

# Developing your OpenVidu application

Here's a high-level overview of the steps involved in building an OpenVidu application:

1. **Launch an OpenVidu deployment**
1. **Use LiveKit Server SDK in your application server**
1. **Build the UI of your client application**
1. **Deploy OpenVidu and your application**

## 1. Launch an OpenVidu deployment

The quickest way is to use [OpenVidu local deployment](../self-hosting/local/).

If you feel like it, you can directly launch a production-ready deployment on **AWS**, **Azure** or **your own servers**. Check out the different options at [Deployment types](../self-hosting/deployment-types/).

## 2. Use LiveKit Server SDK in your application server

OpenVidu is fully compatibly with LiveKit APIs. This means that any LiveKit Server SDK can be used in your application server.

The only mandatory task to perform in your application server is:

- **Creating access tokens**. Your Participants will only be able to connect to your Rooms by using a valid access token. Visit the official documentation about [Authentication](https://docs.livekit.io/home/get-started/authentication/) to learn how to generate access tokens and which permissions you can assign to them.

There are other optional tasks that you can perform from your application server, depending on your requirements:

- **Manage your Rooms and Participants**: although most of your application logic will be in the frontend, you can also manage the logic of your Rooms and Participants from the security of your application backend. You can list, create, update and destroy Rooms and Participants. This is the official LiveKit documentation with all the available methods of the **[`RoomServiceClient`](https://docs.livekit.io/reference/server/server-apis/#RoomService-APIs)** exposed by the Server API. These methods are also available in all LiveKit Server SDKs.
- **Manage Egress and Ingress**: if your application needs some kind of recording, broadcasting or media ingestion, this operations must all be performed by your application server.
- **Receive Webhook events**: you can also listen to Webhook events in your application backend. In this way you can react to events happening in your Rooms: a Room has started, a Room has finished, a Participant has joined a Room, a Track has been published... Visit the official documentation about [Webhooks](https://docs.livekit.io/home/server/webhooks/) .
- **Publish Tracks from your backend**: this is only for advanced applications that require server-side media publishing. Publishing media from your backend is possible by using [LiveKit CLI](https://github.com/livekit/livekit-cli) , [Python SDK](https://github.com/livekit/python-sdks) , [Go SDK](https://pkg.go.dev/github.com/livekit/server-sdk-go) , [Node.js SDK](https://github.com/livekit/node-sdks) or [Rust SDK](https://github.com/livekit/rust-sdks) .

To get you started, here is a list of all available LiveKit Server SDKs and an application server tutorial using them. These tutorials are all set up to **generate access tokens** and **receive webhook events**, so they are perfect starting points for your application server.

[Node.js Tutorial](../tutorials/application-server/node/)

[Reference Docs](https://docs.livekit.io/server-sdk-js/)

[Go Tutorial](../tutorials/application-server/go/)

[Reference Docs](https://pkg.go.dev/github.com/livekit/server-sdk-go)

[Ruby Tutorial](../tutorials/application-server/ruby/)

[GitHub Repository](https://github.com/livekit/server-sdk-ruby)

[Java Tutorial](../tutorials/application-server/java/)

[GitHub Repository](https://github.com/livekit/server-sdk-kotlin)

[Python Tutorial](../tutorials/application-server/python/)

[GitHub Repository](https://github.com/livekit/python-sdks)

[Rust Tutorial](../tutorials/application-server/rust/)

[Reference Docs](https://docs.rs/livekit-api/latest/livekit_api/index.html)

[PHP Tutorial](../tutorials/application-server/php/)

[GitHub Repository](https://github.com/agence104/livekit-server-sdk-php)

[.NET Tutorial](../tutorials/application-server/dotnet/)

[GitHub Repository](https://github.com/pabloFuente/livekit-server-sdk-dotnet)

If your backend technology does not have its own SDK, you have two different options:

1. Consume the Server API directly: [Reference Docs](https://docs.livekit.io/reference/server/server-apis/)
1. Use the livekit-cli: [GitHub Repository](https://github.com/livekit/livekit-cli)

## 3. Build the UI of your client application

There are two main strategies to build the UI of your client application:

- **Use a high-level UI Components library**: you can use [Angular Components](../ui-components/angular-components/) and [React Components](../ui-components/react-components/) to quickly set up your UI with building blocks that manage the events and state of the Room for you.
- **Use a low-level client SDK**: if you want extensive control and maximum flexibility when designing your UI, use any of the [LiveKit Client SDKs](https://docs.livekit.io/reference/) .

The table below summarizes the key differences between these two strategies to help you make an informed decision:

|                 | UI Components                                                                                                                                                                                                              | Low-level client SDKs                                                                                                                                                          |
| --------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **What is it?** | Frontend libraries offering videoconferencing components to build your own application. There are [Angular Components](../ui-components/angular-components/) or [React Components](../ui-components/react-components/)     | Integrate OpenVidu from scratch in your web, mobile or desktop application using [LiveKit Client SDKs](https://docs.livekit.io/reference/)                                     |
| **Pros**        | - Very flexible components: adapt, extend or replace any component - Have your first version running in minutes, work on your customizations from there - Easily keep your client code up to date with the latest features | - Unlimited level of customization: build your own UI from scratch as you please - Available for all client platforms: browsers, iOS, Android, Flutter, React Native, Unity... |
| **Cons**        | - Only available for Angular and React web apps                                                                                                                                                                            | - Higher complexity, although there are plenty of tutorials to smooth the learning curve                                                                                       |
| **Tutorials**   | [Angular Components tutorials](../tutorials/angular-components/)                                                                                                                                                           | [Application client tutorials](../tutorials/application-client/)                                                                                                               |

Whatever strategy you choose to build the UI of your application, most common steps to perform are:

- **Connect to a Room with an access token**: the application client will connect to a Room with an access token generated by your application server. Once connected, the client becomes a Participant of the Room.
- **Publish Tracks to the Room**: the application client may create Tracks of any kind (audio from the microphone, video from the camera device, screen sharing from an application...) and publish them to the Room.
- **Subscribe to Tracks from other Participants**: the application client may receive the Tracks published by other Participants in the Room. It is possible to perform selective subscription, so the client can choose which Tracks to specifically subscribe to.
- **Mute and unmute Tracks**: the application client may mute and unmute its own Tracks, and also may disable the reception of any Track published by other Participants.

Of course, depending on the use case, this may not be necessary for all users, or other additional steps may need to be taken. For example, in a live-streaming application, only presenters will publish Tracks, while all other viewers will only subscribe to them. Or it is possible that users may need exchange messages through a chat. Each specific application will need to refine its use of the UI Components or client SDKs to meet its requirements.

Here is the list of all LiveKit Client SDKs: [LiveKit Client SDKs](https://docs.livekit.io/reference/) . Below is a list of application client tutorials, which are perfect starting points for your client application.

[**JavaScript**](../tutorials/application-client/javascript/)

[**React**](../tutorials/application-client/react/)

[**Angular**](../tutorials/application-client/angular/)

[**Vue**](../tutorials/application-client/vue/)

[**Electron**](../tutorials/application-client/electron/)

[**Ionic**](../tutorials/application-client/ionic/)

[**Android**](../tutorials/application-client/android/)

[**iOS**](../tutorials/application-client/ios/)

## 4. Deploy OpenVidu and your application

You have different options to deploy OpenVidu in a production-ready environment, depending on the level of scalability, fault tolerance and observability you need. See [Deployment types](../self-hosting/deployment-types/) for more information.

# How to develop your OpenVidu application

This page is a collection of the most common operations you may want to perform in your application while integrating OpenVidu. Depending on the scope of the operation, these operations will be performed on the client side using a LiveKit Client SDK, or on the server side using a LiveKit Server SDK (or directly using the HTTP server API). Consider the architecture of an OpenVidu application:

You can use this page as a cheat sheet to know at a glance how to do something, and you have links to the LiveKit reference documentation of each operation for a more detailed explanation.

> All client side operations are exemplified using the [LiveKit JS Client SDK](https://docs.livekit.io/client-sdk-js/modules.html) . For other client SDKs, refer to the corresponding LiveKit reference documentation.

### Generate access tokens

The application client needs an access token to connect to a Room. This token must be generated by the application server. Visit LiveKit reference documentation to learn how to generate access tokens:

> [Reference docs](https://docs.livekit.io/home/get-started/authentication/)

### Manage Rooms

#### Connect to a Room

To connect to a Room you need the URL of your OpenVidu deployment (which is a WebSocket URL) and the access token generated by your application server.

```typescript
import { Room } from "livekit-client";

const room = new Room();
await room.connect(wsUrl, token);
```

> [Reference docs](https://docs.livekit.io/home/client/connect/#connecting-to-a-room)

______________________________________________________________________

#### Disconnect from a Room

```typescript
await room.disconnect();
```

> [Reference docs](https://docs.livekit.io/home/client/connect/#disconnection)

______________________________________________________________________

#### Publish a Track

You can directly publish the default camera and microphone of the device using methods `setCameraEnabled` and `setMicrophoneEnabled` of the `LocalParticipant` object:

```typescript
// Publish a video track from the default camera
await room.localParticipant.setCameraEnabled(true);
// Publish an audio track from the default microphone
await room.localParticipant.setMicrophoneEnabled(true);
```

It is also possible to publish both of them at the same time using method `LocalParticipant.enableCameraAndMicrophone`, which has the advantage of showing a single permission dialog to the user:

```typescript
// Publish both default video and audio tracks triggering a single permission dialog
await room.localParticipant.enableCameraAndMicrophone();
```

To craft a custom Track, you can use the `LocalParticipant.createTracks` method and publish them with `LocalParticipant.publishTrack`:

```typescript
var tracks = await room.localParticipant.createTracks({
  audio: {
    deviceId: "default",
    autoGainControl: true,
    echoCancellation: true,
    noiseSuppression: true
  },
  video: {
    deviceId: 'frontcamera';
    facingMode: 'user'
  },
});
await Promise.all([
    room.localParticipant.publishTrack(tracks[0]),
    room.localParticipant.publishTrack(tracks[1]),
]);
```

> [Reference docs](https://docs.livekit.io/home/client/tracks/publish/)

______________________________________________________________________

#### Mute/Unmute a Track

To mute the default camera and microphone Tracks:

```typescript
await room.localParticipant.setCameraEnabled(false);
await room.localParticipant.setMicrophoneEnabled(false);
```

To mute/unmute a custom Track:

```typescript
// Mute the track
await track.mute();

// Unmute the track
await track.unmute();
```

> [Reference docs](https://docs.livekit.io/home/client/tracks/publish/#Mute-and-unmute)

______________________________________________________________________

#### Unpublish a Track

To completely stop sending a Track to the Room, you must unpublish it:

```typescript
await room.localParticipant.unpublishTrack(track, true);
```

The second boolean parameter indicates if the local Track should be stopped. This usually means freeing the device capturing it (switching off the camera LED, for example).

> [Reference docs](https://docs.livekit.io/client-sdk-js/classes/LocalParticipant.html#unpublishTrack)

______________________________________________________________________

#### Send messages

You can share information between Participants of a Room in different ways.

First of all, you can set Room metadata that will be available for all clients in the `Room` object. You do so in your application server when calling the [`CreateRoom` API](https://docs.livekit.io/reference/server/server-apis/#CreateRoom) (available for all LiveKit Server SDKs and the HTTP Server API). The Room metadata will be available in the client side like this:

```typescript
console.log(room.metadata);
```

You can update the Room metadata at any time from your application server with the [`UpdateRoomMetadata` API](https://docs.livekit.io/reference/server/server-apis/#UpdateRoomMetadata) (available for all LiveKit Server SDKs and the HTTP Server API). The client side will be notified of the change with the `roomMetadataChanged` event of the `Room` object:

```typescript
room.on("roomMetadataChanged", (metadata) => {
  console.log("New room metadata", metadata);
});
```

Secondly, you can also set Participant metadata. You do so when creating an [access token](https://docs.livekit.io/home/get-started/authentication/) in your application server, setting `metadata` field of the JWT.

Participants can also update their own metadata from the client side, if their access token was created with [grant `canUpdateOwnMetadata`](https://docs.livekit.io/home/get-started/authentication/#Video-grant) .

```typescript
room.localParticipant.setMetadata("new metadata");
```

The client side will be notified of the change with the `participantMetadataChanged` event of the `Room` and/or `Participant` object:

```typescript
// To handle all metadata changes of all participants
room.on(
  RoomEvent.ParticipantMetadataChanged,
  (previousMetadata: string, participant) => {
    console.log(
      "New metadata for participant",
      participant.identity,
      participant.metadata
    );
  }
);

// To handle only metadata changes of a specific participant
participant.on(
  ParticipantEvent.ParticipantMetadataChanged,
  (previousMetadata) => {
    console.log(
      "New metadata for participant",
      participant.identity,
      participant.metadata
    );
  }
);
```

Finally, you can send messages to Participants in the Room using the [`LocalParticipant.publishData`](https://docs.livekit.io/client-sdk-js/classes/LocalParticipant.html#publishData) method:

```typescript
const data: Uint8Array = new TextEncoder().encode(JSON.stringify(""));
room.localParticipant.publishData(data, {
  reliable: true,
  topic: "chat",
  destinationIdentities: ["participant-identity"],
});
```

The [`DataPublishOptions`](https://docs.livekit.io/client-sdk-js/types/DataPublishOptions.html) allow setting the reliability of the message (depending on the nature of the message it can be sent as a reliable or lossy message), a topic to easily filter messages, and the participants that will receive the message.

The client side will be notified of the message with the `dataReceived` event of the `Room` and/or `Participant` object:

```typescript
// To receive all messages from the Room
room.on(
  RoomEvent.DataReceived,
  (payload: Uint8Array, participant: Participant, kind: DataPacket_Kind) => {
    const strData = new TextDecoder().decode(payload);
    console.log("Received data from", participant.identity, strData);
  }
);

// To receive messages only from a specific participant
participant.on(
  ParticipantEvent.DataReceived,
  (payload: Uint8Array, kind: DataPacket_Kind) => {
    const strData = new TextDecoder().decode(payload);
    console.log("Received data from", participant.identity, strData);
  }
);
```

> [Reference docs](https://docs.livekit.io/home/client/data/)

______________________________________________________________________

#### From your application server

Except for the generation of [access tokens](#generate-access-tokens), it is possible for all the logic of your application to be contained entirely on the client side. Nonetheless, some use cases may require the management of the Rooms from the server side.

These operations are only available in the server SDKs, and not in the client SDKs:

- **Closing a Room**. From the client side, a user can only leave his own Room.
- **Removing any Participant from a Room**. From the client side, a user can only leave his own Room.
- **Muting any Track of any Participant**. From the client side, a user can only mute/unmute his own Tracks.
- **Updating the metadata of any Participant**. From the client side, a user can only update his own metadata.
- **Updating the metadata of the Room**. From the client side this is not possible.
- **Egress operations**. Egress cannot be started and stopped on demand by users from the client side.
- **Ingress operations**. Ingress cannot be started and stopped on demand by users from the client side.

You have here the complete list of the server-side operations, documented for the HTTP Server API. All the LiveKit Server SDKs have the same operations.

- [**RoomService**](https://docs.livekit.io/reference/server/server-apis/#RoomService-APIs) : to manage Rooms and Participants.
- [**Egress**](https://docs.livekit.io/home/egress/overview/#API) : to manage egress operations.
- [**Ingress**](https://docs.livekit.io/home/ingress/overview/#API) : to manage ingress operations.

### Screen Sharing

To quickly publish a screen sharing Track:

```typescript
await room.localParticipant.setScreenShareEnabled(true);
```

You can also create custom screen tracks, for example capturing the audio of the screen and fine-tuning the video capture options (checkout the [ScreenTrackOptions](https://docs.livekit.io/client-sdk-js/interfaces/ScreenShareCaptureOptions.html) interface for detailed information):

```typescript
const screenTracks = await room.localParticipant.createScreenTracks({
  audio: true,
  contentHint: "detail",
  preferCurrentTab: true,
  video: {
    displaySurface: "window",
  },
});
await Promise.all([
  room.localParticipant.publishTrack(screenTracks[0]),
  room.localParticipant.publishTrack(screenTracks[1]),
]);
```

> [Reference docs](https://docs.livekit.io/home/client/tracks/publish/#Screen-sharing)

### Virtual Background

It is possible to apply a virtual background to video tracks. In this way you can blur the background or replace it with an image.

It is necessary to install an additional dependency to use this feature:

```bash
npm add @livekit/track-processors
```

To blur the background:

```typescript
import { BackgroundBlur } from "@livekit/track-processors";

const videoTrack = await createLocalVideoTrack();
const blur = BackgroundBlur(10);
await videoTrack.setProcessor(blur);
```

To replace the background with an image:

```typescript
import { VirtualBackground } from "@livekit/track-processors";

const videoTrack = await createLocalVideoTrack();
const image = VirtualBackground("https://picsum.photos/400");
await videoTrack.setProcessor(image);
```

> [GitHub Repository](https://github.com/livekit/track-processors-js)

### Recording

You can record your Rooms using the Egress module. Egress allows exporting media from a Room in different formats, including

- **Room Composite Egress**: a single video output with all the Tracks of a Room composited in a layout. You can even create your custom layouts.
- **Track Composite Egress**: a single video output combining an audio Track and a video Track.
- **Track Egress**: individual outputs for each Track of a Room.

Visit the LiveKit reference documentation for a detailed explanation of Egress:

> [Reference docs](https://docs.livekit.io/home/egress/overview/)

### Stream ingestion

You can ingest media streams into your Rooms using the Ingress module. It supports different sources, including:

- **RTMP**: the Ingress module exposes an RTMP endpoint to which your user can stream their content. The ingress module will transcode and publish the stream to the Room, making it available to all participants.
- **WHIP**: the Ingress module exposes a WHIP endpoint to which your user can stream their content directly via WebRTC. You can choose whether the Ingress module should transcode the stream or directly relay it to the Room. Avoiding transcoding is the best option to minimize latency when ingesting media to a Room.
- **Media files serve by an HTTP server**: the Ingress module will fetch a media file, transcode it and publish it to the Room.
- **Media served by an SRT server**: the Ingress module will pull the media from an SRT server, transcode it and publish it to the Room.

Visit the LiveKit reference documentation for a detailed explanation of Ingress:

> [Reference docs](https://docs.livekit.io/home/ingress/overview/)

### IP Cameras

With OpenVidu you can ingest **RTSP** streams into your Rooms. To do so, simply use the [Ingress API](https://docs.livekit.io/home/ingress/overview/) to create and ingress of input type `URL`, providing the IP camera RTSP URL as value:

Using [LiveKit Node SDK](https://docs.livekit.io/server-sdk-js/)

```javascript
import { IngressClient, IngressInfo, IngressInput } from 'livekit-server-sdk';

const ingressClient = new IngressClient('https://my-openvidu-host', 'api-key', 'api-secret');

const ingress = {
  name: 'my-ingress',
  roomName: 'my-room',
  participantIdentity: 'my-participant',
  participantName: 'My Participant',
  url: 'rtsp://admin:pass@192.168.1.79/mystream'
};

await ingressClient.createIngress(IngressInput.URL_INPUT, ingress);
```

Using [LiveKit Go SDK](https://pkg.go.dev/github.com/livekit/server-sdk-go/v2)

```go
import (
  lksdk "github.com/livekit/server-sdk-go/v2"
  livekit "github.com/livekit/protocol/livekit"
)

ingressClient := lksdk.NewIngressClient(
    "https://my-openvidu-host",
    "api-key",
    "api-secret",
)

ingressRequest := &livekit.CreateIngressRequest{
    InputType:           livekit.IngressInput_URL_INPUT,
    Name:                "my-ingress",
    RoomName:            "my-room",
    ParticipantIdentity: "my-participant",
    ParticipantName:     "My Participant",
    Url:                 "rtsp://admin:pass@192.168.1.79/mystream",
}

ingressInfo, err := ingressClient.CreateIngress(context.Background(), ingressRequest)
```

Using [LiveKit Ruby SDK](https://github.com/livekit/server-sdk-ruby)

```ruby
require 'livekit'

ingressClient = LiveKit::IngressServiceClient.new("https://my-openvidu-host", api_key: "api-key", api_secret: "api-secret")
response = ingressClient.create_ingress(
  :URL_INPUT,
  name: "my-ingress",
  room_name: "my-room",
  participant_identity: "my-participant",
  participant_name: "My Participant",
  url: "rtsp://admin:pass@192.168.1.79/mystream",
)
if response.error
    puts "Error creating ingress: #{response.error}"
else
    ingressInfo = response.data
    puts "Ingress created: #{ingressInfo}"
end
```

Using [LiveKit Kotlin SDK](https://github.com/livekit/server-sdk-kotlin)

```java
import io.livekit.server.IngressServiceClient;
import livekit.LivekitIngress.IngressInfo;
import livekit.LivekitIngress.IngressInput;

IngressServiceClient ingressService = IngressServiceClient.createClient("https://my-openvidu-host", "api-key", "api-secret");

IngressInfo ingressInfo = ingressService.createIngress(
    "my-ingress", // Ingress name
    "my-room", // Room name
    "my-participant", // Ingress participant identity
    "My Participant", // Ingress participant name
    IngressInput.URL_INPUT, // Ingress input type
    null, null, null, null, // Other default options
    "rtsp://admin:pass@192.168.1.79/mystream" // Input URL
).execute().body();
```

Using [LiveKit Python SDK](https://github.com/livekit/python-sdks)

```python
from livekit.api import LiveKitAPI

lkapi = LiveKitAPI(
    url="https://my-openvidu-host", api_key="api-key", api_secret="api-secret"
)
request = CreateIngressRequest(
    url="rtsp://admin:pass@192.168.1.79/mystream",
    name="my-ingress",
    room_name="my-room",
    participant_identity="my-participant",
    participant_name="My Participant",
    input_type=IngressInput.URL_INPUT,
)
ingressInfo = await lkapi.ingress.create_ingress(request)
```

Using [LiveKit Rust SDK](https://github.com/livekit/rust-sdks)

```rust
use livekit_api::services::ingress::*;
use livekit_protocol::*;

let ingress_client = IngressClient::with_api_key(
    "https://my-openvidu-host",
    "api-key",
    "api-secret",
);
let ingress_info = ingress_client.create_ingress(
    IngressInput::UrlInput,
    CreateIngressOptions {
        name: "my-ingress".to_string(),
        room_name: "my-room".to_string(),
        participant_identity: "my-participant".to_string(),
        participant_name: "My Participant".to_string(),
        url: "rtsp://admin:pass@192.168.1.79/mystream".to_string(),
        ..Default::default()
    }).await;
```

Using [LiveKit PHP SDK](https://github.com/agence104/livekit-server-sdk-php)

```php
<?php
use Agence104\LiveKit\IngressServiceClient;
use Livekit\IngressInput;

$ingress_client = new IngressServiceClient("https://my-openvidu-host", "api-key", "api-secret");
$ingress_info = $ingress_client->createIngress(
  IngressInput::URL_INPUT,
  "my-ingress", // Ingress name
  "my-room", // Room name
  "my-participant", // Ingress participant identity
  "My Participant", // Ingress participant name
  NULL, NULL, NULL, // Other default options
  "rtsp://admin:pass@192.168.1.79/mystream" // Input URL
);
```

Using [LiveKit .NET SDK](https://github.com/pabloFuente/livekit-server-sdk-dotnet)

```csharp
using Livekit.Server.Sdk.Dotnet;

IngressServiceClient ingressServiceClient = new IngressServiceClient(
    "https://my-openvidu-host",
    "api-key",
    "api-secret"
);
var ingressInfo = await ingressServiceClient.CreateIngress(new CreateIngressRequest
{
    Name = "my-ingress",
    RoomName = "my-room",
    ParticipantIdentity = "my-participant",
    ParticipantName = "My Participant",
    InputType = IngressInput.UrlInput,
    Url = "rtsp://admin:pass@192.168.1.79/mystream",
});
```

If your backend technology does not have its own SDK, you have two different options:

1. Consume the Ingress API directly: [Reference Docs](https://docs.livekit.io/home/ingress/overview/#api)

1. Use the [livekit-cli](https://docs.livekit.io/home/cli/cli-setup/) :

   Create a file at `ingress.json` with the following content:

   ```json
   {
     "input_type": "URL_INPUT",
     "name": "Name of the Ingress goes here",
     "room_name": "Name of the room to connect to",
     "participant_identity": "Unique identity for the room participant the Ingress service will connect as",
     "participant_name": "Name displayed in the room for the participant",
     "url": "rtsp://admin:pass@192.168.1.79/mystream"
   }
   ```

   Then run the following commands:

   ```bash
   export LIVEKIT_URL=https://my-openvidu-host
   export LIVEKIT_API_KEY=api-key
   export LIVEKIT_API_SECRET=api-secret

   lk ingress create ingress.json
   ```

Many audio and video codecs are supported for ingesting IP cameras:

For video:

- H264
- VP8
- VP9
- MPEG4
- MJPEG

For audio:

- AAC
- MP3
- OPUS
- G711

### Webhooks

Your application server may receive webhooks coming from the OpenVidu deployment. These webhooks inform about events happening in the Rooms, including when a Room is created and finished, when a Participant joins and leaves a Room, when a Track is published and unpublished, and when Egress/Ingress operations take place in a Room.

Every application server tutorial here is ready to receive webhooks: [Application Server Tutorials](../../tutorials/application-server/).

Visit the LiveKit reference documentation for a detailed explanation of each webhook event:

> [Reference docs](https://docs.livekit.io/home/server/webhooks/)

# Advanced Features Tutorials

Explore more advanced features of LiveKit! For now, we have implemented a basic **recording** tutorial and an advanced one, but our tutorials for **streaming** and **ingesting** are coming soon.

[**Recording Basic S3**](recording-basic-s3/)

[**Recording Advanced S3**](recording-advanced-s3/)

[**Recording Basic Azure**](recording-basic-azure/)

[**Recording Advanced Azure**](recording-advanced-azure/)

# AI Services Tutorials

Explore these tutorials to learn how to integrate AI services in your OpenVidu applications:

[**Live Captions**](openvidu-live-captions/)

# Angular Components Tutorials

Angular Components

In the following tutorials you can learn how to use each one of the available [Angular Components](../../ui-components/angular-components/) to build your application UI tailored to your needs:

- [**Custom UI**](openvidu-custom-ui/): learn how to customize the UI, changing colors, shapes and add your branding logo.
- [**Custom toolbar**](openvidu-custom-toolbar/): learn how to replace the default toolbar with your own.
- [**Toolbar buttons**](openvidu-toolbar-buttons/): learn how to add custom buttons to the toolbar.
- [**Toolbar panel buttons**](openvidu-toolbar-panel-buttons/): learn how to add custom panel buttons to the toolbar.
- [**Custom layout**](openvidu-custom-layout/): learn how to replace the default layout with your own.
- [**Custom stream**](openvidu-custom-stream/): learn how to replace the default stream with your own.
- [**Custom panels**](openvidu-custom-panels/): learn how to replace the default panels with your own.
- [**Additional panel**](openvidu-additional-panels/): learn how to add a new extra panel besides the default ones.
- [**Custom chat panel**](openvidu-custom-chat-panel/): learn how to replace the default chat panel with your own.
- [**Custom activities panel**](openvidu-custom-activities-panel/): learn how to replace the default activities panel with your own.
- [**Custom participants panel**](openvidu-custom-participants-panel/): learn how to replace the default participants panel with your own.
- [**Custom participant panel item**](openvidu-custom-participant-panel-item/): learn how to replace the default participants panel item with your own.
- [**Custom participant panel item element**](openvidu-custom-participant-panel-item-element/): learn how to replace the default participant panel item element with your own.
- [**Toggle hand**](openvidu-toggle-hand/): learn how to add extra features to the videoconference.
- [**Admin dashboard**](openvidu-admin-dashboard/): learn how to add an admin dashboard to the videoconference.

# Application Client Tutorials

Every application client below shares the same core functionality:

- Users request a LiveKit token to any [application server](../application-server/) to connect to a room.
- Users may publish their camera, microphone and screen-share.
- Users automatically subscribe to all media published by other users.
- Users may leave the room at any time.

Every application client below is interchangeable with the others, because:

- All of them are compatible with each other, meaning that participants are able to join the same LiveKit room from any of the client applications.
- All of them are compatible with any [application server](../application-server/), meaning that they can request a LiveKit token from any of the server applications.

[**JavaScript**](javascript/)

[**React**](react/)

[**Angular**](angular/)

[**Vue**](vue/)

[**Electron**](electron/)

[**Ionic**](ionic/)

[**Android**](android/)

[**iOS**](ios/)

# Application Server Tutorials

Every application server below has two specific purposes:

- Generate LiveKit tokens on demand for any [application client](../application-client/).
- Receive LiveKit [webhook events](https://docs.livekit.io/home/server/webhooks/) .

To do so they all define two REST endpoints:

- `/token`: takes a room and participant name and returns a token.
- `/webhook`: for receiving webhook events from LiveKit Server.

They use the proper [LiveKit Server SDK](https://docs.livekit.io/reference/) for their language, if available.

[**Node.js**](node/)

[**Go**](go/)

[**Ruby**](ruby/)

[**Java**](java/)

[**Python**](python/)

[**Rust**](rust/)

[**PHP**](php/)

[**.NET**](dotnet/)

# Deployment types

OpenVidu offers **user-friendly installers** that facilitate quick **on-premises deployments**, so you can self-host your real-time solution in your own infrastructure or any cloud provider.

There are different deployment options available, depending on your needs:

| Type of deployment            | [**OpenVidu Local (development)**](#openvidu-local-development)                                                                                                       | [**OpenVidu Single Node**](#openvidu-single-node)                                                                                                                                | [**OpenVidu Elastic**](#openvidu-elastic)                                                                     | [**OpenVidu High Availability**](#openvidu-high-availability)            |
| ----------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------ |
| **OpenVidu Edition**          | COMMUNITY PRO                                                                                                                                                         | COMMUNITY PRO                                                                                                                                                                    | PRO                                                                                                           | PRO                                                                      |
| **Suitability**               | For local development in your laptop                                                                                                                                  | For applications with medium user load                                                                                                                                           | For applications with dynamic user load that require scalability                                              | For applications where both scalability and fault tolerance are critical |
| **Features**                  | Friendly Docker Compose setup with Redis, Egress, Ingress, S3 storage and observability. With automatic certificate management to test across devices in your network | COMMUNITY Custom LiveKit distribution with Redis, Egress, Ingress, S3 storage and observability. PRO Same features but adding **2x performance** and **advanced observability**. | Same benefits as OpenVidu Single Node plus **2x performance**, **advanced observability** and **scalability** | Same benefits as OpenVidu Elastic plus **fault tolerance**               |
| **Number of servers**         | Your laptop                                                                                                                                                           | 1 Node                                                                                                                                                                           | 1 Master Node + N Media Nodes                                                                                 | 4 Master Nodes + N Media Nodes                                           |
| **Installation instructions** | [Install](../local/)                                                                                                                                                  | [Install](../single-node/)                                                                                                                                                       | [Install](../elastic/)                                                                                        | [Install](../ha/)                                                        |

## OpenVidu Local (development)

To run OpenVidu in your local machine, this is the quickest option. It is a Docker Compose setup that includes all the necessary services to run OpenVidu in your LAN, including automated SSL certificates that will be valid across all devices in your network.

It comes in two flavors:

- **OpenVidu Local COMMUNITY**: mirrors the experience of **OpenVidu Single Node COMMUNITY**, fine-tuned for local development.
- **OpenVidu Local PRO**: mirrors the experience of **OpenVidu Single Node PRO**, fine-tuned for local development. In this case, OpenVidu runs in evaluation mode for free for development and testing purposes (some limits apply: maximum 8 Participants across all Rooms, maximum 5 minutes duration per Room).

OpenVidu Local (development)

## OpenVidu Single Node

This is the simplest production-ready OpenVidu deployment available. It provides all the features you need, but lacks scalability and fault tolerance. But make no mistake about it: it is perfectly suitable for medium-scale production deployments. For most projects OpenVidu Single Node will be enough, at least until your user load gets serious. You can host hundreds of simultaneous participants in your rooms by running OpenVidu Community on a sufficiently powerful server!

It is composed of a single OpenVidu Node hosting all the necessary services in a monolithic setup. It comes in two flavors:

- **OpenVidu Single Node COMMUNITY**: all the features you need to build your real-time application.
- **OpenVidu Single Node PRO**: for those users that want the benefits of OpenVidu PRO in a single-node setup. It includes **2x performance** and **advanced observability** features.

OpenVidu Single Node

## OpenVidu Elastic

This is the intermediate OpenVidu deployment. It provides **scalability** for your video rooms. Suitable for applications with dynamic load in the media plane that require scalability.

It is composed of two different types of nodes, one of them running on a cluster of multiple servers and the other running as a single monolithic server:

- **A cluster of Media Nodes** hosting all the media-related services. Your video rooms scale up and down thanks to this cluster.
- **A single Master Node** hosting all the support services in a monolithic setup.

OpenVidu Elastic

## OpenVidu High Availability

This is the most complete OpenVidu deployment. It provides **scalability** for your video rooms and **fault tolerance** in all its services. Suitable for applications where both scalability and availability are critical.

It is composed of two different types of nodes running on two separate clusters:

- **A cluster of Media Nodes** hosting all the media-related services. Your video rooms scale up and down thanks to this cluster. The minimum number of nodes in this cluster is **1**, and it is designed to scale up and down dynamically according to workload.
- **A cluster of Master Nodes** hosting all the support services in their high availability format. Your deployment is fault-tolerant thanks to this cluster. The minimum number of nodes in this cluster is **4**, and it is designed to have a fixed number of nodes at all times.

OpenVidu High Availability cluster

## Node services

OpenVidu is composed of several services that work together to provide a complete videoconferencing solution. Every service runs as a Docker container, coordinated with Docker Compose.

### Master Node services

| SERVICE                             | DESCRIPTION                                                                                                                                                                                                                                                                               |
| ----------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **[OpenVidu Meet](../../../meet/)** | A high-quality video calling service based on OpenVidu.                                                                                                                                                                                                                                   |
| **OpenVidu Dashboard**              | Web application interface for managing your cluster and visualizing your Rooms.                                                                                                                                                                                                           |
| **OpenVidu Operator**               | Module that supervises the high availability services and updates the loadbalancing configuration dynamically.                                                                                                                                                                            |
| **Redis**                           | Database used to share transient information between Media Nodes and coordinate them. In [OpenVidu High Availability](#openvidu-high-availability) this is an instance of a [Redis Cluster](https://redis.io/docs/latest/operate/oss_and_stack/management/scaling/) .                     |
| **MongoDB**                         | Database used to store analytics and monitoring persistent data. In [OpenVidu High Availability](#openvidu-high-availability) this is an instance of a [MongoDB Replica Set](https://www.mongodb.com/docs/manual/replication/) .                                                          |
| **Minio**                           | S3 bucket used to store recordings and common node configurations. In [OpenVidu High Availability](#openvidu-high-availability) this is an instance of a [Minio Multi-Node](https://min.io/docs/minio/linux/operations/install-deploy-manage/deploy-minio-multi-node-multi-drive.html#) . |
| **Caddy**                           | Reverse proxy used as a loadbalancer to distribute client connections across your nodes and automatically manage your TLS certificate.                                                                                                                                                    |
| **Mimir (observability)**           | Module used to store metrics from Prometheus.                                                                                                                                                                                                                                             |
| **Promtail (observability)**        | Module used to collect logs from all services and send them to Loki.                                                                                                                                                                                                                      |
| **Loki (observability)**            | Module used to store logs.                                                                                                                                                                                                                                                                |
| **Grafana (observability)**         | Module used to visualize logs and metrics in dashboards.                                                                                                                                                                                                                                  |

### Media Node services

| SERVICE                        | DESCRIPTION                                                                                                                                            |
| ------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **OpenVidu Server**            | Media server used to stream real-time video, audio and data. Based on SFUs LiveKit and mediasoup.                                                      |
| **Egress Server**              | Module used to export media from a Room (for example, recordings or RTMP broadcasting). See [Egress](https://docs.livekit.io/home/egress/overview/) .  |
| **Ingress Server**             | Module used to import media into a Room (for example, an MP4 video or an RTSP stream). See [Ingress](https://docs.livekit.io/home/ingress/overview/) . |
| **Agents**                     | Modules used to add AI capabilities to Rooms. See [AI Services](../../ai/overview/).                                                                   |
| **Caddy**                      | Reverse proxy used as a loadbalancer to distribute the load generated by the Media Nodes over the Minio, Mimir and Loki cluster.                       |
| **Prometheus (observability)** | Module used to collect metrics from OpenVidu Server and send them to Loki.                                                                             |
| **Promtail (observability)**   | Module used to collect logs from all services and send them to Loki.                                                                                   |

# OpenVidu Local installation (Development)

For development purposes, we provide an [easy to install local deployment](https://github.com/OpenVidu/openvidu-local-deployment) based on Docker Compose which will automatically configure all the necessary services for OpenVidu to develop and test your applications seamlessly.

## Installation instructions

First, make sure you have the following prerequisites:

- Install [Docker Desktop](https://docs.docker.com/desktop/install/windows-install/)

- Install [Docker Desktop](https://docs.docker.com/desktop/install/mac-install/)

- Install [Docker](https://docs.docker.com/engine/install/#supported-platforms)

- Install [Docker Compose](https://docs.docker.com/compose/install/linux/)

The installation consists of cloning a repository and running a script to configure your local IP address in the deployment. Then, you can start, stop, and manage your deployment with Docker Compose.

To install OpenVidu locally, follow these steps:

1. Clone the following repository:

   ```bash
   git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.1
   ```

   Info

   To use a specific OpenVidu version, switch to the desired tag with `git checkout <version>`, e.g., `git checkout 3.0.0`. By default, the latest version is used.

1. Configure the local deployment

   ```powershell
   cd openvidu-local-deployment/community
   .\configure_lan_private_ip_windows.bat
   ```

   ```bash
   cd openvidu-local-deployment/community
   ./configure_lan_private_ip_macos.sh
   ```

   ```bash
   cd openvidu-local-deployment/community
   ./configure_lan_private_ip_linux.sh
   ```

1. Run OpenVidu

   ```bash
   docker compose up
   ```

1. Clone the following repository:

   ```bash
   git clone https://github.com/OpenVidu/openvidu-local-deployment -b 3.4.1
   ```

   Info

   To use a specific OpenVidu version, switch to the desired tag with `git checkout <version>`, e.g., `git checkout 3.0.0`. By default, the latest version is used.

1. Configure the local deployment

   ```powershell
   cd openvidu-local-deployment/pro
   .\configure_lan_private_ip_windows.bat
   ```

   ```bash
   cd openvidu-local-deployment/pro
   ./configure_lan_private_ip_macos.sh
   ```

   ```bash
   cd openvidu-local-deployment/pro
   ./configure_lan_private_ip_linux.sh
   ```

1. Run OpenVidu

   ```bash
   docker compose up
   ```

Info

**OpenVidu PRO** runs locally in evaluation mode for free for development and testing purposes. Some limits apply:

- Maximum 8 Participants across all Rooms
- Maximum 5 minutes duration per Room

For a production environment, you need to [create an OpenVidu account](/account/) to get a license key. There's a 15 day free trial waiting for you!

The deployment is ready when you see the following message:

```text
 =========================================
 🎉 OpenVidu is ready! 🎉
 =========================================

 OpenVidu Server && LiveKit Server URLs:

     - From this machine:

         - http://localhost:7880
         - ws://localhost:7880

     - From other devices in your LAN:

         - https://xxx-yyy-zzz-www.openvidu-local.dev:7443
         - wss://xxx-yyy-zzz-www.openvidu-local.dev:7443

 =========================================

 OpenVidu Developer UI (services and passwords):

     - http://localhost:7880
     - https://xxx-yyy-zzz-www.openvidu-local.dev:7443

 =========================================
```

By visiting <http://localhost:7880> you have the OpenVidu Developer UI available with a summary of the services and passwords deployed. You can access the following services:

- **OpenVidu API (LiveKit compatible)** (<http://localhost:7880>): the main API endpoint for your OpenVidu and LiveKit applications. OpenVidu v2 compatibility API is only available in **OpenVidu PRO**.
- **OpenVidu Dashboard** (<http://localhost:7880/dashboard>): a web application interface to visualize your Rooms, Ingress and Egress services.
- **MinIO** (<http://localhost:7880/minio-console>): as an S3 storage service for recordings.
- **OpenVidu Meet** (<http://localhost:9080>): a high-quality video calling service based on OpenVidu.

You just need to point your OpenVidu and LiveKit applications to `http://localhost:7880` or `ws://localhost:7880` and start developing. Check our [tutorials](../../tutorials/application-client/) if you want a step-by-step guide to develop your first application using OpenVidu.

## Configuration

### Configure your Application to use the Local Deployment

To point your applications to your local OpenVidu Local deployment, check the credentials at <http://localhost:7880> or simply check the `.env` file. All access credentials of all services are defined in this file.

Your authentication credentials and URLs to point your applications to are:

- **URL**: It must be `ws://localhost:7880` or `http://localhost:7880` depending on the SDK you are using.
- **API Key**: The value in `.env` of `LIVEKIT_API_KEY`
- **API Secret**: The value in `.env` of `LIVEKIT_API_SECRET`

Your authentication credentials and URLs to point your applications to are:

- Applications developed with LiveKit SDK:

  - **URL**: It must be `ws://localhost:7880/` or `http://localhost:7880/` depending on the SDK you are using.
  - **API Key**: The value in `.env` of `LIVEKIT_API_KEY`
  - **API Secret**: The value in `.env` of `LIVEKIT_API_SECRET`

- Applications developed with OpenVidu v2:

  - **URL**: The value in `.env` of `DOMAIN_NAME` as a URL. For example, `http://localhost:7880`
  - **Username**: `OPENVIDUAPP`
  - **Password**: The value in `.env` of `LIVEKIT_API_SECRET`

If you want to use the OpenVidu Local deployment from other devices on your network, follow the instructions in the [next section](#accessing-your-local-deployment-from-other-devices-on-your-network).

### Configuring webhooks

To configure webhooks in your local deployment, simply go to the file `livekit.yaml` and add to the `webhooks` section the URL where you want to receive the events:

```yaml
webhook:
    <LIVEKIT_API_KEY>:<LIVEKIT_API_SECRET>:
    urls:
        - <YOUR_WEBHOOK_URL>
```

In case you are using the *v2compatibility* and you want to receive webhooks for OpenVidu v2 applications, you can configure the webhooks in the `.env` file. For example:

```yaml
V2COMPAT_OPENVIDU_WEBHOOK_ENDPOINT=<YOUR_WEBHOOK_URL>
```

Where `<YOUR_WEBHOOK_URL>` is the URL where you want to receive the events.

## Accessing your local deployment from other devices on your network

Testing WebRTC applications can be challenging because devices require a secure context (HTTPS) to access the camera and microphone. When using LiveKit Open Source, this isn't an issue if you access your app from the same computer where the LiveKit Server is running, as `localhost` is considered a secure context even over plain HTTP. Consider the following architecture:

The simplest way to test your application is:

1. Run LiveKit Server on your computer.
1. Connect your app to LiveKit Server through `localhost`.
1. Serve both your application client and server from the same computer.
1. Access your app from `localhost` in a browser on the same computer.

This setup is straightforward, but what if you need to test your app from multiple devices simultaneously, including real mobile devices? In this case, you must use a secure context (HTTPS), which introduces two challenges:

1. LiveKit Server open source does not natively support HTTPS. You'll need a reverse proxy to serve LiveKit Server over HTTPS.
1. Even with HTTPS, your SSL certificate might not be valid for local network addresses. You'll need to accept it in the browser for web apps, and install it on mobile devices.

OpenVidu Local Deployment addresses these issues by providing a magic domain name `openvidu-local.dev` that resolves to any IP specified as a subdomain and provides a valid wildcard certificate for HTTPS. This is similar to services like [nip.io](https://nip.io) , [traefik.me](https://traefik.me), or [localtls](https://github.com/Corollarium/localtls).

When using OpenVidu Local Deployment, you can access OpenVidu Server (which is 100% LiveKit compatible) and your app from any device on your local network with a valid HTTPS certificate. The following table shows the URLs to access the deployment and your application locally and from other devices on your network:

|                                   | Local access                             | Access from devices in your local network                                                                                                                                                                                                                                                                   |
| --------------------------------- | ---------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Usage                             | Access only from the development machine | Access from any device connected to your local network. In the URLs below, replace **`xxx-yyy-zzz-www`** with the local IP address of the development machine, replacing the dots (`.`) with dashes (`-`). You can find the configured local IP in the **`.env`** file in the **`LAN_PRIVATE_IP`** variable |
| Application Client (frontend)     | <http://localhost:5080>                  | <https://xxx-yyy-zzz-www.openvidu-local.dev:5443>                                                                                                                                                                                                                                                           |
| Application Server (backend)      | <http://localhost:6080>                  | <https://xxx-yyy-zzz-www.openvidu-local.dev:6443>                                                                                                                                                                                                                                                           |
| OpenVidu (LiveKit Compatible) URL | <http://localhost:7880>                  | <https://xxx-yyy-zzz-www.openvidu-local.dev:7443>                                                                                                                                                                                                                                                           |

Info

- If you are developing locally, use `localhost` to access the services, but if you want to test your application from other devices on your network, use the `openvidu-local.dev` URLs.
- Replace `xxx-yyy-zzz-www` with your local IP address. You can find it in the `.env` file in the `LAN_PRIVATE_IP` variable.

Warning

If the URL isn't working because the IP address is incorrect or the installation script couldn't detect it automatically, you can update the `LAN_PRIVATE_IP` value in the `.env` file and restart the deployment with `docker compose up`.

When developing web applications with this deployment, you can use the following code snippet to dynamically determine the appropriate URLs for the application server and the OpenVidu server based on the browser's current location. This approach allows you to seamlessly run your application on both your development machine and other devices within your local network without needing to manually adjust the URLs in your code.

```javascript
if (window.location.hostname === "localhost") {
  APPLICATION_SERVER_URL = "http://localhost:6080";
  OPENVIDU_URL = "ws://localhost:7880";
} else {
  APPLICATION_SERVER_URL = "https://" + window.location.hostname + ":6443";
  OPENVIDU_URL = "wss://" + window.location.hostname + ":7443";
}
```

## About `openvidu-local.dev` domain and SSL certificates

This setup simplifies the configuration of local OpenVidu deployments with SSL, making it easier to develop and test your applications securely on your local network by using the `openvidu-local.dev` domain and a wildcard SSL certificate valid for `*.openvidu-local.dev`. However, it’s important to note that these certificates are publicly available and do not provide an SSL certificate for production use.

The HTTPS offered by `openvidu-local.dev` is intended for development or testing purposes with the only goal of making your local devices trust your application (which is mandatory in WebRTC applications). For any other use case, it should be treated with the same security considerations as plain HTTP.

For production, you should consider deploying a [production-grade OpenVidu deployment](../deployment-types/#openvidu-single-node).

# OpenVidu Single Node COMMUNITY installation

OpenVidu Single Node COMMUNITY is a production-ready deployment option that provides all the necessary features for running real-time applications with medium user load.

Install OpenVidu Single Node COMMUNITY in your preferred environment:

- [**On-premises installation**](on-premises/install/): set up on your own servers.
- [**AWS installation**](aws/install/): deploy to Amazon Web Services.
- [**Azure installation**](azure/install/): deploy to Microsoft Azure.
- [**Google Cloud Platform installation**](gcp/install/): deploy to Google Cloud Platform.

Once your deployment is complete, refer to the following sections for configuration and management:

- [**On-premises: configuration and administration**](on-premises/admin/)
- [**AWS: configuration and administration**](aws/admin/)
- [**Azure: configuration and administration**](azure/admin/)
- [**Google Cloud Platform: configuration and administration**](gcp/admin/)

If you want to upgrade your OpenVidu Single Node COMMUNITY installation, refer to this section:

- [**On-premises: upgrade OpenVidu Single Node Community**](on-premises/upgrade/)
- [**AWS: upgrade OpenVidu Single Node Community**](aws/upgrade/)
- [**Azure: upgrade OpenVidu Single Node Community**](azure/upgrade/)
- [**Google Cloud Platform: upgrade OpenVidu Single Node Community**](gcp/upgrade/)

# OpenVidu Single Node PRO installation

OpenVidu Single Node PRO brings all the features of OpenVidu Single Node COMMUNITY plus [**2x performance**](../production-ready/performance/) and [**advanced observability**](../production-ready/observability/). It is aimed to users that want a single-node setup but still want OpenVidu PRO features.

Info

Scalability and fault tolerance require a multi-node setup. If you need them, consider using [OpenVidu Elastic](../elastic/) or [OpenVidu High Availability](../ha/).

Install OpenVidu Single Node PRO in your preferred environment:

- [**On-premises installation**](on-premises/install/): set up on your own servers.
- [**AWS installation**](aws/install/): deploy to Amazon Web Services.
- [**Azure installation**](azure/install/): deploy to Microsoft Azure.

Once your deployment is complete, refer to the following sections for configuration and management:

- [**On-premises: configuration and administration**](on-premises/admin/)
- [**AWS: configuration and administration**](aws/admin/)
- [**Azure: configuration and administration**](azure/admin/)

If you want to upgrade your OpenVidu Single Node PRO installation, refer to this section:

- [**On-premises: upgrade OpenVidu Single Node PRO**](on-premises/upgrade/)
- [**AWS: upgrade OpenVidu Single Node PRO**](aws/upgrade/)
- [**Azure: upgrade OpenVidu Single Node PRO**](azure/upgrade/)

# OpenVidu Elastic installation

OpenVidu Elastic is part of the PRO edition of OpenVidu. You have the following deployment options:

- [**On-premises installation**](on-premises/install/): Set up OpenVidu Elastic on your own servers.
- [**AWS installation**](aws/install/): Deploy OpenVidu Elastic on Amazon Web Services.
- [**Azure installation**](azure/install/): Deploy OpenVidu Elastic on Microsoft Azure.

Once your deployment is complete, refer to the following sections for configuration and management:

- [**On-premises: configuration and administration**](on-premises/admin/)
- [**AWS: configuration and administration**](aws/admin/)
- [**Azure: configuration and administration**](azure/admin/)

If you want to upgrade your OpenVidu Elastic installation, refer to this section:

- [**Upgrade OpenVidu Elastic On-premises**](on-premises/upgrade/)
- [**Upgrade OpenVidu Elastic AWS**](aws/upgrade/)
- [**Upgrade OpenVidu Elastic Azure**](azure/upgrade/)

# OpenVidu High Availability installation

OpenVidu High Availability is part of the PRO edition of OpenVidu. You have the following deployment options:

- [**On-premises installation (DNS Load Balancing)**](on-premises/install-dlb/): Set up OpenVidu High Availability on your own servers with a DNS Load Balancing mechanism.
- [**On-premises installation (Network Load Balancer)**](on-premises/install-nlb/): Set up OpenVidu High Availability on your own servers with a Network Load Balancer.
- [**AWS installation**](aws/install/): Deploy OpenVidu High availability on Amazon Web Services.
- [**Azure installation**](azure/install/): Deploy OpenVidu High Availability on Microsoft Azure.

Once your deployment is complete, refer to the following sections for configuration and management:

- [**On-premises: configuration and administration**](on-premises/admin/)
- [**AWS: configuration and administration**](aws/admin/)
- [**Azure: configuration and administration**](azure/admin/)

If you want to upgrade your OpenVidu High Availability installation, refer to this section:

- [**Upgrade OpenVidu High Availability On-premises**](on-premises/upgrade/)
- [**Upgrade OpenVidu High Availability AWS**](aws/upgrade/)
- [**Upgrade OpenVidu High Availability Azure**](azure/upgrade/)

# Production ready

OpenVidu is designed to be **self-hosted**, whether it is on premises or in a cloud provider. It brings to your own managed service advanced capabilities usually reserved only for SaaS solutions. There are two main reasons why you may need to self-host the real-time solution yourself:

- **Privacy**: you can't afford to let your client's data get out of your reach. OpenVidu allows you to meet all your privacy and regulatory requirements: no data at all is sent to any third-party server. Everything is self-contained on your own servers.
- **Leverage your resources**: your organization has access to its own infrastructure that can be used to host these services. SaaS solutions generally offer complete freedom from infrastructure management, but this comes with generally high prices that cover both the provider's infrastructure and their service surcharge. OpenVidu allows taking full advantage of your own infrastructure, reducing costs and increasing performance.

It is important to mention that when we talk about self-hosting OpenVidu, we don't just mean installing it in bare-metal servers or private VPCs. OpenVidu also supports deployments in the most popular cloud providers, using their native services when possible. **AWS** and **Azure** are currently supported, and others are coming soon. You can learn more about the different options to deploy OpenVidu in the [deployment types](../deployment-types/) section.

One of OpenVidu's main goals is offering a self-hosted, production-ready live-video platform with all the advanced capabilities typically reserved for SaaS solutions. This includes outstanding **performance**, **scalability**, **fault tolerance** and **observability**:

- **Performance**

  ______________________________________________________________________

  OpenVidu is built to be incredibly powerful. It is based on the best open source WebRTC stacks: [LiveKit](https://livekit.io/) and [mediasoup](https://mediasoup.org/) . By combining the best of both worlds, OpenVidu provides outstanding performance.

  [Learn more about performance](performance/)

- **Scalability**

  ______________________________________________________________________

  OpenVidu has been designed from the outset with scalability in mind. Host videoconference rooms and large live streams with hundreds of participants. Autoscale your cluster to adapt to the demand and optimize your resources.

  [Learn more about scalability](scalability/)

- **Fault Tolerance**

  ______________________________________________________________________

  OpenVidu offers fault tolerance in all its components. Deploy a reliable high-availability cluster knowing that if one of your node goes down, others will be able to continue working with no downtime.

  [Learn more about fault tolerance](fault-tolerance/)

- **Observability**

  ______________________________________________________________________

  OpenVidu brings everything necessary to monitor the status, health, load and history of your deployment. It automatically collects events, metrics and logs, and provides [OpenVidu Dashboard](observability/openvidu-dashboard/) and a [Grafana stack](observability/grafana-stack/) to navigate them.

  [Learn more about observability](observability/)

# Performance

OpenVidu is able to handle up to **2x** the load in a single server, doubling the amount of media Tracks that can be transmitted compared to base LiveKit. By not only building upon the giant Open-Source shoulders of LiveKit, but also pushing the bar further, OpenVidu uses the best-in-class technologies to bring considerable performance improvements to the table.

The key element of any WebRTC server solution is the ability to exchange media between participants of a room, in the so-called [WebRTC SFU](../../../comparing-openvidu/#openvidu-vs-sfus). LiveKit implements its own SFU, and that's where OpenVidu makes a different choice by using [mediasoup](https://mediasoup.org/) .

The key points of how this works are:

- On the surface, OpenVidu is the same than LiveKit, and for the most part features work equally, such as connection establishment, participant management, and SDK support.
- Internally however, **mediasoup** is used to replace the original WebRTC engine implementation of LiveKit. *mediasoup* is built with the most efficient technologies and has outstanding low-level optimizations, which translates in a **2x** improvement with respect to the original LiveKit Open Source performance.

## About mediasoup integration

### Architecture

LiveKit created its own WebRTC SFU, based on the [Pion](https://github.com/pion/webrtc) library to route media between participants:

OpenVidu is built by a team of expert WebRTC developers who know all the ins and outs of low-level WebRTC development, so it was possible to replace LiveKit's own implementation with an alternative, and *mediasoup* was the clear best choice given its fantastic performance characteristics:

This means that applications built on top of LiveKit will continue to work exactly the same, while the internal WebRTC engine inside the server can be swapped at will and applications can benefit from that change, without having to be rebuilt.

In terms of the signaling protocol, API and SDKs, OpenVidu maintains the original LiveKit implementation. LiveKit's API is very well designed, with a simple but powerful [set of concepts](../../../getting-started/#basic-concepts), and the amount of SDKs available is very large.

### Choice of technology

Both LiveKit and Pion are written in the [Go programming language](https://go.dev/) , and this has some implications for speed and efficiency. While Go is popular for its simplicity, readability, and approach to concurrency, when it comes to performance other alternatives rank higher in common benchmarks.

First and foremost, the two most defining limitations of Go is that it requires a quite heavy runtime that is able to handle all of the low-level features of the language, such as *goroutines* and memory allocations. Also, speaking of memory management, Go requires a Garbage Collector, which knowledgeable readers will recognize as a hindrance for performance-critical applications.

*mediasoup*, on the other hand, focuses all of its efforts on maximum efficiency. It is written in [C++](https://isocpp.org/) , and it is ultra-optimized for the specific task of routing media packets. C++ is a language that provides fully manual management of all resources, and direct access to the hardware, with the benefit of software that is as fast as it can be on any machine.

We believe that by combining the best of the LiveKit stack with a top-notch WebRTC engine like *mediasoup*, OpenVidu is the best option for those who need a self-hosted and high-performance real-time solution.

## Limitations

OpenVidu developers are hard at work with integrating *mediasoup* as a WebRTC engine within LiveKit, aiming to provide feature parity with the original Pion engine.

Currently there are two [client SDK events](https://docs.livekit.io/home/client/events/#Events) that are not triggered when using mediasoup:

- No `ConnectionQualityChanged` event ([LiveKit JS reference](https://docs.livekit.io/reference/client-sdk-js/enums/RoomEvent.html#connectionqualitychanged) ).
- No `TrackStreamStateChanged` event ([LiveKit JS reference](https://docs.livekit.io/reference/client-sdk-js/enums/RoomEvent.html#trackstreamstatechanged) ).

Also, there are other limitations that must be taken into account:

- All clients will use VP8 video codec.
- Ingress will force VP8 video codec and will disable simulcast.
- Screen sharing with simulcast may result in low-resolution video. It is recommended to disable simulcast for screen sharing video tracks to ensure good quality.

## Benchmarking

Numerous load tests have been performed to determine the true capabilities of OpenVidu on different hardware. To do so we have developed the tool [Openvidu LoadTest](https://github.com/OpenVidu/openvidu-loadtest) : an in development project that aims to improve the precision of load and performance tests in WebRTC systems.

We have compared OpenVidu using the original **Pion** WebRTC engine (this is the default LiveKit Open Source implementation) and using **mediasoup** as WebRTC engine. We tested the performance for both cases in the scenario below.

### Results: Conference rooms

This tests increasingly adds Rooms of 8 Participants each, every one sending 1 video Track and 1 audio Track, and subscribing to all remote Tracks.

The following plot shows the number of Participants that can be added to a Room in OpenVidu using Pion and using mediasoup as WebRTC engines:

The conclusion is that for multiple Rooms, mediasoup performs much better than Pion, almost doubling the total number of Participants (and Tracks) that fit in the server.

Below there is the deatiled connection progression for each Participant in each test.

The X axis reflects the point of time in seconds. For each Participant there is a bar indicating its connection status:

- An orange bar indicates that the browser is up, but the connection to the media server is still in progress.
- A green bar indicates that the connection is up and running.
- A red bar indicates that the connection has failed, indicating the time that it's down.

CPU load of the server is also shown with a black marked plot (from 0 to 1, representing 0% to 100% CPU load).

Progression of the connection of each Participant through the test execution. Benchmark test for Rooms with 8 Participants using OpenVidu with Pion

Progression of the connection of each Participant through the test execution. Benchmark test for Rooms with 8 Participants using OpenVidu with mediasoup

### Benchmarking technical details

- Each participant sending video and audio to the media server uses the following video in loop: [Video](https://openvidu-loadtest-mediafiles.s3.amazonaws.com/interview_480p_30fps.y4m) . The video is in `YUV4MPEG2` format and with a `640x480` resolution. The audio is in WAV format: [Audio](https://openvidu-loadtest-mediafiles.s3.amazonaws.com/interview.wav) .
- All tests were done using AWS EC2 instances. The media server runs with a `m6in.xlarge` instance type, an instance type with 4 vCPUs and better network capabilities compared to other instance types.
- The workers running the browsers that act as participants ran in `c5.xlarge` instances, an instance type with 4 vCPUs with better computing capabilities.

### Benchmarking methodology

Each test begins with no participants on the media server. First, the test controller creates EC2 instances to host the browsers. The controller then sends a request to create a number of participants (this number is known as the batch size). After each browser sends confirmation to the controller that it is connected, the controller sends another request to add more participants (as many participants as the batch size specifies). A participant is considered connected to the room if:

- If the participants sends video and audio, the participant is connected after confirming that both local tracks are being sent correctly.
- If the participant acts as viewer (is only receiving video and audio from a different participant), the participant is connected when it confirms that it is receiving at least both tracks from a user in the room.

The test stops when it determines that no more users can be added to a room. This happens when a user has 5 failed connections. A connection is considered to have failed when it terminates with a fatal error (in LiveKit this is captured when a [`Disconnected`](https://docs.livekit.io/home/client/events/#Events) event occurs) or when the connection times out. A failure in connection can occur when trying to join a room (ending usually in timeout) or during the connection (a `Disconnected` event is thrown). Each time a failure is communicated to the controller, it will kill that browser and restart it again, effectively restarting the connection (up to 5 times, as mentioned before).

### About OpenVidu LoadTest

Tools like [livekit-cli](https://github.com/livekit/livekit-cli) simulate participants directly using WebRTC SDKs, but we found out that **real browsers add significantly more load** than these kind of systems. This makes [Openvidu LoadTest](https://github.com/OpenVidu/openvidu-loadtest) give results that are closer to real-world scenarios. Using real browsers also allows for the collection of useful data related to connections, events and WebRTC statistics. On the other hand, tests performed with Openvidu LoadTest are more expensive, as they require real instances to host the browsers.

# Scalability

Scalability is a very broad term with implications on many levels. In the case of real-time applications, it usually refers to the number of simultaneous Rooms you can host and the maximum number of participants in each Room, or more accurately, the number of media tracks sent and received in each Room.

OpenVidu offers scalability out-of-the-box for typical **videoconferencing** use cases, but also for large low-latency **live streams** with hundreds of viewers. With **OpenVidu Elastic** and **OpenVidu High Availability** you can easily scale your deployment to host many simultaneous videoconferences and live streams. And it is also possible to scale automatically with our **autoscaling** feature, so you can truly adapt your resources to the demand.

## Scalability depending on the use case

### Small and medium videoconferences

OpenVidu allows you to host multiple small and medium videoconferences (up to 10 participants). The number of simultaneous rooms depends on the deployment used and the power of machines.

- **Single Node deployment** (OpenVidu Community): In this deployment, OpenVidu can manage up to **50** simultaneous videoconferences of 8 participants in a 4 CPU server. If you need more videoconferences at the same time, you can use more powerful server. This is known as **vertical scalability**. The limit here is usually the maximum computational power available for a single server and the maximum network bandwidth for it. You can read more about this benchmark scenario in the [Performance benchmarks](../performance/#benchmarking) page.
- **Elastic and High Availability deployments** (OpenVidu Pro): In these deployments, OpenVidu is able to distribute the videoconferences in multiple media servers. This is known as **horizontal scalability**. In this case, the maximum number of simultaneous videoconferences depends on the number of media server used and the computational power of each of them. Also, other services used to coordinate and monitor the media servers (caches, data bases, proxies) can themselves become bottlenecks and limit the capacity of the system. In High Availability deployments, these services are distributed in 4 master nodes, so it is able to handle more load than in the Elastic deployment (with only 1 master node).

### Big live streams

Live streaming is different from a video conference. In a videoconference, usually all participants can publish audio and video. Instead, in a live stream, only one participant can publish audio and video (known as the publisher) and others can view it (known as viewers).

OpenVidu is able to manage live streams with up to **1000** viewers (1 publisher and **1000** subscribers) in a single Room hosted in a server with 4 CPUs. To manage more than one live stream simultaneously, an Elastic or High Availability deployment is needed with several media servers.

### Big videoconferences and massive live streams (Working on it! )

For big videoconferences with many participants (in the order of 100- or even 1000-) and massive live streams with few publishers and thousands of viewers, OpenVidu will offer in the near future two distinct strategies:

- **Distributing participants of one Room in multiple servers**: By connecting multiple media servers between them, OpenVidu will be able to manage Rooms with unlimited number of participants and live streams with unlimited number of viewers.
- **Only show last speakers**: A browser or mobile app is able to show a limited number of participants. A powerful computer can visualize up to 10 simultaneous videoconference participants at the same time with high video quality. To allow big videoconferences, OpenVidu will provide features on its frontend SDKs to show only last speakers in the videoconference.

## Load balancing strategies across Media Nodes

In **OpenVidu Elastic** and **OpenVidu High Availability**, work is distributed across multiple Media Nodes. The distribution strategy varies depending on the type of job.

### Rooms

The Room allocation strategy can be configured in the [**`livekit.yaml`** configuration file](../../configuration/changing-config/#config-files). Specifically, property `node_selector` defines the strategy to select the Media Node where a new Room will be hosted:

livekit.yaml

```yaml
node_selector:
    kind: any # [any, cpuload, sysload]
    sort_by: sysload # [random, sysload, cpuload, rooms, clients, tracks, bytespersec]
    cpu_load_limit: 0.9 # used with kind cpuload
    sysload_limit: 0.9 # used with kind sysload
```

Upon a new Room creation request:

1. First, property `kind` acts as a filter to remove non-eligible nodes:

   | `kind`  | Description                                                                                                                                                                         |
   | ------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
   | any     | All nodes are eligible.                                                                                                                                                             |
   | cpuload | Only nodes with CPU load below `cpu_load_limit` are eligible. cpuload states the current CPU load of the node. This is the **default** option.                                      |
   | sysload | Only nodes with system load below `sysload_limit` are eligible. sysload smooths CPU spikes in comparison to cpuload, as it takes the average load of the system in the last minute. |

1. Then, property `sort_by` defines how to sort the eligible nodes. The first node in the sorted list will be chosen to host the new Room:

   | `sort_by`   | Description                                                                             |
   | ----------- | --------------------------------------------------------------------------------------- |
   | random      | A random node will be selected.                                                         |
   | cpuload     | The node with the lowest CPU load will be selected. This is the **default** option.     |
   | sysload     | The node with the lowest system load will be selected.                                  |
   | rooms       | The node with the lowest total number of Rooms hosted will be selected.                 |
   | clients     | The node with the lowest total number of clients connected will be selected.            |
   | tracks      | The node with the lowest total number of media tracks being processed will be selected. |
   | bytespersec | The node with the lowest bandwidth will be selected.                                    |

   Room allocation never fails, as long as there is at least one Media Node connected to the cluster. Limits `cpu_load_limit` and `sysload_limit` will simply be ignored if no node is eligible.

### Egress

Info

Check out the official Egress documentation of LiveKit [here](https://docs.livekit.io/home/egress/overview/) .

The Egress allocation strategy can be configured in the [**`egress.yaml`** configuration file](../../configuration/changing-config/#config-files).

egress.yaml

```yaml
cpu_cost:
    max_cpu_utilization: 0.8
    room_composite_cpu_cost: 2.0
    audio_room_composite_cpu_cost: 1.0
    web_cpu_cost: 2.0
    audio_web_cpu_cost: 0.5
    participant_cpu_cost: 1.0
    track_composite_cpu_cost: 1.0
    track_cpu_cost: 0.5

openvidu:
    allocation_strategy: cpuload # [cpuload, binpack]
```

Upon a new Egress request:

1. First, OpenVidu filters eligible Media Nodes. A Media Node is eligible to host a new Egress request if:

   1. Its **CPU load is below a certain threshold** (by default 80%).
   1. It has enough **free CPUs** to handle the new Egress. The amount of free CPUs required depends on the type of Egress (room composite egress, web egress, participant egress, track composite egress, track egress).

   Sane defaults are provided by OpenVidu, but you can configure both the CPU load threshold and the amount of free CPUs required for each type of Egress in the `cpu_cost`:

   egress.yaml

   ```yaml
   cpu_cost:
       max_cpu_utilization: 0.8
       room_composite_cpu_cost: 2.0
       audio_room_composite_cpu_cost: 1.0
       web_cpu_cost: 2.0
       audio_web_cpu_cost: 0.5
       participant_cpu_cost: 1.0
       track_composite_cpu_cost: 1.0
       track_cpu_cost: 0.5
   ```

1. Then, OpenVidu chooses from the pool of eligible nodes the best one according to property `openvidu.allocation_strategy`:

   egress.yaml

   ```yaml
   openvidu:
       allocation_strategy: cpuload # [cpuload, binpack]
   ```

   | `sort_by` | Description                                                                                                                                                                                          |
   | --------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
   | cpuload   | The node with the lowest CPU load will be selected. This strategy helps distributing the CPU load evenly across all available nodes. This is the **default** option.                                 |
   | binpack   | Some node already hosting at least one Egress will be selected. If all eligible nodes are idle, a random one will be chosen. This strategy helps filling up nodes before assigning work to new ones. |

1. If no Media Node is eligible, the Egress request fails with a **`503 Service Unavailable`** error.

#### Egress CPU overload killer

By default the Egress service has the ability to **automatically kill active egresses under high CPU load**. If a >95% CPU load is sustained over 10 seconds, the Egress service will automatically terminate the most CPU-intensive active egress.

This helps preventing an egress process from overloading the entire Media Node. Nonetheless, this feature can be disabled by setting property `openvidu.disable_cpu_overload_killer` to `true` in the [**`egress.yaml`** configuration file](../../configuration/changing-config/#config-files):

egress.yaml

```yaml
openvidu:
    disable_cpu_overload_killer: true
```

### Ingress

Info

Check out the official Ingress documentation of LiveKit [here](https://docs.livekit.io/home/ingress/overview/) .

The Ingress allocation strategy is fixed and cannot be changed. Upon a new Ingress request:

1. First, OpenVidu filters eligible Media Nodes. A Media Node is eligible to host a new Ingress request if it has enough **free CPUs** to handle it. The amount of free CPUs required depends on the type of Ingress (RTMP, WHIP, URL). Sane defaults are provided by OpenVidu, but you can tweak these values by modifying the following properties in the [**`ingress.yaml`** configuration file](../../configuration/changing-config/#config-files):

   ingress.yaml

   ```yaml
   cpu_cost:
       rtmp_cpu_cost: 2.0
       whip_cpu_cost: 2.0
       whip_bypass_transcoding_cpu_cost: 0.1
       url_cpu_cost: 2.0
       min_idle_ratio: 0.3
   ```

1. Then, OpenVidu chooses a **random** Media Node among the eligible ones. If no Media Node is eligible, the Ingress request fails with a **`503 Service Unavailable`** error.

### Agents

For AI agents the allocation strategy varies depending if the Agent is an [**OpenVidu agent**](../../../ai/openvidu-agents/overview/) or a [**custom agent**](../../../ai/custom-agents/).

- For [**OpenVidu agents**](../../../ai/openvidu-agents/overview/): the agent will be available to process a new request if the CPU load of its Media Node is below a threshold. The default threshold is 70%, but you can change it in the agent's YAML configuration file. For example, for the **Speech Processing Agent**, you can change it in [**`agent-speech-processing.yaml`**](../../../ai/openvidu-agents/speech-processing-agent/#configuration-reference):

  agent-speech-processing.yaml

  ```yaml
  # Maximum CPU load threshold for the agent to accept new jobs. Value between 0 and 1.
  load_threshold: 0.7
  ```

- When developing a [**custom agent**](../../../ai/custom-agents/): the agent will be available to process a new request if its load does not exceed a specific threshold. Both the load metric and its threshold have the same defaults as for OpenVidu agents (average CPU load must be below 70%), but you can customize them in the `WorkerOptions` when developing your agent:

  ```python
  # Called to determine the current load of the worker. Must return a value between 0 and 1
  def custom_load_function(worker: Worker) -> float:
      ...
      return load_value

  worker_options = WorkerOptions(
      ...
      load_fnc=custom_load_function,
      load_threshold=0.7,  # Maximum load to consider the worker available
      ...
  )
  ```

  ```javascript
  // Called to determine the current load of the worker. Must return a value between 0 and 1
  const customLoadFunction = (worker: Worker): Promise<number> => {
      ...
      return loadValue;
  };

  const workerOptions = {
      ...
      loadFunc: customLoadFunction,
      loadThreshold: 0.7,  // Maximum load to consider the worker available
      ...
  };
  ```

In both cases, OpenVidu will assign the request to a random available agent. If no agent is available, the request will be ignored. The log of the [OpenVidu Server service](../../deployment-types/#media-node-services) will show an INFO message stating `not dispatching agent job since no worker is available`.

## Autoscaling

**OpenVidu Elastic** and **OpenVidu High Availability** have multiple Media Nodes to handle the load.

- Rooms, Egress, Ingress and Agents are distributed across the Media Nodes according to different allocation strategies. Some strategies are configurable, others are fixed, but all of them have sane defaults (see [Load balancing strategies across Media Nodes](#load-balancing-strategies-across-media-nodes)).
- It is possible to dynamically add new Media Nodes to the cluster when the load increases. New nodes will automatically start accepting new jobs according to the allocation strategies.
- It is possible to dynamically remove Media Nodes from the cluster when the load decreases. If the Media Node is hosting ongoing jobs (Rooms, Egresses, Ingresses or Agents), it will enter in a draining state in which it will not accept new jobs, but will continue processing the ongoing ones until they finish. At that point, the Media Node will be removed from the cluster.

The deployment environment determines how the autoscaling is managed:

### Autoscaling in cloud providers

When deploying in a supported **cloud provider** using our official templates, OpenVidu will automatically add and remove Media Nodes according to load. Depending on the cloud provider:

Deploy OpenVidu using our official **CloudFormation** template:

- [OpenVidu Elastic in AWS](../../elastic/aws/install/)
- [OpenVidu High Availability in AWS](../../ha/aws/install/)

The cluster scales automatically thanks to [AWS Auto Scaling Groups](https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-groups.html) . You can configure the Auto Scaling Group parameters when deploying the CloudFormation stack, in section **Media Nodes Autoscaling Group Configuration**.

Parameters in this section look like this:

The **InitialNumberOfMediaNodes** parameter specifies the initial number of Media Nodes to deploy. The **MinNumberOfMediaNodes** and **MaxNumberOfMediaNodes** parameters specify the minimum and maximum number of Media Nodes that you want to be deployed.

The **ScaleTargetCPU** parameter specifies the target CPU utilization to trigger the scaling up or down. The goal is to keep the CPU utilization of the Media Nodes close to this value. The autoscaling policy is based on [Target Tracking Scaling Policy](https://docs.aws.amazon.com/autoscaling/application/userguide/target-tracking-scaling-policy-overview.html) .

Deploy OpenVidu using our official **ARM** template:

- [OpenVidu Elastic in Azure](../../elastic/azure/install/)
- [OpenVidu High Availability in Azure](../../ha/azure/install/)

The cluster scales automatically thanks to [Azure Virtual Machine Scale Sets](https://learn.microsoft.com/en-us/azure/virtual-machine-scale-sets/) . You can configure the Scale Set parameters when deploying the ARM template, in section **Media Nodes Scaling Set Configuration**.

Parameters in this section look like this:

The **Initial Number Of Media Nodes** parameter specifies the initial number of Media Nodes to deploy. The **Min Number Of Media Nodes** and **Max Number Of Media Nodes** parameters specify the minimum and maximum number of Media Nodes that you want to be deployed.

The **Scale Target CPU** parameter specifies the target CPU utilization to trigger the scaling up or down. The goal is to keep the CPU utilization of the Media Nodes close to this value. The autoscaling policy is based on [Azure Monitor autoscale metrics](https://learn.microsoft.com/en-us/azure/architecture/best-practices/auto-scaling#use-the-azure-monitor-autoscale-feature) .

### Autoscaling On Premises

When deploying an OpenVidu cluster **On Premises** you are responsible of monitoring the load of your Media Nodes and triggering the addition of new Media Nodes or removal of existing Media Nodes. Depending on your OpenVidu deployment type, you can do so like this:

- For **OpenVidu Elastic On Premises**:
  - [Add a new Media Node](../../elastic/on-premises/admin/#adding-media-nodes)
  - [Removing Media Nodes gracefully](../../elastic/on-premises/admin/#removing-media-nodes-gracefully)
  - [Removing Media Nodes forcefully](../../elastic/on-premises/admin/#removing-media-nodes-forcefully)
- For **OpenVidu High Availability On Premises**:
  - [Adding Media Nodes](../../ha/on-premises/admin/#adding-media-nodes)
  - [Removing Media Nodes gracefully](../../ha/on-premises/admin/#removing-media-nodes-gracefully)
  - [Removing Media Nodes forcefully](../../ha/on-premises/admin/#removing-media-nodes-forcefully)

# Fault Tolerance

Real-time media is particularly sensitive to downtime events, as they directly affect the user experience in a very disruptive way. OpenVidu is designed from the ground up to be fault tolerant in all its services in case of node downtime, especially in its High Availability deployment.

The extent of fault tolerance depends on the [OpenVidu deployment type](../../deployment-types/):

- **OpenVidu Single Node**: it is not fault tolerant. Fault tolerance requires a multi-node deployment.
- **OpenVidu Elastic**: fault tolerant only for Media Nodes.
- **OpenVidu High Availability**: fault tolerant for both Media Nodes and Master Nodes.

## Fault tolerance in OpenVidu Elastic

### Master Node

An OpenVidu Elastic deployment has a single Master Node, so a failure on this node is fatal and any ongoing video Rooms will be interrupted. The service won't be restored until the Master Node is recovered.

### Media Nodes

You can have any number of Media Nodes in an OpenVidu Elastic deployment. Media Nodes are stateless, meaning that they do not store critical information about the Rooms, Egress or Ingress processes they are handling. This means that they can be easily replicated in any other Media Node in case of a failure.

In the event of a Media Node failure, there are [3 services](../../deployment-types/#media-node-services) affected with the following behaviors:

- Active [Rooms](https://docs.livekit.io/home/get-started/api-primitives/) hosted by the failed Media Node will suffer a temporary interruption of about 5 seconds (this is the time the clients take to realize the Media Node has crashed). After that time has elapsed, the Room will be automatically reconstructed in a healthy Media Node. Every participant and track will be recreated and the Room will be fully operational again.
- Active [Egress](https://docs.livekit.io/home/egress/overview/) hosted by the failed Media Node will be interrupted. If the node's disk is still accessible, egress output files can still be recovered. See [Recovering Egress from node failures](#recovering-egress-from-node-failures).
- Active [Ingress](https://docs.livekit.io/home/ingress/overview/) hosted by the failed Media Node will be interrupted. The participants of the Room will receive the proper [events](https://docs.livekit.io/home/client/events/#Events) indicating the Ingress participant has left the Room: `TrackUnpublished` and `ParticipantDisconnected`. Some famous tools for streaming such as OBS Studio will automatically try to reconnect the stream when they detect a connection loss, so in this case interruption will be minimal and the Ingress tracks will be restored on their own on a healthy Media Node.

## Fault tolerance in OpenVidu High Availability

OpenVidu High Availability delivers the highest possible degree of fault tolerance. This is achieved by running all of the [services in the Master Nodes and the Media Nodes](../../deployment-types/#node-services) in their **High Availability** flavour.

An OpenVidu High Availability deployment runs Master Nodes and Media Nodes in separated groups. Let's see the extent of fault tolerance for each node group:

### Master Nodes

The number of Master Nodes in an OpenVidu High Availability deployment is **4**. This minimum number of nodes ensures that every service running in the Master Nodes is fault tolerant.

If **one** Master Node fails, the service won't be affected. Some users may trigger [event](https://docs.livekit.io/home/client/events/#Events) `Reconnecting` closely followed by `Reconnected`, but the service will remain fully operational.

When two or more Master Nodes fail simultaneously, there can be some degradation of the service:

- If **two** Master Nodes fail, the service will still be operational for the most part. Only active [Egress](https://docs.livekit.io/home/egress/overview/) might be affected, as they won't be stored in the Minio storage. See [Recovering Egress from node failures](#recovering-egress-from-node-failures).
- If **three or four** Master Nodes fail, the service will be interrupted.

In the event of Master Node failures, the service will be automatically restored as soon as the failed node(s) are recovered.

### Media Nodes

Fault tolerance of Media Nodes in OpenVidu High Availability behaves the same as in [OpenVidu Elastic](#media-nodes).

## Recovering Egress from node failures

[Egress](https://docs.livekit.io/home/egress/overview/) processes can be affected by the crash of a Master Node or a Media Node. To recover Egress from...

### From Master Node failures

This only applies to OpenVidu High Availability

If 2 Master Nodes crash, the Egress process won't be able to use the Minio storage. This has different consequences depending on the [configured outputs](https://docs.livekit.io/home/egress/outputs/) for your Egress process:

- For **MP4, OGG or WEBM files**, if the Egress is stopped when 2 Master Nodes are down, the output files will not be uploaded to Minio.
- For **HLS**, the segments will stop being uploaded to Minio. If you are consuming these segments from another process, note that new segments will stop appearing.

In both cases, files are not lost and can be recovered. They will be available in the Egress backup path of the Media Node hosting the Egress process (by default `/opt/openvidu/egress_data/home/egress/backup_storage`).

### From a Media Node failure

This applies to both OpenVidu High Availability and OpenVidu Elastic

If the Media Node hosting an ongoing Egress process crashes, then the Egress process will be immediately interrupted. But as long as the disk of the crashed Media Node is still accessible, you may recover the output files. They will be available in the Media Node at path `/opt/openvidu/egress_data/home/egress/tmp`.

It is possible that if the crashed Egress had **MP4** as [configured output](https://docs.livekit.io/home/egress/outputs/) (which is an option available for [Room Composite](https://docs.livekit.io/home/egress/composite-recording/#roomcomposite-egress) and [Track Composite](https://docs.livekit.io/home/egress/participant/#trackcomposite-egress) ) the recovered file may not be directly playable and it may require a repair process.

# Observability

Any production software needs to be observable. But in real-time applications this becomes an absolute priority. You must be able to:

- Detect and solve networking issues that may prevent your users from connecting to your Rooms.
- Monitor the quality of the video and audio streams, that will reflect in your users' experience.
- Analyze the load in your hardware to detect bottlenecks and scale your deployment accordingly.
- Store historical data to analyze past issues and trends to make future decisions based on them.

OpenVidu brings everything you need to fulfill these requirements. We collect **events**, **metrics** and **logs** from your deployment and provide [**OpenVidu Dashboard**](openvidu-dashboard/) and a [**Grafana stack**](grafana-stack/) to navigate them.

# OpenVidu Dashboard

It is a web application designed to provide **OpenVidu administrators** with a comprehensive view of **usage statistics** and **real-time monitoring** of video **Rooms**. OpenVidu Dashboard is included by default in any [OpenVidu deployment](../../../deployment-types/).

To access **OpenVidu Dashboard**, go to https://your.domain/dashboard/ and **log in** using your **admin credentials**.

### Views

#### Analytics

Display **graphical analytics** for client SDKs, connection types, bandwidth usage, unique participants, rooms and egresses created over different **time periods** (last 24 hours, last 7 days, last 28 days or current month).

#### Rooms

Review the total count of **active rooms** and **active participants**, along with a roster of currently active rooms and a history of **closed rooms** within the last 28 days. Detailed information on each room is accessible by clicking on the respective row.

#### Room Details

This view is part of OpenVidu [PRO](/pricing/#openvidu-pro) edition.

Retrieve in-depth information about a specific **room**, including its duration, bandwidth consumption, participants and related events. A chart illustrating the active participants count over time is also provided.

#### Participant Details

This view is part of OpenVidu [PRO](/pricing/#openvidu-pro) edition.

Obtain detailed insights into each **participant**, covering their duration, bandwidth usage, average audio and video quality score, information about the client they are connecting with, connection stats, published tracks and related events.

A participant may **connect** and **disconnect** from a room multiple times while it remains open. Each instance of connection using the same **participant identity** is referred to as a **`participant session`**. If multiple sessions occur, we will aggregate all participant sessions together and organize them into a timeline at the top of the participant details view. You can easily switch between participant sessions by clicking on each corresponding row:

#### Egress-Ingress

Review an overview of all **egresses** and **ingresses**, including their duration and status. Detailed information for each egress or ingress can be accessed by clicking on the respective row.

#### Egress Details

This view is part of OpenVidu [PRO](/pricing/#openvidu-pro) edition.

Access comprehensive details about a specific **egress**, including its duration, current status, type, associated room, destinations, status timeline and request information.

#### Ingress Details

This view is part of OpenVidu [PRO](/pricing/#openvidu-pro) edition.

Explore detailed information about a specific **ingress**, including its total duration, status and a list of all associated rooms.

# Grafana Stack

OpenVidu also provides different **Grafana dashboards** to monitor **metrics** from **OpenVidu Server** and **logs** from your **cluster**.

\[[](../../../../../assets/videos/grafana_trailer.mp4)\](../../../../../assets/videos/grafana_trailer.mp4)

Grafana is available at https://your.domain/grafana/ and can be accessed using your **Grafana admin credentials**.

Dashboards can be found in the **OpenVidu** folder at https://your.domain/grafana/dashboards/f/openvidu-dashboards/openvidu.

### Services

The **Grafana stack** that comes with OpenVidu is composed of the following services:

- **Grafana** : Tool for **querying**, **visualizing**, **alerting on** and **exploring** **metrics**, **logs** and **traces**. It queries different **data sources** to show data in beautiful **dashboards**. In OpenVidu, contains all [dashboards](#dashboards) built from **Mimir**/**Prometheus** and **Loki** data sources to monitor **OpenVidu Server** and **logs** from your **cluster**.
- **Prometheus** : System **monitoring** and **alerting** toolkit. It collects and stores **metrics** from different targets as **time series data**. In OpenVidu, it collects metrics from **OpenVidu Server** of each **Media Node** and sends them to **Mimir**.
- **Mimir**: Grafana software project that provides **multi-tenant**, **long-term storage** for **Prometheus** metrics. In **OpenVidu**, it is used to store metrics collected by **Prometheus**.
- **Promtail**: Agent that ships the contents of **local logs** to a **Loki** instance. In OpenVidu, it is used to collect logs from all **services** in your **cluster** and send them to **Loki**.
- **Loki**: **Horizontally-scalable**, **highly-available**, **multi-tenant** **log aggregation** system inspired by **Prometheus**. In OpenVidu, it is used to store logs collected by **Promtail**.

### Dashboards

#### OpenVidu Server Metrics

This dashboard provides **metrics** about **OpenVidu Server**. It includes charts about **active rooms**, **active participants**, **published tracks**, **subscribed tracks**, **send/receive bytes**, **packet loss percentage** and **quality score**.

In case you are using **OpenVidu** [PRO](/pricing/#openvidu-pro) and you have more than one **Media Node** deployed, you will see all metrics from all nodes combined in the same chart.

#### OpenVidu Media Nodes Server Metrics

This dashboard is part of OpenVidu [PRO](/pricing/#openvidu-pro) edition.

This dashboard provides the same **metrics** as the [OpenVidu Server Metrics](#openvidu-server-metrics) dashboard, but grouped by **Media Node**.

You can select the **Media Node** you want to see metrics from in the **media_node** dropdown. You will see different charts in the same panel according to the selected **Media Nodes**.

Info

If you add new Media Nodes to your OpenVidu deployment, you will have to refresh the page in order to see the new Media Nodes in the dropdown.

#### OpenVidu Logs

In case you are using **OpenVidu** [COMMUNITY](/pricing/#openvidu-community), this dashboard provides different visualizations for **logs** from your **OpenVidu Single Node deployment**.

There is a panel showing **all containers** logs,

another panel to **filter** logs by **room_id** and **participant_id**,

and one row for each selected **service**, containing **all logs**, **warnings** and **errors** from that service.

You can also filter logs containing a specific **text** by using the **filter search box**.

#### OpenVidu Cluster Nodes Logs

This dashboard is part of OpenVidu [PRO](/pricing/#openvidu-pro) edition.

In case you are using **OpenVidu** [PRO](/pricing/#openvidu-pro), this dashboard provides different visualizations for **logs** from your **OpenVidu Elastic** or **OpenVidu High Availability** cluster, grouped by **node**.

First of all, there is a panel showing **all containers** logs from all nodes.

Then, there is a row for each selected **node**, containing **all logs**, **warnings** and **errors** from that node. Besides, each row contains a panel for each selected container, showing all its logs.

Info

Note that some panels have no data. This is because some containers are running in **Master Nodes** and others in **Media Nodes**.

You can also filter logs containing a specific **text** by using the **filter search box**.

#### OpenVidu Cluster Services Logs

This dashboard is part of OpenVidu [PRO](/pricing/#openvidu-pro) edition.

In case you are using **OpenVidu** [PRO](/pricing/#openvidu-pro), this dashboard provides different visualizations for **logs** from your **OpenVidu Elastic** or **OpenVidu High Availability** cluster, grouped by **service**.

First of all, there is a panel to **filter** logs by **room_id** and **participant_id**.

Then, there is a row for each selected **service**, containing **all logs**, **warnings** and **errors** from that service.

### Limitations

For now, in [**OpenVidu High Availability deployments**](../../../deployment-types/#openvidu-high-availability), we have decided to **not** implement Grafana in High Availability (HA) mode. This decision is based on the fact that Grafana needs a configured HA MySQL or PostgreSQL database to work in HA mode, and we want to keep the deployment as simple as possible.

There are 4 instances of Grafana in an OpenVidu High Availability deployment, one for each Master Node, but they are not synchronized between them. Therefore, if you make any change (change your admin password, create a new dashboard...) in one Grafana instance and the Master Node suddenly goes down, you will be redirected to another Grafana instance where the changes will not be reflected. That is the reason why we disable user signups and saving dashboard or datasource modifications in Grafana.

However, all metrics and logs from all nodes are available in all Grafana instances, so you can monitor your OpenVidu cluster without any problem.

# How To Guides

OpenVidu deployments are installed with sane defaults, but you may want to customize your deployment to suit your needs. This section contains guides on how to configure OpenVidu for specific use cases, so you can get the most out of your deployment.

- [How to configure an external S3 bucket for recordings instead of the default MinIO](external-s3/)
- [Force all traffic including WebRTC to go through 443 with TLS](force-443-tls/)
- [Enable webhooks](enable-webhooks/)
- [Enable and disable modules](enable-disable-modules/)
- [How to deploy and configure OpenVidu with an existing external proxy](deploy-with-external-proxy/)
- [Create and configurate AWS certificate for HA deployment](create-configure-AWS-certificate/)

# AI Services

OpenVidu offers a catalog of AI services that can be easily integrated into your application to enhance the user experience and add advanced features. These services are provided by **OpenVidu agents**: a set of **pre-configured and ready-to-use AI modules**.

These are the currently available OpenVidu agents:

- **Speech Processing agent**: provides all the AI services related to transcribing audio speech to text and processing the results in various ways.

[List of provided AI services](#speech-processing-agent) [Enable the agent](../openvidu-agents/speech-processing-agent/)

## Speech Processing agent

- **Live Captions**

  ______________________________________________________________________

  Generate live captions for your users' speech with great accuracy and display the results in your frontend.

  [Go to Live Captions](../live-captions/)

- **Transcription**

  ______________________________________________________________________

  Store the transcriptions of your Rooms in your backend.

  Coming soon

- **Translation**

  ______________________________________________________________________

  Translate the transcriptions of your Rooms into multiple languages.

  Coming soon

- **Summary**

  ______________________________________________________________________

  Summarize the transcriptions of your Rooms into concise text.

  Coming soon

- **Keyword detection**

  ______________________________________________________________________

  Detect keywords in your users' speech and trigger actions based on them.

  Coming soon

- **Profanity filter**

  ______________________________________________________________________

  Filter profanity words in your users' speech, replacing them with alternative characters.

  Coming soon

# OpenVidu agents: overview

## Basic concepts

The modules that provide AI services in OpenVidu are called **OpenVidu agents**. They are **pre-configured and ready-to-use AI modules**. OpenVidu agents interact with your Rooms in real time using the powerful [LiveKit Agents framework](https://docs.livekit.io/agents/) .

All OpenVidu agents follow the following general principles:

- **Agents run in your OpenVidu nodes**: in [OpenVidu Single Node](../../../self-hosting/deployment-types/#openvidu-single-node), agents run in the same node. In [OpenVidu Elastic](../../../self-hosting/deployment-types/#openvidu-elastic) and [OpenVidu High Availability](../../../self-hosting/deployment-types/#openvidu-high-availability), agents run in Media Nodes. They run as Docker containers, just like any other OpenVidu service.
- **Agents are configured through YAML files**: you just have to add a file `agent-AGENT_NAME.yaml` to the configuration folder of your OpenVidu deployment, and the agent will be automatically launched. This declarative approach makes agents easy to deploy, manage and scale.

In more detail, each OpenVidu agent adheres to the following principles:

- **Each agent is automatically deployed as a Docker container once per node**: once in the only node of an [OpenVidu Single Node](../../../self-hosting/deployment-types/#openvidu-single-node) deployment, and once in each Media Node of [OpenVidu Elastic](../../../self-hosting/deployment-types/#openvidu-elastic) and [OpenVidu High Availability](../../../self-hosting/deployment-types/#openvidu-high-availability) deployments.
- **Each agent is downloaded in background during OpenVidu startup**: take into account that it might not be available immediately after OpenVidu starts, as it may take some time to download the agent image from the Docker registry.
- **Each agent is identified, configured and deployed declaratively via its own `agent-AGENT_NAME.yaml` file**: your OpenVidu deployment will detect agent YAML files and will automatically launch and configure them. **`AGENT_NAME`** must be a unique identifier per agent.
- **Each agent container of each node can process multiple Rooms simultaneously**: the limit is set by the node's hardware.
- **Each enabled agent remains always running**: this happens even when not processing any Rooms. This idle state may consume some resources, but ensures that agents are ready to process Rooms immediately.

## List of available OpenVidu agents

- **Speech Processing agent**: provides all the AI services related to transcribing audio speech to text and processing the results in various ways.

[List of provided AI services](../../overview/#speech-processing-agent) [Enable the agent](../speech-processing-agent/)

## Troubleshooting OpenVidu agents

Sometimes agents fail to process a Room. Sometimes they don't even start properly. This is usually due to some misconfiguration, such as incorrect credentials in the agent configuration.

The best way to troubleshoot a failing agent is to **check its logs**. To do so:

```bash
docker logs agent-AGENT_NAME
```

- You can search for the logs in your [Grafana dashboard](../../../self-hosting/production-ready/observability/grafana-stack/).

- Or SSH into the single OpeVidu node and check docker logs:

  ```bash
  docker logs agent-AGENT_NAME
  ```

- You can search for the logs in your [Grafana dashboard](../../../self-hosting/production-ready/observability/grafana-stack/).

- You can also SSH into the Media Node where the problematic agent is running and check docker logs:

  ```bash
  docker logs agent-AGENT_NAME
  ```

- You can search for the logs in your [Grafana dashboard](../../../self-hosting/production-ready/observability/grafana-stack/).

- You can also SSH into the Media Node where the problematic agent is running and check docker logs:

  ```bash
  docker logs agent-AGENT_NAME
  ```

# Speech Processing agent

The Speech Processing agent provides all the AI services related to transcribing audio speech to text and processing the results in various ways.

## List of provided AI services

- [**Live Captions**](../../live-captions/): transcribe the audio tracks of your Rooms in real time with great accuracy and display the results as live captions in your frontend.

## Enable the agent and configure AI services

### 1. SSH into an OpenVidu Node and go to configuration folder

Depending on your [OpenVidu deployment type](../../../self-hosting/deployment-types/):

If you are using [OpenVidu Local (Development)](../../../self-hosting/deployment-types/#openvidu-local-development), simply navigate to the configuration folder of the project:

```bash
# For OpenVidu Local COMMUNITY
cd openvidu-local-deployment/community

# For OpenVidu Local PRO
cd openvidu-local-deployment/pro
```

If you are using [OpenVidu Single Node](../../../self-hosting/deployment-types/#openvidu-single-node), SSH into the only OpenVidu node and navigate to:

```bash
cd /opt/openvidu/config
```

If you are using [OpenVidu Elastic](../../../self-hosting/deployment-types/#openvidu-elastic), SSH into the only Master Node and navigate to:

```bash
cd /opt/openvidu/config/cluster/media_node
```

If you are using [OpenVidu High Availability](../../../self-hosting/deployment-types/#openvidu-high-availability), SSH into any of your Master Nodes (doesn't matter which one) and navigate to:

```bash
cd /opt/openvidu/config/cluster/media_node
```

### 2. Modify file `agent-speech-processing.yaml`

Locate file `agent-speech-processing.yaml` in the [configuration folder](#1-ssh-into-an-openvidu-node-and-go-to-configuration-folder) of your OpenVidu node. Modify this file to enable the agent and configure the desired AI services.

#### Enable the agent

```yaml
enabled: true
```

#### Configure the desired AI services

You can set up the following AI services in this agent:

- **Live Captions**: see [Live Captions service](../../live-captions/#how-to-enable-live-captions-service-in-your-openvidu-deployment).

### 3. Restart OpenVidu

Depending on your [OpenVidu deployment type](../../../self-hosting/deployment-types/):

Run where `docker-compose.yaml` is located:

```bash
docker compose restart
```

Run this command in your node:

```bash
sudo systemctl restart openvidu
```

Run this command in your Master Node:

```bash
sudo systemctl restart openvidu
```

Run this command in one of your Master Nodes:

```bash
sudo systemctl restart openvidu
```

After restarting OpenVidu your agent will be up and running, ready to process new Rooms.

Warning

If your agent container keeps restarting, there might be an error in your configuration. Check its logs to find out what is wrong.

## Change CPU load threshold

By default, the agent will only accept new jobs if the average CPU load of its Media Node is below 70%. You can change this threshold in [**`agent-speech-processing.yaml`**](#configuration-reference):

agent-speech-processing.yaml

```yaml
# Maximum CPU load threshold for the agent to accept new jobs. Value between 0 and 1.
load_threshold: 0.7
```

## Log level

You can change the log level of the agent in [**`agent-speech-processing.yaml`**](#configuration-reference):

agent-speech-processing.yaml

```yaml
# Log level for the agent [DEBUG, INFO, WARNING, ERROR, CRITICAL]
log_level: INFO
```

## Configuration reference

Below is the full list of configuration properties available for the Speech Processing agent.

[agent-speech-processing.yaml](https://github.com/OpenVidu/openvidu-agents/blob/3.4.1/speech-processing/agent-speech-processing.yaml)

```yaml
# Docker image of the agent.
docker_image: docker.io/openvidu/agent-speech-processing:3.4.1

# Whether to run the agent or not.
enabled: false

# Maximum CPU load threshold for the agent to accept new jobs. Value between 0 and 1.
load_threshold: 0.7

# Log level for the agent [DEBUG, INFO, WARNING, ERROR, CRITICAL]
log_level: INFO

live_captions:
  # How this agent will connect to Rooms [automatic, manual]
  # - automatic: the agent will automatically connect to new Rooms.
  # - manual: the agent will connect to new Rooms only when your application dictates it by using the Agent Dispatch API.
  processing: automatic

  # Which speech-to-text AI provider to use [aws, azure, google, openai, groq, deepgram, assemblyai, fal, clova, speechmatics, gladia, sarvam]
  # The custom configuration for the selected provider must be set below
  provider:

  aws:
    # Credentials for AWS Transcribe. See https://docs.aws.amazon.com/transcribe/latest/dg/what-is.html
    aws_access_key_id:
    aws_secret_access_key:
    aws_default_region:
    # See https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html
    language:
    # The name of the custom vocabulary you want to use.
    # See https://docs.aws.amazon.com/transcribe/latest/dg/custom-vocabulary.html
    vocabulary_name:
    # The name of the custom language model you want to use.
    # See https://docs.aws.amazon.com/transcribe/latest/dg/custom-language-models-using.html
    language_model_name:
    # Whether or not to enable partial result stabilization. Partial result stabilization can reduce latency in your output, but may impact accuracy.
    # See https://docs.aws.amazon.com/transcribe/latest/dg/streaming-partial-results.html#streaming-partial-result-stabilization
    enable_partial_results_stabilization:
    # Specify the level of stability to use when you enable partial results stabilization (enable_partial_results_stabilization: true). Valid values: high | medium | low
    # See https://docs.aws.amazon.com/transcribe/latest/dg/streaming-partial-results.html#streaming-partial-result-stabilization
    partial_results_stability:
    # The name of the custom vocabulary filter you want to use to mask or remove words.
    # See https://docs.aws.amazon.com/transcribe/latest/dg/vocabulary-filtering.html
    vocab_filter_name:
    # The method used to filter the vocabulary. Valid values: mask | remove | tag
    # See https://docs.aws.amazon.com/transcribe/latest/dg/vocabulary-filtering.html
    vocab_filter_method:

  azure:
    # Credentials for Azure Speech Service.
    # One of these combinations must be set:
    #  - speech_host
    #  - speech_key + speech_region
    #  - speech_auth_token + speech_region
    # See https://learn.microsoft.com/en-us/azure/ai-services/speech-service/get-started-speech-to-text?tabs=macos%2Cterminal&pivots=programming-language-python#prerequisites
    speech_host:
    speech_key:
    speech_auth_token:
    speech_region:
    # Azure handles multiple languages and can auto-detect the language used. It requires the candidate set to be set. E.g. ["en-US", "es-ES"]
    # See https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=stt#supported-languages
    language:
    # Removes profanity (swearing), or replaces letters of profane words with stars. Valid values: Masked | Removed | Raw
    # See https://learn.microsoft.com/en-us/azure/ai-services/translator/profanity-filtering
    profanity:

  azure_openai:
    # Credentials for Azure OpenAI APIs. See https://learn.microsoft.com/en-us/azure/api-management/api-management-authenticate-authorize-azure-openai
    # Azure OpenAI API key
    azure_api_key:
    # Azure Active Directory token
    azure_ad_token:
    # Azure OpenAI endpoint in the following format: https://{your-resource-name}.openai.azure.com. Mandatory value.
    azure_endpoint:
    # Name of your model deployment. If given with `azure_endpoint`, sets the base client URL to include `/deployments/{azure_deployment}`.
    azure_deployment:
    # OpenAI REST API version used for the request. Mandatory value.
    api_version:
    # OpenAI organization ID.
    organization:
    # OpenAI project ID.
    project:
    # The language code to use for transcription (e.g., "en" for English).
    language:
    # ID of the model to use for speech-to-text.
    model:
    # Initial prompt to guide the transcription.
    prompt:

  google:
    # Credentials for Google Cloud. This is the content of a Google Cloud credential JSON file.
    # Below is a dummy example for a credential type of "Service Account" (https://cloud.google.com/iam/docs/service-account-creds#key-types)
    credentials_info: |
      {
        "type": "service_account",
        "project_id": "my-project",
        "private_key_id": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
        "private_key": "-----BEGIN PRIVATE KEY-----\nxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n-----END PRIVATE KEY-----\n",
        "client_email": "my-email@my-project.iam.gserviceaccount.com",
        "client_id": "xxxxxxxxxxxxxxxxxxxxx",
        "auth_uri": "https://accounts.google.com/o/oauth2/auth",
        "token_uri": "https://oauth2.googleapis.com/token",
        "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
        "client_x509_cert_url": "https://www.googleapis.com/robot/v1/metadata/x509/my-email%40my-project.iam.gserviceaccount.com",
        "universe_domain": "googleapis.com"
      }
    # Which model to use for recognition. If not set, uses the default model for the selected language.
    # See https://cloud.google.com/speech-to-text/docs/transcription-model
    model:
    # The location to use for recognition. Default is "us-central1". Latency will be best if the location is close to your users.
    # Check supported languages and locations at https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages
    location:
    # List of language codes to recognize. Default is ["en-US"].
    # See https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages
    languages:
    # Whether to detect the language of the audio. Default is true.
    detect_language:
    # If 'true', adds punctuation to recognition result hypotheses. This feature is only available in select languages. Setting this
    # for requests in other languages has no effect at all. The default 'false' value does not add punctuation to result hypotheses.
    # See https://cloud.google.com/speech-to-text/docs/automatic-punctuation
    punctuate:
    # The spoken punctuation behavior for the call. If not set, uses default behavior based on model of choice.
    # e.g. command_and_search will enable spoken punctuation by default. If 'true', replaces spoken punctuation
    # with the corresponding symbols in the request. For example, "how are you question mark" becomes "how are you?".
    # See https://cloud.google.com/speech-to-text/docs/spoken-punctuation for support. If 'false', spoken punctuation is not replaced.
    spoken_punctuation:
    # Whether to return interim (non-final) transcription results. Defaults to true.
    interim_results:

  openai:
    # API key for OpenAI. See https://platform.openai.com/api-keys
    api_key:
    # The OpenAI model to use for transcription. See https://platform.openai.com/docs/guides/speech-to-text
    model:
    # The language of the input audio. Supplying the input language in ISO-639-1 format
    # (https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) will improve accuracy and latency.
    language:
    # Optional text prompt to guide the transcription. Only supported for whisper-1.
    prompt:

  groq:
    # API key for Groq. See https://console.groq.com/keys
    api_key:
    # See https://console.groq.com/docs/speech-to-text
    model:
    # The language of the input audio. Supplying the input language in ISO-639-1 format
    # (https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) will improve accuracy and latency.
    language:
    # Prompt to guide the model's style or specify how to spell unfamiliar words. 224 tokens max.
    prompt:

  deepgram:
    # See https://console.deepgram.com/
    api_key:
    # See https://developers.deepgram.com/reference/speech-to-text-api/listen-streaming#request.query.model
    model:
    # See https://developers.deepgram.com/reference/speech-to-text-api/listen-streaming#request.query.language
    language:
    # Whether to enable automatic language detection. Defaults to false. See https://developers.deepgram.com/docs/language-detection
    detect_language: false
    # Whether to return interim (non-final) transcription results. Defaults to true. See https://developers.deepgram.com/docs/interim-results
    interim_results: true
    # Whether to apply smart formatting to numbers, dates, etc. Defaults to true. See https://developers.deepgram.com/docs/smart-format
    smart_format: true
    # When smart_format is used, ensures it does not wait for sequence to be complete before returning results. Defaults to true. See https://developers.deepgram.com/docs/smart-format#using-no-delay
    no_delay: true
    # Whether to add punctuations to the transcription. Defaults to true. Turn detector will work better with punctuations. See https://developers.deepgram.com/docs/punctuation
    punctuate: true
    # Whether to include filler words (um, uh, etc.) in transcription. Defaults to true. See https://developers.deepgram.com/docs/filler-words
    filler_words: true
    # Whether to filter profanity from the transcription. Defaults to false. See https://developers.deepgram.com/docs/profanity-filter
    profanity_filter: false
    # List of tuples containing keywords and their boost values for improved recognition. Each tuple should be (keyword: str, boost: float). Defaults to None. keywords does not work with Nova-3 models. Use keyterms instead.
    # keywords:
    #   - [OpenVidu, 1.5]
    #   - [WebRTC, 1]
    # List of key terms to improve recognition accuracy. Defaults to None. keyterms is supported by Nova-3 models.
    # Commented below is an example
    keyterms:
      # - "OpenVidu"
      # - "WebRTC"

  assemblyai:
    # API key for AssemblyAI. See https://www.assemblyai.com/dashboard/api-keys
    api_key:
    # Whether to return formatted final transcripts (proper punctuation, letter casing...). If enabled, formatted final transcripts are emitted shortly following an end-of-turn detection.
    format_turns: true

  fal:
    # API key for fal. See https://fal.ai/dashboard/keys
    api_key:
    # See https://fal.ai/models/fal-ai/wizper/api#schema
    language:

  clova:
    # Secret key issued when registering the app
    api_key:
    # API Gateway's unique invoke URL created in CLOVA Speech Domain.
    # See https://guide.ncloud-docs.com/docs/en/clovaspeech-domain#create-domain
    invoke_url:
    # See https://api.ncloud-docs.com/docs/en/ai-application-service-clovaspeech-longsentence
    language:
    # Value between 0 and 1 indicating the threshold for the confidence score of the transcribed text. Default is 0.5.
    # If the confidence score is lower than the threshold, the transcription event is not sent to the client.
    # For a definition of the confidence score see https://api.ncloud-docs.com/docs/en/ai-application-service-clovaspeech-grpc
    threshold:

  speechmatics:
    # API key for Speechmatics. See https://portal.speechmatics.com/manage-access/
    api_key:
    # ISO 639-1 language code. All languages are global and can understand different dialects/accents. To see the list of all supported languages, see https://docs.speechmatics.com/introduction/supported-languages
    language:
    # Operating point to use for the transcription per required accuracy & complexity. To learn more, see https://docs.speechmatics.com/features/accuracy-language-packs#accuracy
    operating_point:
    # Partial transcripts allow you to receive preliminary transcriptions and update as more context is available until the higher-accuracy final transcript is returned. Partials are returned faster but without any post-processing such as formatting. See https://docs.speechmatics.com/features/realtime-latency#partial-transcripts
    enable_partials:
    # RFC-5646 language code to make spelling rules more consistent in the transcription output. See https://docs.speechmatics.com/features/word-tagging#output-locale
    output_locale:
    # The delay in seconds between the end of a spoken word and returning the final transcript results. See https://docs.speechmatics.com/features/realtime-latency#configuration-example
    max_delay:
    # See https://docs.speechmatics.com/features/realtime-latency#configuration-example
    max_delay_mode:
    # Configuration for speaker diarization. See https://docs.speechmatics.com/features/diarization
    speaker_diarization_config:
      # See https://docs.speechmatics.com/features/diarization#max-speakers
      max_speakers:
      # See https://docs.speechmatics.com/features/diarization#speaker-sensitivity
      speaker_sensitivity:
      # See https://docs.speechmatics.com/features/diarization#prefer-current-speaker
      prefer_current_speaker:
    # Permitted punctuation marks for advanced punctuation. See https://docs.speechmatics.com/features/punctuation-settings
    # Commented is an example of punctuation settings
    punctuation_overrides:
      # permitted_marks: [ ".", "," ]
      # sensitivity: 0.4
    # See https://docs.speechmatics.com/features/custom-dictionary
    # Commented below is an example of a custom dictionary
    additional_vocab:
      # - content: financial crisis
      # - content: gnocchi
      #   sounds_like:
      #     - nyohki
      #     - nokey
      #     - nochi
      # - content: CEO
      #   sounds_like:
      #     - C.E.O.

  gladia:
    # API key for Gladia. See https://app.gladia.io/account
    api_key:
    # Whether to return interim (non-final) transcription results. Defaults to True
    interim_results:
    # List of language codes to use for recognition. Defaults to None (auto-detect). See https://docs.gladia.io/chapters/limits-and-specifications/languages
    languages:
    # Whether to allow switching between languages during recognition. Defaults to True
    code_switching:

  sarvam:
    # API key for Sarvam. See https://dashboard.sarvam.ai/key-management
    api_key:
    # BCP-47 language code for supported Indian languages. See https://docs.sarvam.ai/api-reference-docs/speech-to-text/transcribe#request.body.language_code.language_code
    language:
    # The Sarvam STT model to use. See https://docs.sarvam.ai/api-reference-docs/speech-to-text/transcribe#request.body.model.model
    model:
```

# Angular Components

## Introduction

Angular Components are the simplest way to create real-time videoconferencing apps with Angular. There's no need to manage state or low-level events; Angular Components from OpenVidu handle all the complexity for you.

This **Angular library**, offers developers a robust set of **powerful and comprehensive videoconferencing components**. These components are highly adaptable, extendable, and easily replaceable, allowing you to tailor them to your application's specific requirements.

Angular Components

The primary goal of the OpenVidu team is to minimize the developer's effort when creating videoconferencing applications. **Angular Components** significantly contribute to this objective for several reasons:

- **Rapid Development**

  ______________________________________________________________________

  Abstracts the complexity of videoconferencing applications, allowing you to focus on customizations

- **Flexible Customization**

  ______________________________________________________________________

  Offers maximum customization flexibility, allowing you to adapt, extend, and replace any component

- **Easy Maintenance**

  ______________________________________________________________________

  Ensures your code remains up to date, making it easier to update your application with each new OpenVidu release

## How to use

Using Angular Components in your application is straightforward. The official [Angular Components Tutorials](../../tutorials/angular-components/) cover everything Angular Components offers, from customizing colors and branding logos to injecting new custom features.

## Featured Components

- **Videoconference**

  ______________________________________________________________________

  The Videoconference component is the core of Angular Components. You can nest HTML and Angular components inside it or leave it empty to use the default setup.

  ______________________________________________________________________

  [See Reference](../../reference-docs/openvidu-components-angular/components/VideoconferenceComponent.html)

- **Panel**

  ______________________________________________________________________

  The Panel components is the root of side panels in the videoconference. You can nest HTML and Angular components inside it or leave it empty to use the default setup.

  ______________________________________________________________________

  [See Reference](../../reference-docs/openvidu-components-angular/components/PanelComponent.html)

## Prefabricated Components

**Angular Components** provides a wide range of prefabricated components that you can use to build your videoconferencing application in a matter of minutes. These components are designed for direct use without any extensions or modifications.

[Toolbar](../../reference-docs/openvidu-components-angular/components/ToolbarComponent.html) [Layout](../../reference-docs/openvidu-components-angular/components/LayoutComponent.html) [Stream](../../reference-docs/openvidu-components-angular/components/StreamComponent.html) [ChatPanel](../../reference-docs/openvidu-components-angular/components/ChatPanelComponent.html) [ParticipantsPanel](../../reference-docs/openvidu-components-angular/components/ParticipantsPanelComponent.html) [ParticipantPanelItem](../../reference-docs/openvidu-components-angular/components/ParticipantPanelItemComponent.html) [ActivitiesPanel](../../reference-docs/openvidu-components-angular/components/ActivitiesPanelComponent.html) [RecordingActivity](../../reference-docs/openvidu-components-angular/components/RecordingActivityComponent.html) [BroadcastingActivity](../../reference-docs/openvidu-components-angular/components/BroadcastingActivityComponent.html) [AdminLogin](../../reference-docs/openvidu-components-angular/components/AdminLoginComponent.html) [AdminDashboard](../../reference-docs/openvidu-components-angular/components/AdminDashboardComponent.html)

## Directives

Angular Components provides two types of directives: **Structural Directives** and **Attribute Directives**.

- **Structural Directives**: These directives manipulate the DOM by adding or removing elements from the view.

  They are distinguished by the asterisk (**\***) prefix and must be placed inside an HTML element within any [*Featured Component*](#featured-components).

  For example, the `*ovToolbar` directive allows you to add a custom toolbar to the videoconference, replacing the default one.

  You can check the list of available structural directives in the [Angular Components API Reference](../../reference-docs/openvidu-components-angular/modules/OpenViduComponentsDirectiveModule.html).

- **Attribute Directives**: Commonly known as **Components Inputs**, allow you to manipulate the appearance or behavior of an element.

  You can check the list of available structural directives in the [Angular Components API Reference](../../reference-docs/openvidu-components-angular/modules/OpenViduComponentsDirectiveModule.html).

## Events

Each component in **Angular Components** emits a set of events that you can listen to in your application to trigger specific actions.

These events are designed to provide you with the flexibility to customize your videoconferencing application according to your requirements.

You can check out all component events in the [Angular Components API Reference](../../reference-docs/openvidu-components-angular/).

## Applications

A practical example showcases the potential of Angular Components is our production-ready flagship application, [**OpenVidu Meet**](../../../meet/). This application is built using Angular Components and demonstrates the power and flexibility of the library.

## References

- [Angular Components API Reference](../../reference-docs/openvidu-components-angular/)

# React Components

## Introduction

React Components are the simplest way to create real-time audio/video applications with React. There's no need to manage state or low level events, React Components from LiveKit handle all the complexity for you.

## Featured Components

A curated set of components that we believe are essential and serve as a solid foundation for most applications.

- **LiveKitRoom**

  ______________________________________________________________________

  It provides the Room context to all its children, serving as the root component of your application, and also exposes the Room state through a React context.

  ______________________________________________________________________

  [See Reference](https://docs.livekit.io/reference/components/react/component/livekitroom/)

- **RoomAudioRenderer**

  ______________________________________________________________________

  It manages remote participants' audio tracks and ensures that microphones and screen sharing are audible. It also provides a way to control the volume of each participant.

  ______________________________________________________________________

  [See Reference](https://docs.livekit.io/reference/components/react/component/roomaudiorenderer/)

- **TrackLoop**

  ______________________________________________________________________

  Provides an easy way to loop through all participant camera and screen tracks. For each track, TrackLoop creates a TrackRefContext that you can use to render the track.

  ______________________________________________________________________

  [See Reference](https://docs.livekit.io/reference/components/react/component/trackloop/)

## Prefabricated Components

Prefabricated are constructed using components and enhanced with additional functionalities, unique styles, and practical defaults. They are designed for immediate use and are not meant to be extended.

[AudioConference](https://docs.livekit.io/reference/components/react/component/audioconference/) [Chat](https://docs.livekit.io/reference/components/react/component/chat/) [ControlBar](https://docs.livekit.io/reference/components/react/component/controlbar/) [MediaDeviceMenu](https://docs.livekit.io/reference/components/react/component/mediadevicemenu/) [PreJoin](https://docs.livekit.io/reference/components/react/component/prejoin/) [VideoConference](https://docs.livekit.io/reference/components/react/component/videoconference/)

## Contexts

Contexts are used to allow child components to access parent state without having to pass it down the component tree via props

[Participant](https://docs.livekit.io/reference/components/react/component/participantcontext/) [Room](https://docs.livekit.io/reference/components/react/component/roomcontext/) [Chat](https://github.com/livekit/components-js/blob/main/packages/react/src/context/chat-context.ts) [Feature](https://github.com/livekit/components-js/blob/main/packages/react/src/context/feature-context.ts) [Layout](https://docs.livekit.io/reference/components/react/component/layoutcontext/) [Pin](https://github.com/livekit/components-js/blob/main/packages/react/src/context/pin-context.ts) [TrackRef](https://docs.livekit.io/reference/components/react/component/trackrefcontext/)

## Hooks

Hooks are functions that let you use state and other React features without writing a class. They are functions that let you “hook into” React state and lifecycle features from function components.

React Components provides a set of hooks that you can use to interact with the components and the underlying LiveKit client.

[See Reference](https://github.com/livekit/components-js/tree/main/packages/react/src/hooks)

## Applications

A practical example showcases the potential of React Components is the production-ready flagship application, [**LiveKit Meet**](https://meet.livekit.io/) . This application is built using React Components and demonstrates the power and flexibility of the library.

## References

- [React Components](https://docs.livekit.io/reference/components/react/)
